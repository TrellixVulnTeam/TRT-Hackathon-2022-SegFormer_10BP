&&&& RUNNING TensorRT.trtexec [TensorRT v8401] # /usr/local/TensorRT-8.4.1.4/bin/trtexec --onnx=/root/onnx/segformer.b2.1024x1024.city.160k_v1.onnx --minShapes=input:1x3x1024x1024 --optShapes=input:4x3x1024x1024 --maxShapes=input:8x3x1024x1024 --workspace=23000 --saveEngine=segFormer.plan --verbose
[06/10/2022-19:21:28] [I] === Model Options ===
[06/10/2022-19:21:28] [I] Format: ONNX
[06/10/2022-19:21:28] [I] Model: /root/onnx/segformer.b2.1024x1024.city.160k_v1.onnx
[06/10/2022-19:21:28] [I] Output:
[06/10/2022-19:21:28] [I] === Build Options ===
[06/10/2022-19:21:28] [I] Max batch: explicit batch
[06/10/2022-19:21:28] [I] Memory Pools: workspace: 23000 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[06/10/2022-19:21:28] [I] minTiming: 1
[06/10/2022-19:21:28] [I] avgTiming: 8
[06/10/2022-19:21:28] [I] Precision: FP32
[06/10/2022-19:21:28] [I] LayerPrecisions: 
[06/10/2022-19:21:28] [I] Calibration: 
[06/10/2022-19:21:28] [I] Refit: Disabled
[06/10/2022-19:21:28] [I] Sparsity: Disabled
[06/10/2022-19:21:28] [I] Safe mode: Disabled
[06/10/2022-19:21:28] [I] DirectIO mode: Disabled
[06/10/2022-19:21:28] [I] Restricted mode: Disabled
[06/10/2022-19:21:28] [I] Build only: Disabled
[06/10/2022-19:21:28] [I] Save engine: segFormer.plan
[06/10/2022-19:21:28] [I] Load engine: 
[06/10/2022-19:21:28] [I] Profiling verbosity: 0
[06/10/2022-19:21:28] [I] Tactic sources: Using default tactic sources
[06/10/2022-19:21:28] [I] timingCacheMode: local
[06/10/2022-19:21:28] [I] timingCacheFile: 
[06/10/2022-19:21:28] [I] Input(s)s format: fp32:CHW
[06/10/2022-19:21:28] [I] Output(s)s format: fp32:CHW
[06/10/2022-19:21:28] [I] Input build shape: input=1x3x1024x1024+4x3x1024x1024+8x3x1024x1024
[06/10/2022-19:21:28] [I] Input calibration shapes: model
[06/10/2022-19:21:28] [I] === System Options ===
[06/10/2022-19:21:28] [I] Device: 0
[06/10/2022-19:21:28] [I] DLACore: 
[06/10/2022-19:21:28] [I] Plugins:
[06/10/2022-19:21:28] [I] === Inference Options ===
[06/10/2022-19:21:28] [I] Batch: Explicit
[06/10/2022-19:21:28] [I] Input inference shape: input=4x3x1024x1024
[06/10/2022-19:21:28] [I] Iterations: 10
[06/10/2022-19:21:28] [I] Duration: 3s (+ 200ms warm up)
[06/10/2022-19:21:28] [I] Sleep time: 0ms
[06/10/2022-19:21:28] [I] Idle time: 0ms
[06/10/2022-19:21:28] [I] Streams: 1
[06/10/2022-19:21:28] [I] ExposeDMA: Disabled
[06/10/2022-19:21:28] [I] Data transfers: Enabled
[06/10/2022-19:21:28] [I] Spin-wait: Disabled
[06/10/2022-19:21:28] [I] Multithreading: Disabled
[06/10/2022-19:21:28] [I] CUDA Graph: Disabled
[06/10/2022-19:21:28] [I] Separate profiling: Disabled
[06/10/2022-19:21:28] [I] Time Deserialize: Disabled
[06/10/2022-19:21:28] [I] Time Refit: Disabled
[06/10/2022-19:21:28] [I] Inputs:
[06/10/2022-19:21:28] [I] === Reporting Options ===
[06/10/2022-19:21:28] [I] Verbose: Enabled
[06/10/2022-19:21:28] [I] Averages: 10 inferences
[06/10/2022-19:21:28] [I] Percentile: 99
[06/10/2022-19:21:28] [I] Dump refittable layers:Disabled
[06/10/2022-19:21:28] [I] Dump output: Disabled
[06/10/2022-19:21:28] [I] Profile: Disabled
[06/10/2022-19:21:28] [I] Export timing to JSON file: 
[06/10/2022-19:21:28] [I] Export output to JSON file: 
[06/10/2022-19:21:28] [I] Export profile to JSON file: 
[06/10/2022-19:21:28] [I] 
[06/10/2022-19:21:28] [I] === Device Information ===
[06/10/2022-19:21:28] [I] Selected Device: NVIDIA A10
[06/10/2022-19:21:28] [I] Compute Capability: 8.6
[06/10/2022-19:21:28] [I] SMs: 72
[06/10/2022-19:21:28] [I] Compute Clock Rate: 1.695 GHz
[06/10/2022-19:21:28] [I] Device Global Memory: 22731 MiB
[06/10/2022-19:21:28] [I] Shared Memory per SM: 100 KiB
[06/10/2022-19:21:28] [I] Memory Bus Width: 384 bits (ECC enabled)
[06/10/2022-19:21:28] [I] Memory Clock Rate: 6.251 GHz
[06/10/2022-19:21:28] [I] 
[06/10/2022-19:21:28] [I] TensorRT version: 8.4.1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::Proposal version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::Split version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 2
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[06/10/2022-19:21:28] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[06/10/2022-19:21:28] [I] [TRT] [MemUsageChange] Init CUDA: CPU +328, GPU +0, now: CPU 336, GPU 403 (MiB)
[06/10/2022-19:21:29] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +327, GPU +104, now: CPU 682, GPU 507 (MiB)
[06/10/2022-19:21:29] [I] Start parsing network model
[06/10/2022-19:21:29] [I] [TRT] ----------------------------------------------------------------
[06/10/2022-19:21:29] [I] [TRT] Input filename:   /root/onnx/segformer.b2.1024x1024.city.160k_v1.onnx
[06/10/2022-19:21:29] [I] [TRT] ONNX IR version:  0.0.8
[06/10/2022-19:21:29] [I] [TRT] Opset version:    11
[06/10/2022-19:21:29] [I] [TRT] Producer name:    pytorch
[06/10/2022-19:21:29] [I] [TRT] Producer version: 1.8
[06/10/2022-19:21:29] [I] [TRT] Domain:           
[06/10/2022-19:21:29] [I] [TRT] Model version:    0
[06/10/2022-19:21:29] [I] [TRT] Doc string:       
[06/10/2022-19:21:29] [I] [TRT] ----------------------------------------------------------------
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::Split version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 2
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1
[06/10/2022-19:21:30] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1
[06/10/2022-19:21:30] [V] [TRT] Adding network input: input with dtype: float32, dimensions: (-1, 3, 1024, 1024)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: input for ONNX tensor: input
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 352
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3058
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 363
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 364
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 368
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 369
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 367
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 370
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 373
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 374
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 372
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 375
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 378
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed1.proj.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed1.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 389
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 390
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 388
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 392
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 398
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 401
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed1.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed1.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 409
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 412
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 419
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 422
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 425
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3059
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 430
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3060
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 445
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 446
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3061
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 459
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 462
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3062
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 471
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3063
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3064
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3065
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 486
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 488
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 492
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3066
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 508
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 511
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3067
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 521
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 524
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 529
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 530
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 536
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 537
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 535
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 539
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 543
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 546
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 549
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3068
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.0.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 557
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 560
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 567
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 570
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 573
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3069
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 578
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3070
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 593
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 594
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3071
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 607
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 610
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3072
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 619
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3073
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3074
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3075
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 634
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 636
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 640
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3076
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 656
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 659
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3077
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 669
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 672
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 677
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 678
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 684
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 685
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 683
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 687
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 691
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 694
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 697
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3078
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.1.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 705
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 708
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 715
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 718
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 721
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3079
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 726
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3080
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 741
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 742
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3081
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 755
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 758
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3082
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 767
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3083
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3084
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3085
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 782
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 784
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 788
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3086
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 804
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 807
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3087
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 817
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 820
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 825
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 826
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 832
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 833
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 831
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 835
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 839
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 842
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 845
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3088
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block1.2.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 853
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 856
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 864
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 865
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3089
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed2.proj.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed2.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 872
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 875
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 879
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 880
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 878
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 882
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 888
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 891
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed2.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed2.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 899
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 902
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 909
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 912
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 915
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3090
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 920
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3091
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3092
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 949
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 952
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3093
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 961
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3094
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3095
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3096
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 976
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 978
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 982
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3097
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 998
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1001
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3098
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1011
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1014
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1026
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1027
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1025
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1029
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1033
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1036
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1039
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3099
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.0.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1047
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1050
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1057
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1060
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1063
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3100
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1068
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3101
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3102
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1097
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1100
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3103
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1109
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3104
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3105
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3106
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1124
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1126
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1130
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3107
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1146
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1149
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3108
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1159
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1162
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1174
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1175
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1173
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1177
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1181
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1184
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1187
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3109
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.1.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1195
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1198
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1205
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1208
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1211
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3110
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1216
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3111
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3112
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1245
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1248
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3113
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1257
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3114
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3115
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3116
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1272
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1274
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1278
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3117
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1294
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1297
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3118
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1307
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1310
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1322
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1323
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1321
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1325
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1329
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1332
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1335
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3119
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.2.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1343
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1346
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1353
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1356
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1359
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3120
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1364
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3121
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3122
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1393
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1396
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3123
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1405
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3124
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3125
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3126
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1420
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1422
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1426
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3127
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1442
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1445
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3128
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1455
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1458
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1470
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1471
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1469
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1473
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1477
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1480
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1483
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3129
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block2.3.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1491
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1494
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3130
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed3.proj.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed3.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1510
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1513
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1517
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1518
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1516
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1520
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1526
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1529
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed3.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed3.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1537
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1540
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1547
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1550
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1553
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3131
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1558
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3132
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3133
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1587
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1590
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3134
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1599
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3135
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3136
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3137
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1614
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1616
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1620
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3138
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1636
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1639
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3139
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1649
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1652
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1664
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1665
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1663
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1667
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1671
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1674
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1677
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3140
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.0.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1685
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1688
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1695
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1698
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1701
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3141
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1706
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3142
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3143
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1735
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1738
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3144
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1747
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3145
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3146
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3147
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1762
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1764
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1768
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3148
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1784
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1787
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3149
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1797
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1800
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1812
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1813
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1811
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1815
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1819
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1822
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1825
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3150
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.1.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1833
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1836
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1843
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1846
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1849
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3151
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1854
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3152
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3153
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1883
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1886
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3154
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1895
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3155
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3156
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3157
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1910
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1912
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1916
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3158
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1932
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1935
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3159
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1945
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1948
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1960
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1961
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1959
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1963
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1967
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1970
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1973
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3160
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.2.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1981
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1984
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1991
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1994
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 1997
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3161
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2002
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3162
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3163
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2031
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2034
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3164
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2043
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3165
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3166
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3167
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2058
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2060
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2064
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3168
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2080
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2083
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3169
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2093
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2096
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2108
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2109
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2107
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2111
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2115
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2118
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2121
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3170
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.3.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2129
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2132
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2139
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2142
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2145
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3171
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2150
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3172
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3173
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2179
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2182
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3174
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2191
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3175
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3176
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3177
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2206
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2208
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2212
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3178
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2228
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2231
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3179
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2241
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2244
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2256
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2257
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2255
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2259
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2263
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2266
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2269
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3180
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.4.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2277
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2280
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2287
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2290
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2293
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3181
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2298
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3182
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3183
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2327
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2330
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3184
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2339
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3185
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3186
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3187
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2354
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2356
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2360
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3188
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2376
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2379
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3189
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2389
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2392
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2404
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2405
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2403
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2407
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2411
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2414
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2417
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3190
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block3.5.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2425
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2428
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.norm3.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.norm3.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3191
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed4.proj.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed4.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2444
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2447
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2451
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2452
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2450
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2454
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2460
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2463
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed4.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.patch_embed4.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2471
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2474
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.0.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.0.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2481
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2484
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2487
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3192
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.0.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2492
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3193
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3194
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.0.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2507
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3195
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3196
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3197
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2522
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2524
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2528
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3198
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.0.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2544
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2547
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.0.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.0.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3199
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.0.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2557
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2560
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.0.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.0.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2572
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2573
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2571
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2575
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2579
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2582
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2585
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3200
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.0.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2593
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2596
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.1.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.1.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2603
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2606
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2609
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3201
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.1.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2614
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3202
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3203
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.1.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2629
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3204
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3205
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3206
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2644
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2646
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2650
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3207
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.1.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2666
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2669
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.1.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.1.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3208
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.1.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2679
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2682
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.1.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.1.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2694
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2695
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2693
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2697
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2701
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2704
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2707
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3209
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.1.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2715
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2718
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.2.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.2.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2725
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2728
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2731
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3210
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.2.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2736
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3211
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3212
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.2.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2751
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3213
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3214
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3215
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2766
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2768
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2772
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3216
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.2.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2788
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2791
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.2.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.2.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3217
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.2.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2801
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2804
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.2.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.2.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2816
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2817
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2815
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2819
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2823
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2826
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2829
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3218
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.block4.2.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2837
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2840
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.norm4.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: backbone.norm4.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3219
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2855
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2859
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2860
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2858
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2862
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3220
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: decode_head.linear_c4.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2871
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2874
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3221
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2887
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2888
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2886
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3222
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2884
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2892
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2896
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2897
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2895
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2899
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3223
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: decode_head.linear_c3.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2908
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2911
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3224
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2924
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2925
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2923
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3225
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2921
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2929
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2933
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2934
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2932
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2936
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3226
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: decode_head.linear_c2.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2945
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2948
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3227
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2961
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2962
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2960
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3228
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2958
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2966
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2970
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2971
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2969
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2973
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3229
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: decode_head.linear_c1.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2982
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 2985
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3230
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3056
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3057
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: decode_head.linear_pred.weight
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: decode_head.linear_pred.bias
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3003
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3004
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3002
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3231
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3000
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3008
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3031
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3032
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3035
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3041
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3042
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3040
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3237
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3038
[06/10/2022-19:21:30] [V] [TRT] Importing initializer: 3046
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_0 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: input
[06/10/2022-19:21:30] [V] [TRT] Shape_0 [Shape] inputs: [input -> (-1, 3, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_0 for ONNX node: Shape_0
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 351 for ONNX tensor: 351
[06/10/2022-19:21:30] [V] [TRT] Shape_0 [Shape] outputs: [351 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_2 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 351
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 352
[06/10/2022-19:21:30] [V] [TRT] Gather_2 [Gather] inputs: [351 -> (4)[INT32]], [352 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 352 for ONNX node: 352
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_2 for ONNX node: Gather_2
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 353 for ONNX tensor: 353
[06/10/2022-19:21:30] [V] [TRT] Gather_2 [Gather] outputs: [353 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_9 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 353
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_9 [Unsqueeze] inputs: [353 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_9 for ONNX node: Unsqueeze_9
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 361 for ONNX tensor: 361
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_9 [Unsqueeze] outputs: [361 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_12 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 361
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3058
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 363
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 364
[06/10/2022-19:21:30] [V] [TRT] Concat_12 [Concat] inputs: [361 -> (1)[INT32]], [3058 -> (1)[INT32]], [363 -> (1)[INT32]], [364 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3058 for ONNX node: 3058
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 363 for ONNX node: 363
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 364 for ONNX node: 364
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_12 for ONNX node: Concat_12
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 365 for ONNX tensor: 365
[06/10/2022-19:21:30] [V] [TRT] Concat_12 [Concat] outputs: [365 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ConstantOfShape_13 [ConstantOfShape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 365
[06/10/2022-19:21:30] [V] [TRT] ConstantOfShape_13 [ConstantOfShape] inputs: [365 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ConstantOfShape_13 for ONNX node: ConstantOfShape_13
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 366 for ONNX tensor: 366
[06/10/2022-19:21:30] [V] [TRT] ConstantOfShape_13 [ConstantOfShape] outputs: [366 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_18 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: input
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 368
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 369
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 367
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 370
[06/10/2022-19:21:30] [V] [TRT] Slice_18 [Slice] inputs: [input -> (-1, 3, 1024, 1024)[FLOAT]], [368 -> (1)[INT32]], [369 -> (1)[INT32]], [367 -> (1)[INT32]], [370 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_18 for ONNX node: Slice_18
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 371 for ONNX tensor: 371
[06/10/2022-19:21:30] [V] [TRT] Slice_18 [Slice] outputs: [371 -> (-1, 3, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_23 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 371
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 373
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 374
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 372
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 375
[06/10/2022-19:21:30] [V] [TRT] Slice_23 [Slice] inputs: [371 -> (-1, 3, 1024, 1024)[FLOAT]], [373 -> (1)[INT32]], [374 -> (1)[INT32]], [372 -> (1)[INT32]], [375 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_23 for ONNX node: Slice_23
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 376 for ONNX tensor: 376
[06/10/2022-19:21:30] [V] [TRT] Slice_23 [Slice] outputs: [376 -> (-1, 3, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_24 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 376
[06/10/2022-19:21:30] [V] [TRT] Shape_24 [Shape] inputs: [376 -> (-1, 3, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_24 for ONNX node: Shape_24
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 377 for ONNX tensor: 377
[06/10/2022-19:21:30] [V] [TRT] Shape_24 [Shape] outputs: [377 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_26 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 377
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 378
[06/10/2022-19:21:30] [V] [TRT] Gather_26 [Gather] inputs: [377 -> (4)[INT32]], [378 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 378 for ONNX node: 378
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_26 for ONNX node: Gather_26
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 379 for ONNX tensor: 379
[06/10/2022-19:21:30] [V] [TRT] Gather_26 [Gather] outputs: [379 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_27 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 376
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed1.proj.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed1.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_27 [Conv] inputs: [376 -> (-1, 3, 1024, 1024)[FLOAT]], [backbone.patch_embed1.proj.weight -> (64, 3, 7, 7)[FLOAT]], [backbone.patch_embed1.proj.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 3, 1024, 1024)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_27 for ONNX node: Conv_27
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (7, 7), strides: (4, 4), prepadding: (3, 3), postpadding: (3, 3), dilations: (1, 1), numOutputs: 64
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 64, 256, 256)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 380 for ONNX tensor: 380
[06/10/2022-19:21:30] [V] [TRT] Conv_27 [Conv] outputs: [380 -> (-1, 64, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_34 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 380
[06/10/2022-19:21:30] [V] [TRT] Shape_34 [Shape] inputs: [380 -> (-1, 64, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_34 for ONNX node: Shape_34
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 387 for ONNX tensor: 387
[06/10/2022-19:21:30] [V] [TRT] Shape_34 [Shape] outputs: [387 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_38 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 387
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 389
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 390
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 388
[06/10/2022-19:21:30] [V] [TRT] Slice_38 [Slice] inputs: [387 -> (4)[INT32]], [389 -> (1)[INT32]], [390 -> (1)[INT32]], [388 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_38 for ONNX node: Slice_38
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 391 for ONNX tensor: 391
[06/10/2022-19:21:30] [V] [TRT] Slice_38 [Slice] outputs: [391 -> (2)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_40 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 391
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 392
[06/10/2022-19:21:30] [V] [TRT] Concat_40 [Concat] inputs: [391 -> (2)[INT32]], [392 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 392 for ONNX node: 392
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_40 for ONNX node: Concat_40
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 393 for ONNX tensor: 393
[06/10/2022-19:21:30] [V] [TRT] Concat_40 [Concat] outputs: [393 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_41 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 380
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 393
[06/10/2022-19:21:30] [V] [TRT] Reshape_41 [Reshape] inputs: [380 -> (-1, 64, 256, 256)[FLOAT]], [393 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_41 for ONNX node: Reshape_41
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 394 for ONNX tensor: 394
[06/10/2022-19:21:30] [V] [TRT] Reshape_41 [Reshape] outputs: [394 -> (-1, 64, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_42 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 394
[06/10/2022-19:21:30] [V] [TRT] Transpose_42 [Transpose] inputs: [394 -> (-1, 64, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_42 for ONNX node: Transpose_42
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 395 for ONNX tensor: 395
[06/10/2022-19:21:30] [V] [TRT] Transpose_42 [Transpose] outputs: [395 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_43 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 395
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_43 [ReduceMean] inputs: [395 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_43 for ONNX node: ReduceMean_43
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 396 for ONNX tensor: 396
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_43 [ReduceMean] outputs: [396 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_44 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 395
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 396
[06/10/2022-19:21:30] [V] [TRT] Sub_44 [Sub] inputs: [395 -> (-1, 65536, 64)[FLOAT]], [396 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_44 for ONNX node: Sub_44
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 397 for ONNX tensor: 397
[06/10/2022-19:21:30] [V] [TRT] Sub_44 [Sub] outputs: [397 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_46 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 397
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 398
[06/10/2022-19:21:30] [V] [TRT] Pow_46 [Pow] inputs: [397 -> (-1, 65536, 64)[FLOAT]], [398 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 398 for ONNX node: 398
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_46 for ONNX node: Pow_46
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 399 for ONNX tensor: 399
[06/10/2022-19:21:30] [V] [TRT] Pow_46 [Pow] outputs: [399 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_47 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 399
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_47 [ReduceMean] inputs: [399 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_47 for ONNX node: ReduceMean_47
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 400 for ONNX tensor: 400
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_47 [ReduceMean] outputs: [400 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_49 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 400
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 401
[06/10/2022-19:21:30] [V] [TRT] Add_49 [Add] inputs: [400 -> (-1, 65536, 1)[FLOAT]], [401 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 401 for ONNX node: 401
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_49 for ONNX node: Add_49
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 402 for ONNX tensor: 402
[06/10/2022-19:21:30] [V] [TRT] Add_49 [Add] outputs: [402 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_50 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 402
[06/10/2022-19:21:30] [V] [TRT] Sqrt_50 [Sqrt] inputs: [402 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_50 for ONNX node: Sqrt_50
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 403 for ONNX tensor: 403
[06/10/2022-19:21:30] [V] [TRT] Sqrt_50 [Sqrt] outputs: [403 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_51 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 397
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 403
[06/10/2022-19:21:30] [V] [TRT] Div_51 [Div] inputs: [397 -> (-1, 65536, 64)[FLOAT]], [403 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_51 for ONNX node: Div_51
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 404 for ONNX tensor: 404
[06/10/2022-19:21:30] [V] [TRT] Div_51 [Div] outputs: [404 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_52 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 404
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed1.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_52 [Mul] inputs: [404 -> (-1, 65536, 64)[FLOAT]], [backbone.patch_embed1.norm.weight -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.patch_embed1.norm.weight for ONNX node: backbone.patch_embed1.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_52 for ONNX node: Mul_52
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 405 for ONNX tensor: 405
[06/10/2022-19:21:30] [V] [TRT] Mul_52 [Mul] outputs: [405 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_53 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 405
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed1.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Add_53 [Add] inputs: [405 -> (-1, 65536, 64)[FLOAT]], [backbone.patch_embed1.norm.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.patch_embed1.norm.bias for ONNX node: backbone.patch_embed1.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_53 for ONNX node: Add_53
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 406 for ONNX tensor: 406
[06/10/2022-19:21:30] [V] [TRT] Add_53 [Add] outputs: [406 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_54 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 406
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_54 [ReduceMean] inputs: [406 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_54 for ONNX node: ReduceMean_54
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 407 for ONNX tensor: 407
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_54 [ReduceMean] outputs: [407 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_55 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 406
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 407
[06/10/2022-19:21:30] [V] [TRT] Sub_55 [Sub] inputs: [406 -> (-1, 65536, 64)[FLOAT]], [407 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_55 for ONNX node: Sub_55
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 408 for ONNX tensor: 408
[06/10/2022-19:21:30] [V] [TRT] Sub_55 [Sub] outputs: [408 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_57 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 408
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 409
[06/10/2022-19:21:30] [V] [TRT] Pow_57 [Pow] inputs: [408 -> (-1, 65536, 64)[FLOAT]], [409 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 409 for ONNX node: 409
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_57 for ONNX node: Pow_57
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 410 for ONNX tensor: 410
[06/10/2022-19:21:30] [V] [TRT] Pow_57 [Pow] outputs: [410 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_58 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 410
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_58 [ReduceMean] inputs: [410 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_58 for ONNX node: ReduceMean_58
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 411 for ONNX tensor: 411
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_58 [ReduceMean] outputs: [411 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_60 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 411
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 412
[06/10/2022-19:21:30] [V] [TRT] Add_60 [Add] inputs: [411 -> (-1, 65536, 1)[FLOAT]], [412 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 412 for ONNX node: 412
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_60 for ONNX node: Add_60
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 413 for ONNX tensor: 413
[06/10/2022-19:21:30] [V] [TRT] Add_60 [Add] outputs: [413 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_61 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 413
[06/10/2022-19:21:30] [V] [TRT] Sqrt_61 [Sqrt] inputs: [413 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_61 for ONNX node: Sqrt_61
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 414 for ONNX tensor: 414
[06/10/2022-19:21:30] [V] [TRT] Sqrt_61 [Sqrt] outputs: [414 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_62 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 408
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 414
[06/10/2022-19:21:30] [V] [TRT] Div_62 [Div] inputs: [408 -> (-1, 65536, 64)[FLOAT]], [414 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_62 for ONNX node: Div_62
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 415 for ONNX tensor: 415
[06/10/2022-19:21:30] [V] [TRT] Div_62 [Div] outputs: [415 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_63 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 415
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_63 [Mul] inputs: [415 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.0.norm1.weight -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.0.norm1.weight for ONNX node: backbone.block1.0.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_63 for ONNX node: Mul_63
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 416 for ONNX tensor: 416
[06/10/2022-19:21:30] [V] [TRT] Mul_63 [Mul] outputs: [416 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_64 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 416
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_64 [Add] inputs: [416 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.0.norm1.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.0.norm1.bias for ONNX node: backbone.block1.0.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_64 for ONNX node: Add_64
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 417 for ONNX tensor: 417
[06/10/2022-19:21:30] [V] [TRT] Add_64 [Add] outputs: [417 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_65 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 417
[06/10/2022-19:21:30] [V] [TRT] Shape_65 [Shape] inputs: [417 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_65 for ONNX node: Shape_65
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 418 for ONNX tensor: 418
[06/10/2022-19:21:30] [V] [TRT] Shape_65 [Shape] outputs: [418 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_67 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 418
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 419
[06/10/2022-19:21:30] [V] [TRT] Gather_67 [Gather] inputs: [418 -> (3)[INT32]], [419 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 419 for ONNX node: 419
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_67 for ONNX node: Gather_67
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 420 for ONNX tensor: 420
[06/10/2022-19:21:30] [V] [TRT] Gather_67 [Gather] outputs: [420 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_68 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 417
[06/10/2022-19:21:30] [V] [TRT] Shape_68 [Shape] inputs: [417 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_68 for ONNX node: Shape_68
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 421 for ONNX tensor: 421
[06/10/2022-19:21:30] [V] [TRT] Shape_68 [Shape] outputs: [421 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_70 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 421
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 422
[06/10/2022-19:21:30] [V] [TRT] Gather_70 [Gather] inputs: [421 -> (3)[INT32]], [422 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 422 for ONNX node: 422
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_70 for ONNX node: Gather_70
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 423 for ONNX tensor: 423
[06/10/2022-19:21:30] [V] [TRT] Gather_70 [Gather] outputs: [423 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_71 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 417
[06/10/2022-19:21:30] [V] [TRT] Shape_71 [Shape] inputs: [417 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_71 for ONNX node: Shape_71
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 424 for ONNX tensor: 424
[06/10/2022-19:21:30] [V] [TRT] Shape_71 [Shape] outputs: [424 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_73 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 424
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 425
[06/10/2022-19:21:30] [V] [TRT] Gather_73 [Gather] inputs: [424 -> (3)[INT32]], [425 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 425 for ONNX node: 425
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_73 for ONNX node: Gather_73
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 426 for ONNX tensor: 426
[06/10/2022-19:21:30] [V] [TRT] Gather_73 [Gather] outputs: [426 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_74 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 417
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3059
[06/10/2022-19:21:30] [V] [TRT] MatMul_74 [MatMul] inputs: [417 -> (-1, 65536, 64)[FLOAT]], [3059 -> (64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3059 for ONNX node: 3059
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_74 for ONNX node: MatMul_74
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 428 for ONNX tensor: 428
[06/10/2022-19:21:30] [V] [TRT] MatMul_74 [MatMul] outputs: [428 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_75 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 428
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Add_75 [Add] inputs: [428 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.0.attn.q.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.0.attn.q.bias for ONNX node: backbone.block1.0.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_75 for ONNX node: Add_75
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 429 for ONNX tensor: 429
[06/10/2022-19:21:30] [V] [TRT] Add_75 [Add] outputs: [429 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_77 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 426
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 430
[06/10/2022-19:21:30] [V] [TRT] Div_77 [Div] inputs: [426 -> ()[INT32]], [430 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 430 for ONNX node: 430
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_77 for ONNX node: Div_77
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 431 for ONNX tensor: 431
[06/10/2022-19:21:30] [V] [TRT] Div_77 [Div] outputs: [431 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_78 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 431
[06/10/2022-19:21:30] [V] [TRT] Cast_78 [Cast] inputs: [431 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_78 for ONNX node: Cast_78
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 432 for ONNX tensor: 432
[06/10/2022-19:21:30] [V] [TRT] Cast_78 [Cast] outputs: [432 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_79 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 432
[06/10/2022-19:21:30] [V] [TRT] Cast_79 [Cast] inputs: [432 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_79 for ONNX node: Cast_79
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 433 for ONNX tensor: 433
[06/10/2022-19:21:30] [V] [TRT] Cast_79 [Cast] outputs: [433 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_80 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 420
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_80 [Unsqueeze] inputs: [420 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_80 for ONNX node: Unsqueeze_80
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 435 for ONNX tensor: 435
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_80 [Unsqueeze] outputs: [435 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_81 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 423
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_81 [Unsqueeze] inputs: [423 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_81 for ONNX node: Unsqueeze_81
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 436 for ONNX tensor: 436
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_81 [Unsqueeze] outputs: [436 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_82 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 433
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_82 [Unsqueeze] inputs: [433 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_82 for ONNX node: Unsqueeze_82
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 438 for ONNX tensor: 438
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_82 [Unsqueeze] outputs: [438 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_83 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 435
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 436
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3060
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 438
[06/10/2022-19:21:30] [V] [TRT] Concat_83 [Concat] inputs: [435 -> (1)[INT32]], [436 -> (1)[INT32]], [3060 -> (1)[INT32]], [438 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3060 for ONNX node: 3060
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_83 for ONNX node: Concat_83
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 439 for ONNX tensor: 439
[06/10/2022-19:21:30] [V] [TRT] Concat_83 [Concat] outputs: [439 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_84 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 429
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 439
[06/10/2022-19:21:30] [V] [TRT] Reshape_84 [Reshape] inputs: [429 -> (-1, 65536, 64)[FLOAT]], [439 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_84 for ONNX node: Reshape_84
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 440 for ONNX tensor: 440
[06/10/2022-19:21:30] [V] [TRT] Reshape_84 [Reshape] outputs: [440 -> (-1, 65536, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_85 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 440
[06/10/2022-19:21:30] [V] [TRT] Transpose_85 [Transpose] inputs: [440 -> (-1, 65536, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_85 for ONNX node: Transpose_85
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 441 for ONNX tensor: 441
[06/10/2022-19:21:30] [V] [TRT] Transpose_85 [Transpose] outputs: [441 -> (-1, 1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_86 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 417
[06/10/2022-19:21:30] [V] [TRT] Transpose_86 [Transpose] inputs: [417 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_86 for ONNX node: Transpose_86
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 442 for ONNX tensor: 442
[06/10/2022-19:21:30] [V] [TRT] Transpose_86 [Transpose] outputs: [442 -> (-1, 64, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_87 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 420
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_87 [Unsqueeze] inputs: [420 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_87 for ONNX node: Unsqueeze_87
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 443 for ONNX tensor: 443
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_87 [Unsqueeze] outputs: [443 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_88 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 426
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_88 [Unsqueeze] inputs: [426 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_88 for ONNX node: Unsqueeze_88
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 444 for ONNX tensor: 444
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_88 [Unsqueeze] outputs: [444 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_91 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 443
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 444
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 445
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 446
[06/10/2022-19:21:30] [V] [TRT] Concat_91 [Concat] inputs: [443 -> (1)[INT32]], [444 -> (1)[INT32]], [445 -> (1)[INT32]], [446 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 445 for ONNX node: 445
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 446 for ONNX node: 446
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_91 for ONNX node: Concat_91
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 447 for ONNX tensor: 447
[06/10/2022-19:21:30] [V] [TRT] Concat_91 [Concat] outputs: [447 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_92 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 442
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 447
[06/10/2022-19:21:30] [V] [TRT] Reshape_92 [Reshape] inputs: [442 -> (-1, 64, 65536)[FLOAT]], [447 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_92 for ONNX node: Reshape_92
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 448 for ONNX tensor: 448
[06/10/2022-19:21:30] [V] [TRT] Reshape_92 [Reshape] outputs: [448 -> (-1, 64, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_93 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 448
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_93 [Conv] inputs: [448 -> (-1, 64, 256, 256)[FLOAT]], [backbone.block1.0.attn.sr.weight -> (64, 64, 8, 8)[FLOAT]], [backbone.block1.0.attn.sr.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 64, 256, 256)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_93 for ONNX node: Conv_93
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (8, 8), strides: (8, 8), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 64, 32, 32)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 449 for ONNX tensor: 449
[06/10/2022-19:21:30] [V] [TRT] Conv_93 [Conv] outputs: [449 -> (-1, 64, 32, 32)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_94 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 420
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_94 [Unsqueeze] inputs: [420 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_94 for ONNX node: Unsqueeze_94
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 451 for ONNX tensor: 451
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_94 [Unsqueeze] outputs: [451 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_95 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 426
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_95 [Unsqueeze] inputs: [426 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_95 for ONNX node: Unsqueeze_95
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 452 for ONNX tensor: 452
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_95 [Unsqueeze] outputs: [452 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_96 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 451
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 452
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3061
[06/10/2022-19:21:30] [V] [TRT] Concat_96 [Concat] inputs: [451 -> (1)[INT32]], [452 -> (1)[INT32]], [3061 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3061 for ONNX node: 3061
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_96 for ONNX node: Concat_96
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 454 for ONNX tensor: 454
[06/10/2022-19:21:30] [V] [TRT] Concat_96 [Concat] outputs: [454 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_97 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 449
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 454
[06/10/2022-19:21:30] [V] [TRT] Reshape_97 [Reshape] inputs: [449 -> (-1, 64, 32, 32)[FLOAT]], [454 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_97 for ONNX node: Reshape_97
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 455 for ONNX tensor: 455
[06/10/2022-19:21:30] [V] [TRT] Reshape_97 [Reshape] outputs: [455 -> (-1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_98 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 455
[06/10/2022-19:21:30] [V] [TRT] Transpose_98 [Transpose] inputs: [455 -> (-1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_98 for ONNX node: Transpose_98
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 456 for ONNX tensor: 456
[06/10/2022-19:21:30] [V] [TRT] Transpose_98 [Transpose] outputs: [456 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_99 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 456
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_99 [ReduceMean] inputs: [456 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_99 for ONNX node: ReduceMean_99
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 457 for ONNX tensor: 457
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_99 [ReduceMean] outputs: [457 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_100 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 456
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 457
[06/10/2022-19:21:30] [V] [TRT] Sub_100 [Sub] inputs: [456 -> (-1, 1024, 64)[FLOAT]], [457 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_100 for ONNX node: Sub_100
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 458 for ONNX tensor: 458
[06/10/2022-19:21:30] [V] [TRT] Sub_100 [Sub] outputs: [458 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_102 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 458
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 459
[06/10/2022-19:21:30] [V] [TRT] Pow_102 [Pow] inputs: [458 -> (-1, 1024, 64)[FLOAT]], [459 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 459 for ONNX node: 459
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_102 for ONNX node: Pow_102
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 460 for ONNX tensor: 460
[06/10/2022-19:21:30] [V] [TRT] Pow_102 [Pow] outputs: [460 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_103 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 460
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_103 [ReduceMean] inputs: [460 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_103 for ONNX node: ReduceMean_103
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 461 for ONNX tensor: 461
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_103 [ReduceMean] outputs: [461 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_105 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 461
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 462
[06/10/2022-19:21:30] [V] [TRT] Add_105 [Add] inputs: [461 -> (-1, 1024, 1)[FLOAT]], [462 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 462 for ONNX node: 462
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_105 for ONNX node: Add_105
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 463 for ONNX tensor: 463
[06/10/2022-19:21:30] [V] [TRT] Add_105 [Add] outputs: [463 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_106 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 463
[06/10/2022-19:21:30] [V] [TRT] Sqrt_106 [Sqrt] inputs: [463 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_106 for ONNX node: Sqrt_106
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 464 for ONNX tensor: 464
[06/10/2022-19:21:30] [V] [TRT] Sqrt_106 [Sqrt] outputs: [464 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_107 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 458
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 464
[06/10/2022-19:21:30] [V] [TRT] Div_107 [Div] inputs: [458 -> (-1, 1024, 64)[FLOAT]], [464 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_107 for ONNX node: Div_107
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 465 for ONNX tensor: 465
[06/10/2022-19:21:30] [V] [TRT] Div_107 [Div] outputs: [465 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_108 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 465
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_108 [Mul] inputs: [465 -> (-1, 1024, 64)[FLOAT]], [backbone.block1.0.attn.norm.weight -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.0.attn.norm.weight for ONNX node: backbone.block1.0.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_108 for ONNX node: Mul_108
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 466 for ONNX tensor: 466
[06/10/2022-19:21:30] [V] [TRT] Mul_108 [Mul] outputs: [466 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_109 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 466
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Add_109 [Add] inputs: [466 -> (-1, 1024, 64)[FLOAT]], [backbone.block1.0.attn.norm.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.0.attn.norm.bias for ONNX node: backbone.block1.0.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_109 for ONNX node: Add_109
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 467 for ONNX tensor: 467
[06/10/2022-19:21:30] [V] [TRT] Add_109 [Add] outputs: [467 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_110 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 467
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3062
[06/10/2022-19:21:30] [V] [TRT] MatMul_110 [MatMul] inputs: [467 -> (-1, 1024, 64)[FLOAT]], [3062 -> (64, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3062 for ONNX node: 3062
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_110 for ONNX node: MatMul_110
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 469 for ONNX tensor: 469
[06/10/2022-19:21:30] [V] [TRT] MatMul_110 [MatMul] outputs: [469 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_111 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 469
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Add_111 [Add] inputs: [469 -> (-1, 1024, 128)[FLOAT]], [backbone.block1.0.attn.kv.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.0.attn.kv.bias for ONNX node: backbone.block1.0.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_111 for ONNX node: Add_111
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 470 for ONNX tensor: 470
[06/10/2022-19:21:30] [V] [TRT] Add_111 [Add] outputs: [470 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_113 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 426
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 471
[06/10/2022-19:21:30] [V] [TRT] Div_113 [Div] inputs: [426 -> ()[INT32]], [471 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 471 for ONNX node: 471
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_113 for ONNX node: Div_113
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 472 for ONNX tensor: 472
[06/10/2022-19:21:30] [V] [TRT] Div_113 [Div] outputs: [472 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_114 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 472
[06/10/2022-19:21:30] [V] [TRT] Cast_114 [Cast] inputs: [472 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_114 for ONNX node: Cast_114
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 473 for ONNX tensor: 473
[06/10/2022-19:21:30] [V] [TRT] Cast_114 [Cast] outputs: [473 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_115 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 473
[06/10/2022-19:21:30] [V] [TRT] Cast_115 [Cast] inputs: [473 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_115 for ONNX node: Cast_115
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 474 for ONNX tensor: 474
[06/10/2022-19:21:30] [V] [TRT] Cast_115 [Cast] outputs: [474 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_116 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 420
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_116 [Unsqueeze] inputs: [420 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_116 for ONNX node: Unsqueeze_116
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 478 for ONNX tensor: 478
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_116 [Unsqueeze] outputs: [478 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_117 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 474
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_117 [Unsqueeze] inputs: [474 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_117 for ONNX node: Unsqueeze_117
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 482 for ONNX tensor: 482
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_117 [Unsqueeze] outputs: [482 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_118 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 478
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3063
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3064
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3065
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 482
[06/10/2022-19:21:30] [V] [TRT] Concat_118 [Concat] inputs: [478 -> (1)[INT32]], [3063 -> (1)[INT32]], [3064 -> (1)[INT32]], [3065 -> (1)[INT32]], [482 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3063 for ONNX node: 3063
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3064 for ONNX node: 3064
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3065 for ONNX node: 3065
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_118 for ONNX node: Concat_118
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 483 for ONNX tensor: 483
[06/10/2022-19:21:30] [V] [TRT] Concat_118 [Concat] outputs: [483 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_119 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 470
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 483
[06/10/2022-19:21:30] [V] [TRT] Reshape_119 [Reshape] inputs: [470 -> (-1, 1024, 128)[FLOAT]], [483 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_119 for ONNX node: Reshape_119
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 484 for ONNX tensor: 484
[06/10/2022-19:21:30] [V] [TRT] Reshape_119 [Reshape] outputs: [484 -> (-1, 1024, 2, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_120 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 484
[06/10/2022-19:21:30] [V] [TRT] Transpose_120 [Transpose] inputs: [484 -> (-1, 1024, 2, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_120 for ONNX node: Transpose_120
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 485 for ONNX tensor: 485
[06/10/2022-19:21:30] [V] [TRT] Transpose_120 [Transpose] outputs: [485 -> (2, -1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_122 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 485
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 486
[06/10/2022-19:21:30] [V] [TRT] Gather_122 [Gather] inputs: [485 -> (2, -1, 1, 1024, 64)[FLOAT]], [486 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 486 for ONNX node: 486
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_122 for ONNX node: Gather_122
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 487 for ONNX tensor: 487
[06/10/2022-19:21:30] [V] [TRT] Gather_122 [Gather] outputs: [487 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_124 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 485
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 488
[06/10/2022-19:21:30] [V] [TRT] Gather_124 [Gather] inputs: [485 -> (2, -1, 1, 1024, 64)[FLOAT]], [488 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 488 for ONNX node: 488
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_124 for ONNX node: Gather_124
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 489 for ONNX tensor: 489
[06/10/2022-19:21:30] [V] [TRT] Gather_124 [Gather] outputs: [489 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_125 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 487
[06/10/2022-19:21:30] [V] [TRT] Transpose_125 [Transpose] inputs: [487 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_125 for ONNX node: Transpose_125
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 490 for ONNX tensor: 490
[06/10/2022-19:21:30] [V] [TRT] Transpose_125 [Transpose] outputs: [490 -> (-1, 1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_126 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 441
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 490
[06/10/2022-19:21:30] [V] [TRT] MatMul_126 [MatMul] inputs: [441 -> (-1, 1, 65536, 64)[FLOAT]], [490 -> (-1, 1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_126 for ONNX node: MatMul_126
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 491 for ONNX tensor: 491
[06/10/2022-19:21:30] [V] [TRT] MatMul_126 [MatMul] outputs: [491 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_128 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 491
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 492
[06/10/2022-19:21:30] [V] [TRT] Mul_128 [Mul] inputs: [491 -> (-1, 1, 65536, 1024)[FLOAT]], [492 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 492 for ONNX node: 492
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_128 for ONNX node: Mul_128
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 493 for ONNX tensor: 493
[06/10/2022-19:21:30] [V] [TRT] Mul_128 [Mul] outputs: [493 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Softmax_129 [Softmax]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 493
[06/10/2022-19:21:30] [V] [TRT] Softmax_129 [Softmax] inputs: [493 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Softmax_129 for ONNX node: Softmax_129
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 494 for ONNX tensor: 494
[06/10/2022-19:21:30] [V] [TRT] Softmax_129 [Softmax] outputs: [494 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_130 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 494
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 489
[06/10/2022-19:21:30] [V] [TRT] MatMul_130 [MatMul] inputs: [494 -> (-1, 1, 65536, 1024)[FLOAT]], [489 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_130 for ONNX node: MatMul_130
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 495 for ONNX tensor: 495
[06/10/2022-19:21:30] [V] [TRT] MatMul_130 [MatMul] outputs: [495 -> (-1, 1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_131 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 495
[06/10/2022-19:21:30] [V] [TRT] Transpose_131 [Transpose] inputs: [495 -> (-1, 1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_131 for ONNX node: Transpose_131
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 496 for ONNX tensor: 496
[06/10/2022-19:21:30] [V] [TRT] Transpose_131 [Transpose] outputs: [496 -> (-1, 65536, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_132 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 420
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_132 [Unsqueeze] inputs: [420 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_132 for ONNX node: Unsqueeze_132
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 497 for ONNX tensor: 497
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_132 [Unsqueeze] outputs: [497 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_133 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 423
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_133 [Unsqueeze] inputs: [423 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_133 for ONNX node: Unsqueeze_133
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 498 for ONNX tensor: 498
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_133 [Unsqueeze] outputs: [498 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_134 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 426
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_134 [Unsqueeze] inputs: [426 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_134 for ONNX node: Unsqueeze_134
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 499 for ONNX tensor: 499
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_134 [Unsqueeze] outputs: [499 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_135 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 497
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 498
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 499
[06/10/2022-19:21:30] [V] [TRT] Concat_135 [Concat] inputs: [497 -> (1)[INT32]], [498 -> (1)[INT32]], [499 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_135 for ONNX node: Concat_135
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 500 for ONNX tensor: 500
[06/10/2022-19:21:30] [V] [TRT] Concat_135 [Concat] outputs: [500 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_136 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 496
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 500
[06/10/2022-19:21:30] [V] [TRT] Reshape_136 [Reshape] inputs: [496 -> (-1, 65536, 1, 64)[FLOAT]], [500 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_136 for ONNX node: Reshape_136
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 501 for ONNX tensor: 501
[06/10/2022-19:21:30] [V] [TRT] Reshape_136 [Reshape] outputs: [501 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_137 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 501
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3066
[06/10/2022-19:21:30] [V] [TRT] MatMul_137 [MatMul] inputs: [501 -> (-1, 65536, 64)[FLOAT]], [3066 -> (64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3066 for ONNX node: 3066
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_137 for ONNX node: MatMul_137
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 503 for ONNX tensor: 503
[06/10/2022-19:21:30] [V] [TRT] MatMul_137 [MatMul] outputs: [503 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_138 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 503
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Add_138 [Add] inputs: [503 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.0.attn.proj.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.0.attn.proj.bias for ONNX node: backbone.block1.0.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_138 for ONNX node: Add_138
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 504 for ONNX tensor: 504
[06/10/2022-19:21:30] [V] [TRT] Add_138 [Add] outputs: [504 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_139 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 406
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 504
[06/10/2022-19:21:30] [V] [TRT] Add_139 [Add] inputs: [406 -> (-1, 65536, 64)[FLOAT]], [504 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_139 for ONNX node: Add_139
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 505 for ONNX tensor: 505
[06/10/2022-19:21:30] [V] [TRT] Add_139 [Add] outputs: [505 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_140 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 505
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_140 [ReduceMean] inputs: [505 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_140 for ONNX node: ReduceMean_140
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 506 for ONNX tensor: 506
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_140 [ReduceMean] outputs: [506 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_141 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 505
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 506
[06/10/2022-19:21:30] [V] [TRT] Sub_141 [Sub] inputs: [505 -> (-1, 65536, 64)[FLOAT]], [506 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_141 for ONNX node: Sub_141
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 507 for ONNX tensor: 507
[06/10/2022-19:21:30] [V] [TRT] Sub_141 [Sub] outputs: [507 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_143 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 507
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 508
[06/10/2022-19:21:30] [V] [TRT] Pow_143 [Pow] inputs: [507 -> (-1, 65536, 64)[FLOAT]], [508 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 508 for ONNX node: 508
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_143 for ONNX node: Pow_143
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 509 for ONNX tensor: 509
[06/10/2022-19:21:30] [V] [TRT] Pow_143 [Pow] outputs: [509 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_144 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 509
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_144 [ReduceMean] inputs: [509 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_144 for ONNX node: ReduceMean_144
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 510 for ONNX tensor: 510
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_144 [ReduceMean] outputs: [510 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_146 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 510
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 511
[06/10/2022-19:21:30] [V] [TRT] Add_146 [Add] inputs: [510 -> (-1, 65536, 1)[FLOAT]], [511 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 511 for ONNX node: 511
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_146 for ONNX node: Add_146
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 512 for ONNX tensor: 512
[06/10/2022-19:21:30] [V] [TRT] Add_146 [Add] outputs: [512 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_147 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 512
[06/10/2022-19:21:30] [V] [TRT] Sqrt_147 [Sqrt] inputs: [512 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_147 for ONNX node: Sqrt_147
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 513 for ONNX tensor: 513
[06/10/2022-19:21:30] [V] [TRT] Sqrt_147 [Sqrt] outputs: [513 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_148 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 507
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 513
[06/10/2022-19:21:30] [V] [TRT] Div_148 [Div] inputs: [507 -> (-1, 65536, 64)[FLOAT]], [513 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_148 for ONNX node: Div_148
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 514 for ONNX tensor: 514
[06/10/2022-19:21:30] [V] [TRT] Div_148 [Div] outputs: [514 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_149 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 514
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_149 [Mul] inputs: [514 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.0.norm2.weight -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.0.norm2.weight for ONNX node: backbone.block1.0.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_149 for ONNX node: Mul_149
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 515 for ONNX tensor: 515
[06/10/2022-19:21:30] [V] [TRT] Mul_149 [Mul] outputs: [515 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_150 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 515
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_150 [Add] inputs: [515 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.0.norm2.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.0.norm2.bias for ONNX node: backbone.block1.0.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_150 for ONNX node: Add_150
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 516 for ONNX tensor: 516
[06/10/2022-19:21:30] [V] [TRT] Add_150 [Add] outputs: [516 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_151 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 516
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3067
[06/10/2022-19:21:30] [V] [TRT] MatMul_151 [MatMul] inputs: [516 -> (-1, 65536, 64)[FLOAT]], [3067 -> (64, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3067 for ONNX node: 3067
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_151 for ONNX node: MatMul_151
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 518 for ONNX tensor: 518
[06/10/2022-19:21:30] [V] [TRT] MatMul_151 [MatMul] outputs: [518 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_152 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 518
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_152 [Add] inputs: [518 -> (-1, 65536, 256)[FLOAT]], [backbone.block1.0.mlp.fc1.bias -> (256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.0.mlp.fc1.bias for ONNX node: backbone.block1.0.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_152 for ONNX node: Add_152
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 519 for ONNX tensor: 519
[06/10/2022-19:21:30] [V] [TRT] Add_152 [Add] outputs: [519 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_153 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 519
[06/10/2022-19:21:30] [V] [TRT] Shape_153 [Shape] inputs: [519 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_153 for ONNX node: Shape_153
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 520 for ONNX tensor: 520
[06/10/2022-19:21:30] [V] [TRT] Shape_153 [Shape] outputs: [520 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_155 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 520
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 521
[06/10/2022-19:21:30] [V] [TRT] Gather_155 [Gather] inputs: [520 -> (3)[INT32]], [521 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 521 for ONNX node: 521
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_155 for ONNX node: Gather_155
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 522 for ONNX tensor: 522
[06/10/2022-19:21:30] [V] [TRT] Gather_155 [Gather] outputs: [522 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_156 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 519
[06/10/2022-19:21:30] [V] [TRT] Shape_156 [Shape] inputs: [519 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_156 for ONNX node: Shape_156
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 523 for ONNX tensor: 523
[06/10/2022-19:21:30] [V] [TRT] Shape_156 [Shape] outputs: [523 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_158 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 523
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 524
[06/10/2022-19:21:30] [V] [TRT] Gather_158 [Gather] inputs: [523 -> (3)[INT32]], [524 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 524 for ONNX node: 524
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_158 for ONNX node: Gather_158
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 525 for ONNX tensor: 525
[06/10/2022-19:21:30] [V] [TRT] Gather_158 [Gather] outputs: [525 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_159 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 519
[06/10/2022-19:21:30] [V] [TRT] Transpose_159 [Transpose] inputs: [519 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_159 for ONNX node: Transpose_159
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 526 for ONNX tensor: 526
[06/10/2022-19:21:30] [V] [TRT] Transpose_159 [Transpose] outputs: [526 -> (-1, 256, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_160 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 522
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_160 [Unsqueeze] inputs: [522 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_160 for ONNX node: Unsqueeze_160
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 527 for ONNX tensor: 527
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_160 [Unsqueeze] outputs: [527 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_161 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 525
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_161 [Unsqueeze] inputs: [525 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_161 for ONNX node: Unsqueeze_161
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 528 for ONNX tensor: 528
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_161 [Unsqueeze] outputs: [528 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_164 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 527
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 528
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 529
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 530
[06/10/2022-19:21:30] [V] [TRT] Concat_164 [Concat] inputs: [527 -> (1)[INT32]], [528 -> (1)[INT32]], [529 -> (1)[INT32]], [530 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 529 for ONNX node: 529
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 530 for ONNX node: 530
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_164 for ONNX node: Concat_164
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 531 for ONNX tensor: 531
[06/10/2022-19:21:30] [V] [TRT] Concat_164 [Concat] outputs: [531 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_165 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 526
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 531
[06/10/2022-19:21:30] [V] [TRT] Reshape_165 [Reshape] inputs: [526 -> (-1, 256, 65536)[FLOAT]], [531 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_165 for ONNX node: Reshape_165
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 532 for ONNX tensor: 532
[06/10/2022-19:21:30] [V] [TRT] Reshape_165 [Reshape] outputs: [532 -> (-1, 256, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_166 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 532
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_166 [Conv] inputs: [532 -> (-1, 256, 256, 256)[FLOAT]], [backbone.block1.0.mlp.dwconv.dwconv.weight -> (256, 1, 3, 3)[FLOAT]], [backbone.block1.0.mlp.dwconv.dwconv.bias -> (256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 256, 256, 256)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_166 for ONNX node: Conv_166
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 256, 256, 256)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 533 for ONNX tensor: 533
[06/10/2022-19:21:30] [V] [TRT] Conv_166 [Conv] outputs: [533 -> (-1, 256, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_167 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 533
[06/10/2022-19:21:30] [V] [TRT] Shape_167 [Shape] inputs: [533 -> (-1, 256, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_167 for ONNX node: Shape_167
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 534 for ONNX tensor: 534
[06/10/2022-19:21:30] [V] [TRT] Shape_167 [Shape] outputs: [534 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_171 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 534
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 536
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 537
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 535
[06/10/2022-19:21:30] [V] [TRT] Slice_171 [Slice] inputs: [534 -> (4)[INT32]], [536 -> (1)[INT32]], [537 -> (1)[INT32]], [535 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_171 for ONNX node: Slice_171
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 538 for ONNX tensor: 538
[06/10/2022-19:21:30] [V] [TRT] Slice_171 [Slice] outputs: [538 -> (2)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_173 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 538
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 539
[06/10/2022-19:21:30] [V] [TRT] Concat_173 [Concat] inputs: [538 -> (2)[INT32]], [539 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 539 for ONNX node: 539
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_173 for ONNX node: Concat_173
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 540 for ONNX tensor: 540
[06/10/2022-19:21:30] [V] [TRT] Concat_173 [Concat] outputs: [540 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_174 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 533
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 540
[06/10/2022-19:21:30] [V] [TRT] Reshape_174 [Reshape] inputs: [533 -> (-1, 256, 256, 256)[FLOAT]], [540 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_174 for ONNX node: Reshape_174
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 541 for ONNX tensor: 541
[06/10/2022-19:21:30] [V] [TRT] Reshape_174 [Reshape] outputs: [541 -> (-1, 256, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_175 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 541
[06/10/2022-19:21:30] [V] [TRT] Transpose_175 [Transpose] inputs: [541 -> (-1, 256, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_175 for ONNX node: Transpose_175
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 542 for ONNX tensor: 542
[06/10/2022-19:21:30] [V] [TRT] Transpose_175 [Transpose] outputs: [542 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_177 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 542
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 543
[06/10/2022-19:21:30] [V] [TRT] Div_177 [Div] inputs: [542 -> (-1, 65536, 256)[FLOAT]], [543 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 543 for ONNX node: 543
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_177 for ONNX node: Div_177
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 544 for ONNX tensor: 544
[06/10/2022-19:21:30] [V] [TRT] Div_177 [Div] outputs: [544 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Erf_178 [Erf]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 544
[06/10/2022-19:21:30] [V] [TRT] Erf_178 [Erf] inputs: [544 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Erf_178 for ONNX node: Erf_178
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 545 for ONNX tensor: 545
[06/10/2022-19:21:30] [V] [TRT] Erf_178 [Erf] outputs: [545 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_180 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 545
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 546
[06/10/2022-19:21:30] [V] [TRT] Add_180 [Add] inputs: [545 -> (-1, 65536, 256)[FLOAT]], [546 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 546 for ONNX node: 546
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_180 for ONNX node: Add_180
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 547 for ONNX tensor: 547
[06/10/2022-19:21:30] [V] [TRT] Add_180 [Add] outputs: [547 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_181 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 542
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 547
[06/10/2022-19:21:30] [V] [TRT] Mul_181 [Mul] inputs: [542 -> (-1, 65536, 256)[FLOAT]], [547 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_181 for ONNX node: Mul_181
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 548 for ONNX tensor: 548
[06/10/2022-19:21:30] [V] [TRT] Mul_181 [Mul] outputs: [548 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_183 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 548
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 549
[06/10/2022-19:21:30] [V] [TRT] Mul_183 [Mul] inputs: [548 -> (-1, 65536, 256)[FLOAT]], [549 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 549 for ONNX node: 549
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_183 for ONNX node: Mul_183
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 550 for ONNX tensor: 550
[06/10/2022-19:21:30] [V] [TRT] Mul_183 [Mul] outputs: [550 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_184 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 550
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3068
[06/10/2022-19:21:30] [V] [TRT] MatMul_184 [MatMul] inputs: [550 -> (-1, 65536, 256)[FLOAT]], [3068 -> (256, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3068 for ONNX node: 3068
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_184 for ONNX node: MatMul_184
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 552 for ONNX tensor: 552
[06/10/2022-19:21:30] [V] [TRT] MatMul_184 [MatMul] outputs: [552 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_185 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 552
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.0.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_185 [Add] inputs: [552 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.0.mlp.fc2.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.0.mlp.fc2.bias for ONNX node: backbone.block1.0.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_185 for ONNX node: Add_185
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 553 for ONNX tensor: 553
[06/10/2022-19:21:30] [V] [TRT] Add_185 [Add] outputs: [553 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_186 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 505
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 553
[06/10/2022-19:21:30] [V] [TRT] Add_186 [Add] inputs: [505 -> (-1, 65536, 64)[FLOAT]], [553 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_186 for ONNX node: Add_186
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 554 for ONNX tensor: 554
[06/10/2022-19:21:30] [V] [TRT] Add_186 [Add] outputs: [554 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_187 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 554
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_187 [ReduceMean] inputs: [554 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_187 for ONNX node: ReduceMean_187
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 555 for ONNX tensor: 555
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_187 [ReduceMean] outputs: [555 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_188 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 554
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 555
[06/10/2022-19:21:30] [V] [TRT] Sub_188 [Sub] inputs: [554 -> (-1, 65536, 64)[FLOAT]], [555 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_188 for ONNX node: Sub_188
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 556 for ONNX tensor: 556
[06/10/2022-19:21:30] [V] [TRT] Sub_188 [Sub] outputs: [556 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_190 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 556
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 557
[06/10/2022-19:21:30] [V] [TRT] Pow_190 [Pow] inputs: [556 -> (-1, 65536, 64)[FLOAT]], [557 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 557 for ONNX node: 557
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_190 for ONNX node: Pow_190
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 558 for ONNX tensor: 558
[06/10/2022-19:21:30] [V] [TRT] Pow_190 [Pow] outputs: [558 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_191 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 558
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_191 [ReduceMean] inputs: [558 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_191 for ONNX node: ReduceMean_191
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 559 for ONNX tensor: 559
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_191 [ReduceMean] outputs: [559 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_193 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 559
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 560
[06/10/2022-19:21:30] [V] [TRT] Add_193 [Add] inputs: [559 -> (-1, 65536, 1)[FLOAT]], [560 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 560 for ONNX node: 560
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_193 for ONNX node: Add_193
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 561 for ONNX tensor: 561
[06/10/2022-19:21:30] [V] [TRT] Add_193 [Add] outputs: [561 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_194 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 561
[06/10/2022-19:21:30] [V] [TRT] Sqrt_194 [Sqrt] inputs: [561 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_194 for ONNX node: Sqrt_194
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 562 for ONNX tensor: 562
[06/10/2022-19:21:30] [V] [TRT] Sqrt_194 [Sqrt] outputs: [562 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_195 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 556
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 562
[06/10/2022-19:21:30] [V] [TRT] Div_195 [Div] inputs: [556 -> (-1, 65536, 64)[FLOAT]], [562 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_195 for ONNX node: Div_195
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 563 for ONNX tensor: 563
[06/10/2022-19:21:30] [V] [TRT] Div_195 [Div] outputs: [563 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_196 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 563
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_196 [Mul] inputs: [563 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.1.norm1.weight -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.1.norm1.weight for ONNX node: backbone.block1.1.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_196 for ONNX node: Mul_196
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 564 for ONNX tensor: 564
[06/10/2022-19:21:30] [V] [TRT] Mul_196 [Mul] outputs: [564 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_197 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 564
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_197 [Add] inputs: [564 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.1.norm1.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.1.norm1.bias for ONNX node: backbone.block1.1.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_197 for ONNX node: Add_197
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 565 for ONNX tensor: 565
[06/10/2022-19:21:30] [V] [TRT] Add_197 [Add] outputs: [565 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_198 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 565
[06/10/2022-19:21:30] [V] [TRT] Shape_198 [Shape] inputs: [565 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_198 for ONNX node: Shape_198
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 566 for ONNX tensor: 566
[06/10/2022-19:21:30] [V] [TRT] Shape_198 [Shape] outputs: [566 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_200 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 566
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 567
[06/10/2022-19:21:30] [V] [TRT] Gather_200 [Gather] inputs: [566 -> (3)[INT32]], [567 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 567 for ONNX node: 567
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_200 for ONNX node: Gather_200
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 568 for ONNX tensor: 568
[06/10/2022-19:21:30] [V] [TRT] Gather_200 [Gather] outputs: [568 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_201 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 565
[06/10/2022-19:21:30] [V] [TRT] Shape_201 [Shape] inputs: [565 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_201 for ONNX node: Shape_201
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 569 for ONNX tensor: 569
[06/10/2022-19:21:30] [V] [TRT] Shape_201 [Shape] outputs: [569 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_203 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 569
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 570
[06/10/2022-19:21:30] [V] [TRT] Gather_203 [Gather] inputs: [569 -> (3)[INT32]], [570 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 570 for ONNX node: 570
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_203 for ONNX node: Gather_203
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 571 for ONNX tensor: 571
[06/10/2022-19:21:30] [V] [TRT] Gather_203 [Gather] outputs: [571 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_204 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 565
[06/10/2022-19:21:30] [V] [TRT] Shape_204 [Shape] inputs: [565 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_204 for ONNX node: Shape_204
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 572 for ONNX tensor: 572
[06/10/2022-19:21:30] [V] [TRT] Shape_204 [Shape] outputs: [572 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_206 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 572
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 573
[06/10/2022-19:21:30] [V] [TRT] Gather_206 [Gather] inputs: [572 -> (3)[INT32]], [573 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 573 for ONNX node: 573
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_206 for ONNX node: Gather_206
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 574 for ONNX tensor: 574
[06/10/2022-19:21:30] [V] [TRT] Gather_206 [Gather] outputs: [574 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_207 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 565
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3069
[06/10/2022-19:21:30] [V] [TRT] MatMul_207 [MatMul] inputs: [565 -> (-1, 65536, 64)[FLOAT]], [3069 -> (64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3069 for ONNX node: 3069
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_207 for ONNX node: MatMul_207
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 576 for ONNX tensor: 576
[06/10/2022-19:21:30] [V] [TRT] MatMul_207 [MatMul] outputs: [576 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_208 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 576
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Add_208 [Add] inputs: [576 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.1.attn.q.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.1.attn.q.bias for ONNX node: backbone.block1.1.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_208 for ONNX node: Add_208
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 577 for ONNX tensor: 577
[06/10/2022-19:21:30] [V] [TRT] Add_208 [Add] outputs: [577 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_210 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 574
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 578
[06/10/2022-19:21:30] [V] [TRT] Div_210 [Div] inputs: [574 -> ()[INT32]], [578 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 578 for ONNX node: 578
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_210 for ONNX node: Div_210
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 579 for ONNX tensor: 579
[06/10/2022-19:21:30] [V] [TRT] Div_210 [Div] outputs: [579 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_211 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 579
[06/10/2022-19:21:30] [V] [TRT] Cast_211 [Cast] inputs: [579 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_211 for ONNX node: Cast_211
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 580 for ONNX tensor: 580
[06/10/2022-19:21:30] [V] [TRT] Cast_211 [Cast] outputs: [580 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_212 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 580
[06/10/2022-19:21:30] [V] [TRT] Cast_212 [Cast] inputs: [580 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_212 for ONNX node: Cast_212
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 581 for ONNX tensor: 581
[06/10/2022-19:21:30] [V] [TRT] Cast_212 [Cast] outputs: [581 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_213 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 568
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_213 [Unsqueeze] inputs: [568 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_213 for ONNX node: Unsqueeze_213
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 583 for ONNX tensor: 583
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_213 [Unsqueeze] outputs: [583 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_214 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 571
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_214 [Unsqueeze] inputs: [571 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_214 for ONNX node: Unsqueeze_214
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 584 for ONNX tensor: 584
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_214 [Unsqueeze] outputs: [584 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_215 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 581
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_215 [Unsqueeze] inputs: [581 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_215 for ONNX node: Unsqueeze_215
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 586 for ONNX tensor: 586
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_215 [Unsqueeze] outputs: [586 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_216 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 583
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 584
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3070
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 586
[06/10/2022-19:21:30] [V] [TRT] Concat_216 [Concat] inputs: [583 -> (1)[INT32]], [584 -> (1)[INT32]], [3070 -> (1)[INT32]], [586 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3070 for ONNX node: 3070
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_216 for ONNX node: Concat_216
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 587 for ONNX tensor: 587
[06/10/2022-19:21:30] [V] [TRT] Concat_216 [Concat] outputs: [587 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_217 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 577
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 587
[06/10/2022-19:21:30] [V] [TRT] Reshape_217 [Reshape] inputs: [577 -> (-1, 65536, 64)[FLOAT]], [587 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_217 for ONNX node: Reshape_217
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 588 for ONNX tensor: 588
[06/10/2022-19:21:30] [V] [TRT] Reshape_217 [Reshape] outputs: [588 -> (-1, 65536, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_218 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 588
[06/10/2022-19:21:30] [V] [TRT] Transpose_218 [Transpose] inputs: [588 -> (-1, 65536, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_218 for ONNX node: Transpose_218
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 589 for ONNX tensor: 589
[06/10/2022-19:21:30] [V] [TRT] Transpose_218 [Transpose] outputs: [589 -> (-1, 1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_219 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 565
[06/10/2022-19:21:30] [V] [TRT] Transpose_219 [Transpose] inputs: [565 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_219 for ONNX node: Transpose_219
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 590 for ONNX tensor: 590
[06/10/2022-19:21:30] [V] [TRT] Transpose_219 [Transpose] outputs: [590 -> (-1, 64, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_220 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 568
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_220 [Unsqueeze] inputs: [568 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_220 for ONNX node: Unsqueeze_220
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 591 for ONNX tensor: 591
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_220 [Unsqueeze] outputs: [591 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_221 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 574
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_221 [Unsqueeze] inputs: [574 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_221 for ONNX node: Unsqueeze_221
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 592 for ONNX tensor: 592
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_221 [Unsqueeze] outputs: [592 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_224 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 591
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 592
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 593
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 594
[06/10/2022-19:21:30] [V] [TRT] Concat_224 [Concat] inputs: [591 -> (1)[INT32]], [592 -> (1)[INT32]], [593 -> (1)[INT32]], [594 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 593 for ONNX node: 593
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 594 for ONNX node: 594
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_224 for ONNX node: Concat_224
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 595 for ONNX tensor: 595
[06/10/2022-19:21:30] [V] [TRT] Concat_224 [Concat] outputs: [595 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_225 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 590
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 595
[06/10/2022-19:21:30] [V] [TRT] Reshape_225 [Reshape] inputs: [590 -> (-1, 64, 65536)[FLOAT]], [595 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_225 for ONNX node: Reshape_225
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 596 for ONNX tensor: 596
[06/10/2022-19:21:30] [V] [TRT] Reshape_225 [Reshape] outputs: [596 -> (-1, 64, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_226 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 596
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_226 [Conv] inputs: [596 -> (-1, 64, 256, 256)[FLOAT]], [backbone.block1.1.attn.sr.weight -> (64, 64, 8, 8)[FLOAT]], [backbone.block1.1.attn.sr.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 64, 256, 256)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_226 for ONNX node: Conv_226
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (8, 8), strides: (8, 8), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 64, 32, 32)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 597 for ONNX tensor: 597
[06/10/2022-19:21:30] [V] [TRT] Conv_226 [Conv] outputs: [597 -> (-1, 64, 32, 32)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_227 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 568
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_227 [Unsqueeze] inputs: [568 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_227 for ONNX node: Unsqueeze_227
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 599 for ONNX tensor: 599
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_227 [Unsqueeze] outputs: [599 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_228 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 574
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_228 [Unsqueeze] inputs: [574 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_228 for ONNX node: Unsqueeze_228
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 600 for ONNX tensor: 600
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_228 [Unsqueeze] outputs: [600 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_229 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 599
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 600
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3071
[06/10/2022-19:21:30] [V] [TRT] Concat_229 [Concat] inputs: [599 -> (1)[INT32]], [600 -> (1)[INT32]], [3071 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3071 for ONNX node: 3071
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_229 for ONNX node: Concat_229
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 602 for ONNX tensor: 602
[06/10/2022-19:21:30] [V] [TRT] Concat_229 [Concat] outputs: [602 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_230 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 597
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 602
[06/10/2022-19:21:30] [V] [TRT] Reshape_230 [Reshape] inputs: [597 -> (-1, 64, 32, 32)[FLOAT]], [602 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_230 for ONNX node: Reshape_230
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 603 for ONNX tensor: 603
[06/10/2022-19:21:30] [V] [TRT] Reshape_230 [Reshape] outputs: [603 -> (-1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_231 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 603
[06/10/2022-19:21:30] [V] [TRT] Transpose_231 [Transpose] inputs: [603 -> (-1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_231 for ONNX node: Transpose_231
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 604 for ONNX tensor: 604
[06/10/2022-19:21:30] [V] [TRT] Transpose_231 [Transpose] outputs: [604 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_232 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 604
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_232 [ReduceMean] inputs: [604 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_232 for ONNX node: ReduceMean_232
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 605 for ONNX tensor: 605
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_232 [ReduceMean] outputs: [605 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_233 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 604
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 605
[06/10/2022-19:21:30] [V] [TRT] Sub_233 [Sub] inputs: [604 -> (-1, 1024, 64)[FLOAT]], [605 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_233 for ONNX node: Sub_233
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 606 for ONNX tensor: 606
[06/10/2022-19:21:30] [V] [TRT] Sub_233 [Sub] outputs: [606 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_235 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 606
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 607
[06/10/2022-19:21:30] [V] [TRT] Pow_235 [Pow] inputs: [606 -> (-1, 1024, 64)[FLOAT]], [607 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 607 for ONNX node: 607
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_235 for ONNX node: Pow_235
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 608 for ONNX tensor: 608
[06/10/2022-19:21:30] [V] [TRT] Pow_235 [Pow] outputs: [608 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_236 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 608
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_236 [ReduceMean] inputs: [608 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_236 for ONNX node: ReduceMean_236
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 609 for ONNX tensor: 609
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_236 [ReduceMean] outputs: [609 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_238 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 609
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 610
[06/10/2022-19:21:30] [V] [TRT] Add_238 [Add] inputs: [609 -> (-1, 1024, 1)[FLOAT]], [610 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 610 for ONNX node: 610
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_238 for ONNX node: Add_238
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 611 for ONNX tensor: 611
[06/10/2022-19:21:30] [V] [TRT] Add_238 [Add] outputs: [611 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_239 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 611
[06/10/2022-19:21:30] [V] [TRT] Sqrt_239 [Sqrt] inputs: [611 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_239 for ONNX node: Sqrt_239
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 612 for ONNX tensor: 612
[06/10/2022-19:21:30] [V] [TRT] Sqrt_239 [Sqrt] outputs: [612 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_240 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 606
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 612
[06/10/2022-19:21:30] [V] [TRT] Div_240 [Div] inputs: [606 -> (-1, 1024, 64)[FLOAT]], [612 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_240 for ONNX node: Div_240
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 613 for ONNX tensor: 613
[06/10/2022-19:21:30] [V] [TRT] Div_240 [Div] outputs: [613 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_241 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 613
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_241 [Mul] inputs: [613 -> (-1, 1024, 64)[FLOAT]], [backbone.block1.1.attn.norm.weight -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.1.attn.norm.weight for ONNX node: backbone.block1.1.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_241 for ONNX node: Mul_241
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 614 for ONNX tensor: 614
[06/10/2022-19:21:30] [V] [TRT] Mul_241 [Mul] outputs: [614 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_242 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 614
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Add_242 [Add] inputs: [614 -> (-1, 1024, 64)[FLOAT]], [backbone.block1.1.attn.norm.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.1.attn.norm.bias for ONNX node: backbone.block1.1.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_242 for ONNX node: Add_242
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 615 for ONNX tensor: 615
[06/10/2022-19:21:30] [V] [TRT] Add_242 [Add] outputs: [615 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_243 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 615
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3072
[06/10/2022-19:21:30] [V] [TRT] MatMul_243 [MatMul] inputs: [615 -> (-1, 1024, 64)[FLOAT]], [3072 -> (64, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3072 for ONNX node: 3072
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_243 for ONNX node: MatMul_243
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 617 for ONNX tensor: 617
[06/10/2022-19:21:30] [V] [TRT] MatMul_243 [MatMul] outputs: [617 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_244 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 617
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Add_244 [Add] inputs: [617 -> (-1, 1024, 128)[FLOAT]], [backbone.block1.1.attn.kv.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.1.attn.kv.bias for ONNX node: backbone.block1.1.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_244 for ONNX node: Add_244
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 618 for ONNX tensor: 618
[06/10/2022-19:21:30] [V] [TRT] Add_244 [Add] outputs: [618 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_246 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 574
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 619
[06/10/2022-19:21:30] [V] [TRT] Div_246 [Div] inputs: [574 -> ()[INT32]], [619 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 619 for ONNX node: 619
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_246 for ONNX node: Div_246
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 620 for ONNX tensor: 620
[06/10/2022-19:21:30] [V] [TRT] Div_246 [Div] outputs: [620 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_247 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 620
[06/10/2022-19:21:30] [V] [TRT] Cast_247 [Cast] inputs: [620 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_247 for ONNX node: Cast_247
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 621 for ONNX tensor: 621
[06/10/2022-19:21:30] [V] [TRT] Cast_247 [Cast] outputs: [621 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_248 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 621
[06/10/2022-19:21:30] [V] [TRT] Cast_248 [Cast] inputs: [621 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_248 for ONNX node: Cast_248
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 622 for ONNX tensor: 622
[06/10/2022-19:21:30] [V] [TRT] Cast_248 [Cast] outputs: [622 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_249 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 568
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_249 [Unsqueeze] inputs: [568 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_249 for ONNX node: Unsqueeze_249
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 626 for ONNX tensor: 626
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_249 [Unsqueeze] outputs: [626 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_250 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 622
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_250 [Unsqueeze] inputs: [622 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_250 for ONNX node: Unsqueeze_250
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 630 for ONNX tensor: 630
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_250 [Unsqueeze] outputs: [630 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_251 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 626
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3073
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3074
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3075
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 630
[06/10/2022-19:21:30] [V] [TRT] Concat_251 [Concat] inputs: [626 -> (1)[INT32]], [3073 -> (1)[INT32]], [3074 -> (1)[INT32]], [3075 -> (1)[INT32]], [630 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3073 for ONNX node: 3073
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3074 for ONNX node: 3074
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3075 for ONNX node: 3075
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_251 for ONNX node: Concat_251
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 631 for ONNX tensor: 631
[06/10/2022-19:21:30] [V] [TRT] Concat_251 [Concat] outputs: [631 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_252 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 618
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 631
[06/10/2022-19:21:30] [V] [TRT] Reshape_252 [Reshape] inputs: [618 -> (-1, 1024, 128)[FLOAT]], [631 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_252 for ONNX node: Reshape_252
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 632 for ONNX tensor: 632
[06/10/2022-19:21:30] [V] [TRT] Reshape_252 [Reshape] outputs: [632 -> (-1, 1024, 2, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_253 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 632
[06/10/2022-19:21:30] [V] [TRT] Transpose_253 [Transpose] inputs: [632 -> (-1, 1024, 2, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_253 for ONNX node: Transpose_253
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 633 for ONNX tensor: 633
[06/10/2022-19:21:30] [V] [TRT] Transpose_253 [Transpose] outputs: [633 -> (2, -1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_255 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 633
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 634
[06/10/2022-19:21:30] [V] [TRT] Gather_255 [Gather] inputs: [633 -> (2, -1, 1, 1024, 64)[FLOAT]], [634 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 634 for ONNX node: 634
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_255 for ONNX node: Gather_255
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 635 for ONNX tensor: 635
[06/10/2022-19:21:30] [V] [TRT] Gather_255 [Gather] outputs: [635 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_257 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 633
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 636
[06/10/2022-19:21:30] [V] [TRT] Gather_257 [Gather] inputs: [633 -> (2, -1, 1, 1024, 64)[FLOAT]], [636 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 636 for ONNX node: 636
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_257 for ONNX node: Gather_257
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 637 for ONNX tensor: 637
[06/10/2022-19:21:30] [V] [TRT] Gather_257 [Gather] outputs: [637 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_258 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 635
[06/10/2022-19:21:30] [V] [TRT] Transpose_258 [Transpose] inputs: [635 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_258 for ONNX node: Transpose_258
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 638 for ONNX tensor: 638
[06/10/2022-19:21:30] [V] [TRT] Transpose_258 [Transpose] outputs: [638 -> (-1, 1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_259 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 589
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 638
[06/10/2022-19:21:30] [V] [TRT] MatMul_259 [MatMul] inputs: [589 -> (-1, 1, 65536, 64)[FLOAT]], [638 -> (-1, 1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_259 for ONNX node: MatMul_259
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 639 for ONNX tensor: 639
[06/10/2022-19:21:30] [V] [TRT] MatMul_259 [MatMul] outputs: [639 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_261 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 639
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 640
[06/10/2022-19:21:30] [V] [TRT] Mul_261 [Mul] inputs: [639 -> (-1, 1, 65536, 1024)[FLOAT]], [640 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 640 for ONNX node: 640
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_261 for ONNX node: Mul_261
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 641 for ONNX tensor: 641
[06/10/2022-19:21:30] [V] [TRT] Mul_261 [Mul] outputs: [641 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Softmax_262 [Softmax]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 641
[06/10/2022-19:21:30] [V] [TRT] Softmax_262 [Softmax] inputs: [641 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Softmax_262 for ONNX node: Softmax_262
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 642 for ONNX tensor: 642
[06/10/2022-19:21:30] [V] [TRT] Softmax_262 [Softmax] outputs: [642 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_263 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 642
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 637
[06/10/2022-19:21:30] [V] [TRT] MatMul_263 [MatMul] inputs: [642 -> (-1, 1, 65536, 1024)[FLOAT]], [637 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_263 for ONNX node: MatMul_263
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 643 for ONNX tensor: 643
[06/10/2022-19:21:30] [V] [TRT] MatMul_263 [MatMul] outputs: [643 -> (-1, 1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_264 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 643
[06/10/2022-19:21:30] [V] [TRT] Transpose_264 [Transpose] inputs: [643 -> (-1, 1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_264 for ONNX node: Transpose_264
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 644 for ONNX tensor: 644
[06/10/2022-19:21:30] [V] [TRT] Transpose_264 [Transpose] outputs: [644 -> (-1, 65536, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_265 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 568
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_265 [Unsqueeze] inputs: [568 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_265 for ONNX node: Unsqueeze_265
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 645 for ONNX tensor: 645
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_265 [Unsqueeze] outputs: [645 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_266 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 571
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_266 [Unsqueeze] inputs: [571 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_266 for ONNX node: Unsqueeze_266
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 646 for ONNX tensor: 646
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_266 [Unsqueeze] outputs: [646 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_267 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 574
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_267 [Unsqueeze] inputs: [574 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_267 for ONNX node: Unsqueeze_267
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 647 for ONNX tensor: 647
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_267 [Unsqueeze] outputs: [647 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_268 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 645
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 646
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 647
[06/10/2022-19:21:30] [V] [TRT] Concat_268 [Concat] inputs: [645 -> (1)[INT32]], [646 -> (1)[INT32]], [647 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_268 for ONNX node: Concat_268
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 648 for ONNX tensor: 648
[06/10/2022-19:21:30] [V] [TRT] Concat_268 [Concat] outputs: [648 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_269 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 644
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 648
[06/10/2022-19:21:30] [V] [TRT] Reshape_269 [Reshape] inputs: [644 -> (-1, 65536, 1, 64)[FLOAT]], [648 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_269 for ONNX node: Reshape_269
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 649 for ONNX tensor: 649
[06/10/2022-19:21:30] [V] [TRT] Reshape_269 [Reshape] outputs: [649 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_270 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 649
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3076
[06/10/2022-19:21:30] [V] [TRT] MatMul_270 [MatMul] inputs: [649 -> (-1, 65536, 64)[FLOAT]], [3076 -> (64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3076 for ONNX node: 3076
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_270 for ONNX node: MatMul_270
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 651 for ONNX tensor: 651
[06/10/2022-19:21:30] [V] [TRT] MatMul_270 [MatMul] outputs: [651 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_271 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 651
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Add_271 [Add] inputs: [651 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.1.attn.proj.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.1.attn.proj.bias for ONNX node: backbone.block1.1.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_271 for ONNX node: Add_271
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 652 for ONNX tensor: 652
[06/10/2022-19:21:30] [V] [TRT] Add_271 [Add] outputs: [652 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_272 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 554
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 652
[06/10/2022-19:21:30] [V] [TRT] Add_272 [Add] inputs: [554 -> (-1, 65536, 64)[FLOAT]], [652 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_272 for ONNX node: Add_272
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 653 for ONNX tensor: 653
[06/10/2022-19:21:30] [V] [TRT] Add_272 [Add] outputs: [653 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_273 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 653
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_273 [ReduceMean] inputs: [653 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_273 for ONNX node: ReduceMean_273
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 654 for ONNX tensor: 654
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_273 [ReduceMean] outputs: [654 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_274 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 653
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 654
[06/10/2022-19:21:30] [V] [TRT] Sub_274 [Sub] inputs: [653 -> (-1, 65536, 64)[FLOAT]], [654 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_274 for ONNX node: Sub_274
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 655 for ONNX tensor: 655
[06/10/2022-19:21:30] [V] [TRT] Sub_274 [Sub] outputs: [655 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_276 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 655
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 656
[06/10/2022-19:21:30] [V] [TRT] Pow_276 [Pow] inputs: [655 -> (-1, 65536, 64)[FLOAT]], [656 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 656 for ONNX node: 656
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_276 for ONNX node: Pow_276
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 657 for ONNX tensor: 657
[06/10/2022-19:21:30] [V] [TRT] Pow_276 [Pow] outputs: [657 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_277 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 657
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_277 [ReduceMean] inputs: [657 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_277 for ONNX node: ReduceMean_277
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 658 for ONNX tensor: 658
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_277 [ReduceMean] outputs: [658 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_279 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 658
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 659
[06/10/2022-19:21:30] [V] [TRT] Add_279 [Add] inputs: [658 -> (-1, 65536, 1)[FLOAT]], [659 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 659 for ONNX node: 659
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_279 for ONNX node: Add_279
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 660 for ONNX tensor: 660
[06/10/2022-19:21:30] [V] [TRT] Add_279 [Add] outputs: [660 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_280 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 660
[06/10/2022-19:21:30] [V] [TRT] Sqrt_280 [Sqrt] inputs: [660 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_280 for ONNX node: Sqrt_280
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 661 for ONNX tensor: 661
[06/10/2022-19:21:30] [V] [TRT] Sqrt_280 [Sqrt] outputs: [661 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_281 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 655
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 661
[06/10/2022-19:21:30] [V] [TRT] Div_281 [Div] inputs: [655 -> (-1, 65536, 64)[FLOAT]], [661 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_281 for ONNX node: Div_281
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 662 for ONNX tensor: 662
[06/10/2022-19:21:30] [V] [TRT] Div_281 [Div] outputs: [662 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_282 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 662
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_282 [Mul] inputs: [662 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.1.norm2.weight -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.1.norm2.weight for ONNX node: backbone.block1.1.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_282 for ONNX node: Mul_282
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 663 for ONNX tensor: 663
[06/10/2022-19:21:30] [V] [TRT] Mul_282 [Mul] outputs: [663 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_283 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 663
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_283 [Add] inputs: [663 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.1.norm2.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.1.norm2.bias for ONNX node: backbone.block1.1.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_283 for ONNX node: Add_283
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 664 for ONNX tensor: 664
[06/10/2022-19:21:30] [V] [TRT] Add_283 [Add] outputs: [664 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_284 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 664
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3077
[06/10/2022-19:21:30] [V] [TRT] MatMul_284 [MatMul] inputs: [664 -> (-1, 65536, 64)[FLOAT]], [3077 -> (64, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3077 for ONNX node: 3077
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_284 for ONNX node: MatMul_284
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 666 for ONNX tensor: 666
[06/10/2022-19:21:30] [V] [TRT] MatMul_284 [MatMul] outputs: [666 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_285 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 666
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_285 [Add] inputs: [666 -> (-1, 65536, 256)[FLOAT]], [backbone.block1.1.mlp.fc1.bias -> (256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.1.mlp.fc1.bias for ONNX node: backbone.block1.1.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_285 for ONNX node: Add_285
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 667 for ONNX tensor: 667
[06/10/2022-19:21:30] [V] [TRT] Add_285 [Add] outputs: [667 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_286 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 667
[06/10/2022-19:21:30] [V] [TRT] Shape_286 [Shape] inputs: [667 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_286 for ONNX node: Shape_286
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 668 for ONNX tensor: 668
[06/10/2022-19:21:30] [V] [TRT] Shape_286 [Shape] outputs: [668 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_288 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 668
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 669
[06/10/2022-19:21:30] [V] [TRT] Gather_288 [Gather] inputs: [668 -> (3)[INT32]], [669 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 669 for ONNX node: 669
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_288 for ONNX node: Gather_288
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 670 for ONNX tensor: 670
[06/10/2022-19:21:30] [V] [TRT] Gather_288 [Gather] outputs: [670 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_289 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 667
[06/10/2022-19:21:30] [V] [TRT] Shape_289 [Shape] inputs: [667 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_289 for ONNX node: Shape_289
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 671 for ONNX tensor: 671
[06/10/2022-19:21:30] [V] [TRT] Shape_289 [Shape] outputs: [671 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_291 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 671
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 672
[06/10/2022-19:21:30] [V] [TRT] Gather_291 [Gather] inputs: [671 -> (3)[INT32]], [672 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 672 for ONNX node: 672
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_291 for ONNX node: Gather_291
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 673 for ONNX tensor: 673
[06/10/2022-19:21:30] [V] [TRT] Gather_291 [Gather] outputs: [673 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_292 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 667
[06/10/2022-19:21:30] [V] [TRT] Transpose_292 [Transpose] inputs: [667 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_292 for ONNX node: Transpose_292
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 674 for ONNX tensor: 674
[06/10/2022-19:21:30] [V] [TRT] Transpose_292 [Transpose] outputs: [674 -> (-1, 256, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_293 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 670
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_293 [Unsqueeze] inputs: [670 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_293 for ONNX node: Unsqueeze_293
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 675 for ONNX tensor: 675
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_293 [Unsqueeze] outputs: [675 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_294 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 673
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_294 [Unsqueeze] inputs: [673 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_294 for ONNX node: Unsqueeze_294
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 676 for ONNX tensor: 676
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_294 [Unsqueeze] outputs: [676 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_297 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 675
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 676
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 677
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 678
[06/10/2022-19:21:30] [V] [TRT] Concat_297 [Concat] inputs: [675 -> (1)[INT32]], [676 -> (1)[INT32]], [677 -> (1)[INT32]], [678 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 677 for ONNX node: 677
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 678 for ONNX node: 678
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_297 for ONNX node: Concat_297
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 679 for ONNX tensor: 679
[06/10/2022-19:21:30] [V] [TRT] Concat_297 [Concat] outputs: [679 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_298 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 674
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 679
[06/10/2022-19:21:30] [V] [TRT] Reshape_298 [Reshape] inputs: [674 -> (-1, 256, 65536)[FLOAT]], [679 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_298 for ONNX node: Reshape_298
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 680 for ONNX tensor: 680
[06/10/2022-19:21:30] [V] [TRT] Reshape_298 [Reshape] outputs: [680 -> (-1, 256, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_299 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 680
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_299 [Conv] inputs: [680 -> (-1, 256, 256, 256)[FLOAT]], [backbone.block1.1.mlp.dwconv.dwconv.weight -> (256, 1, 3, 3)[FLOAT]], [backbone.block1.1.mlp.dwconv.dwconv.bias -> (256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 256, 256, 256)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_299 for ONNX node: Conv_299
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 256, 256, 256)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 681 for ONNX tensor: 681
[06/10/2022-19:21:30] [V] [TRT] Conv_299 [Conv] outputs: [681 -> (-1, 256, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_300 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 681
[06/10/2022-19:21:30] [V] [TRT] Shape_300 [Shape] inputs: [681 -> (-1, 256, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_300 for ONNX node: Shape_300
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 682 for ONNX tensor: 682
[06/10/2022-19:21:30] [V] [TRT] Shape_300 [Shape] outputs: [682 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_304 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 682
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 684
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 685
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 683
[06/10/2022-19:21:30] [V] [TRT] Slice_304 [Slice] inputs: [682 -> (4)[INT32]], [684 -> (1)[INT32]], [685 -> (1)[INT32]], [683 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_304 for ONNX node: Slice_304
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 686 for ONNX tensor: 686
[06/10/2022-19:21:30] [V] [TRT] Slice_304 [Slice] outputs: [686 -> (2)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_306 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 686
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 687
[06/10/2022-19:21:30] [V] [TRT] Concat_306 [Concat] inputs: [686 -> (2)[INT32]], [687 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 687 for ONNX node: 687
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_306 for ONNX node: Concat_306
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 688 for ONNX tensor: 688
[06/10/2022-19:21:30] [V] [TRT] Concat_306 [Concat] outputs: [688 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_307 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 681
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 688
[06/10/2022-19:21:30] [V] [TRT] Reshape_307 [Reshape] inputs: [681 -> (-1, 256, 256, 256)[FLOAT]], [688 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_307 for ONNX node: Reshape_307
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 689 for ONNX tensor: 689
[06/10/2022-19:21:30] [V] [TRT] Reshape_307 [Reshape] outputs: [689 -> (-1, 256, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_308 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 689
[06/10/2022-19:21:30] [V] [TRT] Transpose_308 [Transpose] inputs: [689 -> (-1, 256, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_308 for ONNX node: Transpose_308
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 690 for ONNX tensor: 690
[06/10/2022-19:21:30] [V] [TRT] Transpose_308 [Transpose] outputs: [690 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_310 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 690
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 691
[06/10/2022-19:21:30] [V] [TRT] Div_310 [Div] inputs: [690 -> (-1, 65536, 256)[FLOAT]], [691 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 691 for ONNX node: 691
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_310 for ONNX node: Div_310
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 692 for ONNX tensor: 692
[06/10/2022-19:21:30] [V] [TRT] Div_310 [Div] outputs: [692 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Erf_311 [Erf]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 692
[06/10/2022-19:21:30] [V] [TRT] Erf_311 [Erf] inputs: [692 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Erf_311 for ONNX node: Erf_311
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 693 for ONNX tensor: 693
[06/10/2022-19:21:30] [V] [TRT] Erf_311 [Erf] outputs: [693 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_313 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 693
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 694
[06/10/2022-19:21:30] [V] [TRT] Add_313 [Add] inputs: [693 -> (-1, 65536, 256)[FLOAT]], [694 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 694 for ONNX node: 694
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_313 for ONNX node: Add_313
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 695 for ONNX tensor: 695
[06/10/2022-19:21:30] [V] [TRT] Add_313 [Add] outputs: [695 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_314 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 690
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 695
[06/10/2022-19:21:30] [V] [TRT] Mul_314 [Mul] inputs: [690 -> (-1, 65536, 256)[FLOAT]], [695 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_314 for ONNX node: Mul_314
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 696 for ONNX tensor: 696
[06/10/2022-19:21:30] [V] [TRT] Mul_314 [Mul] outputs: [696 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_316 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 696
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 697
[06/10/2022-19:21:30] [V] [TRT] Mul_316 [Mul] inputs: [696 -> (-1, 65536, 256)[FLOAT]], [697 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 697 for ONNX node: 697
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_316 for ONNX node: Mul_316
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 698 for ONNX tensor: 698
[06/10/2022-19:21:30] [V] [TRT] Mul_316 [Mul] outputs: [698 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_317 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 698
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3078
[06/10/2022-19:21:30] [V] [TRT] MatMul_317 [MatMul] inputs: [698 -> (-1, 65536, 256)[FLOAT]], [3078 -> (256, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3078 for ONNX node: 3078
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_317 for ONNX node: MatMul_317
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 700 for ONNX tensor: 700
[06/10/2022-19:21:30] [V] [TRT] MatMul_317 [MatMul] outputs: [700 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_318 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 700
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.1.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_318 [Add] inputs: [700 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.1.mlp.fc2.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.1.mlp.fc2.bias for ONNX node: backbone.block1.1.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_318 for ONNX node: Add_318
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 701 for ONNX tensor: 701
[06/10/2022-19:21:30] [V] [TRT] Add_318 [Add] outputs: [701 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_319 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 653
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 701
[06/10/2022-19:21:30] [V] [TRT] Add_319 [Add] inputs: [653 -> (-1, 65536, 64)[FLOAT]], [701 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_319 for ONNX node: Add_319
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 702 for ONNX tensor: 702
[06/10/2022-19:21:30] [V] [TRT] Add_319 [Add] outputs: [702 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_320 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 702
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_320 [ReduceMean] inputs: [702 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_320 for ONNX node: ReduceMean_320
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 703 for ONNX tensor: 703
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_320 [ReduceMean] outputs: [703 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_321 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 702
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 703
[06/10/2022-19:21:30] [V] [TRT] Sub_321 [Sub] inputs: [702 -> (-1, 65536, 64)[FLOAT]], [703 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_321 for ONNX node: Sub_321
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 704 for ONNX tensor: 704
[06/10/2022-19:21:30] [V] [TRT] Sub_321 [Sub] outputs: [704 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_323 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 704
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 705
[06/10/2022-19:21:30] [V] [TRT] Pow_323 [Pow] inputs: [704 -> (-1, 65536, 64)[FLOAT]], [705 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 705 for ONNX node: 705
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_323 for ONNX node: Pow_323
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 706 for ONNX tensor: 706
[06/10/2022-19:21:30] [V] [TRT] Pow_323 [Pow] outputs: [706 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_324 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 706
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_324 [ReduceMean] inputs: [706 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_324 for ONNX node: ReduceMean_324
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 707 for ONNX tensor: 707
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_324 [ReduceMean] outputs: [707 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_326 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 707
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 708
[06/10/2022-19:21:30] [V] [TRT] Add_326 [Add] inputs: [707 -> (-1, 65536, 1)[FLOAT]], [708 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 708 for ONNX node: 708
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_326 for ONNX node: Add_326
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 709 for ONNX tensor: 709
[06/10/2022-19:21:30] [V] [TRT] Add_326 [Add] outputs: [709 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_327 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 709
[06/10/2022-19:21:30] [V] [TRT] Sqrt_327 [Sqrt] inputs: [709 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_327 for ONNX node: Sqrt_327
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 710 for ONNX tensor: 710
[06/10/2022-19:21:30] [V] [TRT] Sqrt_327 [Sqrt] outputs: [710 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_328 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 704
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 710
[06/10/2022-19:21:30] [V] [TRT] Div_328 [Div] inputs: [704 -> (-1, 65536, 64)[FLOAT]], [710 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_328 for ONNX node: Div_328
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 711 for ONNX tensor: 711
[06/10/2022-19:21:30] [V] [TRT] Div_328 [Div] outputs: [711 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_329 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 711
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_329 [Mul] inputs: [711 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.2.norm1.weight -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.2.norm1.weight for ONNX node: backbone.block1.2.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_329 for ONNX node: Mul_329
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 712 for ONNX tensor: 712
[06/10/2022-19:21:30] [V] [TRT] Mul_329 [Mul] outputs: [712 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_330 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 712
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_330 [Add] inputs: [712 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.2.norm1.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.2.norm1.bias for ONNX node: backbone.block1.2.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_330 for ONNX node: Add_330
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 713 for ONNX tensor: 713
[06/10/2022-19:21:30] [V] [TRT] Add_330 [Add] outputs: [713 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_331 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 713
[06/10/2022-19:21:30] [V] [TRT] Shape_331 [Shape] inputs: [713 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_331 for ONNX node: Shape_331
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 714 for ONNX tensor: 714
[06/10/2022-19:21:30] [V] [TRT] Shape_331 [Shape] outputs: [714 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_333 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 714
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 715
[06/10/2022-19:21:30] [V] [TRT] Gather_333 [Gather] inputs: [714 -> (3)[INT32]], [715 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 715 for ONNX node: 715
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_333 for ONNX node: Gather_333
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 716 for ONNX tensor: 716
[06/10/2022-19:21:30] [V] [TRT] Gather_333 [Gather] outputs: [716 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_334 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 713
[06/10/2022-19:21:30] [V] [TRT] Shape_334 [Shape] inputs: [713 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_334 for ONNX node: Shape_334
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 717 for ONNX tensor: 717
[06/10/2022-19:21:30] [V] [TRT] Shape_334 [Shape] outputs: [717 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_336 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 717
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 718
[06/10/2022-19:21:30] [V] [TRT] Gather_336 [Gather] inputs: [717 -> (3)[INT32]], [718 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 718 for ONNX node: 718
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_336 for ONNX node: Gather_336
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 719 for ONNX tensor: 719
[06/10/2022-19:21:30] [V] [TRT] Gather_336 [Gather] outputs: [719 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_337 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 713
[06/10/2022-19:21:30] [V] [TRT] Shape_337 [Shape] inputs: [713 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_337 for ONNX node: Shape_337
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 720 for ONNX tensor: 720
[06/10/2022-19:21:30] [V] [TRT] Shape_337 [Shape] outputs: [720 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_339 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 720
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 721
[06/10/2022-19:21:30] [V] [TRT] Gather_339 [Gather] inputs: [720 -> (3)[INT32]], [721 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 721 for ONNX node: 721
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_339 for ONNX node: Gather_339
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 722 for ONNX tensor: 722
[06/10/2022-19:21:30] [V] [TRT] Gather_339 [Gather] outputs: [722 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_340 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 713
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3079
[06/10/2022-19:21:30] [V] [TRT] MatMul_340 [MatMul] inputs: [713 -> (-1, 65536, 64)[FLOAT]], [3079 -> (64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3079 for ONNX node: 3079
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_340 for ONNX node: MatMul_340
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 724 for ONNX tensor: 724
[06/10/2022-19:21:30] [V] [TRT] MatMul_340 [MatMul] outputs: [724 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_341 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 724
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Add_341 [Add] inputs: [724 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.2.attn.q.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.2.attn.q.bias for ONNX node: backbone.block1.2.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_341 for ONNX node: Add_341
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 725 for ONNX tensor: 725
[06/10/2022-19:21:30] [V] [TRT] Add_341 [Add] outputs: [725 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_343 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 722
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 726
[06/10/2022-19:21:30] [V] [TRT] Div_343 [Div] inputs: [722 -> ()[INT32]], [726 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 726 for ONNX node: 726
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_343 for ONNX node: Div_343
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 727 for ONNX tensor: 727
[06/10/2022-19:21:30] [V] [TRT] Div_343 [Div] outputs: [727 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_344 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 727
[06/10/2022-19:21:30] [V] [TRT] Cast_344 [Cast] inputs: [727 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_344 for ONNX node: Cast_344
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 728 for ONNX tensor: 728
[06/10/2022-19:21:30] [V] [TRT] Cast_344 [Cast] outputs: [728 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_345 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 728
[06/10/2022-19:21:30] [V] [TRT] Cast_345 [Cast] inputs: [728 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_345 for ONNX node: Cast_345
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 729 for ONNX tensor: 729
[06/10/2022-19:21:30] [V] [TRT] Cast_345 [Cast] outputs: [729 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_346 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 716
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_346 [Unsqueeze] inputs: [716 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_346 for ONNX node: Unsqueeze_346
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 731 for ONNX tensor: 731
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_346 [Unsqueeze] outputs: [731 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_347 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 719
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_347 [Unsqueeze] inputs: [719 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_347 for ONNX node: Unsqueeze_347
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 732 for ONNX tensor: 732
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_347 [Unsqueeze] outputs: [732 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_348 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 729
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_348 [Unsqueeze] inputs: [729 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_348 for ONNX node: Unsqueeze_348
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 734 for ONNX tensor: 734
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_348 [Unsqueeze] outputs: [734 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_349 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 731
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 732
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3080
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 734
[06/10/2022-19:21:30] [V] [TRT] Concat_349 [Concat] inputs: [731 -> (1)[INT32]], [732 -> (1)[INT32]], [3080 -> (1)[INT32]], [734 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3080 for ONNX node: 3080
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_349 for ONNX node: Concat_349
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 735 for ONNX tensor: 735
[06/10/2022-19:21:30] [V] [TRT] Concat_349 [Concat] outputs: [735 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_350 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 725
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 735
[06/10/2022-19:21:30] [V] [TRT] Reshape_350 [Reshape] inputs: [725 -> (-1, 65536, 64)[FLOAT]], [735 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_350 for ONNX node: Reshape_350
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 736 for ONNX tensor: 736
[06/10/2022-19:21:30] [V] [TRT] Reshape_350 [Reshape] outputs: [736 -> (-1, 65536, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_351 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 736
[06/10/2022-19:21:30] [V] [TRT] Transpose_351 [Transpose] inputs: [736 -> (-1, 65536, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_351 for ONNX node: Transpose_351
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 737 for ONNX tensor: 737
[06/10/2022-19:21:30] [V] [TRT] Transpose_351 [Transpose] outputs: [737 -> (-1, 1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_352 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 713
[06/10/2022-19:21:30] [V] [TRT] Transpose_352 [Transpose] inputs: [713 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_352 for ONNX node: Transpose_352
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 738 for ONNX tensor: 738
[06/10/2022-19:21:30] [V] [TRT] Transpose_352 [Transpose] outputs: [738 -> (-1, 64, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_353 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 716
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_353 [Unsqueeze] inputs: [716 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_353 for ONNX node: Unsqueeze_353
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 739 for ONNX tensor: 739
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_353 [Unsqueeze] outputs: [739 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_354 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 722
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_354 [Unsqueeze] inputs: [722 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_354 for ONNX node: Unsqueeze_354
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 740 for ONNX tensor: 740
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_354 [Unsqueeze] outputs: [740 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_357 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 739
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 740
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 741
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 742
[06/10/2022-19:21:30] [V] [TRT] Concat_357 [Concat] inputs: [739 -> (1)[INT32]], [740 -> (1)[INT32]], [741 -> (1)[INT32]], [742 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 741 for ONNX node: 741
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 742 for ONNX node: 742
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_357 for ONNX node: Concat_357
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 743 for ONNX tensor: 743
[06/10/2022-19:21:30] [V] [TRT] Concat_357 [Concat] outputs: [743 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_358 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 738
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 743
[06/10/2022-19:21:30] [V] [TRT] Reshape_358 [Reshape] inputs: [738 -> (-1, 64, 65536)[FLOAT]], [743 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_358 for ONNX node: Reshape_358
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 744 for ONNX tensor: 744
[06/10/2022-19:21:30] [V] [TRT] Reshape_358 [Reshape] outputs: [744 -> (-1, 64, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_359 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 744
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_359 [Conv] inputs: [744 -> (-1, 64, 256, 256)[FLOAT]], [backbone.block1.2.attn.sr.weight -> (64, 64, 8, 8)[FLOAT]], [backbone.block1.2.attn.sr.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 64, 256, 256)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_359 for ONNX node: Conv_359
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (8, 8), strides: (8, 8), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 64, 32, 32)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 745 for ONNX tensor: 745
[06/10/2022-19:21:30] [V] [TRT] Conv_359 [Conv] outputs: [745 -> (-1, 64, 32, 32)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_360 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 716
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_360 [Unsqueeze] inputs: [716 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_360 for ONNX node: Unsqueeze_360
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 747 for ONNX tensor: 747
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_360 [Unsqueeze] outputs: [747 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_361 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 722
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_361 [Unsqueeze] inputs: [722 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_361 for ONNX node: Unsqueeze_361
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 748 for ONNX tensor: 748
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_361 [Unsqueeze] outputs: [748 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_362 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 747
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 748
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3081
[06/10/2022-19:21:30] [V] [TRT] Concat_362 [Concat] inputs: [747 -> (1)[INT32]], [748 -> (1)[INT32]], [3081 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3081 for ONNX node: 3081
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_362 for ONNX node: Concat_362
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 750 for ONNX tensor: 750
[06/10/2022-19:21:30] [V] [TRT] Concat_362 [Concat] outputs: [750 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_363 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 745
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 750
[06/10/2022-19:21:30] [V] [TRT] Reshape_363 [Reshape] inputs: [745 -> (-1, 64, 32, 32)[FLOAT]], [750 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_363 for ONNX node: Reshape_363
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 751 for ONNX tensor: 751
[06/10/2022-19:21:30] [V] [TRT] Reshape_363 [Reshape] outputs: [751 -> (-1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_364 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 751
[06/10/2022-19:21:30] [V] [TRT] Transpose_364 [Transpose] inputs: [751 -> (-1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_364 for ONNX node: Transpose_364
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 752 for ONNX tensor: 752
[06/10/2022-19:21:30] [V] [TRT] Transpose_364 [Transpose] outputs: [752 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_365 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 752
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_365 [ReduceMean] inputs: [752 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_365 for ONNX node: ReduceMean_365
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 753 for ONNX tensor: 753
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_365 [ReduceMean] outputs: [753 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_366 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 752
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 753
[06/10/2022-19:21:30] [V] [TRT] Sub_366 [Sub] inputs: [752 -> (-1, 1024, 64)[FLOAT]], [753 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_366 for ONNX node: Sub_366
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 754 for ONNX tensor: 754
[06/10/2022-19:21:30] [V] [TRT] Sub_366 [Sub] outputs: [754 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_368 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 754
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 755
[06/10/2022-19:21:30] [V] [TRT] Pow_368 [Pow] inputs: [754 -> (-1, 1024, 64)[FLOAT]], [755 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 755 for ONNX node: 755
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_368 for ONNX node: Pow_368
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 756 for ONNX tensor: 756
[06/10/2022-19:21:30] [V] [TRT] Pow_368 [Pow] outputs: [756 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_369 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 756
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_369 [ReduceMean] inputs: [756 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_369 for ONNX node: ReduceMean_369
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 757 for ONNX tensor: 757
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_369 [ReduceMean] outputs: [757 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_371 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 757
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 758
[06/10/2022-19:21:30] [V] [TRT] Add_371 [Add] inputs: [757 -> (-1, 1024, 1)[FLOAT]], [758 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 758 for ONNX node: 758
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_371 for ONNX node: Add_371
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 759 for ONNX tensor: 759
[06/10/2022-19:21:30] [V] [TRT] Add_371 [Add] outputs: [759 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_372 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 759
[06/10/2022-19:21:30] [V] [TRT] Sqrt_372 [Sqrt] inputs: [759 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_372 for ONNX node: Sqrt_372
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 760 for ONNX tensor: 760
[06/10/2022-19:21:30] [V] [TRT] Sqrt_372 [Sqrt] outputs: [760 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_373 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 754
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 760
[06/10/2022-19:21:30] [V] [TRT] Div_373 [Div] inputs: [754 -> (-1, 1024, 64)[FLOAT]], [760 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_373 for ONNX node: Div_373
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 761 for ONNX tensor: 761
[06/10/2022-19:21:30] [V] [TRT] Div_373 [Div] outputs: [761 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_374 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 761
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_374 [Mul] inputs: [761 -> (-1, 1024, 64)[FLOAT]], [backbone.block1.2.attn.norm.weight -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.2.attn.norm.weight for ONNX node: backbone.block1.2.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_374 for ONNX node: Mul_374
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 762 for ONNX tensor: 762
[06/10/2022-19:21:30] [V] [TRT] Mul_374 [Mul] outputs: [762 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_375 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 762
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Add_375 [Add] inputs: [762 -> (-1, 1024, 64)[FLOAT]], [backbone.block1.2.attn.norm.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.2.attn.norm.bias for ONNX node: backbone.block1.2.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_375 for ONNX node: Add_375
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 763 for ONNX tensor: 763
[06/10/2022-19:21:30] [V] [TRT] Add_375 [Add] outputs: [763 -> (-1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_376 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 763
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3082
[06/10/2022-19:21:30] [V] [TRT] MatMul_376 [MatMul] inputs: [763 -> (-1, 1024, 64)[FLOAT]], [3082 -> (64, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3082 for ONNX node: 3082
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_376 for ONNX node: MatMul_376
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 765 for ONNX tensor: 765
[06/10/2022-19:21:30] [V] [TRT] MatMul_376 [MatMul] outputs: [765 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_377 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 765
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Add_377 [Add] inputs: [765 -> (-1, 1024, 128)[FLOAT]], [backbone.block1.2.attn.kv.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.2.attn.kv.bias for ONNX node: backbone.block1.2.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_377 for ONNX node: Add_377
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 766 for ONNX tensor: 766
[06/10/2022-19:21:30] [V] [TRT] Add_377 [Add] outputs: [766 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_379 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 722
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 767
[06/10/2022-19:21:30] [V] [TRT] Div_379 [Div] inputs: [722 -> ()[INT32]], [767 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 767 for ONNX node: 767
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_379 for ONNX node: Div_379
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 768 for ONNX tensor: 768
[06/10/2022-19:21:30] [V] [TRT] Div_379 [Div] outputs: [768 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_380 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 768
[06/10/2022-19:21:30] [V] [TRT] Cast_380 [Cast] inputs: [768 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_380 for ONNX node: Cast_380
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 769 for ONNX tensor: 769
[06/10/2022-19:21:30] [V] [TRT] Cast_380 [Cast] outputs: [769 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_381 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 769
[06/10/2022-19:21:30] [V] [TRT] Cast_381 [Cast] inputs: [769 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_381 for ONNX node: Cast_381
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 770 for ONNX tensor: 770
[06/10/2022-19:21:30] [V] [TRT] Cast_381 [Cast] outputs: [770 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_382 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 716
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_382 [Unsqueeze] inputs: [716 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_382 for ONNX node: Unsqueeze_382
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 774 for ONNX tensor: 774
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_382 [Unsqueeze] outputs: [774 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_383 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 770
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_383 [Unsqueeze] inputs: [770 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_383 for ONNX node: Unsqueeze_383
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 778 for ONNX tensor: 778
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_383 [Unsqueeze] outputs: [778 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_384 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 774
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3083
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3084
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3085
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 778
[06/10/2022-19:21:30] [V] [TRT] Concat_384 [Concat] inputs: [774 -> (1)[INT32]], [3083 -> (1)[INT32]], [3084 -> (1)[INT32]], [3085 -> (1)[INT32]], [778 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3083 for ONNX node: 3083
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3084 for ONNX node: 3084
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3085 for ONNX node: 3085
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_384 for ONNX node: Concat_384
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 779 for ONNX tensor: 779
[06/10/2022-19:21:30] [V] [TRT] Concat_384 [Concat] outputs: [779 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_385 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 766
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 779
[06/10/2022-19:21:30] [V] [TRT] Reshape_385 [Reshape] inputs: [766 -> (-1, 1024, 128)[FLOAT]], [779 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_385 for ONNX node: Reshape_385
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 780 for ONNX tensor: 780
[06/10/2022-19:21:30] [V] [TRT] Reshape_385 [Reshape] outputs: [780 -> (-1, 1024, 2, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_386 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 780
[06/10/2022-19:21:30] [V] [TRT] Transpose_386 [Transpose] inputs: [780 -> (-1, 1024, 2, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_386 for ONNX node: Transpose_386
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 781 for ONNX tensor: 781
[06/10/2022-19:21:30] [V] [TRT] Transpose_386 [Transpose] outputs: [781 -> (2, -1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_388 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 781
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 782
[06/10/2022-19:21:30] [V] [TRT] Gather_388 [Gather] inputs: [781 -> (2, -1, 1, 1024, 64)[FLOAT]], [782 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 782 for ONNX node: 782
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_388 for ONNX node: Gather_388
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 783 for ONNX tensor: 783
[06/10/2022-19:21:30] [V] [TRT] Gather_388 [Gather] outputs: [783 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_390 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 781
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 784
[06/10/2022-19:21:30] [V] [TRT] Gather_390 [Gather] inputs: [781 -> (2, -1, 1, 1024, 64)[FLOAT]], [784 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 784 for ONNX node: 784
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_390 for ONNX node: Gather_390
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 785 for ONNX tensor: 785
[06/10/2022-19:21:30] [V] [TRT] Gather_390 [Gather] outputs: [785 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_391 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 783
[06/10/2022-19:21:30] [V] [TRT] Transpose_391 [Transpose] inputs: [783 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_391 for ONNX node: Transpose_391
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 786 for ONNX tensor: 786
[06/10/2022-19:21:30] [V] [TRT] Transpose_391 [Transpose] outputs: [786 -> (-1, 1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_392 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 737
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 786
[06/10/2022-19:21:30] [V] [TRT] MatMul_392 [MatMul] inputs: [737 -> (-1, 1, 65536, 64)[FLOAT]], [786 -> (-1, 1, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_392 for ONNX node: MatMul_392
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 787 for ONNX tensor: 787
[06/10/2022-19:21:30] [V] [TRT] MatMul_392 [MatMul] outputs: [787 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_394 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 787
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 788
[06/10/2022-19:21:30] [V] [TRT] Mul_394 [Mul] inputs: [787 -> (-1, 1, 65536, 1024)[FLOAT]], [788 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 788 for ONNX node: 788
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_394 for ONNX node: Mul_394
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 789 for ONNX tensor: 789
[06/10/2022-19:21:30] [V] [TRT] Mul_394 [Mul] outputs: [789 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Softmax_395 [Softmax]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 789
[06/10/2022-19:21:30] [V] [TRT] Softmax_395 [Softmax] inputs: [789 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Softmax_395 for ONNX node: Softmax_395
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 790 for ONNX tensor: 790
[06/10/2022-19:21:30] [V] [TRT] Softmax_395 [Softmax] outputs: [790 -> (-1, 1, 65536, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_396 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 790
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 785
[06/10/2022-19:21:30] [V] [TRT] MatMul_396 [MatMul] inputs: [790 -> (-1, 1, 65536, 1024)[FLOAT]], [785 -> (-1, 1, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_396 for ONNX node: MatMul_396
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 791 for ONNX tensor: 791
[06/10/2022-19:21:30] [V] [TRT] MatMul_396 [MatMul] outputs: [791 -> (-1, 1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_397 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 791
[06/10/2022-19:21:30] [V] [TRT] Transpose_397 [Transpose] inputs: [791 -> (-1, 1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_397 for ONNX node: Transpose_397
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 792 for ONNX tensor: 792
[06/10/2022-19:21:30] [V] [TRT] Transpose_397 [Transpose] outputs: [792 -> (-1, 65536, 1, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_398 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 716
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_398 [Unsqueeze] inputs: [716 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_398 for ONNX node: Unsqueeze_398
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 793 for ONNX tensor: 793
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_398 [Unsqueeze] outputs: [793 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_399 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 719
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_399 [Unsqueeze] inputs: [719 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_399 for ONNX node: Unsqueeze_399
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 794 for ONNX tensor: 794
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_399 [Unsqueeze] outputs: [794 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_400 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 722
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_400 [Unsqueeze] inputs: [722 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_400 for ONNX node: Unsqueeze_400
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 795 for ONNX tensor: 795
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_400 [Unsqueeze] outputs: [795 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_401 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 793
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 794
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 795
[06/10/2022-19:21:30] [V] [TRT] Concat_401 [Concat] inputs: [793 -> (1)[INT32]], [794 -> (1)[INT32]], [795 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_401 for ONNX node: Concat_401
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 796 for ONNX tensor: 796
[06/10/2022-19:21:30] [V] [TRT] Concat_401 [Concat] outputs: [796 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_402 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 792
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 796
[06/10/2022-19:21:30] [V] [TRT] Reshape_402 [Reshape] inputs: [792 -> (-1, 65536, 1, 64)[FLOAT]], [796 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_402 for ONNX node: Reshape_402
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 797 for ONNX tensor: 797
[06/10/2022-19:21:30] [V] [TRT] Reshape_402 [Reshape] outputs: [797 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_403 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 797
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3086
[06/10/2022-19:21:30] [V] [TRT] MatMul_403 [MatMul] inputs: [797 -> (-1, 65536, 64)[FLOAT]], [3086 -> (64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3086 for ONNX node: 3086
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_403 for ONNX node: MatMul_403
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 799 for ONNX tensor: 799
[06/10/2022-19:21:30] [V] [TRT] MatMul_403 [MatMul] outputs: [799 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_404 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 799
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Add_404 [Add] inputs: [799 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.2.attn.proj.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.2.attn.proj.bias for ONNX node: backbone.block1.2.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_404 for ONNX node: Add_404
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 800 for ONNX tensor: 800
[06/10/2022-19:21:30] [V] [TRT] Add_404 [Add] outputs: [800 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_405 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 702
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 800
[06/10/2022-19:21:30] [V] [TRT] Add_405 [Add] inputs: [702 -> (-1, 65536, 64)[FLOAT]], [800 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_405 for ONNX node: Add_405
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 801 for ONNX tensor: 801
[06/10/2022-19:21:30] [V] [TRT] Add_405 [Add] outputs: [801 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_406 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 801
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_406 [ReduceMean] inputs: [801 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_406 for ONNX node: ReduceMean_406
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 802 for ONNX tensor: 802
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_406 [ReduceMean] outputs: [802 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_407 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 801
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 802
[06/10/2022-19:21:30] [V] [TRT] Sub_407 [Sub] inputs: [801 -> (-1, 65536, 64)[FLOAT]], [802 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_407 for ONNX node: Sub_407
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 803 for ONNX tensor: 803
[06/10/2022-19:21:30] [V] [TRT] Sub_407 [Sub] outputs: [803 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_409 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 803
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 804
[06/10/2022-19:21:30] [V] [TRT] Pow_409 [Pow] inputs: [803 -> (-1, 65536, 64)[FLOAT]], [804 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 804 for ONNX node: 804
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_409 for ONNX node: Pow_409
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 805 for ONNX tensor: 805
[06/10/2022-19:21:30] [V] [TRT] Pow_409 [Pow] outputs: [805 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_410 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 805
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_410 [ReduceMean] inputs: [805 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_410 for ONNX node: ReduceMean_410
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 806 for ONNX tensor: 806
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_410 [ReduceMean] outputs: [806 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_412 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 806
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 807
[06/10/2022-19:21:30] [V] [TRT] Add_412 [Add] inputs: [806 -> (-1, 65536, 1)[FLOAT]], [807 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 807 for ONNX node: 807
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_412 for ONNX node: Add_412
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 808 for ONNX tensor: 808
[06/10/2022-19:21:30] [V] [TRT] Add_412 [Add] outputs: [808 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_413 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 808
[06/10/2022-19:21:30] [V] [TRT] Sqrt_413 [Sqrt] inputs: [808 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_413 for ONNX node: Sqrt_413
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 809 for ONNX tensor: 809
[06/10/2022-19:21:30] [V] [TRT] Sqrt_413 [Sqrt] outputs: [809 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_414 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 803
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 809
[06/10/2022-19:21:30] [V] [TRT] Div_414 [Div] inputs: [803 -> (-1, 65536, 64)[FLOAT]], [809 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_414 for ONNX node: Div_414
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 810 for ONNX tensor: 810
[06/10/2022-19:21:30] [V] [TRT] Div_414 [Div] outputs: [810 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_415 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 810
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_415 [Mul] inputs: [810 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.2.norm2.weight -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.2.norm2.weight for ONNX node: backbone.block1.2.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_415 for ONNX node: Mul_415
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 811 for ONNX tensor: 811
[06/10/2022-19:21:30] [V] [TRT] Mul_415 [Mul] outputs: [811 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_416 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 811
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_416 [Add] inputs: [811 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.2.norm2.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.2.norm2.bias for ONNX node: backbone.block1.2.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_416 for ONNX node: Add_416
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 812 for ONNX tensor: 812
[06/10/2022-19:21:30] [V] [TRT] Add_416 [Add] outputs: [812 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_417 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 812
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3087
[06/10/2022-19:21:30] [V] [TRT] MatMul_417 [MatMul] inputs: [812 -> (-1, 65536, 64)[FLOAT]], [3087 -> (64, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3087 for ONNX node: 3087
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_417 for ONNX node: MatMul_417
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 814 for ONNX tensor: 814
[06/10/2022-19:21:30] [V] [TRT] MatMul_417 [MatMul] outputs: [814 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_418 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 814
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_418 [Add] inputs: [814 -> (-1, 65536, 256)[FLOAT]], [backbone.block1.2.mlp.fc1.bias -> (256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.2.mlp.fc1.bias for ONNX node: backbone.block1.2.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_418 for ONNX node: Add_418
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 815 for ONNX tensor: 815
[06/10/2022-19:21:30] [V] [TRT] Add_418 [Add] outputs: [815 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_419 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 815
[06/10/2022-19:21:30] [V] [TRT] Shape_419 [Shape] inputs: [815 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_419 for ONNX node: Shape_419
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 816 for ONNX tensor: 816
[06/10/2022-19:21:30] [V] [TRT] Shape_419 [Shape] outputs: [816 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_421 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 816
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 817
[06/10/2022-19:21:30] [V] [TRT] Gather_421 [Gather] inputs: [816 -> (3)[INT32]], [817 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 817 for ONNX node: 817
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_421 for ONNX node: Gather_421
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 818 for ONNX tensor: 818
[06/10/2022-19:21:30] [V] [TRT] Gather_421 [Gather] outputs: [818 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_422 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 815
[06/10/2022-19:21:30] [V] [TRT] Shape_422 [Shape] inputs: [815 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_422 for ONNX node: Shape_422
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 819 for ONNX tensor: 819
[06/10/2022-19:21:30] [V] [TRT] Shape_422 [Shape] outputs: [819 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_424 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 819
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 820
[06/10/2022-19:21:30] [V] [TRT] Gather_424 [Gather] inputs: [819 -> (3)[INT32]], [820 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 820 for ONNX node: 820
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_424 for ONNX node: Gather_424
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 821 for ONNX tensor: 821
[06/10/2022-19:21:30] [V] [TRT] Gather_424 [Gather] outputs: [821 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_425 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 815
[06/10/2022-19:21:30] [V] [TRT] Transpose_425 [Transpose] inputs: [815 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_425 for ONNX node: Transpose_425
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 822 for ONNX tensor: 822
[06/10/2022-19:21:30] [V] [TRT] Transpose_425 [Transpose] outputs: [822 -> (-1, 256, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_426 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 818
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_426 [Unsqueeze] inputs: [818 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_426 for ONNX node: Unsqueeze_426
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 823 for ONNX tensor: 823
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_426 [Unsqueeze] outputs: [823 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_427 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 821
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_427 [Unsqueeze] inputs: [821 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_427 for ONNX node: Unsqueeze_427
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 824 for ONNX tensor: 824
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_427 [Unsqueeze] outputs: [824 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_430 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 823
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 824
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 825
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 826
[06/10/2022-19:21:30] [V] [TRT] Concat_430 [Concat] inputs: [823 -> (1)[INT32]], [824 -> (1)[INT32]], [825 -> (1)[INT32]], [826 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 825 for ONNX node: 825
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 826 for ONNX node: 826
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_430 for ONNX node: Concat_430
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 827 for ONNX tensor: 827
[06/10/2022-19:21:30] [V] [TRT] Concat_430 [Concat] outputs: [827 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_431 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 822
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 827
[06/10/2022-19:21:30] [V] [TRT] Reshape_431 [Reshape] inputs: [822 -> (-1, 256, 65536)[FLOAT]], [827 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_431 for ONNX node: Reshape_431
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 828 for ONNX tensor: 828
[06/10/2022-19:21:30] [V] [TRT] Reshape_431 [Reshape] outputs: [828 -> (-1, 256, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_432 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 828
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_432 [Conv] inputs: [828 -> (-1, 256, 256, 256)[FLOAT]], [backbone.block1.2.mlp.dwconv.dwconv.weight -> (256, 1, 3, 3)[FLOAT]], [backbone.block1.2.mlp.dwconv.dwconv.bias -> (256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 256, 256, 256)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_432 for ONNX node: Conv_432
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 256, 256, 256)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 829 for ONNX tensor: 829
[06/10/2022-19:21:30] [V] [TRT] Conv_432 [Conv] outputs: [829 -> (-1, 256, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_433 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 829
[06/10/2022-19:21:30] [V] [TRT] Shape_433 [Shape] inputs: [829 -> (-1, 256, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_433 for ONNX node: Shape_433
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 830 for ONNX tensor: 830
[06/10/2022-19:21:30] [V] [TRT] Shape_433 [Shape] outputs: [830 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_437 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 830
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 832
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 833
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 831
[06/10/2022-19:21:30] [V] [TRT] Slice_437 [Slice] inputs: [830 -> (4)[INT32]], [832 -> (1)[INT32]], [833 -> (1)[INT32]], [831 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_437 for ONNX node: Slice_437
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 834 for ONNX tensor: 834
[06/10/2022-19:21:30] [V] [TRT] Slice_437 [Slice] outputs: [834 -> (2)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_439 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 834
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 835
[06/10/2022-19:21:30] [V] [TRT] Concat_439 [Concat] inputs: [834 -> (2)[INT32]], [835 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 835 for ONNX node: 835
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_439 for ONNX node: Concat_439
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 836 for ONNX tensor: 836
[06/10/2022-19:21:30] [V] [TRT] Concat_439 [Concat] outputs: [836 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_440 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 829
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 836
[06/10/2022-19:21:30] [V] [TRT] Reshape_440 [Reshape] inputs: [829 -> (-1, 256, 256, 256)[FLOAT]], [836 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_440 for ONNX node: Reshape_440
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 837 for ONNX tensor: 837
[06/10/2022-19:21:30] [V] [TRT] Reshape_440 [Reshape] outputs: [837 -> (-1, 256, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_441 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 837
[06/10/2022-19:21:30] [V] [TRT] Transpose_441 [Transpose] inputs: [837 -> (-1, 256, 65536)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_441 for ONNX node: Transpose_441
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 838 for ONNX tensor: 838
[06/10/2022-19:21:30] [V] [TRT] Transpose_441 [Transpose] outputs: [838 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_443 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 838
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 839
[06/10/2022-19:21:30] [V] [TRT] Div_443 [Div] inputs: [838 -> (-1, 65536, 256)[FLOAT]], [839 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 839 for ONNX node: 839
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_443 for ONNX node: Div_443
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 840 for ONNX tensor: 840
[06/10/2022-19:21:30] [V] [TRT] Div_443 [Div] outputs: [840 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Erf_444 [Erf]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 840
[06/10/2022-19:21:30] [V] [TRT] Erf_444 [Erf] inputs: [840 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Erf_444 for ONNX node: Erf_444
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 841 for ONNX tensor: 841
[06/10/2022-19:21:30] [V] [TRT] Erf_444 [Erf] outputs: [841 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_446 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 841
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 842
[06/10/2022-19:21:30] [V] [TRT] Add_446 [Add] inputs: [841 -> (-1, 65536, 256)[FLOAT]], [842 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 842 for ONNX node: 842
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_446 for ONNX node: Add_446
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 843 for ONNX tensor: 843
[06/10/2022-19:21:30] [V] [TRT] Add_446 [Add] outputs: [843 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_447 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 838
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 843
[06/10/2022-19:21:30] [V] [TRT] Mul_447 [Mul] inputs: [838 -> (-1, 65536, 256)[FLOAT]], [843 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_447 for ONNX node: Mul_447
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 844 for ONNX tensor: 844
[06/10/2022-19:21:30] [V] [TRT] Mul_447 [Mul] outputs: [844 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_449 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 844
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 845
[06/10/2022-19:21:30] [V] [TRT] Mul_449 [Mul] inputs: [844 -> (-1, 65536, 256)[FLOAT]], [845 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 845 for ONNX node: 845
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_449 for ONNX node: Mul_449
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 846 for ONNX tensor: 846
[06/10/2022-19:21:30] [V] [TRT] Mul_449 [Mul] outputs: [846 -> (-1, 65536, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_450 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 846
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3088
[06/10/2022-19:21:30] [V] [TRT] MatMul_450 [MatMul] inputs: [846 -> (-1, 65536, 256)[FLOAT]], [3088 -> (256, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3088 for ONNX node: 3088
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_450 for ONNX node: MatMul_450
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 848 for ONNX tensor: 848
[06/10/2022-19:21:30] [V] [TRT] MatMul_450 [MatMul] outputs: [848 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_451 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 848
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block1.2.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_451 [Add] inputs: [848 -> (-1, 65536, 64)[FLOAT]], [backbone.block1.2.mlp.fc2.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block1.2.mlp.fc2.bias for ONNX node: backbone.block1.2.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_451 for ONNX node: Add_451
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 849 for ONNX tensor: 849
[06/10/2022-19:21:30] [V] [TRT] Add_451 [Add] outputs: [849 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_452 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 801
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 849
[06/10/2022-19:21:30] [V] [TRT] Add_452 [Add] inputs: [801 -> (-1, 65536, 64)[FLOAT]], [849 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_452 for ONNX node: Add_452
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 850 for ONNX tensor: 850
[06/10/2022-19:21:30] [V] [TRT] Add_452 [Add] outputs: [850 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_453 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 850
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_453 [ReduceMean] inputs: [850 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_453 for ONNX node: ReduceMean_453
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 851 for ONNX tensor: 851
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_453 [ReduceMean] outputs: [851 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_454 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 850
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 851
[06/10/2022-19:21:30] [V] [TRT] Sub_454 [Sub] inputs: [850 -> (-1, 65536, 64)[FLOAT]], [851 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_454 for ONNX node: Sub_454
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 852 for ONNX tensor: 852
[06/10/2022-19:21:30] [V] [TRT] Sub_454 [Sub] outputs: [852 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_456 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 852
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 853
[06/10/2022-19:21:30] [V] [TRT] Pow_456 [Pow] inputs: [852 -> (-1, 65536, 64)[FLOAT]], [853 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 853 for ONNX node: 853
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_456 for ONNX node: Pow_456
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 854 for ONNX tensor: 854
[06/10/2022-19:21:30] [V] [TRT] Pow_456 [Pow] outputs: [854 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_457 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 854
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_457 [ReduceMean] inputs: [854 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_457 for ONNX node: ReduceMean_457
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 855 for ONNX tensor: 855
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_457 [ReduceMean] outputs: [855 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_459 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 855
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 856
[06/10/2022-19:21:30] [V] [TRT] Add_459 [Add] inputs: [855 -> (-1, 65536, 1)[FLOAT]], [856 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 856 for ONNX node: 856
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_459 for ONNX node: Add_459
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 857 for ONNX tensor: 857
[06/10/2022-19:21:30] [V] [TRT] Add_459 [Add] outputs: [857 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_460 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 857
[06/10/2022-19:21:30] [V] [TRT] Sqrt_460 [Sqrt] inputs: [857 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_460 for ONNX node: Sqrt_460
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 858 for ONNX tensor: 858
[06/10/2022-19:21:30] [V] [TRT] Sqrt_460 [Sqrt] outputs: [858 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_461 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 852
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 858
[06/10/2022-19:21:30] [V] [TRT] Div_461 [Div] inputs: [852 -> (-1, 65536, 64)[FLOAT]], [858 -> (-1, 65536, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_461 for ONNX node: Div_461
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 859 for ONNX tensor: 859
[06/10/2022-19:21:30] [V] [TRT] Div_461 [Div] outputs: [859 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_462 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 859
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_462 [Mul] inputs: [859 -> (-1, 65536, 64)[FLOAT]], [backbone.norm1.weight -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.norm1.weight for ONNX node: backbone.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_462 for ONNX node: Mul_462
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 860 for ONNX tensor: 860
[06/10/2022-19:21:30] [V] [TRT] Mul_462 [Mul] outputs: [860 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_463 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 860
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_463 [Add] inputs: [860 -> (-1, 65536, 64)[FLOAT]], [backbone.norm1.bias -> (64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.norm1.bias for ONNX node: backbone.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_463 for ONNX node: Add_463
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 861 for ONNX tensor: 861
[06/10/2022-19:21:30] [V] [TRT] Add_463 [Add] outputs: [861 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_464 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 379
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_464 [Unsqueeze] inputs: [379 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_464 for ONNX node: Unsqueeze_464
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 863 for ONNX tensor: 863
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_464 [Unsqueeze] outputs: [863 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_467 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 863
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 864
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 865
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3089
[06/10/2022-19:21:30] [V] [TRT] Concat_467 [Concat] inputs: [863 -> (1)[INT32]], [864 -> (1)[INT32]], [865 -> (1)[INT32]], [3089 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 864 for ONNX node: 864
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 865 for ONNX node: 865
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3089 for ONNX node: 3089
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_467 for ONNX node: Concat_467
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 867 for ONNX tensor: 867
[06/10/2022-19:21:30] [V] [TRT] Concat_467 [Concat] outputs: [867 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_468 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 861
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 867
[06/10/2022-19:21:30] [V] [TRT] Reshape_468 [Reshape] inputs: [861 -> (-1, 65536, 64)[FLOAT]], [867 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_468 for ONNX node: Reshape_468
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 868 for ONNX tensor: 868
[06/10/2022-19:21:30] [V] [TRT] Reshape_468 [Reshape] outputs: [868 -> (-1, 256, 256, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_469 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 868
[06/10/2022-19:21:30] [V] [TRT] Transpose_469 [Transpose] inputs: [868 -> (-1, 256, 256, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_469 for ONNX node: Transpose_469
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 869 for ONNX tensor: 869
[06/10/2022-19:21:30] [V] [TRT] Transpose_469 [Transpose] outputs: [869 -> (-1, 64, 256, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_470 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 869
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed2.proj.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed2.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_470 [Conv] inputs: [869 -> (-1, 64, 256, 256)[FLOAT]], [backbone.patch_embed2.proj.weight -> (128, 64, 3, 3)[FLOAT]], [backbone.patch_embed2.proj.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 64, 256, 256)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_470 for ONNX node: Conv_470
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 128, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 870 for ONNX tensor: 870
[06/10/2022-19:21:30] [V] [TRT] Conv_470 [Conv] outputs: [870 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_471 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 870
[06/10/2022-19:21:30] [V] [TRT] Shape_471 [Shape] inputs: [870 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_471 for ONNX node: Shape_471
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 871 for ONNX tensor: 871
[06/10/2022-19:21:30] [V] [TRT] Shape_471 [Shape] outputs: [871 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_473 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 871
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 872
[06/10/2022-19:21:30] [V] [TRT] Gather_473 [Gather] inputs: [871 -> (4)[INT32]], [872 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 872 for ONNX node: 872
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_473 for ONNX node: Gather_473
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 873 for ONNX tensor: 873
[06/10/2022-19:21:30] [V] [TRT] Gather_473 [Gather] outputs: [873 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_474 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 870
[06/10/2022-19:21:30] [V] [TRT] Shape_474 [Shape] inputs: [870 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_474 for ONNX node: Shape_474
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 874 for ONNX tensor: 874
[06/10/2022-19:21:30] [V] [TRT] Shape_474 [Shape] outputs: [874 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_476 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 874
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 875
[06/10/2022-19:21:30] [V] [TRT] Gather_476 [Gather] inputs: [874 -> (4)[INT32]], [875 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 875 for ONNX node: 875
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_476 for ONNX node: Gather_476
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 876 for ONNX tensor: 876
[06/10/2022-19:21:30] [V] [TRT] Gather_476 [Gather] outputs: [876 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_477 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 870
[06/10/2022-19:21:30] [V] [TRT] Shape_477 [Shape] inputs: [870 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_477 for ONNX node: Shape_477
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 877 for ONNX tensor: 877
[06/10/2022-19:21:30] [V] [TRT] Shape_477 [Shape] outputs: [877 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_481 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 877
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 879
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 880
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 878
[06/10/2022-19:21:30] [V] [TRT] Slice_481 [Slice] inputs: [877 -> (4)[INT32]], [879 -> (1)[INT32]], [880 -> (1)[INT32]], [878 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_481 for ONNX node: Slice_481
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 881 for ONNX tensor: 881
[06/10/2022-19:21:30] [V] [TRT] Slice_481 [Slice] outputs: [881 -> (2)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_483 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 881
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 882
[06/10/2022-19:21:30] [V] [TRT] Concat_483 [Concat] inputs: [881 -> (2)[INT32]], [882 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 882 for ONNX node: 882
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_483 for ONNX node: Concat_483
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 883 for ONNX tensor: 883
[06/10/2022-19:21:30] [V] [TRT] Concat_483 [Concat] outputs: [883 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_484 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 870
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 883
[06/10/2022-19:21:30] [V] [TRT] Reshape_484 [Reshape] inputs: [870 -> (-1, 128, 128, 128)[FLOAT]], [883 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_484 for ONNX node: Reshape_484
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 884 for ONNX tensor: 884
[06/10/2022-19:21:30] [V] [TRT] Reshape_484 [Reshape] outputs: [884 -> (-1, 128, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_485 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 884
[06/10/2022-19:21:30] [V] [TRT] Transpose_485 [Transpose] inputs: [884 -> (-1, 128, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_485 for ONNX node: Transpose_485
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 885 for ONNX tensor: 885
[06/10/2022-19:21:30] [V] [TRT] Transpose_485 [Transpose] outputs: [885 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_486 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 885
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_486 [ReduceMean] inputs: [885 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_486 for ONNX node: ReduceMean_486
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 886 for ONNX tensor: 886
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_486 [ReduceMean] outputs: [886 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_487 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 885
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 886
[06/10/2022-19:21:30] [V] [TRT] Sub_487 [Sub] inputs: [885 -> (-1, 16384, 128)[FLOAT]], [886 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_487 for ONNX node: Sub_487
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 887 for ONNX tensor: 887
[06/10/2022-19:21:30] [V] [TRT] Sub_487 [Sub] outputs: [887 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_489 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 887
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 888
[06/10/2022-19:21:30] [V] [TRT] Pow_489 [Pow] inputs: [887 -> (-1, 16384, 128)[FLOAT]], [888 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 888 for ONNX node: 888
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_489 for ONNX node: Pow_489
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 889 for ONNX tensor: 889
[06/10/2022-19:21:30] [V] [TRT] Pow_489 [Pow] outputs: [889 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_490 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 889
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_490 [ReduceMean] inputs: [889 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_490 for ONNX node: ReduceMean_490
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 890 for ONNX tensor: 890
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_490 [ReduceMean] outputs: [890 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_492 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 890
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 891
[06/10/2022-19:21:30] [V] [TRT] Add_492 [Add] inputs: [890 -> (-1, 16384, 1)[FLOAT]], [891 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 891 for ONNX node: 891
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_492 for ONNX node: Add_492
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 892 for ONNX tensor: 892
[06/10/2022-19:21:30] [V] [TRT] Add_492 [Add] outputs: [892 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_493 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 892
[06/10/2022-19:21:30] [V] [TRT] Sqrt_493 [Sqrt] inputs: [892 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_493 for ONNX node: Sqrt_493
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 893 for ONNX tensor: 893
[06/10/2022-19:21:30] [V] [TRT] Sqrt_493 [Sqrt] outputs: [893 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_494 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 887
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 893
[06/10/2022-19:21:30] [V] [TRT] Div_494 [Div] inputs: [887 -> (-1, 16384, 128)[FLOAT]], [893 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_494 for ONNX node: Div_494
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 894 for ONNX tensor: 894
[06/10/2022-19:21:30] [V] [TRT] Div_494 [Div] outputs: [894 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_495 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 894
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed2.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_495 [Mul] inputs: [894 -> (-1, 16384, 128)[FLOAT]], [backbone.patch_embed2.norm.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.patch_embed2.norm.weight for ONNX node: backbone.patch_embed2.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_495 for ONNX node: Mul_495
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 895 for ONNX tensor: 895
[06/10/2022-19:21:30] [V] [TRT] Mul_495 [Mul] outputs: [895 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_496 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 895
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed2.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Add_496 [Add] inputs: [895 -> (-1, 16384, 128)[FLOAT]], [backbone.patch_embed2.norm.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.patch_embed2.norm.bias for ONNX node: backbone.patch_embed2.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_496 for ONNX node: Add_496
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 896 for ONNX tensor: 896
[06/10/2022-19:21:30] [V] [TRT] Add_496 [Add] outputs: [896 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_497 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 896
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_497 [ReduceMean] inputs: [896 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_497 for ONNX node: ReduceMean_497
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 897 for ONNX tensor: 897
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_497 [ReduceMean] outputs: [897 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_498 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 896
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 897
[06/10/2022-19:21:30] [V] [TRT] Sub_498 [Sub] inputs: [896 -> (-1, 16384, 128)[FLOAT]], [897 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_498 for ONNX node: Sub_498
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 898 for ONNX tensor: 898
[06/10/2022-19:21:30] [V] [TRT] Sub_498 [Sub] outputs: [898 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_500 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 898
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 899
[06/10/2022-19:21:30] [V] [TRT] Pow_500 [Pow] inputs: [898 -> (-1, 16384, 128)[FLOAT]], [899 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 899 for ONNX node: 899
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_500 for ONNX node: Pow_500
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 900 for ONNX tensor: 900
[06/10/2022-19:21:30] [V] [TRT] Pow_500 [Pow] outputs: [900 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_501 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 900
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_501 [ReduceMean] inputs: [900 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_501 for ONNX node: ReduceMean_501
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 901 for ONNX tensor: 901
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_501 [ReduceMean] outputs: [901 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_503 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 901
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 902
[06/10/2022-19:21:30] [V] [TRT] Add_503 [Add] inputs: [901 -> (-1, 16384, 1)[FLOAT]], [902 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 902 for ONNX node: 902
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_503 for ONNX node: Add_503
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 903 for ONNX tensor: 903
[06/10/2022-19:21:30] [V] [TRT] Add_503 [Add] outputs: [903 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_504 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 903
[06/10/2022-19:21:30] [V] [TRT] Sqrt_504 [Sqrt] inputs: [903 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_504 for ONNX node: Sqrt_504
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 904 for ONNX tensor: 904
[06/10/2022-19:21:30] [V] [TRT] Sqrt_504 [Sqrt] outputs: [904 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_505 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 898
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 904
[06/10/2022-19:21:30] [V] [TRT] Div_505 [Div] inputs: [898 -> (-1, 16384, 128)[FLOAT]], [904 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_505 for ONNX node: Div_505
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 905 for ONNX tensor: 905
[06/10/2022-19:21:30] [V] [TRT] Div_505 [Div] outputs: [905 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_506 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 905
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_506 [Mul] inputs: [905 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.0.norm1.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.0.norm1.weight for ONNX node: backbone.block2.0.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_506 for ONNX node: Mul_506
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 906 for ONNX tensor: 906
[06/10/2022-19:21:30] [V] [TRT] Mul_506 [Mul] outputs: [906 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_507 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 906
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_507 [Add] inputs: [906 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.0.norm1.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.0.norm1.bias for ONNX node: backbone.block2.0.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_507 for ONNX node: Add_507
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 907 for ONNX tensor: 907
[06/10/2022-19:21:30] [V] [TRT] Add_507 [Add] outputs: [907 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_508 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 907
[06/10/2022-19:21:30] [V] [TRT] Shape_508 [Shape] inputs: [907 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_508 for ONNX node: Shape_508
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 908 for ONNX tensor: 908
[06/10/2022-19:21:30] [V] [TRT] Shape_508 [Shape] outputs: [908 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_510 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 908
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 909
[06/10/2022-19:21:30] [V] [TRT] Gather_510 [Gather] inputs: [908 -> (3)[INT32]], [909 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 909 for ONNX node: 909
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_510 for ONNX node: Gather_510
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 910 for ONNX tensor: 910
[06/10/2022-19:21:30] [V] [TRT] Gather_510 [Gather] outputs: [910 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_511 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 907
[06/10/2022-19:21:30] [V] [TRT] Shape_511 [Shape] inputs: [907 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_511 for ONNX node: Shape_511
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 911 for ONNX tensor: 911
[06/10/2022-19:21:30] [V] [TRT] Shape_511 [Shape] outputs: [911 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_513 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 911
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 912
[06/10/2022-19:21:30] [V] [TRT] Gather_513 [Gather] inputs: [911 -> (3)[INT32]], [912 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 912 for ONNX node: 912
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_513 for ONNX node: Gather_513
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 913 for ONNX tensor: 913
[06/10/2022-19:21:30] [V] [TRT] Gather_513 [Gather] outputs: [913 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_514 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 907
[06/10/2022-19:21:30] [V] [TRT] Shape_514 [Shape] inputs: [907 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_514 for ONNX node: Shape_514
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 914 for ONNX tensor: 914
[06/10/2022-19:21:30] [V] [TRT] Shape_514 [Shape] outputs: [914 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_516 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 914
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 915
[06/10/2022-19:21:30] [V] [TRT] Gather_516 [Gather] inputs: [914 -> (3)[INT32]], [915 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 915 for ONNX node: 915
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_516 for ONNX node: Gather_516
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 916 for ONNX tensor: 916
[06/10/2022-19:21:30] [V] [TRT] Gather_516 [Gather] outputs: [916 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_517 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 907
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3090
[06/10/2022-19:21:30] [V] [TRT] MatMul_517 [MatMul] inputs: [907 -> (-1, 16384, 128)[FLOAT]], [3090 -> (128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3090 for ONNX node: 3090
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_517 for ONNX node: MatMul_517
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 918 for ONNX tensor: 918
[06/10/2022-19:21:30] [V] [TRT] MatMul_517 [MatMul] outputs: [918 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_518 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 918
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Add_518 [Add] inputs: [918 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.0.attn.q.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.0.attn.q.bias for ONNX node: backbone.block2.0.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_518 for ONNX node: Add_518
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 919 for ONNX tensor: 919
[06/10/2022-19:21:30] [V] [TRT] Add_518 [Add] outputs: [919 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_520 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 916
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 920
[06/10/2022-19:21:30] [V] [TRT] Div_520 [Div] inputs: [916 -> ()[INT32]], [920 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 920 for ONNX node: 920
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_520 for ONNX node: Div_520
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 921 for ONNX tensor: 921
[06/10/2022-19:21:30] [V] [TRT] Div_520 [Div] outputs: [921 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_521 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 921
[06/10/2022-19:21:30] [V] [TRT] Cast_521 [Cast] inputs: [921 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_521 for ONNX node: Cast_521
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 922 for ONNX tensor: 922
[06/10/2022-19:21:30] [V] [TRT] Cast_521 [Cast] outputs: [922 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_522 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 922
[06/10/2022-19:21:30] [V] [TRT] Cast_522 [Cast] inputs: [922 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_522 for ONNX node: Cast_522
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 923 for ONNX tensor: 923
[06/10/2022-19:21:30] [V] [TRT] Cast_522 [Cast] outputs: [923 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_523 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 910
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_523 [Unsqueeze] inputs: [910 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_523 for ONNX node: Unsqueeze_523
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 925 for ONNX tensor: 925
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_523 [Unsqueeze] outputs: [925 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_524 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 913
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_524 [Unsqueeze] inputs: [913 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_524 for ONNX node: Unsqueeze_524
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 926 for ONNX tensor: 926
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_524 [Unsqueeze] outputs: [926 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_525 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 923
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_525 [Unsqueeze] inputs: [923 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_525 for ONNX node: Unsqueeze_525
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 928 for ONNX tensor: 928
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_525 [Unsqueeze] outputs: [928 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_526 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 925
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 926
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3091
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 928
[06/10/2022-19:21:30] [V] [TRT] Concat_526 [Concat] inputs: [925 -> (1)[INT32]], [926 -> (1)[INT32]], [3091 -> (1)[INT32]], [928 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3091 for ONNX node: 3091
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_526 for ONNX node: Concat_526
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 929 for ONNX tensor: 929
[06/10/2022-19:21:30] [V] [TRT] Concat_526 [Concat] outputs: [929 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_527 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 919
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 929
[06/10/2022-19:21:30] [V] [TRT] Reshape_527 [Reshape] inputs: [919 -> (-1, 16384, 128)[FLOAT]], [929 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_527 for ONNX node: Reshape_527
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 930 for ONNX tensor: 930
[06/10/2022-19:21:30] [V] [TRT] Reshape_527 [Reshape] outputs: [930 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_528 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 930
[06/10/2022-19:21:30] [V] [TRT] Transpose_528 [Transpose] inputs: [930 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_528 for ONNX node: Transpose_528
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 931 for ONNX tensor: 931
[06/10/2022-19:21:30] [V] [TRT] Transpose_528 [Transpose] outputs: [931 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_529 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 907
[06/10/2022-19:21:30] [V] [TRT] Transpose_529 [Transpose] inputs: [907 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_529 for ONNX node: Transpose_529
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 932 for ONNX tensor: 932
[06/10/2022-19:21:30] [V] [TRT] Transpose_529 [Transpose] outputs: [932 -> (-1, 128, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_530 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 910
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_530 [Unsqueeze] inputs: [910 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_530 for ONNX node: Unsqueeze_530
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 933 for ONNX tensor: 933
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_530 [Unsqueeze] outputs: [933 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_531 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 916
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_531 [Unsqueeze] inputs: [916 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_531 for ONNX node: Unsqueeze_531
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 934 for ONNX tensor: 934
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_531 [Unsqueeze] outputs: [934 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_532 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 873
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_532 [Unsqueeze] inputs: [873 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_532 for ONNX node: Unsqueeze_532
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 935 for ONNX tensor: 935
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_532 [Unsqueeze] outputs: [935 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_533 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 876
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_533 [Unsqueeze] inputs: [876 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_533 for ONNX node: Unsqueeze_533
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 936 for ONNX tensor: 936
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_533 [Unsqueeze] outputs: [936 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_534 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 933
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 934
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 935
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 936
[06/10/2022-19:21:30] [V] [TRT] Concat_534 [Concat] inputs: [933 -> (1)[INT32]], [934 -> (1)[INT32]], [935 -> (1)[INT32]], [936 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_534 for ONNX node: Concat_534
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 937 for ONNX tensor: 937
[06/10/2022-19:21:30] [V] [TRT] Concat_534 [Concat] outputs: [937 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_535 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 932
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 937
[06/10/2022-19:21:30] [V] [TRT] Reshape_535 [Reshape] inputs: [932 -> (-1, 128, 16384)[FLOAT]], [937 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_535 for ONNX node: Reshape_535
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 938 for ONNX tensor: 938
[06/10/2022-19:21:30] [V] [TRT] Reshape_535 [Reshape] outputs: [938 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_536 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 938
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_536 [Conv] inputs: [938 -> (-1, 128, 128, 128)[FLOAT]], [backbone.block2.0.attn.sr.weight -> (128, 128, 4, 4)[FLOAT]], [backbone.block2.0.attn.sr.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 128, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_536 for ONNX node: Conv_536
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (4, 4), strides: (4, 4), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 128, 32, 32)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 939 for ONNX tensor: 939
[06/10/2022-19:21:30] [V] [TRT] Conv_536 [Conv] outputs: [939 -> (-1, 128, 32, 32)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_537 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 910
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_537 [Unsqueeze] inputs: [910 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_537 for ONNX node: Unsqueeze_537
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 941 for ONNX tensor: 941
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_537 [Unsqueeze] outputs: [941 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_538 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 916
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_538 [Unsqueeze] inputs: [916 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_538 for ONNX node: Unsqueeze_538
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 942 for ONNX tensor: 942
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_538 [Unsqueeze] outputs: [942 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_539 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 941
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 942
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3092
[06/10/2022-19:21:30] [V] [TRT] Concat_539 [Concat] inputs: [941 -> (1)[INT32]], [942 -> (1)[INT32]], [3092 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3092 for ONNX node: 3092
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_539 for ONNX node: Concat_539
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 944 for ONNX tensor: 944
[06/10/2022-19:21:30] [V] [TRT] Concat_539 [Concat] outputs: [944 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_540 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 939
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 944
[06/10/2022-19:21:30] [V] [TRT] Reshape_540 [Reshape] inputs: [939 -> (-1, 128, 32, 32)[FLOAT]], [944 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_540 for ONNX node: Reshape_540
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 945 for ONNX tensor: 945
[06/10/2022-19:21:30] [V] [TRT] Reshape_540 [Reshape] outputs: [945 -> (-1, 128, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_541 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 945
[06/10/2022-19:21:30] [V] [TRT] Transpose_541 [Transpose] inputs: [945 -> (-1, 128, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_541 for ONNX node: Transpose_541
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 946 for ONNX tensor: 946
[06/10/2022-19:21:30] [V] [TRT] Transpose_541 [Transpose] outputs: [946 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_542 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 946
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_542 [ReduceMean] inputs: [946 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_542 for ONNX node: ReduceMean_542
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 947 for ONNX tensor: 947
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_542 [ReduceMean] outputs: [947 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_543 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 946
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 947
[06/10/2022-19:21:30] [V] [TRT] Sub_543 [Sub] inputs: [946 -> (-1, 1024, 128)[FLOAT]], [947 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_543 for ONNX node: Sub_543
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 948 for ONNX tensor: 948
[06/10/2022-19:21:30] [V] [TRT] Sub_543 [Sub] outputs: [948 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_545 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 948
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 949
[06/10/2022-19:21:30] [V] [TRT] Pow_545 [Pow] inputs: [948 -> (-1, 1024, 128)[FLOAT]], [949 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 949 for ONNX node: 949
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_545 for ONNX node: Pow_545
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 950 for ONNX tensor: 950
[06/10/2022-19:21:30] [V] [TRT] Pow_545 [Pow] outputs: [950 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_546 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 950
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_546 [ReduceMean] inputs: [950 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_546 for ONNX node: ReduceMean_546
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 951 for ONNX tensor: 951
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_546 [ReduceMean] outputs: [951 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_548 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 951
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 952
[06/10/2022-19:21:30] [V] [TRT] Add_548 [Add] inputs: [951 -> (-1, 1024, 1)[FLOAT]], [952 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 952 for ONNX node: 952
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_548 for ONNX node: Add_548
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 953 for ONNX tensor: 953
[06/10/2022-19:21:30] [V] [TRT] Add_548 [Add] outputs: [953 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_549 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 953
[06/10/2022-19:21:30] [V] [TRT] Sqrt_549 [Sqrt] inputs: [953 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_549 for ONNX node: Sqrt_549
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 954 for ONNX tensor: 954
[06/10/2022-19:21:30] [V] [TRT] Sqrt_549 [Sqrt] outputs: [954 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_550 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 948
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 954
[06/10/2022-19:21:30] [V] [TRT] Div_550 [Div] inputs: [948 -> (-1, 1024, 128)[FLOAT]], [954 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_550 for ONNX node: Div_550
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 955 for ONNX tensor: 955
[06/10/2022-19:21:30] [V] [TRT] Div_550 [Div] outputs: [955 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_551 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 955
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_551 [Mul] inputs: [955 -> (-1, 1024, 128)[FLOAT]], [backbone.block2.0.attn.norm.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.0.attn.norm.weight for ONNX node: backbone.block2.0.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_551 for ONNX node: Mul_551
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 956 for ONNX tensor: 956
[06/10/2022-19:21:30] [V] [TRT] Mul_551 [Mul] outputs: [956 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_552 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 956
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Add_552 [Add] inputs: [956 -> (-1, 1024, 128)[FLOAT]], [backbone.block2.0.attn.norm.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.0.attn.norm.bias for ONNX node: backbone.block2.0.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_552 for ONNX node: Add_552
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 957 for ONNX tensor: 957
[06/10/2022-19:21:30] [V] [TRT] Add_552 [Add] outputs: [957 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_553 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 957
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3093
[06/10/2022-19:21:30] [V] [TRT] MatMul_553 [MatMul] inputs: [957 -> (-1, 1024, 128)[FLOAT]], [3093 -> (128, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3093 for ONNX node: 3093
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_553 for ONNX node: MatMul_553
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 959 for ONNX tensor: 959
[06/10/2022-19:21:30] [V] [TRT] MatMul_553 [MatMul] outputs: [959 -> (-1, 1024, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_554 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 959
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Add_554 [Add] inputs: [959 -> (-1, 1024, 256)[FLOAT]], [backbone.block2.0.attn.kv.bias -> (256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.0.attn.kv.bias for ONNX node: backbone.block2.0.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_554 for ONNX node: Add_554
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 960 for ONNX tensor: 960
[06/10/2022-19:21:30] [V] [TRT] Add_554 [Add] outputs: [960 -> (-1, 1024, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_556 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 916
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 961
[06/10/2022-19:21:30] [V] [TRT] Div_556 [Div] inputs: [916 -> ()[INT32]], [961 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 961 for ONNX node: 961
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_556 for ONNX node: Div_556
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 962 for ONNX tensor: 962
[06/10/2022-19:21:30] [V] [TRT] Div_556 [Div] outputs: [962 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_557 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 962
[06/10/2022-19:21:30] [V] [TRT] Cast_557 [Cast] inputs: [962 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_557 for ONNX node: Cast_557
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 963 for ONNX tensor: 963
[06/10/2022-19:21:30] [V] [TRT] Cast_557 [Cast] outputs: [963 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_558 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 963
[06/10/2022-19:21:30] [V] [TRT] Cast_558 [Cast] inputs: [963 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_558 for ONNX node: Cast_558
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 964 for ONNX tensor: 964
[06/10/2022-19:21:30] [V] [TRT] Cast_558 [Cast] outputs: [964 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_559 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 910
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_559 [Unsqueeze] inputs: [910 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_559 for ONNX node: Unsqueeze_559
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 968 for ONNX tensor: 968
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_559 [Unsqueeze] outputs: [968 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_560 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 964
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_560 [Unsqueeze] inputs: [964 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_560 for ONNX node: Unsqueeze_560
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 972 for ONNX tensor: 972
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_560 [Unsqueeze] outputs: [972 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_561 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 968
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3094
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3095
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3096
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 972
[06/10/2022-19:21:30] [V] [TRT] Concat_561 [Concat] inputs: [968 -> (1)[INT32]], [3094 -> (1)[INT32]], [3095 -> (1)[INT32]], [3096 -> (1)[INT32]], [972 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3094 for ONNX node: 3094
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3095 for ONNX node: 3095
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3096 for ONNX node: 3096
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_561 for ONNX node: Concat_561
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 973 for ONNX tensor: 973
[06/10/2022-19:21:30] [V] [TRT] Concat_561 [Concat] outputs: [973 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_562 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 960
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 973
[06/10/2022-19:21:30] [V] [TRT] Reshape_562 [Reshape] inputs: [960 -> (-1, 1024, 256)[FLOAT]], [973 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_562 for ONNX node: Reshape_562
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 974 for ONNX tensor: 974
[06/10/2022-19:21:30] [V] [TRT] Reshape_562 [Reshape] outputs: [974 -> (-1, 1024, 2, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_563 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 974
[06/10/2022-19:21:30] [V] [TRT] Transpose_563 [Transpose] inputs: [974 -> (-1, 1024, 2, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_563 for ONNX node: Transpose_563
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 975 for ONNX tensor: 975
[06/10/2022-19:21:30] [V] [TRT] Transpose_563 [Transpose] outputs: [975 -> (2, -1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_565 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 975
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 976
[06/10/2022-19:21:30] [V] [TRT] Gather_565 [Gather] inputs: [975 -> (2, -1, 2, 1024, 64)[FLOAT]], [976 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 976 for ONNX node: 976
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_565 for ONNX node: Gather_565
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 977 for ONNX tensor: 977
[06/10/2022-19:21:30] [V] [TRT] Gather_565 [Gather] outputs: [977 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_567 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 975
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 978
[06/10/2022-19:21:30] [V] [TRT] Gather_567 [Gather] inputs: [975 -> (2, -1, 2, 1024, 64)[FLOAT]], [978 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 978 for ONNX node: 978
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_567 for ONNX node: Gather_567
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 979 for ONNX tensor: 979
[06/10/2022-19:21:30] [V] [TRT] Gather_567 [Gather] outputs: [979 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_568 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 977
[06/10/2022-19:21:30] [V] [TRT] Transpose_568 [Transpose] inputs: [977 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_568 for ONNX node: Transpose_568
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 980 for ONNX tensor: 980
[06/10/2022-19:21:30] [V] [TRT] Transpose_568 [Transpose] outputs: [980 -> (-1, 2, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_569 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 931
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 980
[06/10/2022-19:21:30] [V] [TRT] MatMul_569 [MatMul] inputs: [931 -> (-1, 2, 16384, 64)[FLOAT]], [980 -> (-1, 2, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_569 for ONNX node: MatMul_569
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 981 for ONNX tensor: 981
[06/10/2022-19:21:30] [V] [TRT] MatMul_569 [MatMul] outputs: [981 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_571 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 981
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 982
[06/10/2022-19:21:30] [V] [TRT] Mul_571 [Mul] inputs: [981 -> (-1, 2, 16384, 1024)[FLOAT]], [982 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 982 for ONNX node: 982
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_571 for ONNX node: Mul_571
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 983 for ONNX tensor: 983
[06/10/2022-19:21:30] [V] [TRT] Mul_571 [Mul] outputs: [983 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Softmax_572 [Softmax]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 983
[06/10/2022-19:21:30] [V] [TRT] Softmax_572 [Softmax] inputs: [983 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Softmax_572 for ONNX node: Softmax_572
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 984 for ONNX tensor: 984
[06/10/2022-19:21:30] [V] [TRT] Softmax_572 [Softmax] outputs: [984 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_573 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 984
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 979
[06/10/2022-19:21:30] [V] [TRT] MatMul_573 [MatMul] inputs: [984 -> (-1, 2, 16384, 1024)[FLOAT]], [979 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_573 for ONNX node: MatMul_573
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 985 for ONNX tensor: 985
[06/10/2022-19:21:30] [V] [TRT] MatMul_573 [MatMul] outputs: [985 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_574 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 985
[06/10/2022-19:21:30] [V] [TRT] Transpose_574 [Transpose] inputs: [985 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_574 for ONNX node: Transpose_574
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 986 for ONNX tensor: 986
[06/10/2022-19:21:30] [V] [TRT] Transpose_574 [Transpose] outputs: [986 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_575 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 910
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_575 [Unsqueeze] inputs: [910 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_575 for ONNX node: Unsqueeze_575
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 987 for ONNX tensor: 987
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_575 [Unsqueeze] outputs: [987 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_576 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 913
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_576 [Unsqueeze] inputs: [913 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_576 for ONNX node: Unsqueeze_576
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 988 for ONNX tensor: 988
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_576 [Unsqueeze] outputs: [988 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_577 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 916
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_577 [Unsqueeze] inputs: [916 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_577 for ONNX node: Unsqueeze_577
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 989 for ONNX tensor: 989
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_577 [Unsqueeze] outputs: [989 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_578 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 987
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 988
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 989
[06/10/2022-19:21:30] [V] [TRT] Concat_578 [Concat] inputs: [987 -> (1)[INT32]], [988 -> (1)[INT32]], [989 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_578 for ONNX node: Concat_578
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 990 for ONNX tensor: 990
[06/10/2022-19:21:30] [V] [TRT] Concat_578 [Concat] outputs: [990 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_579 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 986
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 990
[06/10/2022-19:21:30] [V] [TRT] Reshape_579 [Reshape] inputs: [986 -> (-1, 16384, 2, 64)[FLOAT]], [990 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_579 for ONNX node: Reshape_579
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 991 for ONNX tensor: 991
[06/10/2022-19:21:30] [V] [TRT] Reshape_579 [Reshape] outputs: [991 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_580 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 991
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3097
[06/10/2022-19:21:30] [V] [TRT] MatMul_580 [MatMul] inputs: [991 -> (-1, 16384, 128)[FLOAT]], [3097 -> (128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3097 for ONNX node: 3097
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_580 for ONNX node: MatMul_580
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 993 for ONNX tensor: 993
[06/10/2022-19:21:30] [V] [TRT] MatMul_580 [MatMul] outputs: [993 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_581 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 993
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Add_581 [Add] inputs: [993 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.0.attn.proj.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.0.attn.proj.bias for ONNX node: backbone.block2.0.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_581 for ONNX node: Add_581
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 994 for ONNX tensor: 994
[06/10/2022-19:21:30] [V] [TRT] Add_581 [Add] outputs: [994 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_582 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 896
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 994
[06/10/2022-19:21:30] [V] [TRT] Add_582 [Add] inputs: [896 -> (-1, 16384, 128)[FLOAT]], [994 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_582 for ONNX node: Add_582
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 995 for ONNX tensor: 995
[06/10/2022-19:21:30] [V] [TRT] Add_582 [Add] outputs: [995 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_583 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 995
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_583 [ReduceMean] inputs: [995 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_583 for ONNX node: ReduceMean_583
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 996 for ONNX tensor: 996
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_583 [ReduceMean] outputs: [996 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_584 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 995
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 996
[06/10/2022-19:21:30] [V] [TRT] Sub_584 [Sub] inputs: [995 -> (-1, 16384, 128)[FLOAT]], [996 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_584 for ONNX node: Sub_584
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 997 for ONNX tensor: 997
[06/10/2022-19:21:30] [V] [TRT] Sub_584 [Sub] outputs: [997 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_586 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 997
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 998
[06/10/2022-19:21:30] [V] [TRT] Pow_586 [Pow] inputs: [997 -> (-1, 16384, 128)[FLOAT]], [998 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 998 for ONNX node: 998
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_586 for ONNX node: Pow_586
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 999 for ONNX tensor: 999
[06/10/2022-19:21:30] [V] [TRT] Pow_586 [Pow] outputs: [999 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_587 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 999
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_587 [ReduceMean] inputs: [999 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_587 for ONNX node: ReduceMean_587
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1000 for ONNX tensor: 1000
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_587 [ReduceMean] outputs: [1000 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_589 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1000
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1001
[06/10/2022-19:21:30] [V] [TRT] Add_589 [Add] inputs: [1000 -> (-1, 16384, 1)[FLOAT]], [1001 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1001 for ONNX node: 1001
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_589 for ONNX node: Add_589
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1002 for ONNX tensor: 1002
[06/10/2022-19:21:30] [V] [TRT] Add_589 [Add] outputs: [1002 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_590 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1002
[06/10/2022-19:21:30] [V] [TRT] Sqrt_590 [Sqrt] inputs: [1002 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_590 for ONNX node: Sqrt_590
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1003 for ONNX tensor: 1003
[06/10/2022-19:21:30] [V] [TRT] Sqrt_590 [Sqrt] outputs: [1003 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_591 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 997
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1003
[06/10/2022-19:21:30] [V] [TRT] Div_591 [Div] inputs: [997 -> (-1, 16384, 128)[FLOAT]], [1003 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_591 for ONNX node: Div_591
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1004 for ONNX tensor: 1004
[06/10/2022-19:21:30] [V] [TRT] Div_591 [Div] outputs: [1004 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_592 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1004
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_592 [Mul] inputs: [1004 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.0.norm2.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.0.norm2.weight for ONNX node: backbone.block2.0.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_592 for ONNX node: Mul_592
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1005 for ONNX tensor: 1005
[06/10/2022-19:21:30] [V] [TRT] Mul_592 [Mul] outputs: [1005 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_593 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1005
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_593 [Add] inputs: [1005 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.0.norm2.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.0.norm2.bias for ONNX node: backbone.block2.0.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_593 for ONNX node: Add_593
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1006 for ONNX tensor: 1006
[06/10/2022-19:21:30] [V] [TRT] Add_593 [Add] outputs: [1006 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_594 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1006
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3098
[06/10/2022-19:21:30] [V] [TRT] MatMul_594 [MatMul] inputs: [1006 -> (-1, 16384, 128)[FLOAT]], [3098 -> (128, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3098 for ONNX node: 3098
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_594 for ONNX node: MatMul_594
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1008 for ONNX tensor: 1008
[06/10/2022-19:21:30] [V] [TRT] MatMul_594 [MatMul] outputs: [1008 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_595 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1008
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_595 [Add] inputs: [1008 -> (-1, 16384, 512)[FLOAT]], [backbone.block2.0.mlp.fc1.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.0.mlp.fc1.bias for ONNX node: backbone.block2.0.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_595 for ONNX node: Add_595
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1009 for ONNX tensor: 1009
[06/10/2022-19:21:30] [V] [TRT] Add_595 [Add] outputs: [1009 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_596 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1009
[06/10/2022-19:21:30] [V] [TRT] Shape_596 [Shape] inputs: [1009 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_596 for ONNX node: Shape_596
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1010 for ONNX tensor: 1010
[06/10/2022-19:21:30] [V] [TRT] Shape_596 [Shape] outputs: [1010 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_598 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1010
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1011
[06/10/2022-19:21:30] [V] [TRT] Gather_598 [Gather] inputs: [1010 -> (3)[INT32]], [1011 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1011 for ONNX node: 1011
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_598 for ONNX node: Gather_598
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1012 for ONNX tensor: 1012
[06/10/2022-19:21:30] [V] [TRT] Gather_598 [Gather] outputs: [1012 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_599 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1009
[06/10/2022-19:21:30] [V] [TRT] Shape_599 [Shape] inputs: [1009 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_599 for ONNX node: Shape_599
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1013 for ONNX tensor: 1013
[06/10/2022-19:21:30] [V] [TRT] Shape_599 [Shape] outputs: [1013 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_601 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1013
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1014
[06/10/2022-19:21:30] [V] [TRT] Gather_601 [Gather] inputs: [1013 -> (3)[INT32]], [1014 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1014 for ONNX node: 1014
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_601 for ONNX node: Gather_601
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1015 for ONNX tensor: 1015
[06/10/2022-19:21:30] [V] [TRT] Gather_601 [Gather] outputs: [1015 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_602 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1009
[06/10/2022-19:21:30] [V] [TRT] Transpose_602 [Transpose] inputs: [1009 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_602 for ONNX node: Transpose_602
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1016 for ONNX tensor: 1016
[06/10/2022-19:21:30] [V] [TRT] Transpose_602 [Transpose] outputs: [1016 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_603 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1012
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_603 [Unsqueeze] inputs: [1012 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_603 for ONNX node: Unsqueeze_603
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1017 for ONNX tensor: 1017
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_603 [Unsqueeze] outputs: [1017 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_604 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1015
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_604 [Unsqueeze] inputs: [1015 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_604 for ONNX node: Unsqueeze_604
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1018 for ONNX tensor: 1018
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_604 [Unsqueeze] outputs: [1018 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_605 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 873
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_605 [Unsqueeze] inputs: [873 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_605 for ONNX node: Unsqueeze_605
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1019 for ONNX tensor: 1019
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_605 [Unsqueeze] outputs: [1019 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_606 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 876
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_606 [Unsqueeze] inputs: [876 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_606 for ONNX node: Unsqueeze_606
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1020 for ONNX tensor: 1020
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_606 [Unsqueeze] outputs: [1020 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_607 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1017
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1018
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1019
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1020
[06/10/2022-19:21:30] [V] [TRT] Concat_607 [Concat] inputs: [1017 -> (1)[INT32]], [1018 -> (1)[INT32]], [1019 -> (1)[INT32]], [1020 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_607 for ONNX node: Concat_607
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1021 for ONNX tensor: 1021
[06/10/2022-19:21:30] [V] [TRT] Concat_607 [Concat] outputs: [1021 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_608 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1016
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1021
[06/10/2022-19:21:30] [V] [TRT] Reshape_608 [Reshape] inputs: [1016 -> (-1, 512, 16384)[FLOAT]], [1021 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_608 for ONNX node: Reshape_608
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1022 for ONNX tensor: 1022
[06/10/2022-19:21:30] [V] [TRT] Reshape_608 [Reshape] outputs: [1022 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_609 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1022
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_609 [Conv] inputs: [1022 -> (-1, 512, 128, 128)[FLOAT]], [backbone.block2.0.mlp.dwconv.dwconv.weight -> (512, 1, 3, 3)[FLOAT]], [backbone.block2.0.mlp.dwconv.dwconv.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 512, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_609 for ONNX node: Conv_609
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 512, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1023 for ONNX tensor: 1023
[06/10/2022-19:21:30] [V] [TRT] Conv_609 [Conv] outputs: [1023 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_610 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1023
[06/10/2022-19:21:30] [V] [TRT] Shape_610 [Shape] inputs: [1023 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_610 for ONNX node: Shape_610
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1024 for ONNX tensor: 1024
[06/10/2022-19:21:30] [V] [TRT] Shape_610 [Shape] outputs: [1024 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_614 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1024
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1026
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1027
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1025
[06/10/2022-19:21:30] [V] [TRT] Slice_614 [Slice] inputs: [1024 -> (4)[INT32]], [1026 -> (1)[INT32]], [1027 -> (1)[INT32]], [1025 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_614 for ONNX node: Slice_614
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1028 for ONNX tensor: 1028
[06/10/2022-19:21:30] [V] [TRT] Slice_614 [Slice] outputs: [1028 -> (2)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_616 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1028
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1029
[06/10/2022-19:21:30] [V] [TRT] Concat_616 [Concat] inputs: [1028 -> (2)[INT32]], [1029 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1029 for ONNX node: 1029
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_616 for ONNX node: Concat_616
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1030 for ONNX tensor: 1030
[06/10/2022-19:21:30] [V] [TRT] Concat_616 [Concat] outputs: [1030 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_617 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1023
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1030
[06/10/2022-19:21:30] [V] [TRT] Reshape_617 [Reshape] inputs: [1023 -> (-1, 512, 128, 128)[FLOAT]], [1030 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_617 for ONNX node: Reshape_617
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1031 for ONNX tensor: 1031
[06/10/2022-19:21:30] [V] [TRT] Reshape_617 [Reshape] outputs: [1031 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_618 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1031
[06/10/2022-19:21:30] [V] [TRT] Transpose_618 [Transpose] inputs: [1031 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_618 for ONNX node: Transpose_618
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1032 for ONNX tensor: 1032
[06/10/2022-19:21:30] [V] [TRT] Transpose_618 [Transpose] outputs: [1032 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_620 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1032
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1033
[06/10/2022-19:21:30] [V] [TRT] Div_620 [Div] inputs: [1032 -> (-1, 16384, 512)[FLOAT]], [1033 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1033 for ONNX node: 1033
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_620 for ONNX node: Div_620
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1034 for ONNX tensor: 1034
[06/10/2022-19:21:30] [V] [TRT] Div_620 [Div] outputs: [1034 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Erf_621 [Erf]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1034
[06/10/2022-19:21:30] [V] [TRT] Erf_621 [Erf] inputs: [1034 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Erf_621 for ONNX node: Erf_621
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1035 for ONNX tensor: 1035
[06/10/2022-19:21:30] [V] [TRT] Erf_621 [Erf] outputs: [1035 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_623 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1035
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1036
[06/10/2022-19:21:30] [V] [TRT] Add_623 [Add] inputs: [1035 -> (-1, 16384, 512)[FLOAT]], [1036 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1036 for ONNX node: 1036
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_623 for ONNX node: Add_623
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1037 for ONNX tensor: 1037
[06/10/2022-19:21:30] [V] [TRT] Add_623 [Add] outputs: [1037 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_624 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1032
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1037
[06/10/2022-19:21:30] [V] [TRT] Mul_624 [Mul] inputs: [1032 -> (-1, 16384, 512)[FLOAT]], [1037 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_624 for ONNX node: Mul_624
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1038 for ONNX tensor: 1038
[06/10/2022-19:21:30] [V] [TRT] Mul_624 [Mul] outputs: [1038 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_626 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1038
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1039
[06/10/2022-19:21:30] [V] [TRT] Mul_626 [Mul] inputs: [1038 -> (-1, 16384, 512)[FLOAT]], [1039 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1039 for ONNX node: 1039
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_626 for ONNX node: Mul_626
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1040 for ONNX tensor: 1040
[06/10/2022-19:21:30] [V] [TRT] Mul_626 [Mul] outputs: [1040 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_627 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1040
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3099
[06/10/2022-19:21:30] [V] [TRT] MatMul_627 [MatMul] inputs: [1040 -> (-1, 16384, 512)[FLOAT]], [3099 -> (512, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3099 for ONNX node: 3099
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_627 for ONNX node: MatMul_627
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1042 for ONNX tensor: 1042
[06/10/2022-19:21:30] [V] [TRT] MatMul_627 [MatMul] outputs: [1042 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_628 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1042
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.0.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_628 [Add] inputs: [1042 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.0.mlp.fc2.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.0.mlp.fc2.bias for ONNX node: backbone.block2.0.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_628 for ONNX node: Add_628
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1043 for ONNX tensor: 1043
[06/10/2022-19:21:30] [V] [TRT] Add_628 [Add] outputs: [1043 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_629 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 995
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1043
[06/10/2022-19:21:30] [V] [TRT] Add_629 [Add] inputs: [995 -> (-1, 16384, 128)[FLOAT]], [1043 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_629 for ONNX node: Add_629
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1044 for ONNX tensor: 1044
[06/10/2022-19:21:30] [V] [TRT] Add_629 [Add] outputs: [1044 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_630 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1044
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_630 [ReduceMean] inputs: [1044 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_630 for ONNX node: ReduceMean_630
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1045 for ONNX tensor: 1045
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_630 [ReduceMean] outputs: [1045 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_631 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1044
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1045
[06/10/2022-19:21:30] [V] [TRT] Sub_631 [Sub] inputs: [1044 -> (-1, 16384, 128)[FLOAT]], [1045 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_631 for ONNX node: Sub_631
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1046 for ONNX tensor: 1046
[06/10/2022-19:21:30] [V] [TRT] Sub_631 [Sub] outputs: [1046 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_633 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1046
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1047
[06/10/2022-19:21:30] [V] [TRT] Pow_633 [Pow] inputs: [1046 -> (-1, 16384, 128)[FLOAT]], [1047 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1047 for ONNX node: 1047
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_633 for ONNX node: Pow_633
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1048 for ONNX tensor: 1048
[06/10/2022-19:21:30] [V] [TRT] Pow_633 [Pow] outputs: [1048 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_634 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1048
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_634 [ReduceMean] inputs: [1048 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_634 for ONNX node: ReduceMean_634
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1049 for ONNX tensor: 1049
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_634 [ReduceMean] outputs: [1049 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_636 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1049
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1050
[06/10/2022-19:21:30] [V] [TRT] Add_636 [Add] inputs: [1049 -> (-1, 16384, 1)[FLOAT]], [1050 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1050 for ONNX node: 1050
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_636 for ONNX node: Add_636
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1051 for ONNX tensor: 1051
[06/10/2022-19:21:30] [V] [TRT] Add_636 [Add] outputs: [1051 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_637 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1051
[06/10/2022-19:21:30] [V] [TRT] Sqrt_637 [Sqrt] inputs: [1051 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_637 for ONNX node: Sqrt_637
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1052 for ONNX tensor: 1052
[06/10/2022-19:21:30] [V] [TRT] Sqrt_637 [Sqrt] outputs: [1052 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_638 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1046
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1052
[06/10/2022-19:21:30] [V] [TRT] Div_638 [Div] inputs: [1046 -> (-1, 16384, 128)[FLOAT]], [1052 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_638 for ONNX node: Div_638
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1053 for ONNX tensor: 1053
[06/10/2022-19:21:30] [V] [TRT] Div_638 [Div] outputs: [1053 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_639 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1053
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_639 [Mul] inputs: [1053 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.1.norm1.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.1.norm1.weight for ONNX node: backbone.block2.1.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_639 for ONNX node: Mul_639
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1054 for ONNX tensor: 1054
[06/10/2022-19:21:30] [V] [TRT] Mul_639 [Mul] outputs: [1054 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_640 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1054
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_640 [Add] inputs: [1054 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.1.norm1.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.1.norm1.bias for ONNX node: backbone.block2.1.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_640 for ONNX node: Add_640
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1055 for ONNX tensor: 1055
[06/10/2022-19:21:30] [V] [TRT] Add_640 [Add] outputs: [1055 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_641 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1055
[06/10/2022-19:21:30] [V] [TRT] Shape_641 [Shape] inputs: [1055 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_641 for ONNX node: Shape_641
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1056 for ONNX tensor: 1056
[06/10/2022-19:21:30] [V] [TRT] Shape_641 [Shape] outputs: [1056 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_643 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1056
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1057
[06/10/2022-19:21:30] [V] [TRT] Gather_643 [Gather] inputs: [1056 -> (3)[INT32]], [1057 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1057 for ONNX node: 1057
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_643 for ONNX node: Gather_643
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1058 for ONNX tensor: 1058
[06/10/2022-19:21:30] [V] [TRT] Gather_643 [Gather] outputs: [1058 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_644 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1055
[06/10/2022-19:21:30] [V] [TRT] Shape_644 [Shape] inputs: [1055 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_644 for ONNX node: Shape_644
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1059 for ONNX tensor: 1059
[06/10/2022-19:21:30] [V] [TRT] Shape_644 [Shape] outputs: [1059 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_646 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1059
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1060
[06/10/2022-19:21:30] [V] [TRT] Gather_646 [Gather] inputs: [1059 -> (3)[INT32]], [1060 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1060 for ONNX node: 1060
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_646 for ONNX node: Gather_646
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1061 for ONNX tensor: 1061
[06/10/2022-19:21:30] [V] [TRT] Gather_646 [Gather] outputs: [1061 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_647 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1055
[06/10/2022-19:21:30] [V] [TRT] Shape_647 [Shape] inputs: [1055 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_647 for ONNX node: Shape_647
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1062 for ONNX tensor: 1062
[06/10/2022-19:21:30] [V] [TRT] Shape_647 [Shape] outputs: [1062 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_649 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1062
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1063
[06/10/2022-19:21:30] [V] [TRT] Gather_649 [Gather] inputs: [1062 -> (3)[INT32]], [1063 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1063 for ONNX node: 1063
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_649 for ONNX node: Gather_649
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1064 for ONNX tensor: 1064
[06/10/2022-19:21:30] [V] [TRT] Gather_649 [Gather] outputs: [1064 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_650 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1055
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3100
[06/10/2022-19:21:30] [V] [TRT] MatMul_650 [MatMul] inputs: [1055 -> (-1, 16384, 128)[FLOAT]], [3100 -> (128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3100 for ONNX node: 3100
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_650 for ONNX node: MatMul_650
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1066 for ONNX tensor: 1066
[06/10/2022-19:21:30] [V] [TRT] MatMul_650 [MatMul] outputs: [1066 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_651 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1066
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Add_651 [Add] inputs: [1066 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.1.attn.q.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.1.attn.q.bias for ONNX node: backbone.block2.1.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_651 for ONNX node: Add_651
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1067 for ONNX tensor: 1067
[06/10/2022-19:21:30] [V] [TRT] Add_651 [Add] outputs: [1067 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_653 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1064
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1068
[06/10/2022-19:21:30] [V] [TRT] Div_653 [Div] inputs: [1064 -> ()[INT32]], [1068 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1068 for ONNX node: 1068
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_653 for ONNX node: Div_653
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1069 for ONNX tensor: 1069
[06/10/2022-19:21:30] [V] [TRT] Div_653 [Div] outputs: [1069 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_654 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1069
[06/10/2022-19:21:30] [V] [TRT] Cast_654 [Cast] inputs: [1069 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_654 for ONNX node: Cast_654
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1070 for ONNX tensor: 1070
[06/10/2022-19:21:30] [V] [TRT] Cast_654 [Cast] outputs: [1070 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_655 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1070
[06/10/2022-19:21:30] [V] [TRT] Cast_655 [Cast] inputs: [1070 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_655 for ONNX node: Cast_655
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1071 for ONNX tensor: 1071
[06/10/2022-19:21:30] [V] [TRT] Cast_655 [Cast] outputs: [1071 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_656 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1058
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_656 [Unsqueeze] inputs: [1058 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_656 for ONNX node: Unsqueeze_656
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1073 for ONNX tensor: 1073
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_656 [Unsqueeze] outputs: [1073 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_657 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1061
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_657 [Unsqueeze] inputs: [1061 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_657 for ONNX node: Unsqueeze_657
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1074 for ONNX tensor: 1074
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_657 [Unsqueeze] outputs: [1074 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_658 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1071
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_658 [Unsqueeze] inputs: [1071 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_658 for ONNX node: Unsqueeze_658
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1076 for ONNX tensor: 1076
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_658 [Unsqueeze] outputs: [1076 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_659 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1073
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1074
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3101
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1076
[06/10/2022-19:21:30] [V] [TRT] Concat_659 [Concat] inputs: [1073 -> (1)[INT32]], [1074 -> (1)[INT32]], [3101 -> (1)[INT32]], [1076 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3101 for ONNX node: 3101
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_659 for ONNX node: Concat_659
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1077 for ONNX tensor: 1077
[06/10/2022-19:21:30] [V] [TRT] Concat_659 [Concat] outputs: [1077 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_660 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1067
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1077
[06/10/2022-19:21:30] [V] [TRT] Reshape_660 [Reshape] inputs: [1067 -> (-1, 16384, 128)[FLOAT]], [1077 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_660 for ONNX node: Reshape_660
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1078 for ONNX tensor: 1078
[06/10/2022-19:21:30] [V] [TRT] Reshape_660 [Reshape] outputs: [1078 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_661 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1078
[06/10/2022-19:21:30] [V] [TRT] Transpose_661 [Transpose] inputs: [1078 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_661 for ONNX node: Transpose_661
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1079 for ONNX tensor: 1079
[06/10/2022-19:21:30] [V] [TRT] Transpose_661 [Transpose] outputs: [1079 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_662 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1055
[06/10/2022-19:21:30] [V] [TRT] Transpose_662 [Transpose] inputs: [1055 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_662 for ONNX node: Transpose_662
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1080 for ONNX tensor: 1080
[06/10/2022-19:21:30] [V] [TRT] Transpose_662 [Transpose] outputs: [1080 -> (-1, 128, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_663 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1058
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_663 [Unsqueeze] inputs: [1058 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_663 for ONNX node: Unsqueeze_663
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1081 for ONNX tensor: 1081
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_663 [Unsqueeze] outputs: [1081 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_664 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1064
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_664 [Unsqueeze] inputs: [1064 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_664 for ONNX node: Unsqueeze_664
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1082 for ONNX tensor: 1082
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_664 [Unsqueeze] outputs: [1082 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_665 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 873
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_665 [Unsqueeze] inputs: [873 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_665 for ONNX node: Unsqueeze_665
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1083 for ONNX tensor: 1083
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_665 [Unsqueeze] outputs: [1083 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_666 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 876
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_666 [Unsqueeze] inputs: [876 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_666 for ONNX node: Unsqueeze_666
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1084 for ONNX tensor: 1084
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_666 [Unsqueeze] outputs: [1084 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_667 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1081
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1082
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1083
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1084
[06/10/2022-19:21:30] [V] [TRT] Concat_667 [Concat] inputs: [1081 -> (1)[INT32]], [1082 -> (1)[INT32]], [1083 -> (1)[INT32]], [1084 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_667 for ONNX node: Concat_667
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1085 for ONNX tensor: 1085
[06/10/2022-19:21:30] [V] [TRT] Concat_667 [Concat] outputs: [1085 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_668 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1080
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1085
[06/10/2022-19:21:30] [V] [TRT] Reshape_668 [Reshape] inputs: [1080 -> (-1, 128, 16384)[FLOAT]], [1085 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_668 for ONNX node: Reshape_668
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1086 for ONNX tensor: 1086
[06/10/2022-19:21:30] [V] [TRT] Reshape_668 [Reshape] outputs: [1086 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_669 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1086
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_669 [Conv] inputs: [1086 -> (-1, 128, 128, 128)[FLOAT]], [backbone.block2.1.attn.sr.weight -> (128, 128, 4, 4)[FLOAT]], [backbone.block2.1.attn.sr.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 128, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_669 for ONNX node: Conv_669
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (4, 4), strides: (4, 4), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 128, 32, 32)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1087 for ONNX tensor: 1087
[06/10/2022-19:21:30] [V] [TRT] Conv_669 [Conv] outputs: [1087 -> (-1, 128, 32, 32)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_670 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1058
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_670 [Unsqueeze] inputs: [1058 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_670 for ONNX node: Unsqueeze_670
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1089 for ONNX tensor: 1089
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_670 [Unsqueeze] outputs: [1089 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_671 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1064
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_671 [Unsqueeze] inputs: [1064 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_671 for ONNX node: Unsqueeze_671
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1090 for ONNX tensor: 1090
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_671 [Unsqueeze] outputs: [1090 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_672 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1089
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1090
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3102
[06/10/2022-19:21:30] [V] [TRT] Concat_672 [Concat] inputs: [1089 -> (1)[INT32]], [1090 -> (1)[INT32]], [3102 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3102 for ONNX node: 3102
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_672 for ONNX node: Concat_672
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1092 for ONNX tensor: 1092
[06/10/2022-19:21:30] [V] [TRT] Concat_672 [Concat] outputs: [1092 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_673 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1087
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1092
[06/10/2022-19:21:30] [V] [TRT] Reshape_673 [Reshape] inputs: [1087 -> (-1, 128, 32, 32)[FLOAT]], [1092 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_673 for ONNX node: Reshape_673
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1093 for ONNX tensor: 1093
[06/10/2022-19:21:30] [V] [TRT] Reshape_673 [Reshape] outputs: [1093 -> (-1, 128, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_674 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1093
[06/10/2022-19:21:30] [V] [TRT] Transpose_674 [Transpose] inputs: [1093 -> (-1, 128, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_674 for ONNX node: Transpose_674
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1094 for ONNX tensor: 1094
[06/10/2022-19:21:30] [V] [TRT] Transpose_674 [Transpose] outputs: [1094 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_675 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1094
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_675 [ReduceMean] inputs: [1094 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_675 for ONNX node: ReduceMean_675
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1095 for ONNX tensor: 1095
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_675 [ReduceMean] outputs: [1095 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_676 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1094
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1095
[06/10/2022-19:21:30] [V] [TRT] Sub_676 [Sub] inputs: [1094 -> (-1, 1024, 128)[FLOAT]], [1095 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_676 for ONNX node: Sub_676
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1096 for ONNX tensor: 1096
[06/10/2022-19:21:30] [V] [TRT] Sub_676 [Sub] outputs: [1096 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_678 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1096
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1097
[06/10/2022-19:21:30] [V] [TRT] Pow_678 [Pow] inputs: [1096 -> (-1, 1024, 128)[FLOAT]], [1097 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1097 for ONNX node: 1097
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_678 for ONNX node: Pow_678
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1098 for ONNX tensor: 1098
[06/10/2022-19:21:30] [V] [TRT] Pow_678 [Pow] outputs: [1098 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_679 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1098
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_679 [ReduceMean] inputs: [1098 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_679 for ONNX node: ReduceMean_679
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1099 for ONNX tensor: 1099
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_679 [ReduceMean] outputs: [1099 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_681 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1099
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1100
[06/10/2022-19:21:30] [V] [TRT] Add_681 [Add] inputs: [1099 -> (-1, 1024, 1)[FLOAT]], [1100 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1100 for ONNX node: 1100
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_681 for ONNX node: Add_681
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1101 for ONNX tensor: 1101
[06/10/2022-19:21:30] [V] [TRT] Add_681 [Add] outputs: [1101 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_682 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1101
[06/10/2022-19:21:30] [V] [TRT] Sqrt_682 [Sqrt] inputs: [1101 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_682 for ONNX node: Sqrt_682
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1102 for ONNX tensor: 1102
[06/10/2022-19:21:30] [V] [TRT] Sqrt_682 [Sqrt] outputs: [1102 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_683 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1096
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1102
[06/10/2022-19:21:30] [V] [TRT] Div_683 [Div] inputs: [1096 -> (-1, 1024, 128)[FLOAT]], [1102 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_683 for ONNX node: Div_683
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1103 for ONNX tensor: 1103
[06/10/2022-19:21:30] [V] [TRT] Div_683 [Div] outputs: [1103 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_684 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1103
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_684 [Mul] inputs: [1103 -> (-1, 1024, 128)[FLOAT]], [backbone.block2.1.attn.norm.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.1.attn.norm.weight for ONNX node: backbone.block2.1.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_684 for ONNX node: Mul_684
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1104 for ONNX tensor: 1104
[06/10/2022-19:21:30] [V] [TRT] Mul_684 [Mul] outputs: [1104 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_685 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1104
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Add_685 [Add] inputs: [1104 -> (-1, 1024, 128)[FLOAT]], [backbone.block2.1.attn.norm.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.1.attn.norm.bias for ONNX node: backbone.block2.1.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_685 for ONNX node: Add_685
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1105 for ONNX tensor: 1105
[06/10/2022-19:21:30] [V] [TRT] Add_685 [Add] outputs: [1105 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_686 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1105
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3103
[06/10/2022-19:21:30] [V] [TRT] MatMul_686 [MatMul] inputs: [1105 -> (-1, 1024, 128)[FLOAT]], [3103 -> (128, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3103 for ONNX node: 3103
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_686 for ONNX node: MatMul_686
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1107 for ONNX tensor: 1107
[06/10/2022-19:21:30] [V] [TRT] MatMul_686 [MatMul] outputs: [1107 -> (-1, 1024, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_687 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1107
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Add_687 [Add] inputs: [1107 -> (-1, 1024, 256)[FLOAT]], [backbone.block2.1.attn.kv.bias -> (256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.1.attn.kv.bias for ONNX node: backbone.block2.1.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_687 for ONNX node: Add_687
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1108 for ONNX tensor: 1108
[06/10/2022-19:21:30] [V] [TRT] Add_687 [Add] outputs: [1108 -> (-1, 1024, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_689 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1064
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1109
[06/10/2022-19:21:30] [V] [TRT] Div_689 [Div] inputs: [1064 -> ()[INT32]], [1109 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1109 for ONNX node: 1109
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_689 for ONNX node: Div_689
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1110 for ONNX tensor: 1110
[06/10/2022-19:21:30] [V] [TRT] Div_689 [Div] outputs: [1110 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_690 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1110
[06/10/2022-19:21:30] [V] [TRT] Cast_690 [Cast] inputs: [1110 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_690 for ONNX node: Cast_690
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1111 for ONNX tensor: 1111
[06/10/2022-19:21:30] [V] [TRT] Cast_690 [Cast] outputs: [1111 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_691 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1111
[06/10/2022-19:21:30] [V] [TRT] Cast_691 [Cast] inputs: [1111 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_691 for ONNX node: Cast_691
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1112 for ONNX tensor: 1112
[06/10/2022-19:21:30] [V] [TRT] Cast_691 [Cast] outputs: [1112 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_692 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1058
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_692 [Unsqueeze] inputs: [1058 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_692 for ONNX node: Unsqueeze_692
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1116 for ONNX tensor: 1116
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_692 [Unsqueeze] outputs: [1116 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_693 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1112
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_693 [Unsqueeze] inputs: [1112 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_693 for ONNX node: Unsqueeze_693
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1120 for ONNX tensor: 1120
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_693 [Unsqueeze] outputs: [1120 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_694 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1116
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3104
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3105
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3106
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1120
[06/10/2022-19:21:30] [V] [TRT] Concat_694 [Concat] inputs: [1116 -> (1)[INT32]], [3104 -> (1)[INT32]], [3105 -> (1)[INT32]], [3106 -> (1)[INT32]], [1120 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3104 for ONNX node: 3104
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3105 for ONNX node: 3105
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3106 for ONNX node: 3106
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_694 for ONNX node: Concat_694
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1121 for ONNX tensor: 1121
[06/10/2022-19:21:30] [V] [TRT] Concat_694 [Concat] outputs: [1121 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_695 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1108
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1121
[06/10/2022-19:21:30] [V] [TRT] Reshape_695 [Reshape] inputs: [1108 -> (-1, 1024, 256)[FLOAT]], [1121 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_695 for ONNX node: Reshape_695
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1122 for ONNX tensor: 1122
[06/10/2022-19:21:30] [V] [TRT] Reshape_695 [Reshape] outputs: [1122 -> (-1, 1024, 2, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_696 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1122
[06/10/2022-19:21:30] [V] [TRT] Transpose_696 [Transpose] inputs: [1122 -> (-1, 1024, 2, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_696 for ONNX node: Transpose_696
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1123 for ONNX tensor: 1123
[06/10/2022-19:21:30] [V] [TRT] Transpose_696 [Transpose] outputs: [1123 -> (2, -1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_698 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1123
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1124
[06/10/2022-19:21:30] [V] [TRT] Gather_698 [Gather] inputs: [1123 -> (2, -1, 2, 1024, 64)[FLOAT]], [1124 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1124 for ONNX node: 1124
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_698 for ONNX node: Gather_698
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1125 for ONNX tensor: 1125
[06/10/2022-19:21:30] [V] [TRT] Gather_698 [Gather] outputs: [1125 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_700 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1123
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1126
[06/10/2022-19:21:30] [V] [TRT] Gather_700 [Gather] inputs: [1123 -> (2, -1, 2, 1024, 64)[FLOAT]], [1126 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1126 for ONNX node: 1126
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_700 for ONNX node: Gather_700
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1127 for ONNX tensor: 1127
[06/10/2022-19:21:30] [V] [TRT] Gather_700 [Gather] outputs: [1127 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_701 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1125
[06/10/2022-19:21:30] [V] [TRT] Transpose_701 [Transpose] inputs: [1125 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_701 for ONNX node: Transpose_701
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1128 for ONNX tensor: 1128
[06/10/2022-19:21:30] [V] [TRT] Transpose_701 [Transpose] outputs: [1128 -> (-1, 2, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_702 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1079
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1128
[06/10/2022-19:21:30] [V] [TRT] MatMul_702 [MatMul] inputs: [1079 -> (-1, 2, 16384, 64)[FLOAT]], [1128 -> (-1, 2, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_702 for ONNX node: MatMul_702
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1129 for ONNX tensor: 1129
[06/10/2022-19:21:30] [V] [TRT] MatMul_702 [MatMul] outputs: [1129 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_704 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1129
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1130
[06/10/2022-19:21:30] [V] [TRT] Mul_704 [Mul] inputs: [1129 -> (-1, 2, 16384, 1024)[FLOAT]], [1130 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1130 for ONNX node: 1130
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_704 for ONNX node: Mul_704
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1131 for ONNX tensor: 1131
[06/10/2022-19:21:30] [V] [TRT] Mul_704 [Mul] outputs: [1131 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Softmax_705 [Softmax]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1131
[06/10/2022-19:21:30] [V] [TRT] Softmax_705 [Softmax] inputs: [1131 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Softmax_705 for ONNX node: Softmax_705
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1132 for ONNX tensor: 1132
[06/10/2022-19:21:30] [V] [TRT] Softmax_705 [Softmax] outputs: [1132 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_706 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1132
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1127
[06/10/2022-19:21:30] [V] [TRT] MatMul_706 [MatMul] inputs: [1132 -> (-1, 2, 16384, 1024)[FLOAT]], [1127 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_706 for ONNX node: MatMul_706
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1133 for ONNX tensor: 1133
[06/10/2022-19:21:30] [V] [TRT] MatMul_706 [MatMul] outputs: [1133 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_707 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1133
[06/10/2022-19:21:30] [V] [TRT] Transpose_707 [Transpose] inputs: [1133 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_707 for ONNX node: Transpose_707
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1134 for ONNX tensor: 1134
[06/10/2022-19:21:30] [V] [TRT] Transpose_707 [Transpose] outputs: [1134 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_708 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1058
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_708 [Unsqueeze] inputs: [1058 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_708 for ONNX node: Unsqueeze_708
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1135 for ONNX tensor: 1135
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_708 [Unsqueeze] outputs: [1135 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_709 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1061
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_709 [Unsqueeze] inputs: [1061 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_709 for ONNX node: Unsqueeze_709
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1136 for ONNX tensor: 1136
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_709 [Unsqueeze] outputs: [1136 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_710 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1064
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_710 [Unsqueeze] inputs: [1064 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_710 for ONNX node: Unsqueeze_710
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1137 for ONNX tensor: 1137
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_710 [Unsqueeze] outputs: [1137 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_711 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1135
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1136
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1137
[06/10/2022-19:21:30] [V] [TRT] Concat_711 [Concat] inputs: [1135 -> (1)[INT32]], [1136 -> (1)[INT32]], [1137 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_711 for ONNX node: Concat_711
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1138 for ONNX tensor: 1138
[06/10/2022-19:21:30] [V] [TRT] Concat_711 [Concat] outputs: [1138 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_712 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1134
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1138
[06/10/2022-19:21:30] [V] [TRT] Reshape_712 [Reshape] inputs: [1134 -> (-1, 16384, 2, 64)[FLOAT]], [1138 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_712 for ONNX node: Reshape_712
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1139 for ONNX tensor: 1139
[06/10/2022-19:21:30] [V] [TRT] Reshape_712 [Reshape] outputs: [1139 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_713 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1139
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3107
[06/10/2022-19:21:30] [V] [TRT] MatMul_713 [MatMul] inputs: [1139 -> (-1, 16384, 128)[FLOAT]], [3107 -> (128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3107 for ONNX node: 3107
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_713 for ONNX node: MatMul_713
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1141 for ONNX tensor: 1141
[06/10/2022-19:21:30] [V] [TRT] MatMul_713 [MatMul] outputs: [1141 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_714 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1141
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Add_714 [Add] inputs: [1141 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.1.attn.proj.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.1.attn.proj.bias for ONNX node: backbone.block2.1.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_714 for ONNX node: Add_714
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1142 for ONNX tensor: 1142
[06/10/2022-19:21:30] [V] [TRT] Add_714 [Add] outputs: [1142 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_715 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1044
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1142
[06/10/2022-19:21:30] [V] [TRT] Add_715 [Add] inputs: [1044 -> (-1, 16384, 128)[FLOAT]], [1142 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_715 for ONNX node: Add_715
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1143 for ONNX tensor: 1143
[06/10/2022-19:21:30] [V] [TRT] Add_715 [Add] outputs: [1143 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_716 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1143
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_716 [ReduceMean] inputs: [1143 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_716 for ONNX node: ReduceMean_716
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1144 for ONNX tensor: 1144
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_716 [ReduceMean] outputs: [1144 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_717 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1143
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1144
[06/10/2022-19:21:30] [V] [TRT] Sub_717 [Sub] inputs: [1143 -> (-1, 16384, 128)[FLOAT]], [1144 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_717 for ONNX node: Sub_717
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1145 for ONNX tensor: 1145
[06/10/2022-19:21:30] [V] [TRT] Sub_717 [Sub] outputs: [1145 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_719 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1145
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1146
[06/10/2022-19:21:30] [V] [TRT] Pow_719 [Pow] inputs: [1145 -> (-1, 16384, 128)[FLOAT]], [1146 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1146 for ONNX node: 1146
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_719 for ONNX node: Pow_719
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1147 for ONNX tensor: 1147
[06/10/2022-19:21:30] [V] [TRT] Pow_719 [Pow] outputs: [1147 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_720 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1147
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_720 [ReduceMean] inputs: [1147 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_720 for ONNX node: ReduceMean_720
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1148 for ONNX tensor: 1148
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_720 [ReduceMean] outputs: [1148 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_722 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1148
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1149
[06/10/2022-19:21:30] [V] [TRT] Add_722 [Add] inputs: [1148 -> (-1, 16384, 1)[FLOAT]], [1149 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1149 for ONNX node: 1149
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_722 for ONNX node: Add_722
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1150 for ONNX tensor: 1150
[06/10/2022-19:21:30] [V] [TRT] Add_722 [Add] outputs: [1150 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_723 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1150
[06/10/2022-19:21:30] [V] [TRT] Sqrt_723 [Sqrt] inputs: [1150 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_723 for ONNX node: Sqrt_723
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1151 for ONNX tensor: 1151
[06/10/2022-19:21:30] [V] [TRT] Sqrt_723 [Sqrt] outputs: [1151 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_724 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1145
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1151
[06/10/2022-19:21:30] [V] [TRT] Div_724 [Div] inputs: [1145 -> (-1, 16384, 128)[FLOAT]], [1151 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_724 for ONNX node: Div_724
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1152 for ONNX tensor: 1152
[06/10/2022-19:21:30] [V] [TRT] Div_724 [Div] outputs: [1152 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_725 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1152
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_725 [Mul] inputs: [1152 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.1.norm2.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.1.norm2.weight for ONNX node: backbone.block2.1.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_725 for ONNX node: Mul_725
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1153 for ONNX tensor: 1153
[06/10/2022-19:21:30] [V] [TRT] Mul_725 [Mul] outputs: [1153 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_726 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1153
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_726 [Add] inputs: [1153 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.1.norm2.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.1.norm2.bias for ONNX node: backbone.block2.1.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_726 for ONNX node: Add_726
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1154 for ONNX tensor: 1154
[06/10/2022-19:21:30] [V] [TRT] Add_726 [Add] outputs: [1154 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_727 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1154
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3108
[06/10/2022-19:21:30] [V] [TRT] MatMul_727 [MatMul] inputs: [1154 -> (-1, 16384, 128)[FLOAT]], [3108 -> (128, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3108 for ONNX node: 3108
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_727 for ONNX node: MatMul_727
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1156 for ONNX tensor: 1156
[06/10/2022-19:21:30] [V] [TRT] MatMul_727 [MatMul] outputs: [1156 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_728 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1156
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_728 [Add] inputs: [1156 -> (-1, 16384, 512)[FLOAT]], [backbone.block2.1.mlp.fc1.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.1.mlp.fc1.bias for ONNX node: backbone.block2.1.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_728 for ONNX node: Add_728
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1157 for ONNX tensor: 1157
[06/10/2022-19:21:30] [V] [TRT] Add_728 [Add] outputs: [1157 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_729 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1157
[06/10/2022-19:21:30] [V] [TRT] Shape_729 [Shape] inputs: [1157 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_729 for ONNX node: Shape_729
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1158 for ONNX tensor: 1158
[06/10/2022-19:21:30] [V] [TRT] Shape_729 [Shape] outputs: [1158 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_731 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1158
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1159
[06/10/2022-19:21:30] [V] [TRT] Gather_731 [Gather] inputs: [1158 -> (3)[INT32]], [1159 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1159 for ONNX node: 1159
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_731 for ONNX node: Gather_731
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1160 for ONNX tensor: 1160
[06/10/2022-19:21:30] [V] [TRT] Gather_731 [Gather] outputs: [1160 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_732 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1157
[06/10/2022-19:21:30] [V] [TRT] Shape_732 [Shape] inputs: [1157 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_732 for ONNX node: Shape_732
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1161 for ONNX tensor: 1161
[06/10/2022-19:21:30] [V] [TRT] Shape_732 [Shape] outputs: [1161 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_734 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1161
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1162
[06/10/2022-19:21:30] [V] [TRT] Gather_734 [Gather] inputs: [1161 -> (3)[INT32]], [1162 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1162 for ONNX node: 1162
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_734 for ONNX node: Gather_734
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1163 for ONNX tensor: 1163
[06/10/2022-19:21:30] [V] [TRT] Gather_734 [Gather] outputs: [1163 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_735 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1157
[06/10/2022-19:21:30] [V] [TRT] Transpose_735 [Transpose] inputs: [1157 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_735 for ONNX node: Transpose_735
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1164 for ONNX tensor: 1164
[06/10/2022-19:21:30] [V] [TRT] Transpose_735 [Transpose] outputs: [1164 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_736 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1160
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_736 [Unsqueeze] inputs: [1160 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_736 for ONNX node: Unsqueeze_736
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1165 for ONNX tensor: 1165
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_736 [Unsqueeze] outputs: [1165 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_737 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1163
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_737 [Unsqueeze] inputs: [1163 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_737 for ONNX node: Unsqueeze_737
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1166 for ONNX tensor: 1166
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_737 [Unsqueeze] outputs: [1166 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_738 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 873
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_738 [Unsqueeze] inputs: [873 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_738 for ONNX node: Unsqueeze_738
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1167 for ONNX tensor: 1167
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_738 [Unsqueeze] outputs: [1167 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_739 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 876
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_739 [Unsqueeze] inputs: [876 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_739 for ONNX node: Unsqueeze_739
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1168 for ONNX tensor: 1168
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_739 [Unsqueeze] outputs: [1168 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_740 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1165
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1166
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1167
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1168
[06/10/2022-19:21:30] [V] [TRT] Concat_740 [Concat] inputs: [1165 -> (1)[INT32]], [1166 -> (1)[INT32]], [1167 -> (1)[INT32]], [1168 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_740 for ONNX node: Concat_740
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1169 for ONNX tensor: 1169
[06/10/2022-19:21:30] [V] [TRT] Concat_740 [Concat] outputs: [1169 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_741 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1164
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1169
[06/10/2022-19:21:30] [V] [TRT] Reshape_741 [Reshape] inputs: [1164 -> (-1, 512, 16384)[FLOAT]], [1169 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_741 for ONNX node: Reshape_741
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1170 for ONNX tensor: 1170
[06/10/2022-19:21:30] [V] [TRT] Reshape_741 [Reshape] outputs: [1170 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_742 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1170
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_742 [Conv] inputs: [1170 -> (-1, 512, 128, 128)[FLOAT]], [backbone.block2.1.mlp.dwconv.dwconv.weight -> (512, 1, 3, 3)[FLOAT]], [backbone.block2.1.mlp.dwconv.dwconv.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 512, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_742 for ONNX node: Conv_742
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 512, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1171 for ONNX tensor: 1171
[06/10/2022-19:21:30] [V] [TRT] Conv_742 [Conv] outputs: [1171 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_743 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1171
[06/10/2022-19:21:30] [V] [TRT] Shape_743 [Shape] inputs: [1171 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_743 for ONNX node: Shape_743
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1172 for ONNX tensor: 1172
[06/10/2022-19:21:30] [V] [TRT] Shape_743 [Shape] outputs: [1172 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_747 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1172
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1174
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1175
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1173
[06/10/2022-19:21:30] [V] [TRT] Slice_747 [Slice] inputs: [1172 -> (4)[INT32]], [1174 -> (1)[INT32]], [1175 -> (1)[INT32]], [1173 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_747 for ONNX node: Slice_747
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1176 for ONNX tensor: 1176
[06/10/2022-19:21:30] [V] [TRT] Slice_747 [Slice] outputs: [1176 -> (2)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_749 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1176
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1177
[06/10/2022-19:21:30] [V] [TRT] Concat_749 [Concat] inputs: [1176 -> (2)[INT32]], [1177 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1177 for ONNX node: 1177
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_749 for ONNX node: Concat_749
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1178 for ONNX tensor: 1178
[06/10/2022-19:21:30] [V] [TRT] Concat_749 [Concat] outputs: [1178 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_750 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1171
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1178
[06/10/2022-19:21:30] [V] [TRT] Reshape_750 [Reshape] inputs: [1171 -> (-1, 512, 128, 128)[FLOAT]], [1178 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_750 for ONNX node: Reshape_750
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1179 for ONNX tensor: 1179
[06/10/2022-19:21:30] [V] [TRT] Reshape_750 [Reshape] outputs: [1179 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_751 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1179
[06/10/2022-19:21:30] [V] [TRT] Transpose_751 [Transpose] inputs: [1179 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_751 for ONNX node: Transpose_751
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1180 for ONNX tensor: 1180
[06/10/2022-19:21:30] [V] [TRT] Transpose_751 [Transpose] outputs: [1180 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_753 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1180
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1181
[06/10/2022-19:21:30] [V] [TRT] Div_753 [Div] inputs: [1180 -> (-1, 16384, 512)[FLOAT]], [1181 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1181 for ONNX node: 1181
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_753 for ONNX node: Div_753
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1182 for ONNX tensor: 1182
[06/10/2022-19:21:30] [V] [TRT] Div_753 [Div] outputs: [1182 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Erf_754 [Erf]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1182
[06/10/2022-19:21:30] [V] [TRT] Erf_754 [Erf] inputs: [1182 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Erf_754 for ONNX node: Erf_754
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1183 for ONNX tensor: 1183
[06/10/2022-19:21:30] [V] [TRT] Erf_754 [Erf] outputs: [1183 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_756 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1183
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1184
[06/10/2022-19:21:30] [V] [TRT] Add_756 [Add] inputs: [1183 -> (-1, 16384, 512)[FLOAT]], [1184 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1184 for ONNX node: 1184
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_756 for ONNX node: Add_756
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1185 for ONNX tensor: 1185
[06/10/2022-19:21:30] [V] [TRT] Add_756 [Add] outputs: [1185 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_757 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1180
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1185
[06/10/2022-19:21:30] [V] [TRT] Mul_757 [Mul] inputs: [1180 -> (-1, 16384, 512)[FLOAT]], [1185 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_757 for ONNX node: Mul_757
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1186 for ONNX tensor: 1186
[06/10/2022-19:21:30] [V] [TRT] Mul_757 [Mul] outputs: [1186 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_759 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1186
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1187
[06/10/2022-19:21:30] [V] [TRT] Mul_759 [Mul] inputs: [1186 -> (-1, 16384, 512)[FLOAT]], [1187 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1187 for ONNX node: 1187
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_759 for ONNX node: Mul_759
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1188 for ONNX tensor: 1188
[06/10/2022-19:21:30] [V] [TRT] Mul_759 [Mul] outputs: [1188 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_760 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1188
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3109
[06/10/2022-19:21:30] [V] [TRT] MatMul_760 [MatMul] inputs: [1188 -> (-1, 16384, 512)[FLOAT]], [3109 -> (512, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3109 for ONNX node: 3109
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_760 for ONNX node: MatMul_760
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1190 for ONNX tensor: 1190
[06/10/2022-19:21:30] [V] [TRT] MatMul_760 [MatMul] outputs: [1190 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_761 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1190
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.1.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_761 [Add] inputs: [1190 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.1.mlp.fc2.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.1.mlp.fc2.bias for ONNX node: backbone.block2.1.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_761 for ONNX node: Add_761
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1191 for ONNX tensor: 1191
[06/10/2022-19:21:30] [V] [TRT] Add_761 [Add] outputs: [1191 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_762 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1143
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1191
[06/10/2022-19:21:30] [V] [TRT] Add_762 [Add] inputs: [1143 -> (-1, 16384, 128)[FLOAT]], [1191 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_762 for ONNX node: Add_762
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1192 for ONNX tensor: 1192
[06/10/2022-19:21:30] [V] [TRT] Add_762 [Add] outputs: [1192 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_763 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1192
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_763 [ReduceMean] inputs: [1192 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_763 for ONNX node: ReduceMean_763
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1193 for ONNX tensor: 1193
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_763 [ReduceMean] outputs: [1193 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_764 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1192
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1193
[06/10/2022-19:21:30] [V] [TRT] Sub_764 [Sub] inputs: [1192 -> (-1, 16384, 128)[FLOAT]], [1193 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_764 for ONNX node: Sub_764
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1194 for ONNX tensor: 1194
[06/10/2022-19:21:30] [V] [TRT] Sub_764 [Sub] outputs: [1194 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_766 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1194
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1195
[06/10/2022-19:21:30] [V] [TRT] Pow_766 [Pow] inputs: [1194 -> (-1, 16384, 128)[FLOAT]], [1195 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1195 for ONNX node: 1195
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_766 for ONNX node: Pow_766
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1196 for ONNX tensor: 1196
[06/10/2022-19:21:30] [V] [TRT] Pow_766 [Pow] outputs: [1196 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_767 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1196
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_767 [ReduceMean] inputs: [1196 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_767 for ONNX node: ReduceMean_767
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1197 for ONNX tensor: 1197
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_767 [ReduceMean] outputs: [1197 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_769 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1197
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1198
[06/10/2022-19:21:30] [V] [TRT] Add_769 [Add] inputs: [1197 -> (-1, 16384, 1)[FLOAT]], [1198 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1198 for ONNX node: 1198
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_769 for ONNX node: Add_769
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1199 for ONNX tensor: 1199
[06/10/2022-19:21:30] [V] [TRT] Add_769 [Add] outputs: [1199 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_770 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1199
[06/10/2022-19:21:30] [V] [TRT] Sqrt_770 [Sqrt] inputs: [1199 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_770 for ONNX node: Sqrt_770
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1200 for ONNX tensor: 1200
[06/10/2022-19:21:30] [V] [TRT] Sqrt_770 [Sqrt] outputs: [1200 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_771 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1194
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1200
[06/10/2022-19:21:30] [V] [TRT] Div_771 [Div] inputs: [1194 -> (-1, 16384, 128)[FLOAT]], [1200 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_771 for ONNX node: Div_771
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1201 for ONNX tensor: 1201
[06/10/2022-19:21:30] [V] [TRT] Div_771 [Div] outputs: [1201 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_772 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1201
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_772 [Mul] inputs: [1201 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.2.norm1.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.2.norm1.weight for ONNX node: backbone.block2.2.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_772 for ONNX node: Mul_772
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1202 for ONNX tensor: 1202
[06/10/2022-19:21:30] [V] [TRT] Mul_772 [Mul] outputs: [1202 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_773 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1202
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_773 [Add] inputs: [1202 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.2.norm1.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.2.norm1.bias for ONNX node: backbone.block2.2.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_773 for ONNX node: Add_773
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1203 for ONNX tensor: 1203
[06/10/2022-19:21:30] [V] [TRT] Add_773 [Add] outputs: [1203 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_774 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1203
[06/10/2022-19:21:30] [V] [TRT] Shape_774 [Shape] inputs: [1203 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_774 for ONNX node: Shape_774
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1204 for ONNX tensor: 1204
[06/10/2022-19:21:30] [V] [TRT] Shape_774 [Shape] outputs: [1204 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_776 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1204
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1205
[06/10/2022-19:21:30] [V] [TRT] Gather_776 [Gather] inputs: [1204 -> (3)[INT32]], [1205 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1205 for ONNX node: 1205
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_776 for ONNX node: Gather_776
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1206 for ONNX tensor: 1206
[06/10/2022-19:21:30] [V] [TRT] Gather_776 [Gather] outputs: [1206 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_777 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1203
[06/10/2022-19:21:30] [V] [TRT] Shape_777 [Shape] inputs: [1203 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_777 for ONNX node: Shape_777
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1207 for ONNX tensor: 1207
[06/10/2022-19:21:30] [V] [TRT] Shape_777 [Shape] outputs: [1207 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_779 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1207
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1208
[06/10/2022-19:21:30] [V] [TRT] Gather_779 [Gather] inputs: [1207 -> (3)[INT32]], [1208 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1208 for ONNX node: 1208
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_779 for ONNX node: Gather_779
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1209 for ONNX tensor: 1209
[06/10/2022-19:21:30] [V] [TRT] Gather_779 [Gather] outputs: [1209 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_780 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1203
[06/10/2022-19:21:30] [V] [TRT] Shape_780 [Shape] inputs: [1203 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_780 for ONNX node: Shape_780
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1210 for ONNX tensor: 1210
[06/10/2022-19:21:30] [V] [TRT] Shape_780 [Shape] outputs: [1210 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_782 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1210
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1211
[06/10/2022-19:21:30] [V] [TRT] Gather_782 [Gather] inputs: [1210 -> (3)[INT32]], [1211 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1211 for ONNX node: 1211
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_782 for ONNX node: Gather_782
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1212 for ONNX tensor: 1212
[06/10/2022-19:21:30] [V] [TRT] Gather_782 [Gather] outputs: [1212 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_783 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1203
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3110
[06/10/2022-19:21:30] [V] [TRT] MatMul_783 [MatMul] inputs: [1203 -> (-1, 16384, 128)[FLOAT]], [3110 -> (128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3110 for ONNX node: 3110
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_783 for ONNX node: MatMul_783
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1214 for ONNX tensor: 1214
[06/10/2022-19:21:30] [V] [TRT] MatMul_783 [MatMul] outputs: [1214 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_784 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1214
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Add_784 [Add] inputs: [1214 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.2.attn.q.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.2.attn.q.bias for ONNX node: backbone.block2.2.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_784 for ONNX node: Add_784
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1215 for ONNX tensor: 1215
[06/10/2022-19:21:30] [V] [TRT] Add_784 [Add] outputs: [1215 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_786 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1212
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1216
[06/10/2022-19:21:30] [V] [TRT] Div_786 [Div] inputs: [1212 -> ()[INT32]], [1216 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1216 for ONNX node: 1216
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_786 for ONNX node: Div_786
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1217 for ONNX tensor: 1217
[06/10/2022-19:21:30] [V] [TRT] Div_786 [Div] outputs: [1217 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_787 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1217
[06/10/2022-19:21:30] [V] [TRT] Cast_787 [Cast] inputs: [1217 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_787 for ONNX node: Cast_787
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1218 for ONNX tensor: 1218
[06/10/2022-19:21:30] [V] [TRT] Cast_787 [Cast] outputs: [1218 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_788 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1218
[06/10/2022-19:21:30] [V] [TRT] Cast_788 [Cast] inputs: [1218 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_788 for ONNX node: Cast_788
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1219 for ONNX tensor: 1219
[06/10/2022-19:21:30] [V] [TRT] Cast_788 [Cast] outputs: [1219 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_789 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1206
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_789 [Unsqueeze] inputs: [1206 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_789 for ONNX node: Unsqueeze_789
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1221 for ONNX tensor: 1221
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_789 [Unsqueeze] outputs: [1221 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_790 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1209
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_790 [Unsqueeze] inputs: [1209 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_790 for ONNX node: Unsqueeze_790
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1222 for ONNX tensor: 1222
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_790 [Unsqueeze] outputs: [1222 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_791 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1219
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_791 [Unsqueeze] inputs: [1219 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_791 for ONNX node: Unsqueeze_791
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1224 for ONNX tensor: 1224
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_791 [Unsqueeze] outputs: [1224 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_792 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1221
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1222
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3111
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1224
[06/10/2022-19:21:30] [V] [TRT] Concat_792 [Concat] inputs: [1221 -> (1)[INT32]], [1222 -> (1)[INT32]], [3111 -> (1)[INT32]], [1224 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3111 for ONNX node: 3111
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_792 for ONNX node: Concat_792
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1225 for ONNX tensor: 1225
[06/10/2022-19:21:30] [V] [TRT] Concat_792 [Concat] outputs: [1225 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_793 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1215
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1225
[06/10/2022-19:21:30] [V] [TRT] Reshape_793 [Reshape] inputs: [1215 -> (-1, 16384, 128)[FLOAT]], [1225 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_793 for ONNX node: Reshape_793
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1226 for ONNX tensor: 1226
[06/10/2022-19:21:30] [V] [TRT] Reshape_793 [Reshape] outputs: [1226 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_794 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1226
[06/10/2022-19:21:30] [V] [TRT] Transpose_794 [Transpose] inputs: [1226 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_794 for ONNX node: Transpose_794
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1227 for ONNX tensor: 1227
[06/10/2022-19:21:30] [V] [TRT] Transpose_794 [Transpose] outputs: [1227 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_795 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1203
[06/10/2022-19:21:30] [V] [TRT] Transpose_795 [Transpose] inputs: [1203 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_795 for ONNX node: Transpose_795
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1228 for ONNX tensor: 1228
[06/10/2022-19:21:30] [V] [TRT] Transpose_795 [Transpose] outputs: [1228 -> (-1, 128, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_796 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1206
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_796 [Unsqueeze] inputs: [1206 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_796 for ONNX node: Unsqueeze_796
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1229 for ONNX tensor: 1229
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_796 [Unsqueeze] outputs: [1229 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_797 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1212
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_797 [Unsqueeze] inputs: [1212 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_797 for ONNX node: Unsqueeze_797
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1230 for ONNX tensor: 1230
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_797 [Unsqueeze] outputs: [1230 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_798 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 873
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_798 [Unsqueeze] inputs: [873 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_798 for ONNX node: Unsqueeze_798
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1231 for ONNX tensor: 1231
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_798 [Unsqueeze] outputs: [1231 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_799 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 876
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_799 [Unsqueeze] inputs: [876 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_799 for ONNX node: Unsqueeze_799
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1232 for ONNX tensor: 1232
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_799 [Unsqueeze] outputs: [1232 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_800 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1229
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1230
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1231
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1232
[06/10/2022-19:21:30] [V] [TRT] Concat_800 [Concat] inputs: [1229 -> (1)[INT32]], [1230 -> (1)[INT32]], [1231 -> (1)[INT32]], [1232 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_800 for ONNX node: Concat_800
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1233 for ONNX tensor: 1233
[06/10/2022-19:21:30] [V] [TRT] Concat_800 [Concat] outputs: [1233 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_801 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1228
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1233
[06/10/2022-19:21:30] [V] [TRT] Reshape_801 [Reshape] inputs: [1228 -> (-1, 128, 16384)[FLOAT]], [1233 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_801 for ONNX node: Reshape_801
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1234 for ONNX tensor: 1234
[06/10/2022-19:21:30] [V] [TRT] Reshape_801 [Reshape] outputs: [1234 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_802 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1234
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_802 [Conv] inputs: [1234 -> (-1, 128, 128, 128)[FLOAT]], [backbone.block2.2.attn.sr.weight -> (128, 128, 4, 4)[FLOAT]], [backbone.block2.2.attn.sr.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 128, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_802 for ONNX node: Conv_802
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (4, 4), strides: (4, 4), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 128, 32, 32)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1235 for ONNX tensor: 1235
[06/10/2022-19:21:30] [V] [TRT] Conv_802 [Conv] outputs: [1235 -> (-1, 128, 32, 32)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_803 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1206
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_803 [Unsqueeze] inputs: [1206 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_803 for ONNX node: Unsqueeze_803
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1237 for ONNX tensor: 1237
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_803 [Unsqueeze] outputs: [1237 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_804 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1212
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_804 [Unsqueeze] inputs: [1212 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_804 for ONNX node: Unsqueeze_804
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1238 for ONNX tensor: 1238
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_804 [Unsqueeze] outputs: [1238 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_805 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1237
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1238
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3112
[06/10/2022-19:21:30] [V] [TRT] Concat_805 [Concat] inputs: [1237 -> (1)[INT32]], [1238 -> (1)[INT32]], [3112 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3112 for ONNX node: 3112
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_805 for ONNX node: Concat_805
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1240 for ONNX tensor: 1240
[06/10/2022-19:21:30] [V] [TRT] Concat_805 [Concat] outputs: [1240 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_806 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1235
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1240
[06/10/2022-19:21:30] [V] [TRT] Reshape_806 [Reshape] inputs: [1235 -> (-1, 128, 32, 32)[FLOAT]], [1240 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_806 for ONNX node: Reshape_806
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1241 for ONNX tensor: 1241
[06/10/2022-19:21:30] [V] [TRT] Reshape_806 [Reshape] outputs: [1241 -> (-1, 128, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_807 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1241
[06/10/2022-19:21:30] [V] [TRT] Transpose_807 [Transpose] inputs: [1241 -> (-1, 128, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_807 for ONNX node: Transpose_807
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1242 for ONNX tensor: 1242
[06/10/2022-19:21:30] [V] [TRT] Transpose_807 [Transpose] outputs: [1242 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_808 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1242
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_808 [ReduceMean] inputs: [1242 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_808 for ONNX node: ReduceMean_808
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1243 for ONNX tensor: 1243
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_808 [ReduceMean] outputs: [1243 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_809 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1242
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1243
[06/10/2022-19:21:30] [V] [TRT] Sub_809 [Sub] inputs: [1242 -> (-1, 1024, 128)[FLOAT]], [1243 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_809 for ONNX node: Sub_809
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1244 for ONNX tensor: 1244
[06/10/2022-19:21:30] [V] [TRT] Sub_809 [Sub] outputs: [1244 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_811 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1244
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1245
[06/10/2022-19:21:30] [V] [TRT] Pow_811 [Pow] inputs: [1244 -> (-1, 1024, 128)[FLOAT]], [1245 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1245 for ONNX node: 1245
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_811 for ONNX node: Pow_811
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1246 for ONNX tensor: 1246
[06/10/2022-19:21:30] [V] [TRT] Pow_811 [Pow] outputs: [1246 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_812 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1246
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_812 [ReduceMean] inputs: [1246 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_812 for ONNX node: ReduceMean_812
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1247 for ONNX tensor: 1247
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_812 [ReduceMean] outputs: [1247 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_814 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1247
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1248
[06/10/2022-19:21:30] [V] [TRT] Add_814 [Add] inputs: [1247 -> (-1, 1024, 1)[FLOAT]], [1248 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1248 for ONNX node: 1248
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_814 for ONNX node: Add_814
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1249 for ONNX tensor: 1249
[06/10/2022-19:21:30] [V] [TRT] Add_814 [Add] outputs: [1249 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_815 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1249
[06/10/2022-19:21:30] [V] [TRT] Sqrt_815 [Sqrt] inputs: [1249 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_815 for ONNX node: Sqrt_815
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1250 for ONNX tensor: 1250
[06/10/2022-19:21:30] [V] [TRT] Sqrt_815 [Sqrt] outputs: [1250 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_816 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1244
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1250
[06/10/2022-19:21:30] [V] [TRT] Div_816 [Div] inputs: [1244 -> (-1, 1024, 128)[FLOAT]], [1250 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_816 for ONNX node: Div_816
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1251 for ONNX tensor: 1251
[06/10/2022-19:21:30] [V] [TRT] Div_816 [Div] outputs: [1251 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_817 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1251
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_817 [Mul] inputs: [1251 -> (-1, 1024, 128)[FLOAT]], [backbone.block2.2.attn.norm.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.2.attn.norm.weight for ONNX node: backbone.block2.2.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_817 for ONNX node: Mul_817
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1252 for ONNX tensor: 1252
[06/10/2022-19:21:30] [V] [TRT] Mul_817 [Mul] outputs: [1252 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_818 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1252
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Add_818 [Add] inputs: [1252 -> (-1, 1024, 128)[FLOAT]], [backbone.block2.2.attn.norm.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.2.attn.norm.bias for ONNX node: backbone.block2.2.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_818 for ONNX node: Add_818
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1253 for ONNX tensor: 1253
[06/10/2022-19:21:30] [V] [TRT] Add_818 [Add] outputs: [1253 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_819 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1253
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3113
[06/10/2022-19:21:30] [V] [TRT] MatMul_819 [MatMul] inputs: [1253 -> (-1, 1024, 128)[FLOAT]], [3113 -> (128, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3113 for ONNX node: 3113
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_819 for ONNX node: MatMul_819
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1255 for ONNX tensor: 1255
[06/10/2022-19:21:30] [V] [TRT] MatMul_819 [MatMul] outputs: [1255 -> (-1, 1024, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_820 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1255
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Add_820 [Add] inputs: [1255 -> (-1, 1024, 256)[FLOAT]], [backbone.block2.2.attn.kv.bias -> (256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.2.attn.kv.bias for ONNX node: backbone.block2.2.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_820 for ONNX node: Add_820
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1256 for ONNX tensor: 1256
[06/10/2022-19:21:30] [V] [TRT] Add_820 [Add] outputs: [1256 -> (-1, 1024, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_822 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1212
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1257
[06/10/2022-19:21:30] [V] [TRT] Div_822 [Div] inputs: [1212 -> ()[INT32]], [1257 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1257 for ONNX node: 1257
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_822 for ONNX node: Div_822
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1258 for ONNX tensor: 1258
[06/10/2022-19:21:30] [V] [TRT] Div_822 [Div] outputs: [1258 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_823 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1258
[06/10/2022-19:21:30] [V] [TRT] Cast_823 [Cast] inputs: [1258 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_823 for ONNX node: Cast_823
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1259 for ONNX tensor: 1259
[06/10/2022-19:21:30] [V] [TRT] Cast_823 [Cast] outputs: [1259 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_824 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1259
[06/10/2022-19:21:30] [V] [TRT] Cast_824 [Cast] inputs: [1259 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_824 for ONNX node: Cast_824
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1260 for ONNX tensor: 1260
[06/10/2022-19:21:30] [V] [TRT] Cast_824 [Cast] outputs: [1260 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_825 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1206
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_825 [Unsqueeze] inputs: [1206 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_825 for ONNX node: Unsqueeze_825
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1264 for ONNX tensor: 1264
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_825 [Unsqueeze] outputs: [1264 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_826 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1260
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_826 [Unsqueeze] inputs: [1260 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_826 for ONNX node: Unsqueeze_826
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1268 for ONNX tensor: 1268
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_826 [Unsqueeze] outputs: [1268 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_827 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1264
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3114
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3115
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3116
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1268
[06/10/2022-19:21:30] [V] [TRT] Concat_827 [Concat] inputs: [1264 -> (1)[INT32]], [3114 -> (1)[INT32]], [3115 -> (1)[INT32]], [3116 -> (1)[INT32]], [1268 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3114 for ONNX node: 3114
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3115 for ONNX node: 3115
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3116 for ONNX node: 3116
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_827 for ONNX node: Concat_827
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1269 for ONNX tensor: 1269
[06/10/2022-19:21:30] [V] [TRT] Concat_827 [Concat] outputs: [1269 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_828 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1256
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1269
[06/10/2022-19:21:30] [V] [TRT] Reshape_828 [Reshape] inputs: [1256 -> (-1, 1024, 256)[FLOAT]], [1269 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_828 for ONNX node: Reshape_828
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1270 for ONNX tensor: 1270
[06/10/2022-19:21:30] [V] [TRT] Reshape_828 [Reshape] outputs: [1270 -> (-1, 1024, 2, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_829 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1270
[06/10/2022-19:21:30] [V] [TRT] Transpose_829 [Transpose] inputs: [1270 -> (-1, 1024, 2, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_829 for ONNX node: Transpose_829
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1271 for ONNX tensor: 1271
[06/10/2022-19:21:30] [V] [TRT] Transpose_829 [Transpose] outputs: [1271 -> (2, -1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_831 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1271
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1272
[06/10/2022-19:21:30] [V] [TRT] Gather_831 [Gather] inputs: [1271 -> (2, -1, 2, 1024, 64)[FLOAT]], [1272 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1272 for ONNX node: 1272
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_831 for ONNX node: Gather_831
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1273 for ONNX tensor: 1273
[06/10/2022-19:21:30] [V] [TRT] Gather_831 [Gather] outputs: [1273 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_833 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1271
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1274
[06/10/2022-19:21:30] [V] [TRT] Gather_833 [Gather] inputs: [1271 -> (2, -1, 2, 1024, 64)[FLOAT]], [1274 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1274 for ONNX node: 1274
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_833 for ONNX node: Gather_833
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1275 for ONNX tensor: 1275
[06/10/2022-19:21:30] [V] [TRT] Gather_833 [Gather] outputs: [1275 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_834 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1273
[06/10/2022-19:21:30] [V] [TRT] Transpose_834 [Transpose] inputs: [1273 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_834 for ONNX node: Transpose_834
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1276 for ONNX tensor: 1276
[06/10/2022-19:21:30] [V] [TRT] Transpose_834 [Transpose] outputs: [1276 -> (-1, 2, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_835 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1227
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1276
[06/10/2022-19:21:30] [V] [TRT] MatMul_835 [MatMul] inputs: [1227 -> (-1, 2, 16384, 64)[FLOAT]], [1276 -> (-1, 2, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_835 for ONNX node: MatMul_835
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1277 for ONNX tensor: 1277
[06/10/2022-19:21:30] [V] [TRT] MatMul_835 [MatMul] outputs: [1277 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_837 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1277
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1278
[06/10/2022-19:21:30] [V] [TRT] Mul_837 [Mul] inputs: [1277 -> (-1, 2, 16384, 1024)[FLOAT]], [1278 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1278 for ONNX node: 1278
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_837 for ONNX node: Mul_837
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1279 for ONNX tensor: 1279
[06/10/2022-19:21:30] [V] [TRT] Mul_837 [Mul] outputs: [1279 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Softmax_838 [Softmax]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1279
[06/10/2022-19:21:30] [V] [TRT] Softmax_838 [Softmax] inputs: [1279 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Softmax_838 for ONNX node: Softmax_838
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1280 for ONNX tensor: 1280
[06/10/2022-19:21:30] [V] [TRT] Softmax_838 [Softmax] outputs: [1280 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_839 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1280
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1275
[06/10/2022-19:21:30] [V] [TRT] MatMul_839 [MatMul] inputs: [1280 -> (-1, 2, 16384, 1024)[FLOAT]], [1275 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_839 for ONNX node: MatMul_839
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1281 for ONNX tensor: 1281
[06/10/2022-19:21:30] [V] [TRT] MatMul_839 [MatMul] outputs: [1281 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_840 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1281
[06/10/2022-19:21:30] [V] [TRT] Transpose_840 [Transpose] inputs: [1281 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_840 for ONNX node: Transpose_840
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1282 for ONNX tensor: 1282
[06/10/2022-19:21:30] [V] [TRT] Transpose_840 [Transpose] outputs: [1282 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_841 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1206
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_841 [Unsqueeze] inputs: [1206 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_841 for ONNX node: Unsqueeze_841
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1283 for ONNX tensor: 1283
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_841 [Unsqueeze] outputs: [1283 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_842 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1209
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_842 [Unsqueeze] inputs: [1209 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_842 for ONNX node: Unsqueeze_842
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1284 for ONNX tensor: 1284
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_842 [Unsqueeze] outputs: [1284 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_843 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1212
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_843 [Unsqueeze] inputs: [1212 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_843 for ONNX node: Unsqueeze_843
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1285 for ONNX tensor: 1285
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_843 [Unsqueeze] outputs: [1285 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_844 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1283
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1284
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1285
[06/10/2022-19:21:30] [V] [TRT] Concat_844 [Concat] inputs: [1283 -> (1)[INT32]], [1284 -> (1)[INT32]], [1285 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_844 for ONNX node: Concat_844
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1286 for ONNX tensor: 1286
[06/10/2022-19:21:30] [V] [TRT] Concat_844 [Concat] outputs: [1286 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_845 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1282
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1286
[06/10/2022-19:21:30] [V] [TRT] Reshape_845 [Reshape] inputs: [1282 -> (-1, 16384, 2, 64)[FLOAT]], [1286 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_845 for ONNX node: Reshape_845
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1287 for ONNX tensor: 1287
[06/10/2022-19:21:30] [V] [TRT] Reshape_845 [Reshape] outputs: [1287 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_846 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1287
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3117
[06/10/2022-19:21:30] [V] [TRT] MatMul_846 [MatMul] inputs: [1287 -> (-1, 16384, 128)[FLOAT]], [3117 -> (128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3117 for ONNX node: 3117
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_846 for ONNX node: MatMul_846
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1289 for ONNX tensor: 1289
[06/10/2022-19:21:30] [V] [TRT] MatMul_846 [MatMul] outputs: [1289 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_847 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1289
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Add_847 [Add] inputs: [1289 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.2.attn.proj.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.2.attn.proj.bias for ONNX node: backbone.block2.2.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_847 for ONNX node: Add_847
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1290 for ONNX tensor: 1290
[06/10/2022-19:21:30] [V] [TRT] Add_847 [Add] outputs: [1290 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_848 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1192
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1290
[06/10/2022-19:21:30] [V] [TRT] Add_848 [Add] inputs: [1192 -> (-1, 16384, 128)[FLOAT]], [1290 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_848 for ONNX node: Add_848
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1291 for ONNX tensor: 1291
[06/10/2022-19:21:30] [V] [TRT] Add_848 [Add] outputs: [1291 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_849 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1291
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_849 [ReduceMean] inputs: [1291 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_849 for ONNX node: ReduceMean_849
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1292 for ONNX tensor: 1292
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_849 [ReduceMean] outputs: [1292 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_850 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1291
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1292
[06/10/2022-19:21:30] [V] [TRT] Sub_850 [Sub] inputs: [1291 -> (-1, 16384, 128)[FLOAT]], [1292 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_850 for ONNX node: Sub_850
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1293 for ONNX tensor: 1293
[06/10/2022-19:21:30] [V] [TRT] Sub_850 [Sub] outputs: [1293 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_852 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1293
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1294
[06/10/2022-19:21:30] [V] [TRT] Pow_852 [Pow] inputs: [1293 -> (-1, 16384, 128)[FLOAT]], [1294 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1294 for ONNX node: 1294
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_852 for ONNX node: Pow_852
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1295 for ONNX tensor: 1295
[06/10/2022-19:21:30] [V] [TRT] Pow_852 [Pow] outputs: [1295 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_853 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1295
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_853 [ReduceMean] inputs: [1295 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_853 for ONNX node: ReduceMean_853
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1296 for ONNX tensor: 1296
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_853 [ReduceMean] outputs: [1296 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_855 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1296
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1297
[06/10/2022-19:21:30] [V] [TRT] Add_855 [Add] inputs: [1296 -> (-1, 16384, 1)[FLOAT]], [1297 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1297 for ONNX node: 1297
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_855 for ONNX node: Add_855
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1298 for ONNX tensor: 1298
[06/10/2022-19:21:30] [V] [TRT] Add_855 [Add] outputs: [1298 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_856 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1298
[06/10/2022-19:21:30] [V] [TRT] Sqrt_856 [Sqrt] inputs: [1298 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_856 for ONNX node: Sqrt_856
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1299 for ONNX tensor: 1299
[06/10/2022-19:21:30] [V] [TRT] Sqrt_856 [Sqrt] outputs: [1299 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_857 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1293
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1299
[06/10/2022-19:21:30] [V] [TRT] Div_857 [Div] inputs: [1293 -> (-1, 16384, 128)[FLOAT]], [1299 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_857 for ONNX node: Div_857
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1300 for ONNX tensor: 1300
[06/10/2022-19:21:30] [V] [TRT] Div_857 [Div] outputs: [1300 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_858 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1300
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_858 [Mul] inputs: [1300 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.2.norm2.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.2.norm2.weight for ONNX node: backbone.block2.2.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_858 for ONNX node: Mul_858
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1301 for ONNX tensor: 1301
[06/10/2022-19:21:30] [V] [TRT] Mul_858 [Mul] outputs: [1301 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_859 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1301
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_859 [Add] inputs: [1301 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.2.norm2.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.2.norm2.bias for ONNX node: backbone.block2.2.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_859 for ONNX node: Add_859
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1302 for ONNX tensor: 1302
[06/10/2022-19:21:30] [V] [TRT] Add_859 [Add] outputs: [1302 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_860 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1302
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3118
[06/10/2022-19:21:30] [V] [TRT] MatMul_860 [MatMul] inputs: [1302 -> (-1, 16384, 128)[FLOAT]], [3118 -> (128, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3118 for ONNX node: 3118
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_860 for ONNX node: MatMul_860
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1304 for ONNX tensor: 1304
[06/10/2022-19:21:30] [V] [TRT] MatMul_860 [MatMul] outputs: [1304 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_861 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1304
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_861 [Add] inputs: [1304 -> (-1, 16384, 512)[FLOAT]], [backbone.block2.2.mlp.fc1.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.2.mlp.fc1.bias for ONNX node: backbone.block2.2.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_861 for ONNX node: Add_861
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1305 for ONNX tensor: 1305
[06/10/2022-19:21:30] [V] [TRT] Add_861 [Add] outputs: [1305 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_862 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1305
[06/10/2022-19:21:30] [V] [TRT] Shape_862 [Shape] inputs: [1305 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_862 for ONNX node: Shape_862
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1306 for ONNX tensor: 1306
[06/10/2022-19:21:30] [V] [TRT] Shape_862 [Shape] outputs: [1306 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_864 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1306
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1307
[06/10/2022-19:21:30] [V] [TRT] Gather_864 [Gather] inputs: [1306 -> (3)[INT32]], [1307 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1307 for ONNX node: 1307
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_864 for ONNX node: Gather_864
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1308 for ONNX tensor: 1308
[06/10/2022-19:21:30] [V] [TRT] Gather_864 [Gather] outputs: [1308 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_865 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1305
[06/10/2022-19:21:30] [V] [TRT] Shape_865 [Shape] inputs: [1305 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_865 for ONNX node: Shape_865
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1309 for ONNX tensor: 1309
[06/10/2022-19:21:30] [V] [TRT] Shape_865 [Shape] outputs: [1309 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_867 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1309
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1310
[06/10/2022-19:21:30] [V] [TRT] Gather_867 [Gather] inputs: [1309 -> (3)[INT32]], [1310 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1310 for ONNX node: 1310
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_867 for ONNX node: Gather_867
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1311 for ONNX tensor: 1311
[06/10/2022-19:21:30] [V] [TRT] Gather_867 [Gather] outputs: [1311 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_868 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1305
[06/10/2022-19:21:30] [V] [TRT] Transpose_868 [Transpose] inputs: [1305 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_868 for ONNX node: Transpose_868
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1312 for ONNX tensor: 1312
[06/10/2022-19:21:30] [V] [TRT] Transpose_868 [Transpose] outputs: [1312 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_869 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1308
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_869 [Unsqueeze] inputs: [1308 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_869 for ONNX node: Unsqueeze_869
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1313 for ONNX tensor: 1313
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_869 [Unsqueeze] outputs: [1313 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_870 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1311
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_870 [Unsqueeze] inputs: [1311 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_870 for ONNX node: Unsqueeze_870
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1314 for ONNX tensor: 1314
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_870 [Unsqueeze] outputs: [1314 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_871 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 873
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_871 [Unsqueeze] inputs: [873 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_871 for ONNX node: Unsqueeze_871
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1315 for ONNX tensor: 1315
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_871 [Unsqueeze] outputs: [1315 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_872 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 876
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_872 [Unsqueeze] inputs: [876 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_872 for ONNX node: Unsqueeze_872
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1316 for ONNX tensor: 1316
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_872 [Unsqueeze] outputs: [1316 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_873 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1313
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1314
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1315
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1316
[06/10/2022-19:21:30] [V] [TRT] Concat_873 [Concat] inputs: [1313 -> (1)[INT32]], [1314 -> (1)[INT32]], [1315 -> (1)[INT32]], [1316 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_873 for ONNX node: Concat_873
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1317 for ONNX tensor: 1317
[06/10/2022-19:21:30] [V] [TRT] Concat_873 [Concat] outputs: [1317 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_874 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1312
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1317
[06/10/2022-19:21:30] [V] [TRT] Reshape_874 [Reshape] inputs: [1312 -> (-1, 512, 16384)[FLOAT]], [1317 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_874 for ONNX node: Reshape_874
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1318 for ONNX tensor: 1318
[06/10/2022-19:21:30] [V] [TRT] Reshape_874 [Reshape] outputs: [1318 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_875 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1318
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_875 [Conv] inputs: [1318 -> (-1, 512, 128, 128)[FLOAT]], [backbone.block2.2.mlp.dwconv.dwconv.weight -> (512, 1, 3, 3)[FLOAT]], [backbone.block2.2.mlp.dwconv.dwconv.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 512, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_875 for ONNX node: Conv_875
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 512, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1319 for ONNX tensor: 1319
[06/10/2022-19:21:30] [V] [TRT] Conv_875 [Conv] outputs: [1319 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_876 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1319
[06/10/2022-19:21:30] [V] [TRT] Shape_876 [Shape] inputs: [1319 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_876 for ONNX node: Shape_876
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1320 for ONNX tensor: 1320
[06/10/2022-19:21:30] [V] [TRT] Shape_876 [Shape] outputs: [1320 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_880 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1320
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1322
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1323
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1321
[06/10/2022-19:21:30] [V] [TRT] Slice_880 [Slice] inputs: [1320 -> (4)[INT32]], [1322 -> (1)[INT32]], [1323 -> (1)[INT32]], [1321 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_880 for ONNX node: Slice_880
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1324 for ONNX tensor: 1324
[06/10/2022-19:21:30] [V] [TRT] Slice_880 [Slice] outputs: [1324 -> (2)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_882 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1324
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1325
[06/10/2022-19:21:30] [V] [TRT] Concat_882 [Concat] inputs: [1324 -> (2)[INT32]], [1325 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1325 for ONNX node: 1325
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_882 for ONNX node: Concat_882
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1326 for ONNX tensor: 1326
[06/10/2022-19:21:30] [V] [TRT] Concat_882 [Concat] outputs: [1326 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_883 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1319
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1326
[06/10/2022-19:21:30] [V] [TRT] Reshape_883 [Reshape] inputs: [1319 -> (-1, 512, 128, 128)[FLOAT]], [1326 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_883 for ONNX node: Reshape_883
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1327 for ONNX tensor: 1327
[06/10/2022-19:21:30] [V] [TRT] Reshape_883 [Reshape] outputs: [1327 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_884 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1327
[06/10/2022-19:21:30] [V] [TRT] Transpose_884 [Transpose] inputs: [1327 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_884 for ONNX node: Transpose_884
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1328 for ONNX tensor: 1328
[06/10/2022-19:21:30] [V] [TRT] Transpose_884 [Transpose] outputs: [1328 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_886 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1328
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1329
[06/10/2022-19:21:30] [V] [TRT] Div_886 [Div] inputs: [1328 -> (-1, 16384, 512)[FLOAT]], [1329 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1329 for ONNX node: 1329
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_886 for ONNX node: Div_886
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1330 for ONNX tensor: 1330
[06/10/2022-19:21:30] [V] [TRT] Div_886 [Div] outputs: [1330 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Erf_887 [Erf]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1330
[06/10/2022-19:21:30] [V] [TRT] Erf_887 [Erf] inputs: [1330 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Erf_887 for ONNX node: Erf_887
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1331 for ONNX tensor: 1331
[06/10/2022-19:21:30] [V] [TRT] Erf_887 [Erf] outputs: [1331 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_889 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1331
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1332
[06/10/2022-19:21:30] [V] [TRT] Add_889 [Add] inputs: [1331 -> (-1, 16384, 512)[FLOAT]], [1332 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1332 for ONNX node: 1332
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_889 for ONNX node: Add_889
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1333 for ONNX tensor: 1333
[06/10/2022-19:21:30] [V] [TRT] Add_889 [Add] outputs: [1333 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_890 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1328
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1333
[06/10/2022-19:21:30] [V] [TRT] Mul_890 [Mul] inputs: [1328 -> (-1, 16384, 512)[FLOAT]], [1333 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_890 for ONNX node: Mul_890
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1334 for ONNX tensor: 1334
[06/10/2022-19:21:30] [V] [TRT] Mul_890 [Mul] outputs: [1334 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_892 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1334
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1335
[06/10/2022-19:21:30] [V] [TRT] Mul_892 [Mul] inputs: [1334 -> (-1, 16384, 512)[FLOAT]], [1335 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1335 for ONNX node: 1335
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_892 for ONNX node: Mul_892
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1336 for ONNX tensor: 1336
[06/10/2022-19:21:30] [V] [TRT] Mul_892 [Mul] outputs: [1336 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_893 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1336
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3119
[06/10/2022-19:21:30] [V] [TRT] MatMul_893 [MatMul] inputs: [1336 -> (-1, 16384, 512)[FLOAT]], [3119 -> (512, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3119 for ONNX node: 3119
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_893 for ONNX node: MatMul_893
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1338 for ONNX tensor: 1338
[06/10/2022-19:21:30] [V] [TRT] MatMul_893 [MatMul] outputs: [1338 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_894 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1338
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.2.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_894 [Add] inputs: [1338 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.2.mlp.fc2.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.2.mlp.fc2.bias for ONNX node: backbone.block2.2.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_894 for ONNX node: Add_894
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1339 for ONNX tensor: 1339
[06/10/2022-19:21:30] [V] [TRT] Add_894 [Add] outputs: [1339 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_895 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1291
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1339
[06/10/2022-19:21:30] [V] [TRT] Add_895 [Add] inputs: [1291 -> (-1, 16384, 128)[FLOAT]], [1339 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_895 for ONNX node: Add_895
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1340 for ONNX tensor: 1340
[06/10/2022-19:21:30] [V] [TRT] Add_895 [Add] outputs: [1340 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_896 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1340
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_896 [ReduceMean] inputs: [1340 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_896 for ONNX node: ReduceMean_896
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1341 for ONNX tensor: 1341
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_896 [ReduceMean] outputs: [1341 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_897 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1340
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1341
[06/10/2022-19:21:30] [V] [TRT] Sub_897 [Sub] inputs: [1340 -> (-1, 16384, 128)[FLOAT]], [1341 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_897 for ONNX node: Sub_897
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1342 for ONNX tensor: 1342
[06/10/2022-19:21:30] [V] [TRT] Sub_897 [Sub] outputs: [1342 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_899 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1342
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1343
[06/10/2022-19:21:30] [V] [TRT] Pow_899 [Pow] inputs: [1342 -> (-1, 16384, 128)[FLOAT]], [1343 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1343 for ONNX node: 1343
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_899 for ONNX node: Pow_899
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1344 for ONNX tensor: 1344
[06/10/2022-19:21:30] [V] [TRT] Pow_899 [Pow] outputs: [1344 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_900 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1344
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_900 [ReduceMean] inputs: [1344 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_900 for ONNX node: ReduceMean_900
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1345 for ONNX tensor: 1345
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_900 [ReduceMean] outputs: [1345 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_902 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1345
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1346
[06/10/2022-19:21:30] [V] [TRT] Add_902 [Add] inputs: [1345 -> (-1, 16384, 1)[FLOAT]], [1346 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1346 for ONNX node: 1346
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_902 for ONNX node: Add_902
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1347 for ONNX tensor: 1347
[06/10/2022-19:21:30] [V] [TRT] Add_902 [Add] outputs: [1347 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_903 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1347
[06/10/2022-19:21:30] [V] [TRT] Sqrt_903 [Sqrt] inputs: [1347 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_903 for ONNX node: Sqrt_903
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1348 for ONNX tensor: 1348
[06/10/2022-19:21:30] [V] [TRT] Sqrt_903 [Sqrt] outputs: [1348 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_904 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1342
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1348
[06/10/2022-19:21:30] [V] [TRT] Div_904 [Div] inputs: [1342 -> (-1, 16384, 128)[FLOAT]], [1348 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_904 for ONNX node: Div_904
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1349 for ONNX tensor: 1349
[06/10/2022-19:21:30] [V] [TRT] Div_904 [Div] outputs: [1349 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_905 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1349
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_905 [Mul] inputs: [1349 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.3.norm1.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.3.norm1.weight for ONNX node: backbone.block2.3.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_905 for ONNX node: Mul_905
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1350 for ONNX tensor: 1350
[06/10/2022-19:21:30] [V] [TRT] Mul_905 [Mul] outputs: [1350 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_906 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1350
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_906 [Add] inputs: [1350 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.3.norm1.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.3.norm1.bias for ONNX node: backbone.block2.3.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_906 for ONNX node: Add_906
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1351 for ONNX tensor: 1351
[06/10/2022-19:21:30] [V] [TRT] Add_906 [Add] outputs: [1351 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_907 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1351
[06/10/2022-19:21:30] [V] [TRT] Shape_907 [Shape] inputs: [1351 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_907 for ONNX node: Shape_907
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1352 for ONNX tensor: 1352
[06/10/2022-19:21:30] [V] [TRT] Shape_907 [Shape] outputs: [1352 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_909 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1352
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1353
[06/10/2022-19:21:30] [V] [TRT] Gather_909 [Gather] inputs: [1352 -> (3)[INT32]], [1353 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1353 for ONNX node: 1353
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_909 for ONNX node: Gather_909
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1354 for ONNX tensor: 1354
[06/10/2022-19:21:30] [V] [TRT] Gather_909 [Gather] outputs: [1354 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_910 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1351
[06/10/2022-19:21:30] [V] [TRT] Shape_910 [Shape] inputs: [1351 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_910 for ONNX node: Shape_910
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1355 for ONNX tensor: 1355
[06/10/2022-19:21:30] [V] [TRT] Shape_910 [Shape] outputs: [1355 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_912 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1355
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1356
[06/10/2022-19:21:30] [V] [TRT] Gather_912 [Gather] inputs: [1355 -> (3)[INT32]], [1356 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1356 for ONNX node: 1356
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_912 for ONNX node: Gather_912
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1357 for ONNX tensor: 1357
[06/10/2022-19:21:30] [V] [TRT] Gather_912 [Gather] outputs: [1357 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_913 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1351
[06/10/2022-19:21:30] [V] [TRT] Shape_913 [Shape] inputs: [1351 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_913 for ONNX node: Shape_913
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1358 for ONNX tensor: 1358
[06/10/2022-19:21:30] [V] [TRT] Shape_913 [Shape] outputs: [1358 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_915 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1358
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1359
[06/10/2022-19:21:30] [V] [TRT] Gather_915 [Gather] inputs: [1358 -> (3)[INT32]], [1359 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1359 for ONNX node: 1359
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_915 for ONNX node: Gather_915
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1360 for ONNX tensor: 1360
[06/10/2022-19:21:30] [V] [TRT] Gather_915 [Gather] outputs: [1360 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_916 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1351
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3120
[06/10/2022-19:21:30] [V] [TRT] MatMul_916 [MatMul] inputs: [1351 -> (-1, 16384, 128)[FLOAT]], [3120 -> (128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3120 for ONNX node: 3120
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_916 for ONNX node: MatMul_916
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1362 for ONNX tensor: 1362
[06/10/2022-19:21:30] [V] [TRT] MatMul_916 [MatMul] outputs: [1362 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_917 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1362
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Add_917 [Add] inputs: [1362 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.3.attn.q.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.3.attn.q.bias for ONNX node: backbone.block2.3.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_917 for ONNX node: Add_917
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1363 for ONNX tensor: 1363
[06/10/2022-19:21:30] [V] [TRT] Add_917 [Add] outputs: [1363 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_919 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1360
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1364
[06/10/2022-19:21:30] [V] [TRT] Div_919 [Div] inputs: [1360 -> ()[INT32]], [1364 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1364 for ONNX node: 1364
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_919 for ONNX node: Div_919
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1365 for ONNX tensor: 1365
[06/10/2022-19:21:30] [V] [TRT] Div_919 [Div] outputs: [1365 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_920 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1365
[06/10/2022-19:21:30] [V] [TRT] Cast_920 [Cast] inputs: [1365 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_920 for ONNX node: Cast_920
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1366 for ONNX tensor: 1366
[06/10/2022-19:21:30] [V] [TRT] Cast_920 [Cast] outputs: [1366 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_921 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1366
[06/10/2022-19:21:30] [V] [TRT] Cast_921 [Cast] inputs: [1366 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_921 for ONNX node: Cast_921
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1367 for ONNX tensor: 1367
[06/10/2022-19:21:30] [V] [TRT] Cast_921 [Cast] outputs: [1367 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_922 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1354
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_922 [Unsqueeze] inputs: [1354 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_922 for ONNX node: Unsqueeze_922
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1369 for ONNX tensor: 1369
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_922 [Unsqueeze] outputs: [1369 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_923 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1357
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_923 [Unsqueeze] inputs: [1357 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_923 for ONNX node: Unsqueeze_923
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1370 for ONNX tensor: 1370
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_923 [Unsqueeze] outputs: [1370 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_924 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1367
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_924 [Unsqueeze] inputs: [1367 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_924 for ONNX node: Unsqueeze_924
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1372 for ONNX tensor: 1372
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_924 [Unsqueeze] outputs: [1372 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_925 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1369
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1370
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3121
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1372
[06/10/2022-19:21:30] [V] [TRT] Concat_925 [Concat] inputs: [1369 -> (1)[INT32]], [1370 -> (1)[INT32]], [3121 -> (1)[INT32]], [1372 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3121 for ONNX node: 3121
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_925 for ONNX node: Concat_925
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1373 for ONNX tensor: 1373
[06/10/2022-19:21:30] [V] [TRT] Concat_925 [Concat] outputs: [1373 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_926 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1363
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1373
[06/10/2022-19:21:30] [V] [TRT] Reshape_926 [Reshape] inputs: [1363 -> (-1, 16384, 128)[FLOAT]], [1373 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_926 for ONNX node: Reshape_926
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1374 for ONNX tensor: 1374
[06/10/2022-19:21:30] [V] [TRT] Reshape_926 [Reshape] outputs: [1374 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_927 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1374
[06/10/2022-19:21:30] [V] [TRT] Transpose_927 [Transpose] inputs: [1374 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_927 for ONNX node: Transpose_927
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1375 for ONNX tensor: 1375
[06/10/2022-19:21:30] [V] [TRT] Transpose_927 [Transpose] outputs: [1375 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_928 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1351
[06/10/2022-19:21:30] [V] [TRT] Transpose_928 [Transpose] inputs: [1351 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_928 for ONNX node: Transpose_928
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1376 for ONNX tensor: 1376
[06/10/2022-19:21:30] [V] [TRT] Transpose_928 [Transpose] outputs: [1376 -> (-1, 128, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_929 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1354
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_929 [Unsqueeze] inputs: [1354 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_929 for ONNX node: Unsqueeze_929
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1377 for ONNX tensor: 1377
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_929 [Unsqueeze] outputs: [1377 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_930 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1360
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_930 [Unsqueeze] inputs: [1360 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_930 for ONNX node: Unsqueeze_930
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1378 for ONNX tensor: 1378
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_930 [Unsqueeze] outputs: [1378 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_931 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 873
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_931 [Unsqueeze] inputs: [873 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_931 for ONNX node: Unsqueeze_931
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1379 for ONNX tensor: 1379
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_931 [Unsqueeze] outputs: [1379 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_932 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 876
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_932 [Unsqueeze] inputs: [876 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_932 for ONNX node: Unsqueeze_932
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1380 for ONNX tensor: 1380
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_932 [Unsqueeze] outputs: [1380 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_933 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1377
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1378
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1379
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1380
[06/10/2022-19:21:30] [V] [TRT] Concat_933 [Concat] inputs: [1377 -> (1)[INT32]], [1378 -> (1)[INT32]], [1379 -> (1)[INT32]], [1380 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_933 for ONNX node: Concat_933
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1381 for ONNX tensor: 1381
[06/10/2022-19:21:30] [V] [TRT] Concat_933 [Concat] outputs: [1381 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_934 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1376
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1381
[06/10/2022-19:21:30] [V] [TRT] Reshape_934 [Reshape] inputs: [1376 -> (-1, 128, 16384)[FLOAT]], [1381 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_934 for ONNX node: Reshape_934
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1382 for ONNX tensor: 1382
[06/10/2022-19:21:30] [V] [TRT] Reshape_934 [Reshape] outputs: [1382 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_935 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1382
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_935 [Conv] inputs: [1382 -> (-1, 128, 128, 128)[FLOAT]], [backbone.block2.3.attn.sr.weight -> (128, 128, 4, 4)[FLOAT]], [backbone.block2.3.attn.sr.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 128, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_935 for ONNX node: Conv_935
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (4, 4), strides: (4, 4), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 128, 32, 32)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1383 for ONNX tensor: 1383
[06/10/2022-19:21:30] [V] [TRT] Conv_935 [Conv] outputs: [1383 -> (-1, 128, 32, 32)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_936 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1354
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_936 [Unsqueeze] inputs: [1354 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_936 for ONNX node: Unsqueeze_936
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1385 for ONNX tensor: 1385
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_936 [Unsqueeze] outputs: [1385 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_937 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1360
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_937 [Unsqueeze] inputs: [1360 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_937 for ONNX node: Unsqueeze_937
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1386 for ONNX tensor: 1386
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_937 [Unsqueeze] outputs: [1386 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_938 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1385
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1386
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3122
[06/10/2022-19:21:30] [V] [TRT] Concat_938 [Concat] inputs: [1385 -> (1)[INT32]], [1386 -> (1)[INT32]], [3122 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3122 for ONNX node: 3122
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_938 for ONNX node: Concat_938
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1388 for ONNX tensor: 1388
[06/10/2022-19:21:30] [V] [TRT] Concat_938 [Concat] outputs: [1388 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_939 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1383
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1388
[06/10/2022-19:21:30] [V] [TRT] Reshape_939 [Reshape] inputs: [1383 -> (-1, 128, 32, 32)[FLOAT]], [1388 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_939 for ONNX node: Reshape_939
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1389 for ONNX tensor: 1389
[06/10/2022-19:21:30] [V] [TRT] Reshape_939 [Reshape] outputs: [1389 -> (-1, 128, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_940 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1389
[06/10/2022-19:21:30] [V] [TRT] Transpose_940 [Transpose] inputs: [1389 -> (-1, 128, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_940 for ONNX node: Transpose_940
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1390 for ONNX tensor: 1390
[06/10/2022-19:21:30] [V] [TRT] Transpose_940 [Transpose] outputs: [1390 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_941 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1390
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_941 [ReduceMean] inputs: [1390 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_941 for ONNX node: ReduceMean_941
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1391 for ONNX tensor: 1391
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_941 [ReduceMean] outputs: [1391 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_942 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1390
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1391
[06/10/2022-19:21:30] [V] [TRT] Sub_942 [Sub] inputs: [1390 -> (-1, 1024, 128)[FLOAT]], [1391 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_942 for ONNX node: Sub_942
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1392 for ONNX tensor: 1392
[06/10/2022-19:21:30] [V] [TRT] Sub_942 [Sub] outputs: [1392 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_944 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1392
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1393
[06/10/2022-19:21:30] [V] [TRT] Pow_944 [Pow] inputs: [1392 -> (-1, 1024, 128)[FLOAT]], [1393 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1393 for ONNX node: 1393
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_944 for ONNX node: Pow_944
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1394 for ONNX tensor: 1394
[06/10/2022-19:21:30] [V] [TRT] Pow_944 [Pow] outputs: [1394 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_945 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1394
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_945 [ReduceMean] inputs: [1394 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_945 for ONNX node: ReduceMean_945
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1395 for ONNX tensor: 1395
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_945 [ReduceMean] outputs: [1395 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_947 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1395
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1396
[06/10/2022-19:21:30] [V] [TRT] Add_947 [Add] inputs: [1395 -> (-1, 1024, 1)[FLOAT]], [1396 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1396 for ONNX node: 1396
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_947 for ONNX node: Add_947
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1397 for ONNX tensor: 1397
[06/10/2022-19:21:30] [V] [TRT] Add_947 [Add] outputs: [1397 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_948 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1397
[06/10/2022-19:21:30] [V] [TRT] Sqrt_948 [Sqrt] inputs: [1397 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_948 for ONNX node: Sqrt_948
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1398 for ONNX tensor: 1398
[06/10/2022-19:21:30] [V] [TRT] Sqrt_948 [Sqrt] outputs: [1398 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_949 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1392
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1398
[06/10/2022-19:21:30] [V] [TRT] Div_949 [Div] inputs: [1392 -> (-1, 1024, 128)[FLOAT]], [1398 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_949 for ONNX node: Div_949
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1399 for ONNX tensor: 1399
[06/10/2022-19:21:30] [V] [TRT] Div_949 [Div] outputs: [1399 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_950 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1399
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_950 [Mul] inputs: [1399 -> (-1, 1024, 128)[FLOAT]], [backbone.block2.3.attn.norm.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.3.attn.norm.weight for ONNX node: backbone.block2.3.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_950 for ONNX node: Mul_950
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1400 for ONNX tensor: 1400
[06/10/2022-19:21:30] [V] [TRT] Mul_950 [Mul] outputs: [1400 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_951 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1400
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Add_951 [Add] inputs: [1400 -> (-1, 1024, 128)[FLOAT]], [backbone.block2.3.attn.norm.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.3.attn.norm.bias for ONNX node: backbone.block2.3.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_951 for ONNX node: Add_951
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1401 for ONNX tensor: 1401
[06/10/2022-19:21:30] [V] [TRT] Add_951 [Add] outputs: [1401 -> (-1, 1024, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_952 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1401
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3123
[06/10/2022-19:21:30] [V] [TRT] MatMul_952 [MatMul] inputs: [1401 -> (-1, 1024, 128)[FLOAT]], [3123 -> (128, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3123 for ONNX node: 3123
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_952 for ONNX node: MatMul_952
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1403 for ONNX tensor: 1403
[06/10/2022-19:21:30] [V] [TRT] MatMul_952 [MatMul] outputs: [1403 -> (-1, 1024, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_953 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1403
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Add_953 [Add] inputs: [1403 -> (-1, 1024, 256)[FLOAT]], [backbone.block2.3.attn.kv.bias -> (256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.3.attn.kv.bias for ONNX node: backbone.block2.3.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_953 for ONNX node: Add_953
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1404 for ONNX tensor: 1404
[06/10/2022-19:21:30] [V] [TRT] Add_953 [Add] outputs: [1404 -> (-1, 1024, 256)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_955 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1360
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1405
[06/10/2022-19:21:30] [V] [TRT] Div_955 [Div] inputs: [1360 -> ()[INT32]], [1405 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1405 for ONNX node: 1405
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_955 for ONNX node: Div_955
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1406 for ONNX tensor: 1406
[06/10/2022-19:21:30] [V] [TRT] Div_955 [Div] outputs: [1406 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_956 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1406
[06/10/2022-19:21:30] [V] [TRT] Cast_956 [Cast] inputs: [1406 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_956 for ONNX node: Cast_956
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1407 for ONNX tensor: 1407
[06/10/2022-19:21:30] [V] [TRT] Cast_956 [Cast] outputs: [1407 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_957 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1407
[06/10/2022-19:21:30] [V] [TRT] Cast_957 [Cast] inputs: [1407 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_957 for ONNX node: Cast_957
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1408 for ONNX tensor: 1408
[06/10/2022-19:21:30] [V] [TRT] Cast_957 [Cast] outputs: [1408 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_958 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1354
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_958 [Unsqueeze] inputs: [1354 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_958 for ONNX node: Unsqueeze_958
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1412 for ONNX tensor: 1412
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_958 [Unsqueeze] outputs: [1412 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_959 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1408
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_959 [Unsqueeze] inputs: [1408 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_959 for ONNX node: Unsqueeze_959
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1416 for ONNX tensor: 1416
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_959 [Unsqueeze] outputs: [1416 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_960 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1412
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3124
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3125
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3126
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1416
[06/10/2022-19:21:30] [V] [TRT] Concat_960 [Concat] inputs: [1412 -> (1)[INT32]], [3124 -> (1)[INT32]], [3125 -> (1)[INT32]], [3126 -> (1)[INT32]], [1416 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3124 for ONNX node: 3124
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3125 for ONNX node: 3125
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3126 for ONNX node: 3126
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_960 for ONNX node: Concat_960
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1417 for ONNX tensor: 1417
[06/10/2022-19:21:30] [V] [TRT] Concat_960 [Concat] outputs: [1417 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_961 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1404
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1417
[06/10/2022-19:21:30] [V] [TRT] Reshape_961 [Reshape] inputs: [1404 -> (-1, 1024, 256)[FLOAT]], [1417 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_961 for ONNX node: Reshape_961
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1418 for ONNX tensor: 1418
[06/10/2022-19:21:30] [V] [TRT] Reshape_961 [Reshape] outputs: [1418 -> (-1, 1024, 2, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_962 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1418
[06/10/2022-19:21:30] [V] [TRT] Transpose_962 [Transpose] inputs: [1418 -> (-1, 1024, 2, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_962 for ONNX node: Transpose_962
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1419 for ONNX tensor: 1419
[06/10/2022-19:21:30] [V] [TRT] Transpose_962 [Transpose] outputs: [1419 -> (2, -1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_964 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1419
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1420
[06/10/2022-19:21:30] [V] [TRT] Gather_964 [Gather] inputs: [1419 -> (2, -1, 2, 1024, 64)[FLOAT]], [1420 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1420 for ONNX node: 1420
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_964 for ONNX node: Gather_964
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1421 for ONNX tensor: 1421
[06/10/2022-19:21:30] [V] [TRT] Gather_964 [Gather] outputs: [1421 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_966 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1419
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1422
[06/10/2022-19:21:30] [V] [TRT] Gather_966 [Gather] inputs: [1419 -> (2, -1, 2, 1024, 64)[FLOAT]], [1422 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1422 for ONNX node: 1422
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_966 for ONNX node: Gather_966
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1423 for ONNX tensor: 1423
[06/10/2022-19:21:30] [V] [TRT] Gather_966 [Gather] outputs: [1423 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_967 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1421
[06/10/2022-19:21:30] [V] [TRT] Transpose_967 [Transpose] inputs: [1421 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_967 for ONNX node: Transpose_967
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1424 for ONNX tensor: 1424
[06/10/2022-19:21:30] [V] [TRT] Transpose_967 [Transpose] outputs: [1424 -> (-1, 2, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_968 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1375
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1424
[06/10/2022-19:21:30] [V] [TRT] MatMul_968 [MatMul] inputs: [1375 -> (-1, 2, 16384, 64)[FLOAT]], [1424 -> (-1, 2, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_968 for ONNX node: MatMul_968
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1425 for ONNX tensor: 1425
[06/10/2022-19:21:30] [V] [TRT] MatMul_968 [MatMul] outputs: [1425 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_970 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1425
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1426
[06/10/2022-19:21:30] [V] [TRT] Mul_970 [Mul] inputs: [1425 -> (-1, 2, 16384, 1024)[FLOAT]], [1426 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1426 for ONNX node: 1426
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_970 for ONNX node: Mul_970
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1427 for ONNX tensor: 1427
[06/10/2022-19:21:30] [V] [TRT] Mul_970 [Mul] outputs: [1427 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Softmax_971 [Softmax]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1427
[06/10/2022-19:21:30] [V] [TRT] Softmax_971 [Softmax] inputs: [1427 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Softmax_971 for ONNX node: Softmax_971
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1428 for ONNX tensor: 1428
[06/10/2022-19:21:30] [V] [TRT] Softmax_971 [Softmax] outputs: [1428 -> (-1, 2, 16384, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_972 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1428
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1423
[06/10/2022-19:21:30] [V] [TRT] MatMul_972 [MatMul] inputs: [1428 -> (-1, 2, 16384, 1024)[FLOAT]], [1423 -> (-1, 2, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_972 for ONNX node: MatMul_972
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1429 for ONNX tensor: 1429
[06/10/2022-19:21:30] [V] [TRT] MatMul_972 [MatMul] outputs: [1429 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_973 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1429
[06/10/2022-19:21:30] [V] [TRT] Transpose_973 [Transpose] inputs: [1429 -> (-1, 2, 16384, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_973 for ONNX node: Transpose_973
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1430 for ONNX tensor: 1430
[06/10/2022-19:21:30] [V] [TRT] Transpose_973 [Transpose] outputs: [1430 -> (-1, 16384, 2, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_974 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1354
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_974 [Unsqueeze] inputs: [1354 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_974 for ONNX node: Unsqueeze_974
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1431 for ONNX tensor: 1431
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_974 [Unsqueeze] outputs: [1431 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_975 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1357
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_975 [Unsqueeze] inputs: [1357 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_975 for ONNX node: Unsqueeze_975
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1432 for ONNX tensor: 1432
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_975 [Unsqueeze] outputs: [1432 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_976 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1360
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_976 [Unsqueeze] inputs: [1360 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_976 for ONNX node: Unsqueeze_976
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1433 for ONNX tensor: 1433
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_976 [Unsqueeze] outputs: [1433 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_977 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1431
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1432
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1433
[06/10/2022-19:21:30] [V] [TRT] Concat_977 [Concat] inputs: [1431 -> (1)[INT32]], [1432 -> (1)[INT32]], [1433 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_977 for ONNX node: Concat_977
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1434 for ONNX tensor: 1434
[06/10/2022-19:21:30] [V] [TRT] Concat_977 [Concat] outputs: [1434 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_978 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1430
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1434
[06/10/2022-19:21:30] [V] [TRT] Reshape_978 [Reshape] inputs: [1430 -> (-1, 16384, 2, 64)[FLOAT]], [1434 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_978 for ONNX node: Reshape_978
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1435 for ONNX tensor: 1435
[06/10/2022-19:21:30] [V] [TRT] Reshape_978 [Reshape] outputs: [1435 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_979 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1435
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3127
[06/10/2022-19:21:30] [V] [TRT] MatMul_979 [MatMul] inputs: [1435 -> (-1, 16384, 128)[FLOAT]], [3127 -> (128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3127 for ONNX node: 3127
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_979 for ONNX node: MatMul_979
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1437 for ONNX tensor: 1437
[06/10/2022-19:21:30] [V] [TRT] MatMul_979 [MatMul] outputs: [1437 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_980 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1437
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Add_980 [Add] inputs: [1437 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.3.attn.proj.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.3.attn.proj.bias for ONNX node: backbone.block2.3.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_980 for ONNX node: Add_980
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1438 for ONNX tensor: 1438
[06/10/2022-19:21:30] [V] [TRT] Add_980 [Add] outputs: [1438 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_981 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1340
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1438
[06/10/2022-19:21:30] [V] [TRT] Add_981 [Add] inputs: [1340 -> (-1, 16384, 128)[FLOAT]], [1438 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_981 for ONNX node: Add_981
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1439 for ONNX tensor: 1439
[06/10/2022-19:21:30] [V] [TRT] Add_981 [Add] outputs: [1439 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_982 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1439
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_982 [ReduceMean] inputs: [1439 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_982 for ONNX node: ReduceMean_982
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1440 for ONNX tensor: 1440
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_982 [ReduceMean] outputs: [1440 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_983 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1439
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1440
[06/10/2022-19:21:30] [V] [TRT] Sub_983 [Sub] inputs: [1439 -> (-1, 16384, 128)[FLOAT]], [1440 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_983 for ONNX node: Sub_983
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1441 for ONNX tensor: 1441
[06/10/2022-19:21:30] [V] [TRT] Sub_983 [Sub] outputs: [1441 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_985 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1441
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1442
[06/10/2022-19:21:30] [V] [TRT] Pow_985 [Pow] inputs: [1441 -> (-1, 16384, 128)[FLOAT]], [1442 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1442 for ONNX node: 1442
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_985 for ONNX node: Pow_985
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1443 for ONNX tensor: 1443
[06/10/2022-19:21:30] [V] [TRT] Pow_985 [Pow] outputs: [1443 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_986 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1443
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_986 [ReduceMean] inputs: [1443 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_986 for ONNX node: ReduceMean_986
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1444 for ONNX tensor: 1444
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_986 [ReduceMean] outputs: [1444 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_988 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1444
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1445
[06/10/2022-19:21:30] [V] [TRT] Add_988 [Add] inputs: [1444 -> (-1, 16384, 1)[FLOAT]], [1445 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1445 for ONNX node: 1445
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_988 for ONNX node: Add_988
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1446 for ONNX tensor: 1446
[06/10/2022-19:21:30] [V] [TRT] Add_988 [Add] outputs: [1446 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_989 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1446
[06/10/2022-19:21:30] [V] [TRT] Sqrt_989 [Sqrt] inputs: [1446 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_989 for ONNX node: Sqrt_989
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1447 for ONNX tensor: 1447
[06/10/2022-19:21:30] [V] [TRT] Sqrt_989 [Sqrt] outputs: [1447 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_990 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1441
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1447
[06/10/2022-19:21:30] [V] [TRT] Div_990 [Div] inputs: [1441 -> (-1, 16384, 128)[FLOAT]], [1447 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_990 for ONNX node: Div_990
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1448 for ONNX tensor: 1448
[06/10/2022-19:21:30] [V] [TRT] Div_990 [Div] outputs: [1448 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_991 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1448
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_991 [Mul] inputs: [1448 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.3.norm2.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.3.norm2.weight for ONNX node: backbone.block2.3.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_991 for ONNX node: Mul_991
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1449 for ONNX tensor: 1449
[06/10/2022-19:21:30] [V] [TRT] Mul_991 [Mul] outputs: [1449 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_992 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1449
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_992 [Add] inputs: [1449 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.3.norm2.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.3.norm2.bias for ONNX node: backbone.block2.3.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_992 for ONNX node: Add_992
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1450 for ONNX tensor: 1450
[06/10/2022-19:21:30] [V] [TRT] Add_992 [Add] outputs: [1450 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_993 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1450
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3128
[06/10/2022-19:21:30] [V] [TRT] MatMul_993 [MatMul] inputs: [1450 -> (-1, 16384, 128)[FLOAT]], [3128 -> (128, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3128 for ONNX node: 3128
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_993 for ONNX node: MatMul_993
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1452 for ONNX tensor: 1452
[06/10/2022-19:21:30] [V] [TRT] MatMul_993 [MatMul] outputs: [1452 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_994 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1452
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_994 [Add] inputs: [1452 -> (-1, 16384, 512)[FLOAT]], [backbone.block2.3.mlp.fc1.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.3.mlp.fc1.bias for ONNX node: backbone.block2.3.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_994 for ONNX node: Add_994
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1453 for ONNX tensor: 1453
[06/10/2022-19:21:30] [V] [TRT] Add_994 [Add] outputs: [1453 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_995 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1453
[06/10/2022-19:21:30] [V] [TRT] Shape_995 [Shape] inputs: [1453 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_995 for ONNX node: Shape_995
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1454 for ONNX tensor: 1454
[06/10/2022-19:21:30] [V] [TRT] Shape_995 [Shape] outputs: [1454 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_997 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1454
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1455
[06/10/2022-19:21:30] [V] [TRT] Gather_997 [Gather] inputs: [1454 -> (3)[INT32]], [1455 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1455 for ONNX node: 1455
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_997 for ONNX node: Gather_997
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1456 for ONNX tensor: 1456
[06/10/2022-19:21:30] [V] [TRT] Gather_997 [Gather] outputs: [1456 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_998 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1453
[06/10/2022-19:21:30] [V] [TRT] Shape_998 [Shape] inputs: [1453 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_998 for ONNX node: Shape_998
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1457 for ONNX tensor: 1457
[06/10/2022-19:21:30] [V] [TRT] Shape_998 [Shape] outputs: [1457 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_1000 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1457
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1458
[06/10/2022-19:21:30] [V] [TRT] Gather_1000 [Gather] inputs: [1457 -> (3)[INT32]], [1458 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1458 for ONNX node: 1458
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_1000 for ONNX node: Gather_1000
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1459 for ONNX tensor: 1459
[06/10/2022-19:21:30] [V] [TRT] Gather_1000 [Gather] outputs: [1459 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1001 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1453
[06/10/2022-19:21:30] [V] [TRT] Transpose_1001 [Transpose] inputs: [1453 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1001 for ONNX node: Transpose_1001
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1460 for ONNX tensor: 1460
[06/10/2022-19:21:30] [V] [TRT] Transpose_1001 [Transpose] outputs: [1460 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1002 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1456
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1002 [Unsqueeze] inputs: [1456 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1002 for ONNX node: Unsqueeze_1002
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1461 for ONNX tensor: 1461
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1002 [Unsqueeze] outputs: [1461 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1003 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1459
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1003 [Unsqueeze] inputs: [1459 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1003 for ONNX node: Unsqueeze_1003
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1462 for ONNX tensor: 1462
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1003 [Unsqueeze] outputs: [1462 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1004 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 873
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1004 [Unsqueeze] inputs: [873 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1004 for ONNX node: Unsqueeze_1004
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1463 for ONNX tensor: 1463
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1004 [Unsqueeze] outputs: [1463 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1005 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 876
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1005 [Unsqueeze] inputs: [876 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1005 for ONNX node: Unsqueeze_1005
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1464 for ONNX tensor: 1464
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1005 [Unsqueeze] outputs: [1464 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_1006 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1461
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1462
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1463
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1464
[06/10/2022-19:21:30] [V] [TRT] Concat_1006 [Concat] inputs: [1461 -> (1)[INT32]], [1462 -> (1)[INT32]], [1463 -> (1)[INT32]], [1464 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_1006 for ONNX node: Concat_1006
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1465 for ONNX tensor: 1465
[06/10/2022-19:21:30] [V] [TRT] Concat_1006 [Concat] outputs: [1465 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_1007 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1460
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1465
[06/10/2022-19:21:30] [V] [TRT] Reshape_1007 [Reshape] inputs: [1460 -> (-1, 512, 16384)[FLOAT]], [1465 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_1007 for ONNX node: Reshape_1007
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1466 for ONNX tensor: 1466
[06/10/2022-19:21:30] [V] [TRT] Reshape_1007 [Reshape] outputs: [1466 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_1008 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1466
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_1008 [Conv] inputs: [1466 -> (-1, 512, 128, 128)[FLOAT]], [backbone.block2.3.mlp.dwconv.dwconv.weight -> (512, 1, 3, 3)[FLOAT]], [backbone.block2.3.mlp.dwconv.dwconv.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 512, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_1008 for ONNX node: Conv_1008
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 512, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1467 for ONNX tensor: 1467
[06/10/2022-19:21:30] [V] [TRT] Conv_1008 [Conv] outputs: [1467 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_1009 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1467
[06/10/2022-19:21:30] [V] [TRT] Shape_1009 [Shape] inputs: [1467 -> (-1, 512, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_1009 for ONNX node: Shape_1009
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1468 for ONNX tensor: 1468
[06/10/2022-19:21:30] [V] [TRT] Shape_1009 [Shape] outputs: [1468 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_1013 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1468
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1470
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1471
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1469
[06/10/2022-19:21:30] [V] [TRT] Slice_1013 [Slice] inputs: [1468 -> (4)[INT32]], [1470 -> (1)[INT32]], [1471 -> (1)[INT32]], [1469 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_1013 for ONNX node: Slice_1013
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1472 for ONNX tensor: 1472
[06/10/2022-19:21:30] [V] [TRT] Slice_1013 [Slice] outputs: [1472 -> (2)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_1015 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1472
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1473
[06/10/2022-19:21:30] [V] [TRT] Concat_1015 [Concat] inputs: [1472 -> (2)[INT32]], [1473 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1473 for ONNX node: 1473
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_1015 for ONNX node: Concat_1015
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1474 for ONNX tensor: 1474
[06/10/2022-19:21:30] [V] [TRT] Concat_1015 [Concat] outputs: [1474 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_1016 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1467
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1474
[06/10/2022-19:21:30] [V] [TRT] Reshape_1016 [Reshape] inputs: [1467 -> (-1, 512, 128, 128)[FLOAT]], [1474 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_1016 for ONNX node: Reshape_1016
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1475 for ONNX tensor: 1475
[06/10/2022-19:21:30] [V] [TRT] Reshape_1016 [Reshape] outputs: [1475 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1017 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1475
[06/10/2022-19:21:30] [V] [TRT] Transpose_1017 [Transpose] inputs: [1475 -> (-1, 512, 16384)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1017 for ONNX node: Transpose_1017
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1476 for ONNX tensor: 1476
[06/10/2022-19:21:30] [V] [TRT] Transpose_1017 [Transpose] outputs: [1476 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_1019 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1476
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1477
[06/10/2022-19:21:30] [V] [TRT] Div_1019 [Div] inputs: [1476 -> (-1, 16384, 512)[FLOAT]], [1477 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1477 for ONNX node: 1477
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_1019 for ONNX node: Div_1019
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1478 for ONNX tensor: 1478
[06/10/2022-19:21:30] [V] [TRT] Div_1019 [Div] outputs: [1478 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Erf_1020 [Erf]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1478
[06/10/2022-19:21:30] [V] [TRT] Erf_1020 [Erf] inputs: [1478 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Erf_1020 for ONNX node: Erf_1020
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1479 for ONNX tensor: 1479
[06/10/2022-19:21:30] [V] [TRT] Erf_1020 [Erf] outputs: [1479 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1022 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1479
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1480
[06/10/2022-19:21:30] [V] [TRT] Add_1022 [Add] inputs: [1479 -> (-1, 16384, 512)[FLOAT]], [1480 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1480 for ONNX node: 1480
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1022 for ONNX node: Add_1022
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1481 for ONNX tensor: 1481
[06/10/2022-19:21:30] [V] [TRT] Add_1022 [Add] outputs: [1481 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_1023 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1476
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1481
[06/10/2022-19:21:30] [V] [TRT] Mul_1023 [Mul] inputs: [1476 -> (-1, 16384, 512)[FLOAT]], [1481 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_1023 for ONNX node: Mul_1023
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1482 for ONNX tensor: 1482
[06/10/2022-19:21:30] [V] [TRT] Mul_1023 [Mul] outputs: [1482 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_1025 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1482
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1483
[06/10/2022-19:21:30] [V] [TRT] Mul_1025 [Mul] inputs: [1482 -> (-1, 16384, 512)[FLOAT]], [1483 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1483 for ONNX node: 1483
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_1025 for ONNX node: Mul_1025
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1484 for ONNX tensor: 1484
[06/10/2022-19:21:30] [V] [TRT] Mul_1025 [Mul] outputs: [1484 -> (-1, 16384, 512)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_1026 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1484
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3129
[06/10/2022-19:21:30] [V] [TRT] MatMul_1026 [MatMul] inputs: [1484 -> (-1, 16384, 512)[FLOAT]], [3129 -> (512, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3129 for ONNX node: 3129
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_1026 for ONNX node: MatMul_1026
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1486 for ONNX tensor: 1486
[06/10/2022-19:21:30] [V] [TRT] MatMul_1026 [MatMul] outputs: [1486 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1027 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1486
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block2.3.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1027 [Add] inputs: [1486 -> (-1, 16384, 128)[FLOAT]], [backbone.block2.3.mlp.fc2.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block2.3.mlp.fc2.bias for ONNX node: backbone.block2.3.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1027 for ONNX node: Add_1027
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1487 for ONNX tensor: 1487
[06/10/2022-19:21:30] [V] [TRT] Add_1027 [Add] outputs: [1487 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1028 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1439
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1487
[06/10/2022-19:21:30] [V] [TRT] Add_1028 [Add] inputs: [1439 -> (-1, 16384, 128)[FLOAT]], [1487 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1028 for ONNX node: Add_1028
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1488 for ONNX tensor: 1488
[06/10/2022-19:21:30] [V] [TRT] Add_1028 [Add] outputs: [1488 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1029 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1488
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1029 [ReduceMean] inputs: [1488 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1029 for ONNX node: ReduceMean_1029
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1489 for ONNX tensor: 1489
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1029 [ReduceMean] outputs: [1489 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_1030 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1488
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1489
[06/10/2022-19:21:30] [V] [TRT] Sub_1030 [Sub] inputs: [1488 -> (-1, 16384, 128)[FLOAT]], [1489 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_1030 for ONNX node: Sub_1030
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1490 for ONNX tensor: 1490
[06/10/2022-19:21:30] [V] [TRT] Sub_1030 [Sub] outputs: [1490 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_1032 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1490
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1491
[06/10/2022-19:21:30] [V] [TRT] Pow_1032 [Pow] inputs: [1490 -> (-1, 16384, 128)[FLOAT]], [1491 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1491 for ONNX node: 1491
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_1032 for ONNX node: Pow_1032
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1492 for ONNX tensor: 1492
[06/10/2022-19:21:30] [V] [TRT] Pow_1032 [Pow] outputs: [1492 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1033 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1492
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1033 [ReduceMean] inputs: [1492 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1033 for ONNX node: ReduceMean_1033
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1493 for ONNX tensor: 1493
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1033 [ReduceMean] outputs: [1493 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1035 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1493
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1494
[06/10/2022-19:21:30] [V] [TRT] Add_1035 [Add] inputs: [1493 -> (-1, 16384, 1)[FLOAT]], [1494 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1494 for ONNX node: 1494
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1035 for ONNX node: Add_1035
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1495 for ONNX tensor: 1495
[06/10/2022-19:21:30] [V] [TRT] Add_1035 [Add] outputs: [1495 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_1036 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1495
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1036 [Sqrt] inputs: [1495 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_1036 for ONNX node: Sqrt_1036
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1496 for ONNX tensor: 1496
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1036 [Sqrt] outputs: [1496 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_1037 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1490
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1496
[06/10/2022-19:21:30] [V] [TRT] Div_1037 [Div] inputs: [1490 -> (-1, 16384, 128)[FLOAT]], [1496 -> (-1, 16384, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_1037 for ONNX node: Div_1037
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1497 for ONNX tensor: 1497
[06/10/2022-19:21:30] [V] [TRT] Div_1037 [Div] outputs: [1497 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_1038 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1497
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_1038 [Mul] inputs: [1497 -> (-1, 16384, 128)[FLOAT]], [backbone.norm2.weight -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.norm2.weight for ONNX node: backbone.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_1038 for ONNX node: Mul_1038
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1498 for ONNX tensor: 1498
[06/10/2022-19:21:30] [V] [TRT] Mul_1038 [Mul] outputs: [1498 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1039 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1498
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1039 [Add] inputs: [1498 -> (-1, 16384, 128)[FLOAT]], [backbone.norm2.bias -> (128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.norm2.bias for ONNX node: backbone.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1039 for ONNX node: Add_1039
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1499 for ONNX tensor: 1499
[06/10/2022-19:21:30] [V] [TRT] Add_1039 [Add] outputs: [1499 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1040 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 379
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1040 [Unsqueeze] inputs: [379 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1040 for ONNX node: Unsqueeze_1040
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1501 for ONNX tensor: 1501
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1040 [Unsqueeze] outputs: [1501 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1041 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 873
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1041 [Unsqueeze] inputs: [873 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1041 for ONNX node: Unsqueeze_1041
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1502 for ONNX tensor: 1502
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1041 [Unsqueeze] outputs: [1502 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1042 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 876
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1042 [Unsqueeze] inputs: [876 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1042 for ONNX node: Unsqueeze_1042
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1503 for ONNX tensor: 1503
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1042 [Unsqueeze] outputs: [1503 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_1043 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1501
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1502
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1503
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3130
[06/10/2022-19:21:30] [V] [TRT] Concat_1043 [Concat] inputs: [1501 -> (1)[INT32]], [1502 -> (1)[INT32]], [1503 -> (1)[INT32]], [3130 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3130 for ONNX node: 3130
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_1043 for ONNX node: Concat_1043
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1505 for ONNX tensor: 1505
[06/10/2022-19:21:30] [V] [TRT] Concat_1043 [Concat] outputs: [1505 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_1044 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1499
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1505
[06/10/2022-19:21:30] [V] [TRT] Reshape_1044 [Reshape] inputs: [1499 -> (-1, 16384, 128)[FLOAT]], [1505 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_1044 for ONNX node: Reshape_1044
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1506 for ONNX tensor: 1506
[06/10/2022-19:21:30] [V] [TRT] Reshape_1044 [Reshape] outputs: [1506 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1045 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1506
[06/10/2022-19:21:30] [V] [TRT] Transpose_1045 [Transpose] inputs: [1506 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1045 for ONNX node: Transpose_1045
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1507 for ONNX tensor: 1507
[06/10/2022-19:21:30] [V] [TRT] Transpose_1045 [Transpose] outputs: [1507 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_1046 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1507
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed3.proj.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed3.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_1046 [Conv] inputs: [1507 -> (-1, 128, 128, 128)[FLOAT]], [backbone.patch_embed3.proj.weight -> (320, 128, 3, 3)[FLOAT]], [backbone.patch_embed3.proj.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 128, 128, 128)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_1046 for ONNX node: Conv_1046
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 320
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 320, 64, 64)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1508 for ONNX tensor: 1508
[06/10/2022-19:21:30] [V] [TRT] Conv_1046 [Conv] outputs: [1508 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_1047 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1508
[06/10/2022-19:21:30] [V] [TRT] Shape_1047 [Shape] inputs: [1508 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_1047 for ONNX node: Shape_1047
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1509 for ONNX tensor: 1509
[06/10/2022-19:21:30] [V] [TRT] Shape_1047 [Shape] outputs: [1509 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_1049 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1509
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1510
[06/10/2022-19:21:30] [V] [TRT] Gather_1049 [Gather] inputs: [1509 -> (4)[INT32]], [1510 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1510 for ONNX node: 1510
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_1049 for ONNX node: Gather_1049
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1511 for ONNX tensor: 1511
[06/10/2022-19:21:30] [V] [TRT] Gather_1049 [Gather] outputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_1050 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1508
[06/10/2022-19:21:30] [V] [TRT] Shape_1050 [Shape] inputs: [1508 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_1050 for ONNX node: Shape_1050
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1512 for ONNX tensor: 1512
[06/10/2022-19:21:30] [V] [TRT] Shape_1050 [Shape] outputs: [1512 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_1052 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1512
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1513
[06/10/2022-19:21:30] [V] [TRT] Gather_1052 [Gather] inputs: [1512 -> (4)[INT32]], [1513 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1513 for ONNX node: 1513
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_1052 for ONNX node: Gather_1052
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1514 for ONNX tensor: 1514
[06/10/2022-19:21:30] [V] [TRT] Gather_1052 [Gather] outputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_1053 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1508
[06/10/2022-19:21:30] [V] [TRT] Shape_1053 [Shape] inputs: [1508 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_1053 for ONNX node: Shape_1053
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1515 for ONNX tensor: 1515
[06/10/2022-19:21:30] [V] [TRT] Shape_1053 [Shape] outputs: [1515 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_1057 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1515
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1517
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1518
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1516
[06/10/2022-19:21:30] [V] [TRT] Slice_1057 [Slice] inputs: [1515 -> (4)[INT32]], [1517 -> (1)[INT32]], [1518 -> (1)[INT32]], [1516 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_1057 for ONNX node: Slice_1057
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1519 for ONNX tensor: 1519
[06/10/2022-19:21:30] [V] [TRT] Slice_1057 [Slice] outputs: [1519 -> (2)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_1059 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1519
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1520
[06/10/2022-19:21:30] [V] [TRT] Concat_1059 [Concat] inputs: [1519 -> (2)[INT32]], [1520 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1520 for ONNX node: 1520
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_1059 for ONNX node: Concat_1059
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1521 for ONNX tensor: 1521
[06/10/2022-19:21:30] [V] [TRT] Concat_1059 [Concat] outputs: [1521 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_1060 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1508
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1521
[06/10/2022-19:21:30] [V] [TRT] Reshape_1060 [Reshape] inputs: [1508 -> (-1, 320, 64, 64)[FLOAT]], [1521 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_1060 for ONNX node: Reshape_1060
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1522 for ONNX tensor: 1522
[06/10/2022-19:21:30] [V] [TRT] Reshape_1060 [Reshape] outputs: [1522 -> (-1, 320, 4096)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1061 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1522
[06/10/2022-19:21:30] [V] [TRT] Transpose_1061 [Transpose] inputs: [1522 -> (-1, 320, 4096)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1061 for ONNX node: Transpose_1061
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1523 for ONNX tensor: 1523
[06/10/2022-19:21:30] [V] [TRT] Transpose_1061 [Transpose] outputs: [1523 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1062 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1523
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1062 [ReduceMean] inputs: [1523 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1062 for ONNX node: ReduceMean_1062
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1524 for ONNX tensor: 1524
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1062 [ReduceMean] outputs: [1524 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_1063 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1523
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1524
[06/10/2022-19:21:30] [V] [TRT] Sub_1063 [Sub] inputs: [1523 -> (-1, 4096, 320)[FLOAT]], [1524 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_1063 for ONNX node: Sub_1063
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1525 for ONNX tensor: 1525
[06/10/2022-19:21:30] [V] [TRT] Sub_1063 [Sub] outputs: [1525 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_1065 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1525
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1526
[06/10/2022-19:21:30] [V] [TRT] Pow_1065 [Pow] inputs: [1525 -> (-1, 4096, 320)[FLOAT]], [1526 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1526 for ONNX node: 1526
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_1065 for ONNX node: Pow_1065
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1527 for ONNX tensor: 1527
[06/10/2022-19:21:30] [V] [TRT] Pow_1065 [Pow] outputs: [1527 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1066 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1527
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1066 [ReduceMean] inputs: [1527 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1066 for ONNX node: ReduceMean_1066
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1528 for ONNX tensor: 1528
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1066 [ReduceMean] outputs: [1528 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1068 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1528
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1529
[06/10/2022-19:21:30] [V] [TRT] Add_1068 [Add] inputs: [1528 -> (-1, 4096, 1)[FLOAT]], [1529 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1529 for ONNX node: 1529
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1068 for ONNX node: Add_1068
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1530 for ONNX tensor: 1530
[06/10/2022-19:21:30] [V] [TRT] Add_1068 [Add] outputs: [1530 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_1069 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1530
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1069 [Sqrt] inputs: [1530 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_1069 for ONNX node: Sqrt_1069
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1531 for ONNX tensor: 1531
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1069 [Sqrt] outputs: [1531 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_1070 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1525
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1531
[06/10/2022-19:21:30] [V] [TRT] Div_1070 [Div] inputs: [1525 -> (-1, 4096, 320)[FLOAT]], [1531 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_1070 for ONNX node: Div_1070
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1532 for ONNX tensor: 1532
[06/10/2022-19:21:30] [V] [TRT] Div_1070 [Div] outputs: [1532 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_1071 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1532
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed3.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_1071 [Mul] inputs: [1532 -> (-1, 4096, 320)[FLOAT]], [backbone.patch_embed3.norm.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.patch_embed3.norm.weight for ONNX node: backbone.patch_embed3.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_1071 for ONNX node: Mul_1071
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1533 for ONNX tensor: 1533
[06/10/2022-19:21:30] [V] [TRT] Mul_1071 [Mul] outputs: [1533 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1072 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1533
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.patch_embed3.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1072 [Add] inputs: [1533 -> (-1, 4096, 320)[FLOAT]], [backbone.patch_embed3.norm.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.patch_embed3.norm.bias for ONNX node: backbone.patch_embed3.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1072 for ONNX node: Add_1072
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1534 for ONNX tensor: 1534
[06/10/2022-19:21:30] [V] [TRT] Add_1072 [Add] outputs: [1534 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1073 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1534
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1073 [ReduceMean] inputs: [1534 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1073 for ONNX node: ReduceMean_1073
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1535 for ONNX tensor: 1535
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1073 [ReduceMean] outputs: [1535 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_1074 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1534
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1535
[06/10/2022-19:21:30] [V] [TRT] Sub_1074 [Sub] inputs: [1534 -> (-1, 4096, 320)[FLOAT]], [1535 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_1074 for ONNX node: Sub_1074
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1536 for ONNX tensor: 1536
[06/10/2022-19:21:30] [V] [TRT] Sub_1074 [Sub] outputs: [1536 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_1076 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1536
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1537
[06/10/2022-19:21:30] [V] [TRT] Pow_1076 [Pow] inputs: [1536 -> (-1, 4096, 320)[FLOAT]], [1537 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1537 for ONNX node: 1537
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_1076 for ONNX node: Pow_1076
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1538 for ONNX tensor: 1538
[06/10/2022-19:21:30] [V] [TRT] Pow_1076 [Pow] outputs: [1538 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1077 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1538
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1077 [ReduceMean] inputs: [1538 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1077 for ONNX node: ReduceMean_1077
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1539 for ONNX tensor: 1539
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1077 [ReduceMean] outputs: [1539 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1079 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1539
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1540
[06/10/2022-19:21:30] [V] [TRT] Add_1079 [Add] inputs: [1539 -> (-1, 4096, 1)[FLOAT]], [1540 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1540 for ONNX node: 1540
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1079 for ONNX node: Add_1079
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1541 for ONNX tensor: 1541
[06/10/2022-19:21:30] [V] [TRT] Add_1079 [Add] outputs: [1541 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_1080 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1541
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1080 [Sqrt] inputs: [1541 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_1080 for ONNX node: Sqrt_1080
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1542 for ONNX tensor: 1542
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1080 [Sqrt] outputs: [1542 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_1081 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1536
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1542
[06/10/2022-19:21:30] [V] [TRT] Div_1081 [Div] inputs: [1536 -> (-1, 4096, 320)[FLOAT]], [1542 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_1081 for ONNX node: Div_1081
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1543 for ONNX tensor: 1543
[06/10/2022-19:21:30] [V] [TRT] Div_1081 [Div] outputs: [1543 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_1082 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1543
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_1082 [Mul] inputs: [1543 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.0.norm1.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.0.norm1.weight for ONNX node: backbone.block3.0.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_1082 for ONNX node: Mul_1082
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1544 for ONNX tensor: 1544
[06/10/2022-19:21:30] [V] [TRT] Mul_1082 [Mul] outputs: [1544 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1083 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1544
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1083 [Add] inputs: [1544 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.0.norm1.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.0.norm1.bias for ONNX node: backbone.block3.0.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1083 for ONNX node: Add_1083
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1545 for ONNX tensor: 1545
[06/10/2022-19:21:30] [V] [TRT] Add_1083 [Add] outputs: [1545 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_1084 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1545
[06/10/2022-19:21:30] [V] [TRT] Shape_1084 [Shape] inputs: [1545 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_1084 for ONNX node: Shape_1084
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1546 for ONNX tensor: 1546
[06/10/2022-19:21:30] [V] [TRT] Shape_1084 [Shape] outputs: [1546 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_1086 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1546
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1547
[06/10/2022-19:21:30] [V] [TRT] Gather_1086 [Gather] inputs: [1546 -> (3)[INT32]], [1547 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1547 for ONNX node: 1547
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_1086 for ONNX node: Gather_1086
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1548 for ONNX tensor: 1548
[06/10/2022-19:21:30] [V] [TRT] Gather_1086 [Gather] outputs: [1548 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_1087 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1545
[06/10/2022-19:21:30] [V] [TRT] Shape_1087 [Shape] inputs: [1545 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_1087 for ONNX node: Shape_1087
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1549 for ONNX tensor: 1549
[06/10/2022-19:21:30] [V] [TRT] Shape_1087 [Shape] outputs: [1549 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_1089 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1549
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1550
[06/10/2022-19:21:30] [V] [TRT] Gather_1089 [Gather] inputs: [1549 -> (3)[INT32]], [1550 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1550 for ONNX node: 1550
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_1089 for ONNX node: Gather_1089
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1551 for ONNX tensor: 1551
[06/10/2022-19:21:30] [V] [TRT] Gather_1089 [Gather] outputs: [1551 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_1090 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1545
[06/10/2022-19:21:30] [V] [TRT] Shape_1090 [Shape] inputs: [1545 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_1090 for ONNX node: Shape_1090
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1552 for ONNX tensor: 1552
[06/10/2022-19:21:30] [V] [TRT] Shape_1090 [Shape] outputs: [1552 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_1092 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1552
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1553
[06/10/2022-19:21:30] [V] [TRT] Gather_1092 [Gather] inputs: [1552 -> (3)[INT32]], [1553 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1553 for ONNX node: 1553
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_1092 for ONNX node: Gather_1092
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1554 for ONNX tensor: 1554
[06/10/2022-19:21:30] [V] [TRT] Gather_1092 [Gather] outputs: [1554 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_1093 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1545
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3131
[06/10/2022-19:21:30] [V] [TRT] MatMul_1093 [MatMul] inputs: [1545 -> (-1, 4096, 320)[FLOAT]], [3131 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3131 for ONNX node: 3131
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_1093 for ONNX node: MatMul_1093
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1556 for ONNX tensor: 1556
[06/10/2022-19:21:30] [V] [TRT] MatMul_1093 [MatMul] outputs: [1556 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1094 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1556
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1094 [Add] inputs: [1556 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.0.attn.q.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.0.attn.q.bias for ONNX node: backbone.block3.0.attn.q.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1094 for ONNX node: Add_1094
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1557 for ONNX tensor: 1557
[06/10/2022-19:21:30] [V] [TRT] Add_1094 [Add] outputs: [1557 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_1096 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1554
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1558
[06/10/2022-19:21:30] [V] [TRT] Div_1096 [Div] inputs: [1554 -> ()[INT32]], [1558 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1558 for ONNX node: 1558
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_1096 for ONNX node: Div_1096
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1559 for ONNX tensor: 1559
[06/10/2022-19:21:30] [V] [TRT] Div_1096 [Div] outputs: [1559 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_1097 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1559
[06/10/2022-19:21:30] [V] [TRT] Cast_1097 [Cast] inputs: [1559 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_1097 for ONNX node: Cast_1097
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1560 for ONNX tensor: 1560
[06/10/2022-19:21:30] [V] [TRT] Cast_1097 [Cast] outputs: [1560 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_1098 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1560
[06/10/2022-19:21:30] [V] [TRT] Cast_1098 [Cast] inputs: [1560 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_1098 for ONNX node: Cast_1098
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1561 for ONNX tensor: 1561
[06/10/2022-19:21:30] [V] [TRT] Cast_1098 [Cast] outputs: [1561 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1099 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1548
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1099 [Unsqueeze] inputs: [1548 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1099 for ONNX node: Unsqueeze_1099
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1563 for ONNX tensor: 1563
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1099 [Unsqueeze] outputs: [1563 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1100 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1551
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1100 [Unsqueeze] inputs: [1551 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1100 for ONNX node: Unsqueeze_1100
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1564 for ONNX tensor: 1564
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1100 [Unsqueeze] outputs: [1564 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1101 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1561
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1101 [Unsqueeze] inputs: [1561 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1101 for ONNX node: Unsqueeze_1101
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1566 for ONNX tensor: 1566
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1101 [Unsqueeze] outputs: [1566 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_1102 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1563
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1564
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3132
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1566
[06/10/2022-19:21:30] [V] [TRT] Concat_1102 [Concat] inputs: [1563 -> (1)[INT32]], [1564 -> (1)[INT32]], [3132 -> (1)[INT32]], [1566 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3132 for ONNX node: 3132
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_1102 for ONNX node: Concat_1102
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1567 for ONNX tensor: 1567
[06/10/2022-19:21:30] [V] [TRT] Concat_1102 [Concat] outputs: [1567 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_1103 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1557
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1567
[06/10/2022-19:21:30] [V] [TRT] Reshape_1103 [Reshape] inputs: [1557 -> (-1, 4096, 320)[FLOAT]], [1567 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_1103 for ONNX node: Reshape_1103
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1568 for ONNX tensor: 1568
[06/10/2022-19:21:30] [V] [TRT] Reshape_1103 [Reshape] outputs: [1568 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1104 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1568
[06/10/2022-19:21:30] [V] [TRT] Transpose_1104 [Transpose] inputs: [1568 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1104 for ONNX node: Transpose_1104
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1569 for ONNX tensor: 1569
[06/10/2022-19:21:30] [V] [TRT] Transpose_1104 [Transpose] outputs: [1569 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1105 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1545
[06/10/2022-19:21:30] [V] [TRT] Transpose_1105 [Transpose] inputs: [1545 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1105 for ONNX node: Transpose_1105
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1570 for ONNX tensor: 1570
[06/10/2022-19:21:30] [V] [TRT] Transpose_1105 [Transpose] outputs: [1570 -> (-1, 320, 4096)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1106 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1548
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1106 [Unsqueeze] inputs: [1548 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1106 for ONNX node: Unsqueeze_1106
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1571 for ONNX tensor: 1571
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1106 [Unsqueeze] outputs: [1571 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1107 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1554
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1107 [Unsqueeze] inputs: [1554 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1107 for ONNX node: Unsqueeze_1107
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1572 for ONNX tensor: 1572
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1107 [Unsqueeze] outputs: [1572 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1108 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1108 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1108 for ONNX node: Unsqueeze_1108
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1573 for ONNX tensor: 1573
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1108 [Unsqueeze] outputs: [1573 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1109 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1109 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1109 for ONNX node: Unsqueeze_1109
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1574 for ONNX tensor: 1574
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1109 [Unsqueeze] outputs: [1574 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_1110 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1571
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1572
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1573
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1574
[06/10/2022-19:21:30] [V] [TRT] Concat_1110 [Concat] inputs: [1571 -> (1)[INT32]], [1572 -> (1)[INT32]], [1573 -> (1)[INT32]], [1574 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_1110 for ONNX node: Concat_1110
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1575 for ONNX tensor: 1575
[06/10/2022-19:21:30] [V] [TRT] Concat_1110 [Concat] outputs: [1575 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_1111 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1570
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1575
[06/10/2022-19:21:30] [V] [TRT] Reshape_1111 [Reshape] inputs: [1570 -> (-1, 320, 4096)[FLOAT]], [1575 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_1111 for ONNX node: Reshape_1111
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1576 for ONNX tensor: 1576
[06/10/2022-19:21:30] [V] [TRT] Reshape_1111 [Reshape] outputs: [1576 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_1112 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1576
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.attn.sr.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.attn.sr.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_1112 [Conv] inputs: [1576 -> (-1, 320, 64, 64)[FLOAT]], [backbone.block3.0.attn.sr.weight -> (320, 320, 2, 2)[FLOAT]], [backbone.block3.0.attn.sr.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 320, 64, 64)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_1112 for ONNX node: Conv_1112
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (2, 2), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 320
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 320, 32, 32)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1577 for ONNX tensor: 1577
[06/10/2022-19:21:30] [V] [TRT] Conv_1112 [Conv] outputs: [1577 -> (-1, 320, 32, 32)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1113 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1548
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1113 [Unsqueeze] inputs: [1548 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1113 for ONNX node: Unsqueeze_1113
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1579 for ONNX tensor: 1579
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1113 [Unsqueeze] outputs: [1579 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1114 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1554
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1114 [Unsqueeze] inputs: [1554 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1114 for ONNX node: Unsqueeze_1114
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1580 for ONNX tensor: 1580
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1114 [Unsqueeze] outputs: [1580 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_1115 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1579
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1580
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3133
[06/10/2022-19:21:30] [V] [TRT] Concat_1115 [Concat] inputs: [1579 -> (1)[INT32]], [1580 -> (1)[INT32]], [3133 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3133 for ONNX node: 3133
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_1115 for ONNX node: Concat_1115
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1582 for ONNX tensor: 1582
[06/10/2022-19:21:30] [V] [TRT] Concat_1115 [Concat] outputs: [1582 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_1116 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1577
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1582
[06/10/2022-19:21:30] [V] [TRT] Reshape_1116 [Reshape] inputs: [1577 -> (-1, 320, 32, 32)[FLOAT]], [1582 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_1116 for ONNX node: Reshape_1116
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1583 for ONNX tensor: 1583
[06/10/2022-19:21:30] [V] [TRT] Reshape_1116 [Reshape] outputs: [1583 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1117 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1583
[06/10/2022-19:21:30] [V] [TRT] Transpose_1117 [Transpose] inputs: [1583 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1117 for ONNX node: Transpose_1117
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1584 for ONNX tensor: 1584
[06/10/2022-19:21:30] [V] [TRT] Transpose_1117 [Transpose] outputs: [1584 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1118 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1584
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1118 [ReduceMean] inputs: [1584 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1118 for ONNX node: ReduceMean_1118
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1585 for ONNX tensor: 1585
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1118 [ReduceMean] outputs: [1585 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_1119 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1584
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1585
[06/10/2022-19:21:30] [V] [TRT] Sub_1119 [Sub] inputs: [1584 -> (-1, 1024, 320)[FLOAT]], [1585 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_1119 for ONNX node: Sub_1119
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1586 for ONNX tensor: 1586
[06/10/2022-19:21:30] [V] [TRT] Sub_1119 [Sub] outputs: [1586 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_1121 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1586
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1587
[06/10/2022-19:21:30] [V] [TRT] Pow_1121 [Pow] inputs: [1586 -> (-1, 1024, 320)[FLOAT]], [1587 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1587 for ONNX node: 1587
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_1121 for ONNX node: Pow_1121
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1588 for ONNX tensor: 1588
[06/10/2022-19:21:30] [V] [TRT] Pow_1121 [Pow] outputs: [1588 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1122 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1588
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1122 [ReduceMean] inputs: [1588 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1122 for ONNX node: ReduceMean_1122
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1589 for ONNX tensor: 1589
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1122 [ReduceMean] outputs: [1589 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1124 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1589
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1590
[06/10/2022-19:21:30] [V] [TRT] Add_1124 [Add] inputs: [1589 -> (-1, 1024, 1)[FLOAT]], [1590 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1590 for ONNX node: 1590
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1124 for ONNX node: Add_1124
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1591 for ONNX tensor: 1591
[06/10/2022-19:21:30] [V] [TRT] Add_1124 [Add] outputs: [1591 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_1125 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1591
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1125 [Sqrt] inputs: [1591 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_1125 for ONNX node: Sqrt_1125
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1592 for ONNX tensor: 1592
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1125 [Sqrt] outputs: [1592 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_1126 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1586
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1592
[06/10/2022-19:21:30] [V] [TRT] Div_1126 [Div] inputs: [1586 -> (-1, 1024, 320)[FLOAT]], [1592 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_1126 for ONNX node: Div_1126
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1593 for ONNX tensor: 1593
[06/10/2022-19:21:30] [V] [TRT] Div_1126 [Div] outputs: [1593 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_1127 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1593
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_1127 [Mul] inputs: [1593 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.0.attn.norm.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.0.attn.norm.weight for ONNX node: backbone.block3.0.attn.norm.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_1127 for ONNX node: Mul_1127
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1594 for ONNX tensor: 1594
[06/10/2022-19:21:30] [V] [TRT] Mul_1127 [Mul] outputs: [1594 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1128 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1594
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1128 [Add] inputs: [1594 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.0.attn.norm.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.0.attn.norm.bias for ONNX node: backbone.block3.0.attn.norm.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1128 for ONNX node: Add_1128
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1595 for ONNX tensor: 1595
[06/10/2022-19:21:30] [V] [TRT] Add_1128 [Add] outputs: [1595 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_1129 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1595
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3134
[06/10/2022-19:21:30] [V] [TRT] MatMul_1129 [MatMul] inputs: [1595 -> (-1, 1024, 320)[FLOAT]], [3134 -> (320, 640)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3134 for ONNX node: 3134
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_1129 for ONNX node: MatMul_1129
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1597 for ONNX tensor: 1597
[06/10/2022-19:21:30] [V] [TRT] MatMul_1129 [MatMul] outputs: [1597 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1130 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1597
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1130 [Add] inputs: [1597 -> (-1, 1024, 640)[FLOAT]], [backbone.block3.0.attn.kv.bias -> (640)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.0.attn.kv.bias for ONNX node: backbone.block3.0.attn.kv.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1130 for ONNX node: Add_1130
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1598 for ONNX tensor: 1598
[06/10/2022-19:21:30] [V] [TRT] Add_1130 [Add] outputs: [1598 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_1132 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1554
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1599
[06/10/2022-19:21:30] [V] [TRT] Div_1132 [Div] inputs: [1554 -> ()[INT32]], [1599 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1599 for ONNX node: 1599
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_1132 for ONNX node: Div_1132
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1600 for ONNX tensor: 1600
[06/10/2022-19:21:30] [V] [TRT] Div_1132 [Div] outputs: [1600 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_1133 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1600
[06/10/2022-19:21:30] [V] [TRT] Cast_1133 [Cast] inputs: [1600 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_1133 for ONNX node: Cast_1133
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1601 for ONNX tensor: 1601
[06/10/2022-19:21:30] [V] [TRT] Cast_1133 [Cast] outputs: [1601 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Cast_1134 [Cast]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1601
[06/10/2022-19:21:30] [V] [TRT] Cast_1134 [Cast] inputs: [1601 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Cast_1134 for ONNX node: Cast_1134
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1602 for ONNX tensor: 1602
[06/10/2022-19:21:30] [V] [TRT] Cast_1134 [Cast] outputs: [1602 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1135 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1548
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1135 [Unsqueeze] inputs: [1548 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1135 for ONNX node: Unsqueeze_1135
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1606 for ONNX tensor: 1606
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1135 [Unsqueeze] outputs: [1606 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1136 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1602
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1136 [Unsqueeze] inputs: [1602 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1136 for ONNX node: Unsqueeze_1136
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1610 for ONNX tensor: 1610
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1136 [Unsqueeze] outputs: [1610 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_1137 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1606
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3135
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3136
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3137
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1610
[06/10/2022-19:21:30] [V] [TRT] Concat_1137 [Concat] inputs: [1606 -> (1)[INT32]], [3135 -> (1)[INT32]], [3136 -> (1)[INT32]], [3137 -> (1)[INT32]], [1610 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3135 for ONNX node: 3135
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3136 for ONNX node: 3136
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3137 for ONNX node: 3137
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_1137 for ONNX node: Concat_1137
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1611 for ONNX tensor: 1611
[06/10/2022-19:21:30] [V] [TRT] Concat_1137 [Concat] outputs: [1611 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_1138 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1598
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1611
[06/10/2022-19:21:30] [V] [TRT] Reshape_1138 [Reshape] inputs: [1598 -> (-1, 1024, 640)[FLOAT]], [1611 -> (5)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_1138 for ONNX node: Reshape_1138
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1612 for ONNX tensor: 1612
[06/10/2022-19:21:30] [V] [TRT] Reshape_1138 [Reshape] outputs: [1612 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1139 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1612
[06/10/2022-19:21:30] [V] [TRT] Transpose_1139 [Transpose] inputs: [1612 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1139 for ONNX node: Transpose_1139
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1613 for ONNX tensor: 1613
[06/10/2022-19:21:30] [V] [TRT] Transpose_1139 [Transpose] outputs: [1613 -> (2, -1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_1141 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1613
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1614
[06/10/2022-19:21:30] [V] [TRT] Gather_1141 [Gather] inputs: [1613 -> (2, -1, 5, 1024, 64)[FLOAT]], [1614 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1614 for ONNX node: 1614
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_1141 for ONNX node: Gather_1141
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1615 for ONNX tensor: 1615
[06/10/2022-19:21:30] [V] [TRT] Gather_1141 [Gather] outputs: [1615 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_1143 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1613
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1616
[06/10/2022-19:21:30] [V] [TRT] Gather_1143 [Gather] inputs: [1613 -> (2, -1, 5, 1024, 64)[FLOAT]], [1616 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1616 for ONNX node: 1616
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_1143 for ONNX node: Gather_1143
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1617 for ONNX tensor: 1617
[06/10/2022-19:21:30] [V] [TRT] Gather_1143 [Gather] outputs: [1617 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1144 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1615
[06/10/2022-19:21:30] [V] [TRT] Transpose_1144 [Transpose] inputs: [1615 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1144 for ONNX node: Transpose_1144
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1618 for ONNX tensor: 1618
[06/10/2022-19:21:30] [V] [TRT] Transpose_1144 [Transpose] outputs: [1618 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_1145 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1569
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1618
[06/10/2022-19:21:30] [V] [TRT] MatMul_1145 [MatMul] inputs: [1569 -> (-1, 5, 4096, 64)[FLOAT]], [1618 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_1145 for ONNX node: MatMul_1145
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1619 for ONNX tensor: 1619
[06/10/2022-19:21:30] [V] [TRT] MatMul_1145 [MatMul] outputs: [1619 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_1147 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1619
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1620
[06/10/2022-19:21:30] [V] [TRT] Mul_1147 [Mul] inputs: [1619 -> (-1, 5, 4096, 1024)[FLOAT]], [1620 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1620 for ONNX node: 1620
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_1147 for ONNX node: Mul_1147
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1621 for ONNX tensor: 1621
[06/10/2022-19:21:30] [V] [TRT] Mul_1147 [Mul] outputs: [1621 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Softmax_1148 [Softmax]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1621
[06/10/2022-19:21:30] [V] [TRT] Softmax_1148 [Softmax] inputs: [1621 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Softmax_1148 for ONNX node: Softmax_1148
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1622 for ONNX tensor: 1622
[06/10/2022-19:21:30] [V] [TRT] Softmax_1148 [Softmax] outputs: [1622 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_1149 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1622
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1617
[06/10/2022-19:21:30] [V] [TRT] MatMul_1149 [MatMul] inputs: [1622 -> (-1, 5, 4096, 1024)[FLOAT]], [1617 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_1149 for ONNX node: MatMul_1149
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1623 for ONNX tensor: 1623
[06/10/2022-19:21:30] [V] [TRT] MatMul_1149 [MatMul] outputs: [1623 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1150 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1623
[06/10/2022-19:21:30] [V] [TRT] Transpose_1150 [Transpose] inputs: [1623 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1150 for ONNX node: Transpose_1150
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1624 for ONNX tensor: 1624
[06/10/2022-19:21:30] [V] [TRT] Transpose_1150 [Transpose] outputs: [1624 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1151 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1548
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1151 [Unsqueeze] inputs: [1548 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1151 for ONNX node: Unsqueeze_1151
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1625 for ONNX tensor: 1625
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1151 [Unsqueeze] outputs: [1625 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1152 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1551
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1152 [Unsqueeze] inputs: [1551 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1152 for ONNX node: Unsqueeze_1152
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1626 for ONNX tensor: 1626
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1152 [Unsqueeze] outputs: [1626 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1153 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1554
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1153 [Unsqueeze] inputs: [1554 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1153 for ONNX node: Unsqueeze_1153
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1627 for ONNX tensor: 1627
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1153 [Unsqueeze] outputs: [1627 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_1154 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1625
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1626
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1627
[06/10/2022-19:21:30] [V] [TRT] Concat_1154 [Concat] inputs: [1625 -> (1)[INT32]], [1626 -> (1)[INT32]], [1627 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_1154 for ONNX node: Concat_1154
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1628 for ONNX tensor: 1628
[06/10/2022-19:21:30] [V] [TRT] Concat_1154 [Concat] outputs: [1628 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_1155 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1624
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1628
[06/10/2022-19:21:30] [V] [TRT] Reshape_1155 [Reshape] inputs: [1624 -> (-1, 4096, 5, 64)[FLOAT]], [1628 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_1155 for ONNX node: Reshape_1155
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1629 for ONNX tensor: 1629
[06/10/2022-19:21:30] [V] [TRT] Reshape_1155 [Reshape] outputs: [1629 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_1156 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1629
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3138
[06/10/2022-19:21:30] [V] [TRT] MatMul_1156 [MatMul] inputs: [1629 -> (-1, 4096, 320)[FLOAT]], [3138 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3138 for ONNX node: 3138
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_1156 for ONNX node: MatMul_1156
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1631 for ONNX tensor: 1631
[06/10/2022-19:21:30] [V] [TRT] MatMul_1156 [MatMul] outputs: [1631 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1157 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1631
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1157 [Add] inputs: [1631 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.0.attn.proj.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.0.attn.proj.bias for ONNX node: backbone.block3.0.attn.proj.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1157 for ONNX node: Add_1157
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1632 for ONNX tensor: 1632
[06/10/2022-19:21:30] [V] [TRT] Add_1157 [Add] outputs: [1632 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1158 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1534
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1632
[06/10/2022-19:21:30] [V] [TRT] Add_1158 [Add] inputs: [1534 -> (-1, 4096, 320)[FLOAT]], [1632 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1158 for ONNX node: Add_1158
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1633 for ONNX tensor: 1633
[06/10/2022-19:21:30] [V] [TRT] Add_1158 [Add] outputs: [1633 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1159 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1633
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1159 [ReduceMean] inputs: [1633 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1159 for ONNX node: ReduceMean_1159
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1634 for ONNX tensor: 1634
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1159 [ReduceMean] outputs: [1634 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_1160 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1633
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1634
[06/10/2022-19:21:30] [V] [TRT] Sub_1160 [Sub] inputs: [1633 -> (-1, 4096, 320)[FLOAT]], [1634 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_1160 for ONNX node: Sub_1160
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1635 for ONNX tensor: 1635
[06/10/2022-19:21:30] [V] [TRT] Sub_1160 [Sub] outputs: [1635 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_1162 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1635
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1636
[06/10/2022-19:21:30] [V] [TRT] Pow_1162 [Pow] inputs: [1635 -> (-1, 4096, 320)[FLOAT]], [1636 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1636 for ONNX node: 1636
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_1162 for ONNX node: Pow_1162
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1637 for ONNX tensor: 1637
[06/10/2022-19:21:30] [V] [TRT] Pow_1162 [Pow] outputs: [1637 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1163 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1637
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1163 [ReduceMean] inputs: [1637 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1163 for ONNX node: ReduceMean_1163
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1638 for ONNX tensor: 1638
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1163 [ReduceMean] outputs: [1638 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1165 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1638
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1639
[06/10/2022-19:21:30] [V] [TRT] Add_1165 [Add] inputs: [1638 -> (-1, 4096, 1)[FLOAT]], [1639 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1639 for ONNX node: 1639
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1165 for ONNX node: Add_1165
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1640 for ONNX tensor: 1640
[06/10/2022-19:21:30] [V] [TRT] Add_1165 [Add] outputs: [1640 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_1166 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1640
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1166 [Sqrt] inputs: [1640 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_1166 for ONNX node: Sqrt_1166
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1641 for ONNX tensor: 1641
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1166 [Sqrt] outputs: [1641 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_1167 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1635
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1641
[06/10/2022-19:21:30] [V] [TRT] Div_1167 [Div] inputs: [1635 -> (-1, 4096, 320)[FLOAT]], [1641 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_1167 for ONNX node: Div_1167
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1642 for ONNX tensor: 1642
[06/10/2022-19:21:30] [V] [TRT] Div_1167 [Div] outputs: [1642 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_1168 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1642
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_1168 [Mul] inputs: [1642 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.0.norm2.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.0.norm2.weight for ONNX node: backbone.block3.0.norm2.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_1168 for ONNX node: Mul_1168
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1643 for ONNX tensor: 1643
[06/10/2022-19:21:30] [V] [TRT] Mul_1168 [Mul] outputs: [1643 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1169 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1643
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1169 [Add] inputs: [1643 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.0.norm2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.0.norm2.bias for ONNX node: backbone.block3.0.norm2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1169 for ONNX node: Add_1169
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1644 for ONNX tensor: 1644
[06/10/2022-19:21:30] [V] [TRT] Add_1169 [Add] outputs: [1644 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_1170 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1644
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3139
[06/10/2022-19:21:30] [V] [TRT] MatMul_1170 [MatMul] inputs: [1644 -> (-1, 4096, 320)[FLOAT]], [3139 -> (320, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3139 for ONNX node: 3139
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_1170 for ONNX node: MatMul_1170
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1646 for ONNX tensor: 1646
[06/10/2022-19:21:30] [V] [TRT] MatMul_1170 [MatMul] outputs: [1646 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1171 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1646
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1171 [Add] inputs: [1646 -> (-1, 4096, 1280)[FLOAT]], [backbone.block3.0.mlp.fc1.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.0.mlp.fc1.bias for ONNX node: backbone.block3.0.mlp.fc1.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1171 for ONNX node: Add_1171
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1647 for ONNX tensor: 1647
[06/10/2022-19:21:30] [V] [TRT] Add_1171 [Add] outputs: [1647 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_1172 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1647
[06/10/2022-19:21:30] [V] [TRT] Shape_1172 [Shape] inputs: [1647 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_1172 for ONNX node: Shape_1172
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1648 for ONNX tensor: 1648
[06/10/2022-19:21:30] [V] [TRT] Shape_1172 [Shape] outputs: [1648 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_1174 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1648
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1649
[06/10/2022-19:21:30] [V] [TRT] Gather_1174 [Gather] inputs: [1648 -> (3)[INT32]], [1649 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1649 for ONNX node: 1649
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_1174 for ONNX node: Gather_1174
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1650 for ONNX tensor: 1650
[06/10/2022-19:21:30] [V] [TRT] Gather_1174 [Gather] outputs: [1650 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_1175 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1647
[06/10/2022-19:21:30] [V] [TRT] Shape_1175 [Shape] inputs: [1647 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_1175 for ONNX node: Shape_1175
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1651 for ONNX tensor: 1651
[06/10/2022-19:21:30] [V] [TRT] Shape_1175 [Shape] outputs: [1651 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Gather_1177 [Gather]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1651
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1652
[06/10/2022-19:21:30] [V] [TRT] Gather_1177 [Gather] inputs: [1651 -> (3)[INT32]], [1652 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1652 for ONNX node: 1652
[06/10/2022-19:21:30] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Gather_1177 for ONNX node: Gather_1177
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1653 for ONNX tensor: 1653
[06/10/2022-19:21:30] [V] [TRT] Gather_1177 [Gather] outputs: [1653 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1178 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1647
[06/10/2022-19:21:30] [V] [TRT] Transpose_1178 [Transpose] inputs: [1647 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1178 for ONNX node: Transpose_1178
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1654 for ONNX tensor: 1654
[06/10/2022-19:21:30] [V] [TRT] Transpose_1178 [Transpose] outputs: [1654 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1179 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1650
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1179 [Unsqueeze] inputs: [1650 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1179 for ONNX node: Unsqueeze_1179
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1655 for ONNX tensor: 1655
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1179 [Unsqueeze] outputs: [1655 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1180 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1653
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1180 [Unsqueeze] inputs: [1653 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1180 for ONNX node: Unsqueeze_1180
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1656 for ONNX tensor: 1656
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1180 [Unsqueeze] outputs: [1656 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1181 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1181 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1181 for ONNX node: Unsqueeze_1181
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1657 for ONNX tensor: 1657
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1181 [Unsqueeze] outputs: [1657 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Unsqueeze_1182 [Unsqueeze]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1182 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Unsqueeze_1182 for ONNX node: Unsqueeze_1182
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1658 for ONNX tensor: 1658
[06/10/2022-19:21:30] [V] [TRT] Unsqueeze_1182 [Unsqueeze] outputs: [1658 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_1183 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1655
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1656
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1657
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1658
[06/10/2022-19:21:30] [V] [TRT] Concat_1183 [Concat] inputs: [1655 -> (1)[INT32]], [1656 -> (1)[INT32]], [1657 -> (1)[INT32]], [1658 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_1183 for ONNX node: Concat_1183
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1659 for ONNX tensor: 1659
[06/10/2022-19:21:30] [V] [TRT] Concat_1183 [Concat] outputs: [1659 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_1184 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1654
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1659
[06/10/2022-19:21:30] [V] [TRT] Reshape_1184 [Reshape] inputs: [1654 -> (-1, 1280, 4096)[FLOAT]], [1659 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_1184 for ONNX node: Reshape_1184
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1660 for ONNX tensor: 1660
[06/10/2022-19:21:30] [V] [TRT] Reshape_1184 [Reshape] outputs: [1660 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Conv_1185 [Conv]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1660
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:30] [V] [TRT] Conv_1185 [Conv] inputs: [1660 -> (-1, 1280, 64, 64)[FLOAT]], [backbone.block3.0.mlp.dwconv.dwconv.weight -> (1280, 1, 3, 3)[FLOAT]], [backbone.block3.0.mlp.dwconv.dwconv.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Convolution input dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Conv_1185 for ONNX node: Conv_1185
[06/10/2022-19:21:30] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1280
[06/10/2022-19:21:30] [V] [TRT] Convolution output dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1661 for ONNX tensor: 1661
[06/10/2022-19:21:30] [V] [TRT] Conv_1185 [Conv] outputs: [1661 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Shape_1186 [Shape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1661
[06/10/2022-19:21:30] [V] [TRT] Shape_1186 [Shape] inputs: [1661 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Shape_1186 for ONNX node: Shape_1186
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1662 for ONNX tensor: 1662
[06/10/2022-19:21:30] [V] [TRT] Shape_1186 [Shape] outputs: [1662 -> (4)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Slice_1190 [Slice]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1662
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1664
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1665
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1663
[06/10/2022-19:21:30] [V] [TRT] Slice_1190 [Slice] inputs: [1662 -> (4)[INT32]], [1664 -> (1)[INT32]], [1665 -> (1)[INT32]], [1663 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Slice_1190 for ONNX node: Slice_1190
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1666 for ONNX tensor: 1666
[06/10/2022-19:21:30] [V] [TRT] Slice_1190 [Slice] outputs: [1666 -> (2)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Concat_1192 [Concat]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1666
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1667
[06/10/2022-19:21:30] [V] [TRT] Concat_1192 [Concat] inputs: [1666 -> (2)[INT32]], [1667 -> (1)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1667 for ONNX node: 1667
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Concat_1192 for ONNX node: Concat_1192
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1668 for ONNX tensor: 1668
[06/10/2022-19:21:30] [V] [TRT] Concat_1192 [Concat] outputs: [1668 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Reshape_1193 [Reshape]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1661
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1668
[06/10/2022-19:21:30] [V] [TRT] Reshape_1193 [Reshape] inputs: [1661 -> (-1, 1280, 64, 64)[FLOAT]], [1668 -> (3)[INT32]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Reshape_1193 for ONNX node: Reshape_1193
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1669 for ONNX tensor: 1669
[06/10/2022-19:21:30] [V] [TRT] Reshape_1193 [Reshape] outputs: [1669 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Transpose_1194 [Transpose]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1669
[06/10/2022-19:21:30] [V] [TRT] Transpose_1194 [Transpose] inputs: [1669 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Transpose_1194 for ONNX node: Transpose_1194
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1670 for ONNX tensor: 1670
[06/10/2022-19:21:30] [V] [TRT] Transpose_1194 [Transpose] outputs: [1670 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_1196 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1670
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1671
[06/10/2022-19:21:30] [V] [TRT] Div_1196 [Div] inputs: [1670 -> (-1, 4096, 1280)[FLOAT]], [1671 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1671 for ONNX node: 1671
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_1196 for ONNX node: Div_1196
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1672 for ONNX tensor: 1672
[06/10/2022-19:21:30] [V] [TRT] Div_1196 [Div] outputs: [1672 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Erf_1197 [Erf]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1672
[06/10/2022-19:21:30] [V] [TRT] Erf_1197 [Erf] inputs: [1672 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Erf_1197 for ONNX node: Erf_1197
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1673 for ONNX tensor: 1673
[06/10/2022-19:21:30] [V] [TRT] Erf_1197 [Erf] outputs: [1673 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1199 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1673
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1674
[06/10/2022-19:21:30] [V] [TRT] Add_1199 [Add] inputs: [1673 -> (-1, 4096, 1280)[FLOAT]], [1674 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1674 for ONNX node: 1674
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1199 for ONNX node: Add_1199
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1675 for ONNX tensor: 1675
[06/10/2022-19:21:30] [V] [TRT] Add_1199 [Add] outputs: [1675 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_1200 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1670
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1675
[06/10/2022-19:21:30] [V] [TRT] Mul_1200 [Mul] inputs: [1670 -> (-1, 4096, 1280)[FLOAT]], [1675 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_1200 for ONNX node: Mul_1200
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1676 for ONNX tensor: 1676
[06/10/2022-19:21:30] [V] [TRT] Mul_1200 [Mul] outputs: [1676 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_1202 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1676
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1677
[06/10/2022-19:21:30] [V] [TRT] Mul_1202 [Mul] inputs: [1676 -> (-1, 4096, 1280)[FLOAT]], [1677 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1677 for ONNX node: 1677
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_1202 for ONNX node: Mul_1202
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1678 for ONNX tensor: 1678
[06/10/2022-19:21:30] [V] [TRT] Mul_1202 [Mul] outputs: [1678 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: MatMul_1203 [MatMul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1678
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 3140
[06/10/2022-19:21:30] [V] [TRT] MatMul_1203 [MatMul] inputs: [1678 -> (-1, 4096, 1280)[FLOAT]], [3140 -> (1280, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 3140 for ONNX node: 3140
[06/10/2022-19:21:30] [V] [TRT] Registering layer: MatMul_1203 for ONNX node: MatMul_1203
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1680 for ONNX tensor: 1680
[06/10/2022-19:21:30] [V] [TRT] MatMul_1203 [MatMul] outputs: [1680 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1204 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1680
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.0.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1204 [Add] inputs: [1680 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.0.mlp.fc2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.0.mlp.fc2.bias for ONNX node: backbone.block3.0.mlp.fc2.bias
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1204 for ONNX node: Add_1204
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1681 for ONNX tensor: 1681
[06/10/2022-19:21:30] [V] [TRT] Add_1204 [Add] outputs: [1681 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1205 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1633
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1681
[06/10/2022-19:21:30] [V] [TRT] Add_1205 [Add] inputs: [1633 -> (-1, 4096, 320)[FLOAT]], [1681 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1205 for ONNX node: Add_1205
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1682 for ONNX tensor: 1682
[06/10/2022-19:21:30] [V] [TRT] Add_1205 [Add] outputs: [1682 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1206 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1682
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1206 [ReduceMean] inputs: [1682 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1206 for ONNX node: ReduceMean_1206
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1683 for ONNX tensor: 1683
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1206 [ReduceMean] outputs: [1683 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sub_1207 [Sub]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1682
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1683
[06/10/2022-19:21:30] [V] [TRT] Sub_1207 [Sub] inputs: [1682 -> (-1, 4096, 320)[FLOAT]], [1683 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sub_1207 for ONNX node: Sub_1207
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1684 for ONNX tensor: 1684
[06/10/2022-19:21:30] [V] [TRT] Sub_1207 [Sub] outputs: [1684 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Pow_1209 [Pow]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1684
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1685
[06/10/2022-19:21:30] [V] [TRT] Pow_1209 [Pow] inputs: [1684 -> (-1, 4096, 320)[FLOAT]], [1685 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1685 for ONNX node: 1685
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Pow_1209 for ONNX node: Pow_1209
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1686 for ONNX tensor: 1686
[06/10/2022-19:21:30] [V] [TRT] Pow_1209 [Pow] outputs: [1686 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: ReduceMean_1210 [ReduceMean]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1686
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1210 [ReduceMean] inputs: [1686 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: ReduceMean_1210 for ONNX node: ReduceMean_1210
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1687 for ONNX tensor: 1687
[06/10/2022-19:21:30] [V] [TRT] ReduceMean_1210 [ReduceMean] outputs: [1687 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1212 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1687
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1688
[06/10/2022-19:21:30] [V] [TRT] Add_1212 [Add] inputs: [1687 -> (-1, 4096, 1)[FLOAT]], [1688 -> ()[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: 1688 for ONNX node: 1688
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Add_1212 for ONNX node: Add_1212
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1689 for ONNX tensor: 1689
[06/10/2022-19:21:30] [V] [TRT] Add_1212 [Add] outputs: [1689 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Sqrt_1213 [Sqrt]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1689
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1213 [Sqrt] inputs: [1689 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Sqrt_1213 for ONNX node: Sqrt_1213
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1690 for ONNX tensor: 1690
[06/10/2022-19:21:30] [V] [TRT] Sqrt_1213 [Sqrt] outputs: [1690 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Div_1214 [Div]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1684
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1690
[06/10/2022-19:21:30] [V] [TRT] Div_1214 [Div] inputs: [1684 -> (-1, 4096, 320)[FLOAT]], [1690 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Div_1214 for ONNX node: Div_1214
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1691 for ONNX tensor: 1691
[06/10/2022-19:21:30] [V] [TRT] Div_1214 [Div] outputs: [1691 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Mul_1215 [Mul]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1691
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.1.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Mul_1215 [Mul] inputs: [1691 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.1.norm1.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.1.norm1.weight for ONNX node: backbone.block3.1.norm1.weight
[06/10/2022-19:21:30] [V] [TRT] Registering layer: Mul_1215 for ONNX node: Mul_1215
[06/10/2022-19:21:30] [V] [TRT] Registering tensor: 1692 for ONNX tensor: 1692
[06/10/2022-19:21:30] [V] [TRT] Mul_1215 [Mul] outputs: [1692 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Parsing node: Add_1216 [Add]
[06/10/2022-19:21:30] [V] [TRT] Searching for input: 1692
[06/10/2022-19:21:30] [V] [TRT] Searching for input: backbone.block3.1.norm1.bias
[06/10/2022-19:21:30] [V] [TRT] Add_1216 [Add] inputs: [1692 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.1.norm1.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:30] [V] [TRT] Registering layer: backbone.block3.1.norm1.bias for ONNX node: backbone.block3.1.norm1.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1216 for ONNX node: Add_1216
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1693 for ONNX tensor: 1693
[06/10/2022-19:21:31] [V] [TRT] Add_1216 [Add] outputs: [1693 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1217 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1693
[06/10/2022-19:21:31] [V] [TRT] Shape_1217 [Shape] inputs: [1693 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1217 for ONNX node: Shape_1217
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1694 for ONNX tensor: 1694
[06/10/2022-19:21:31] [V] [TRT] Shape_1217 [Shape] outputs: [1694 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1219 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1694
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1695
[06/10/2022-19:21:31] [V] [TRT] Gather_1219 [Gather] inputs: [1694 -> (3)[INT32]], [1695 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1695 for ONNX node: 1695
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1219 for ONNX node: Gather_1219
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1696 for ONNX tensor: 1696
[06/10/2022-19:21:31] [V] [TRT] Gather_1219 [Gather] outputs: [1696 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1220 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1693
[06/10/2022-19:21:31] [V] [TRT] Shape_1220 [Shape] inputs: [1693 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1220 for ONNX node: Shape_1220
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1697 for ONNX tensor: 1697
[06/10/2022-19:21:31] [V] [TRT] Shape_1220 [Shape] outputs: [1697 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1222 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1697
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1698
[06/10/2022-19:21:31] [V] [TRT] Gather_1222 [Gather] inputs: [1697 -> (3)[INT32]], [1698 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1698 for ONNX node: 1698
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1222 for ONNX node: Gather_1222
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1699 for ONNX tensor: 1699
[06/10/2022-19:21:31] [V] [TRT] Gather_1222 [Gather] outputs: [1699 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1223 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1693
[06/10/2022-19:21:31] [V] [TRT] Shape_1223 [Shape] inputs: [1693 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1223 for ONNX node: Shape_1223
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1700 for ONNX tensor: 1700
[06/10/2022-19:21:31] [V] [TRT] Shape_1223 [Shape] outputs: [1700 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1225 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1700
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1701
[06/10/2022-19:21:31] [V] [TRT] Gather_1225 [Gather] inputs: [1700 -> (3)[INT32]], [1701 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1701 for ONNX node: 1701
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1225 for ONNX node: Gather_1225
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1702 for ONNX tensor: 1702
[06/10/2022-19:21:31] [V] [TRT] Gather_1225 [Gather] outputs: [1702 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1226 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1693
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3141
[06/10/2022-19:21:31] [V] [TRT] MatMul_1226 [MatMul] inputs: [1693 -> (-1, 4096, 320)[FLOAT]], [3141 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3141 for ONNX node: 3141
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1226 for ONNX node: MatMul_1226
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1704 for ONNX tensor: 1704
[06/10/2022-19:21:31] [V] [TRT] MatMul_1226 [MatMul] outputs: [1704 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1227 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1704
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.attn.q.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1227 [Add] inputs: [1704 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.1.attn.q.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.1.attn.q.bias for ONNX node: backbone.block3.1.attn.q.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1227 for ONNX node: Add_1227
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1705 for ONNX tensor: 1705
[06/10/2022-19:21:31] [V] [TRT] Add_1227 [Add] outputs: [1705 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1229 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1702
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1706
[06/10/2022-19:21:31] [V] [TRT] Div_1229 [Div] inputs: [1702 -> ()[INT32]], [1706 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1706 for ONNX node: 1706
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1229 for ONNX node: Div_1229
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1707 for ONNX tensor: 1707
[06/10/2022-19:21:31] [V] [TRT] Div_1229 [Div] outputs: [1707 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1230 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1707
[06/10/2022-19:21:31] [V] [TRT] Cast_1230 [Cast] inputs: [1707 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1230 for ONNX node: Cast_1230
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1708 for ONNX tensor: 1708
[06/10/2022-19:21:31] [V] [TRT] Cast_1230 [Cast] outputs: [1708 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1231 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1708
[06/10/2022-19:21:31] [V] [TRT] Cast_1231 [Cast] inputs: [1708 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1231 for ONNX node: Cast_1231
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1709 for ONNX tensor: 1709
[06/10/2022-19:21:31] [V] [TRT] Cast_1231 [Cast] outputs: [1709 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1232 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1696
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1232 [Unsqueeze] inputs: [1696 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1232 for ONNX node: Unsqueeze_1232
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1711 for ONNX tensor: 1711
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1232 [Unsqueeze] outputs: [1711 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1233 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1699
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1233 [Unsqueeze] inputs: [1699 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1233 for ONNX node: Unsqueeze_1233
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1712 for ONNX tensor: 1712
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1233 [Unsqueeze] outputs: [1712 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1234 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1709
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1234 [Unsqueeze] inputs: [1709 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1234 for ONNX node: Unsqueeze_1234
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1714 for ONNX tensor: 1714
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1234 [Unsqueeze] outputs: [1714 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1235 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1711
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1712
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3142
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1714
[06/10/2022-19:21:31] [V] [TRT] Concat_1235 [Concat] inputs: [1711 -> (1)[INT32]], [1712 -> (1)[INT32]], [3142 -> (1)[INT32]], [1714 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3142 for ONNX node: 3142
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1235 for ONNX node: Concat_1235
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1715 for ONNX tensor: 1715
[06/10/2022-19:21:31] [V] [TRT] Concat_1235 [Concat] outputs: [1715 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1236 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1705
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1715
[06/10/2022-19:21:31] [V] [TRT] Reshape_1236 [Reshape] inputs: [1705 -> (-1, 4096, 320)[FLOAT]], [1715 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1236 for ONNX node: Reshape_1236
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1716 for ONNX tensor: 1716
[06/10/2022-19:21:31] [V] [TRT] Reshape_1236 [Reshape] outputs: [1716 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1237 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1716
[06/10/2022-19:21:31] [V] [TRT] Transpose_1237 [Transpose] inputs: [1716 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1237 for ONNX node: Transpose_1237
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1717 for ONNX tensor: 1717
[06/10/2022-19:21:31] [V] [TRT] Transpose_1237 [Transpose] outputs: [1717 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1238 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1693
[06/10/2022-19:21:31] [V] [TRT] Transpose_1238 [Transpose] inputs: [1693 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1238 for ONNX node: Transpose_1238
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1718 for ONNX tensor: 1718
[06/10/2022-19:21:31] [V] [TRT] Transpose_1238 [Transpose] outputs: [1718 -> (-1, 320, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1239 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1696
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1239 [Unsqueeze] inputs: [1696 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1239 for ONNX node: Unsqueeze_1239
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1719 for ONNX tensor: 1719
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1239 [Unsqueeze] outputs: [1719 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1240 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1702
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1240 [Unsqueeze] inputs: [1702 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1240 for ONNX node: Unsqueeze_1240
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1720 for ONNX tensor: 1720
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1240 [Unsqueeze] outputs: [1720 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1241 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1241 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1241 for ONNX node: Unsqueeze_1241
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1721 for ONNX tensor: 1721
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1241 [Unsqueeze] outputs: [1721 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1242 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1242 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1242 for ONNX node: Unsqueeze_1242
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1722 for ONNX tensor: 1722
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1242 [Unsqueeze] outputs: [1722 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1243 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1719
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1720
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1721
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1722
[06/10/2022-19:21:31] [V] [TRT] Concat_1243 [Concat] inputs: [1719 -> (1)[INT32]], [1720 -> (1)[INT32]], [1721 -> (1)[INT32]], [1722 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1243 for ONNX node: Concat_1243
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1723 for ONNX tensor: 1723
[06/10/2022-19:21:31] [V] [TRT] Concat_1243 [Concat] outputs: [1723 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1244 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1718
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1723
[06/10/2022-19:21:31] [V] [TRT] Reshape_1244 [Reshape] inputs: [1718 -> (-1, 320, 4096)[FLOAT]], [1723 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1244 for ONNX node: Reshape_1244
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1724 for ONNX tensor: 1724
[06/10/2022-19:21:31] [V] [TRT] Reshape_1244 [Reshape] outputs: [1724 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Conv_1245 [Conv]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1724
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.attn.sr.weight
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.attn.sr.bias
[06/10/2022-19:21:31] [V] [TRT] Conv_1245 [Conv] inputs: [1724 -> (-1, 320, 64, 64)[FLOAT]], [backbone.block3.1.attn.sr.weight -> (320, 320, 2, 2)[FLOAT]], [backbone.block3.1.attn.sr.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Convolution input dimensions: (-1, 320, 64, 64)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Conv_1245 for ONNX node: Conv_1245
[06/10/2022-19:21:31] [V] [TRT] Using kernel: (2, 2), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 320
[06/10/2022-19:21:31] [V] [TRT] Convolution output dimensions: (-1, 320, 32, 32)
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1725 for ONNX tensor: 1725
[06/10/2022-19:21:31] [V] [TRT] Conv_1245 [Conv] outputs: [1725 -> (-1, 320, 32, 32)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1246 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1696
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1246 [Unsqueeze] inputs: [1696 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1246 for ONNX node: Unsqueeze_1246
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1727 for ONNX tensor: 1727
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1246 [Unsqueeze] outputs: [1727 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1247 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1702
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1247 [Unsqueeze] inputs: [1702 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1247 for ONNX node: Unsqueeze_1247
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1728 for ONNX tensor: 1728
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1247 [Unsqueeze] outputs: [1728 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1248 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1727
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1728
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3143
[06/10/2022-19:21:31] [V] [TRT] Concat_1248 [Concat] inputs: [1727 -> (1)[INT32]], [1728 -> (1)[INT32]], [3143 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3143 for ONNX node: 3143
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1248 for ONNX node: Concat_1248
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1730 for ONNX tensor: 1730
[06/10/2022-19:21:31] [V] [TRT] Concat_1248 [Concat] outputs: [1730 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1249 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1725
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1730
[06/10/2022-19:21:31] [V] [TRT] Reshape_1249 [Reshape] inputs: [1725 -> (-1, 320, 32, 32)[FLOAT]], [1730 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1249 for ONNX node: Reshape_1249
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1731 for ONNX tensor: 1731
[06/10/2022-19:21:31] [V] [TRT] Reshape_1249 [Reshape] outputs: [1731 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1250 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1731
[06/10/2022-19:21:31] [V] [TRT] Transpose_1250 [Transpose] inputs: [1731 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1250 for ONNX node: Transpose_1250
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1732 for ONNX tensor: 1732
[06/10/2022-19:21:31] [V] [TRT] Transpose_1250 [Transpose] outputs: [1732 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1251 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1732
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1251 [ReduceMean] inputs: [1732 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1251 for ONNX node: ReduceMean_1251
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1733 for ONNX tensor: 1733
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1251 [ReduceMean] outputs: [1733 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sub_1252 [Sub]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1732
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1733
[06/10/2022-19:21:31] [V] [TRT] Sub_1252 [Sub] inputs: [1732 -> (-1, 1024, 320)[FLOAT]], [1733 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sub_1252 for ONNX node: Sub_1252
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1734 for ONNX tensor: 1734
[06/10/2022-19:21:31] [V] [TRT] Sub_1252 [Sub] outputs: [1734 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Pow_1254 [Pow]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1734
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1735
[06/10/2022-19:21:31] [V] [TRT] Pow_1254 [Pow] inputs: [1734 -> (-1, 1024, 320)[FLOAT]], [1735 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1735 for ONNX node: 1735
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Pow_1254 for ONNX node: Pow_1254
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1736 for ONNX tensor: 1736
[06/10/2022-19:21:31] [V] [TRT] Pow_1254 [Pow] outputs: [1736 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1255 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1736
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1255 [ReduceMean] inputs: [1736 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1255 for ONNX node: ReduceMean_1255
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1737 for ONNX tensor: 1737
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1255 [ReduceMean] outputs: [1737 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1257 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1737
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1738
[06/10/2022-19:21:31] [V] [TRT] Add_1257 [Add] inputs: [1737 -> (-1, 1024, 1)[FLOAT]], [1738 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1738 for ONNX node: 1738
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1257 for ONNX node: Add_1257
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1739 for ONNX tensor: 1739
[06/10/2022-19:21:31] [V] [TRT] Add_1257 [Add] outputs: [1739 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sqrt_1258 [Sqrt]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1739
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1258 [Sqrt] inputs: [1739 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sqrt_1258 for ONNX node: Sqrt_1258
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1740 for ONNX tensor: 1740
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1258 [Sqrt] outputs: [1740 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1259 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1734
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1740
[06/10/2022-19:21:31] [V] [TRT] Div_1259 [Div] inputs: [1734 -> (-1, 1024, 320)[FLOAT]], [1740 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1259 for ONNX node: Div_1259
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1741 for ONNX tensor: 1741
[06/10/2022-19:21:31] [V] [TRT] Div_1259 [Div] outputs: [1741 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1260 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1741
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.attn.norm.weight
[06/10/2022-19:21:31] [V] [TRT] Mul_1260 [Mul] inputs: [1741 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.1.attn.norm.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.1.attn.norm.weight for ONNX node: backbone.block3.1.attn.norm.weight
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1260 for ONNX node: Mul_1260
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1742 for ONNX tensor: 1742
[06/10/2022-19:21:31] [V] [TRT] Mul_1260 [Mul] outputs: [1742 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1261 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1742
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.attn.norm.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1261 [Add] inputs: [1742 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.1.attn.norm.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.1.attn.norm.bias for ONNX node: backbone.block3.1.attn.norm.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1261 for ONNX node: Add_1261
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1743 for ONNX tensor: 1743
[06/10/2022-19:21:31] [V] [TRT] Add_1261 [Add] outputs: [1743 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1262 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1743
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3144
[06/10/2022-19:21:31] [V] [TRT] MatMul_1262 [MatMul] inputs: [1743 -> (-1, 1024, 320)[FLOAT]], [3144 -> (320, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3144 for ONNX node: 3144
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1262 for ONNX node: MatMul_1262
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1745 for ONNX tensor: 1745
[06/10/2022-19:21:31] [V] [TRT] MatMul_1262 [MatMul] outputs: [1745 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1263 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1745
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.attn.kv.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1263 [Add] inputs: [1745 -> (-1, 1024, 640)[FLOAT]], [backbone.block3.1.attn.kv.bias -> (640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.1.attn.kv.bias for ONNX node: backbone.block3.1.attn.kv.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1263 for ONNX node: Add_1263
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1746 for ONNX tensor: 1746
[06/10/2022-19:21:31] [V] [TRT] Add_1263 [Add] outputs: [1746 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1265 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1702
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1747
[06/10/2022-19:21:31] [V] [TRT] Div_1265 [Div] inputs: [1702 -> ()[INT32]], [1747 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1747 for ONNX node: 1747
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1265 for ONNX node: Div_1265
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1748 for ONNX tensor: 1748
[06/10/2022-19:21:31] [V] [TRT] Div_1265 [Div] outputs: [1748 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1266 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1748
[06/10/2022-19:21:31] [V] [TRT] Cast_1266 [Cast] inputs: [1748 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1266 for ONNX node: Cast_1266
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1749 for ONNX tensor: 1749
[06/10/2022-19:21:31] [V] [TRT] Cast_1266 [Cast] outputs: [1749 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1267 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1749
[06/10/2022-19:21:31] [V] [TRT] Cast_1267 [Cast] inputs: [1749 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1267 for ONNX node: Cast_1267
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1750 for ONNX tensor: 1750
[06/10/2022-19:21:31] [V] [TRT] Cast_1267 [Cast] outputs: [1750 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1268 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1696
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1268 [Unsqueeze] inputs: [1696 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1268 for ONNX node: Unsqueeze_1268
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1754 for ONNX tensor: 1754
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1268 [Unsqueeze] outputs: [1754 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1269 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1750
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1269 [Unsqueeze] inputs: [1750 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1269 for ONNX node: Unsqueeze_1269
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1758 for ONNX tensor: 1758
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1269 [Unsqueeze] outputs: [1758 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1270 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1754
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3145
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3146
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3147
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1758
[06/10/2022-19:21:31] [V] [TRT] Concat_1270 [Concat] inputs: [1754 -> (1)[INT32]], [3145 -> (1)[INT32]], [3146 -> (1)[INT32]], [3147 -> (1)[INT32]], [1758 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3145 for ONNX node: 3145
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3146 for ONNX node: 3146
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3147 for ONNX node: 3147
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1270 for ONNX node: Concat_1270
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1759 for ONNX tensor: 1759
[06/10/2022-19:21:31] [V] [TRT] Concat_1270 [Concat] outputs: [1759 -> (5)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1271 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1746
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1759
[06/10/2022-19:21:31] [V] [TRT] Reshape_1271 [Reshape] inputs: [1746 -> (-1, 1024, 640)[FLOAT]], [1759 -> (5)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1271 for ONNX node: Reshape_1271
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1760 for ONNX tensor: 1760
[06/10/2022-19:21:31] [V] [TRT] Reshape_1271 [Reshape] outputs: [1760 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1272 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1760
[06/10/2022-19:21:31] [V] [TRT] Transpose_1272 [Transpose] inputs: [1760 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1272 for ONNX node: Transpose_1272
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1761 for ONNX tensor: 1761
[06/10/2022-19:21:31] [V] [TRT] Transpose_1272 [Transpose] outputs: [1761 -> (2, -1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1274 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1761
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1762
[06/10/2022-19:21:31] [V] [TRT] Gather_1274 [Gather] inputs: [1761 -> (2, -1, 5, 1024, 64)[FLOAT]], [1762 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1762 for ONNX node: 1762
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1274 for ONNX node: Gather_1274
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1763 for ONNX tensor: 1763
[06/10/2022-19:21:31] [V] [TRT] Gather_1274 [Gather] outputs: [1763 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1276 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1761
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1764
[06/10/2022-19:21:31] [V] [TRT] Gather_1276 [Gather] inputs: [1761 -> (2, -1, 5, 1024, 64)[FLOAT]], [1764 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1764 for ONNX node: 1764
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1276 for ONNX node: Gather_1276
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1765 for ONNX tensor: 1765
[06/10/2022-19:21:31] [V] [TRT] Gather_1276 [Gather] outputs: [1765 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1277 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1763
[06/10/2022-19:21:31] [V] [TRT] Transpose_1277 [Transpose] inputs: [1763 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1277 for ONNX node: Transpose_1277
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1766 for ONNX tensor: 1766
[06/10/2022-19:21:31] [V] [TRT] Transpose_1277 [Transpose] outputs: [1766 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1278 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1717
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1766
[06/10/2022-19:21:31] [V] [TRT] MatMul_1278 [MatMul] inputs: [1717 -> (-1, 5, 4096, 64)[FLOAT]], [1766 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1278 for ONNX node: MatMul_1278
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1767 for ONNX tensor: 1767
[06/10/2022-19:21:31] [V] [TRT] MatMul_1278 [MatMul] outputs: [1767 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1280 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1767
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1768
[06/10/2022-19:21:31] [V] [TRT] Mul_1280 [Mul] inputs: [1767 -> (-1, 5, 4096, 1024)[FLOAT]], [1768 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1768 for ONNX node: 1768
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1280 for ONNX node: Mul_1280
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1769 for ONNX tensor: 1769
[06/10/2022-19:21:31] [V] [TRT] Mul_1280 [Mul] outputs: [1769 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Softmax_1281 [Softmax]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1769
[06/10/2022-19:21:31] [V] [TRT] Softmax_1281 [Softmax] inputs: [1769 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Softmax_1281 for ONNX node: Softmax_1281
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1770 for ONNX tensor: 1770
[06/10/2022-19:21:31] [V] [TRT] Softmax_1281 [Softmax] outputs: [1770 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1282 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1770
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1765
[06/10/2022-19:21:31] [V] [TRT] MatMul_1282 [MatMul] inputs: [1770 -> (-1, 5, 4096, 1024)[FLOAT]], [1765 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1282 for ONNX node: MatMul_1282
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1771 for ONNX tensor: 1771
[06/10/2022-19:21:31] [V] [TRT] MatMul_1282 [MatMul] outputs: [1771 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1283 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1771
[06/10/2022-19:21:31] [V] [TRT] Transpose_1283 [Transpose] inputs: [1771 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1283 for ONNX node: Transpose_1283
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1772 for ONNX tensor: 1772
[06/10/2022-19:21:31] [V] [TRT] Transpose_1283 [Transpose] outputs: [1772 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1284 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1696
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1284 [Unsqueeze] inputs: [1696 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1284 for ONNX node: Unsqueeze_1284
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1773 for ONNX tensor: 1773
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1284 [Unsqueeze] outputs: [1773 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1285 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1699
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1285 [Unsqueeze] inputs: [1699 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1285 for ONNX node: Unsqueeze_1285
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1774 for ONNX tensor: 1774
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1285 [Unsqueeze] outputs: [1774 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1286 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1702
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1286 [Unsqueeze] inputs: [1702 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1286 for ONNX node: Unsqueeze_1286
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1775 for ONNX tensor: 1775
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1286 [Unsqueeze] outputs: [1775 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1287 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1773
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1774
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1775
[06/10/2022-19:21:31] [V] [TRT] Concat_1287 [Concat] inputs: [1773 -> (1)[INT32]], [1774 -> (1)[INT32]], [1775 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1287 for ONNX node: Concat_1287
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1776 for ONNX tensor: 1776
[06/10/2022-19:21:31] [V] [TRT] Concat_1287 [Concat] outputs: [1776 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1288 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1772
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1776
[06/10/2022-19:21:31] [V] [TRT] Reshape_1288 [Reshape] inputs: [1772 -> (-1, 4096, 5, 64)[FLOAT]], [1776 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1288 for ONNX node: Reshape_1288
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1777 for ONNX tensor: 1777
[06/10/2022-19:21:31] [V] [TRT] Reshape_1288 [Reshape] outputs: [1777 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1289 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1777
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3148
[06/10/2022-19:21:31] [V] [TRT] MatMul_1289 [MatMul] inputs: [1777 -> (-1, 4096, 320)[FLOAT]], [3148 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3148 for ONNX node: 3148
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1289 for ONNX node: MatMul_1289
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1779 for ONNX tensor: 1779
[06/10/2022-19:21:31] [V] [TRT] MatMul_1289 [MatMul] outputs: [1779 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1290 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1779
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.attn.proj.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1290 [Add] inputs: [1779 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.1.attn.proj.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.1.attn.proj.bias for ONNX node: backbone.block3.1.attn.proj.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1290 for ONNX node: Add_1290
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1780 for ONNX tensor: 1780
[06/10/2022-19:21:31] [V] [TRT] Add_1290 [Add] outputs: [1780 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1291 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1682
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1780
[06/10/2022-19:21:31] [V] [TRT] Add_1291 [Add] inputs: [1682 -> (-1, 4096, 320)[FLOAT]], [1780 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1291 for ONNX node: Add_1291
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1781 for ONNX tensor: 1781
[06/10/2022-19:21:31] [V] [TRT] Add_1291 [Add] outputs: [1781 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1292 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1781
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1292 [ReduceMean] inputs: [1781 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1292 for ONNX node: ReduceMean_1292
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1782 for ONNX tensor: 1782
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1292 [ReduceMean] outputs: [1782 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sub_1293 [Sub]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1781
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1782
[06/10/2022-19:21:31] [V] [TRT] Sub_1293 [Sub] inputs: [1781 -> (-1, 4096, 320)[FLOAT]], [1782 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sub_1293 for ONNX node: Sub_1293
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1783 for ONNX tensor: 1783
[06/10/2022-19:21:31] [V] [TRT] Sub_1293 [Sub] outputs: [1783 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Pow_1295 [Pow]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1783
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1784
[06/10/2022-19:21:31] [V] [TRT] Pow_1295 [Pow] inputs: [1783 -> (-1, 4096, 320)[FLOAT]], [1784 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1784 for ONNX node: 1784
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Pow_1295 for ONNX node: Pow_1295
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1785 for ONNX tensor: 1785
[06/10/2022-19:21:31] [V] [TRT] Pow_1295 [Pow] outputs: [1785 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1296 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1785
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1296 [ReduceMean] inputs: [1785 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1296 for ONNX node: ReduceMean_1296
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1786 for ONNX tensor: 1786
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1296 [ReduceMean] outputs: [1786 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1298 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1786
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1787
[06/10/2022-19:21:31] [V] [TRT] Add_1298 [Add] inputs: [1786 -> (-1, 4096, 1)[FLOAT]], [1787 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1787 for ONNX node: 1787
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1298 for ONNX node: Add_1298
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1788 for ONNX tensor: 1788
[06/10/2022-19:21:31] [V] [TRT] Add_1298 [Add] outputs: [1788 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sqrt_1299 [Sqrt]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1788
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1299 [Sqrt] inputs: [1788 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sqrt_1299 for ONNX node: Sqrt_1299
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1789 for ONNX tensor: 1789
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1299 [Sqrt] outputs: [1789 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1300 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1783
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1789
[06/10/2022-19:21:31] [V] [TRT] Div_1300 [Div] inputs: [1783 -> (-1, 4096, 320)[FLOAT]], [1789 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1300 for ONNX node: Div_1300
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1790 for ONNX tensor: 1790
[06/10/2022-19:21:31] [V] [TRT] Div_1300 [Div] outputs: [1790 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1301 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1790
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.norm2.weight
[06/10/2022-19:21:31] [V] [TRT] Mul_1301 [Mul] inputs: [1790 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.1.norm2.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.1.norm2.weight for ONNX node: backbone.block3.1.norm2.weight
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1301 for ONNX node: Mul_1301
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1791 for ONNX tensor: 1791
[06/10/2022-19:21:31] [V] [TRT] Mul_1301 [Mul] outputs: [1791 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1302 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1791
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.norm2.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1302 [Add] inputs: [1791 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.1.norm2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.1.norm2.bias for ONNX node: backbone.block3.1.norm2.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1302 for ONNX node: Add_1302
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1792 for ONNX tensor: 1792
[06/10/2022-19:21:31] [V] [TRT] Add_1302 [Add] outputs: [1792 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1303 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1792
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3149
[06/10/2022-19:21:31] [V] [TRT] MatMul_1303 [MatMul] inputs: [1792 -> (-1, 4096, 320)[FLOAT]], [3149 -> (320, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3149 for ONNX node: 3149
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1303 for ONNX node: MatMul_1303
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1794 for ONNX tensor: 1794
[06/10/2022-19:21:31] [V] [TRT] MatMul_1303 [MatMul] outputs: [1794 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1304 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1794
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.mlp.fc1.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1304 [Add] inputs: [1794 -> (-1, 4096, 1280)[FLOAT]], [backbone.block3.1.mlp.fc1.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.1.mlp.fc1.bias for ONNX node: backbone.block3.1.mlp.fc1.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1304 for ONNX node: Add_1304
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1795 for ONNX tensor: 1795
[06/10/2022-19:21:31] [V] [TRT] Add_1304 [Add] outputs: [1795 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1305 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1795
[06/10/2022-19:21:31] [V] [TRT] Shape_1305 [Shape] inputs: [1795 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1305 for ONNX node: Shape_1305
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1796 for ONNX tensor: 1796
[06/10/2022-19:21:31] [V] [TRT] Shape_1305 [Shape] outputs: [1796 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1307 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1796
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1797
[06/10/2022-19:21:31] [V] [TRT] Gather_1307 [Gather] inputs: [1796 -> (3)[INT32]], [1797 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1797 for ONNX node: 1797
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1307 for ONNX node: Gather_1307
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1798 for ONNX tensor: 1798
[06/10/2022-19:21:31] [V] [TRT] Gather_1307 [Gather] outputs: [1798 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1308 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1795
[06/10/2022-19:21:31] [V] [TRT] Shape_1308 [Shape] inputs: [1795 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1308 for ONNX node: Shape_1308
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1799 for ONNX tensor: 1799
[06/10/2022-19:21:31] [V] [TRT] Shape_1308 [Shape] outputs: [1799 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1310 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1799
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1800
[06/10/2022-19:21:31] [V] [TRT] Gather_1310 [Gather] inputs: [1799 -> (3)[INT32]], [1800 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1800 for ONNX node: 1800
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1310 for ONNX node: Gather_1310
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1801 for ONNX tensor: 1801
[06/10/2022-19:21:31] [V] [TRT] Gather_1310 [Gather] outputs: [1801 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1311 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1795
[06/10/2022-19:21:31] [V] [TRT] Transpose_1311 [Transpose] inputs: [1795 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1311 for ONNX node: Transpose_1311
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1802 for ONNX tensor: 1802
[06/10/2022-19:21:31] [V] [TRT] Transpose_1311 [Transpose] outputs: [1802 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1312 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1798
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1312 [Unsqueeze] inputs: [1798 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1312 for ONNX node: Unsqueeze_1312
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1803 for ONNX tensor: 1803
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1312 [Unsqueeze] outputs: [1803 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1313 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1801
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1313 [Unsqueeze] inputs: [1801 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1313 for ONNX node: Unsqueeze_1313
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1804 for ONNX tensor: 1804
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1313 [Unsqueeze] outputs: [1804 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1314 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1314 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1314 for ONNX node: Unsqueeze_1314
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1805 for ONNX tensor: 1805
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1314 [Unsqueeze] outputs: [1805 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1315 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1315 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1315 for ONNX node: Unsqueeze_1315
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1806 for ONNX tensor: 1806
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1315 [Unsqueeze] outputs: [1806 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1316 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1803
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1804
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1805
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1806
[06/10/2022-19:21:31] [V] [TRT] Concat_1316 [Concat] inputs: [1803 -> (1)[INT32]], [1804 -> (1)[INT32]], [1805 -> (1)[INT32]], [1806 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1316 for ONNX node: Concat_1316
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1807 for ONNX tensor: 1807
[06/10/2022-19:21:31] [V] [TRT] Concat_1316 [Concat] outputs: [1807 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1317 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1802
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1807
[06/10/2022-19:21:31] [V] [TRT] Reshape_1317 [Reshape] inputs: [1802 -> (-1, 1280, 4096)[FLOAT]], [1807 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1317 for ONNX node: Reshape_1317
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1808 for ONNX tensor: 1808
[06/10/2022-19:21:31] [V] [TRT] Reshape_1317 [Reshape] outputs: [1808 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Conv_1318 [Conv]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1808
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:31] [V] [TRT] Conv_1318 [Conv] inputs: [1808 -> (-1, 1280, 64, 64)[FLOAT]], [backbone.block3.1.mlp.dwconv.dwconv.weight -> (1280, 1, 3, 3)[FLOAT]], [backbone.block3.1.mlp.dwconv.dwconv.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Convolution input dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Conv_1318 for ONNX node: Conv_1318
[06/10/2022-19:21:31] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1280
[06/10/2022-19:21:31] [V] [TRT] Convolution output dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1809 for ONNX tensor: 1809
[06/10/2022-19:21:31] [V] [TRT] Conv_1318 [Conv] outputs: [1809 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1319 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1809
[06/10/2022-19:21:31] [V] [TRT] Shape_1319 [Shape] inputs: [1809 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1319 for ONNX node: Shape_1319
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1810 for ONNX tensor: 1810
[06/10/2022-19:21:31] [V] [TRT] Shape_1319 [Shape] outputs: [1810 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Slice_1323 [Slice]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1810
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1812
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1813
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1811
[06/10/2022-19:21:31] [V] [TRT] Slice_1323 [Slice] inputs: [1810 -> (4)[INT32]], [1812 -> (1)[INT32]], [1813 -> (1)[INT32]], [1811 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Slice_1323 for ONNX node: Slice_1323
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1814 for ONNX tensor: 1814
[06/10/2022-19:21:31] [V] [TRT] Slice_1323 [Slice] outputs: [1814 -> (2)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1325 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1814
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1815
[06/10/2022-19:21:31] [V] [TRT] Concat_1325 [Concat] inputs: [1814 -> (2)[INT32]], [1815 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1815 for ONNX node: 1815
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1325 for ONNX node: Concat_1325
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1816 for ONNX tensor: 1816
[06/10/2022-19:21:31] [V] [TRT] Concat_1325 [Concat] outputs: [1816 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1326 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1809
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1816
[06/10/2022-19:21:31] [V] [TRT] Reshape_1326 [Reshape] inputs: [1809 -> (-1, 1280, 64, 64)[FLOAT]], [1816 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1326 for ONNX node: Reshape_1326
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1817 for ONNX tensor: 1817
[06/10/2022-19:21:31] [V] [TRT] Reshape_1326 [Reshape] outputs: [1817 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1327 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1817
[06/10/2022-19:21:31] [V] [TRT] Transpose_1327 [Transpose] inputs: [1817 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1327 for ONNX node: Transpose_1327
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1818 for ONNX tensor: 1818
[06/10/2022-19:21:31] [V] [TRT] Transpose_1327 [Transpose] outputs: [1818 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1329 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1818
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1819
[06/10/2022-19:21:31] [V] [TRT] Div_1329 [Div] inputs: [1818 -> (-1, 4096, 1280)[FLOAT]], [1819 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1819 for ONNX node: 1819
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1329 for ONNX node: Div_1329
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1820 for ONNX tensor: 1820
[06/10/2022-19:21:31] [V] [TRT] Div_1329 [Div] outputs: [1820 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Erf_1330 [Erf]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1820
[06/10/2022-19:21:31] [V] [TRT] Erf_1330 [Erf] inputs: [1820 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Erf_1330 for ONNX node: Erf_1330
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1821 for ONNX tensor: 1821
[06/10/2022-19:21:31] [V] [TRT] Erf_1330 [Erf] outputs: [1821 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1332 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1821
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1822
[06/10/2022-19:21:31] [V] [TRT] Add_1332 [Add] inputs: [1821 -> (-1, 4096, 1280)[FLOAT]], [1822 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1822 for ONNX node: 1822
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1332 for ONNX node: Add_1332
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1823 for ONNX tensor: 1823
[06/10/2022-19:21:31] [V] [TRT] Add_1332 [Add] outputs: [1823 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1333 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1818
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1823
[06/10/2022-19:21:31] [V] [TRT] Mul_1333 [Mul] inputs: [1818 -> (-1, 4096, 1280)[FLOAT]], [1823 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1333 for ONNX node: Mul_1333
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1824 for ONNX tensor: 1824
[06/10/2022-19:21:31] [V] [TRT] Mul_1333 [Mul] outputs: [1824 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1335 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1824
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1825
[06/10/2022-19:21:31] [V] [TRT] Mul_1335 [Mul] inputs: [1824 -> (-1, 4096, 1280)[FLOAT]], [1825 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1825 for ONNX node: 1825
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1335 for ONNX node: Mul_1335
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1826 for ONNX tensor: 1826
[06/10/2022-19:21:31] [V] [TRT] Mul_1335 [Mul] outputs: [1826 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1336 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1826
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3150
[06/10/2022-19:21:31] [V] [TRT] MatMul_1336 [MatMul] inputs: [1826 -> (-1, 4096, 1280)[FLOAT]], [3150 -> (1280, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3150 for ONNX node: 3150
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1336 for ONNX node: MatMul_1336
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1828 for ONNX tensor: 1828
[06/10/2022-19:21:31] [V] [TRT] MatMul_1336 [MatMul] outputs: [1828 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1337 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1828
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.1.mlp.fc2.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1337 [Add] inputs: [1828 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.1.mlp.fc2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.1.mlp.fc2.bias for ONNX node: backbone.block3.1.mlp.fc2.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1337 for ONNX node: Add_1337
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1829 for ONNX tensor: 1829
[06/10/2022-19:21:31] [V] [TRT] Add_1337 [Add] outputs: [1829 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1338 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1781
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1829
[06/10/2022-19:21:31] [V] [TRT] Add_1338 [Add] inputs: [1781 -> (-1, 4096, 320)[FLOAT]], [1829 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1338 for ONNX node: Add_1338
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1830 for ONNX tensor: 1830
[06/10/2022-19:21:31] [V] [TRT] Add_1338 [Add] outputs: [1830 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1339 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1830
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1339 [ReduceMean] inputs: [1830 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1339 for ONNX node: ReduceMean_1339
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1831 for ONNX tensor: 1831
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1339 [ReduceMean] outputs: [1831 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sub_1340 [Sub]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1830
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1831
[06/10/2022-19:21:31] [V] [TRT] Sub_1340 [Sub] inputs: [1830 -> (-1, 4096, 320)[FLOAT]], [1831 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sub_1340 for ONNX node: Sub_1340
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1832 for ONNX tensor: 1832
[06/10/2022-19:21:31] [V] [TRT] Sub_1340 [Sub] outputs: [1832 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Pow_1342 [Pow]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1832
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1833
[06/10/2022-19:21:31] [V] [TRT] Pow_1342 [Pow] inputs: [1832 -> (-1, 4096, 320)[FLOAT]], [1833 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1833 for ONNX node: 1833
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Pow_1342 for ONNX node: Pow_1342
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1834 for ONNX tensor: 1834
[06/10/2022-19:21:31] [V] [TRT] Pow_1342 [Pow] outputs: [1834 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1343 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1834
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1343 [ReduceMean] inputs: [1834 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1343 for ONNX node: ReduceMean_1343
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1835 for ONNX tensor: 1835
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1343 [ReduceMean] outputs: [1835 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1345 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1835
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1836
[06/10/2022-19:21:31] [V] [TRT] Add_1345 [Add] inputs: [1835 -> (-1, 4096, 1)[FLOAT]], [1836 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1836 for ONNX node: 1836
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1345 for ONNX node: Add_1345
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1837 for ONNX tensor: 1837
[06/10/2022-19:21:31] [V] [TRT] Add_1345 [Add] outputs: [1837 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sqrt_1346 [Sqrt]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1837
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1346 [Sqrt] inputs: [1837 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sqrt_1346 for ONNX node: Sqrt_1346
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1838 for ONNX tensor: 1838
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1346 [Sqrt] outputs: [1838 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1347 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1832
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1838
[06/10/2022-19:21:31] [V] [TRT] Div_1347 [Div] inputs: [1832 -> (-1, 4096, 320)[FLOAT]], [1838 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1347 for ONNX node: Div_1347
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1839 for ONNX tensor: 1839
[06/10/2022-19:21:31] [V] [TRT] Div_1347 [Div] outputs: [1839 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1348 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1839
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.norm1.weight
[06/10/2022-19:21:31] [V] [TRT] Mul_1348 [Mul] inputs: [1839 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.2.norm1.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.2.norm1.weight for ONNX node: backbone.block3.2.norm1.weight
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1348 for ONNX node: Mul_1348
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1840 for ONNX tensor: 1840
[06/10/2022-19:21:31] [V] [TRT] Mul_1348 [Mul] outputs: [1840 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1349 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1840
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.norm1.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1349 [Add] inputs: [1840 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.2.norm1.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.2.norm1.bias for ONNX node: backbone.block3.2.norm1.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1349 for ONNX node: Add_1349
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1841 for ONNX tensor: 1841
[06/10/2022-19:21:31] [V] [TRT] Add_1349 [Add] outputs: [1841 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1350 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1841
[06/10/2022-19:21:31] [V] [TRT] Shape_1350 [Shape] inputs: [1841 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1350 for ONNX node: Shape_1350
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1842 for ONNX tensor: 1842
[06/10/2022-19:21:31] [V] [TRT] Shape_1350 [Shape] outputs: [1842 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1352 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1842
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1843
[06/10/2022-19:21:31] [V] [TRT] Gather_1352 [Gather] inputs: [1842 -> (3)[INT32]], [1843 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1843 for ONNX node: 1843
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1352 for ONNX node: Gather_1352
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1844 for ONNX tensor: 1844
[06/10/2022-19:21:31] [V] [TRT] Gather_1352 [Gather] outputs: [1844 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1353 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1841
[06/10/2022-19:21:31] [V] [TRT] Shape_1353 [Shape] inputs: [1841 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1353 for ONNX node: Shape_1353
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1845 for ONNX tensor: 1845
[06/10/2022-19:21:31] [V] [TRT] Shape_1353 [Shape] outputs: [1845 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1355 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1845
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1846
[06/10/2022-19:21:31] [V] [TRT] Gather_1355 [Gather] inputs: [1845 -> (3)[INT32]], [1846 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1846 for ONNX node: 1846
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1355 for ONNX node: Gather_1355
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1847 for ONNX tensor: 1847
[06/10/2022-19:21:31] [V] [TRT] Gather_1355 [Gather] outputs: [1847 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1356 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1841
[06/10/2022-19:21:31] [V] [TRT] Shape_1356 [Shape] inputs: [1841 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1356 for ONNX node: Shape_1356
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1848 for ONNX tensor: 1848
[06/10/2022-19:21:31] [V] [TRT] Shape_1356 [Shape] outputs: [1848 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1358 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1848
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1849
[06/10/2022-19:21:31] [V] [TRT] Gather_1358 [Gather] inputs: [1848 -> (3)[INT32]], [1849 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1849 for ONNX node: 1849
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1358 for ONNX node: Gather_1358
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1850 for ONNX tensor: 1850
[06/10/2022-19:21:31] [V] [TRT] Gather_1358 [Gather] outputs: [1850 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1359 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1841
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3151
[06/10/2022-19:21:31] [V] [TRT] MatMul_1359 [MatMul] inputs: [1841 -> (-1, 4096, 320)[FLOAT]], [3151 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3151 for ONNX node: 3151
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1359 for ONNX node: MatMul_1359
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1852 for ONNX tensor: 1852
[06/10/2022-19:21:31] [V] [TRT] MatMul_1359 [MatMul] outputs: [1852 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1360 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1852
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.attn.q.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1360 [Add] inputs: [1852 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.2.attn.q.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.2.attn.q.bias for ONNX node: backbone.block3.2.attn.q.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1360 for ONNX node: Add_1360
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1853 for ONNX tensor: 1853
[06/10/2022-19:21:31] [V] [TRT] Add_1360 [Add] outputs: [1853 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1362 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1850
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1854
[06/10/2022-19:21:31] [V] [TRT] Div_1362 [Div] inputs: [1850 -> ()[INT32]], [1854 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1854 for ONNX node: 1854
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1362 for ONNX node: Div_1362
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1855 for ONNX tensor: 1855
[06/10/2022-19:21:31] [V] [TRT] Div_1362 [Div] outputs: [1855 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1363 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1855
[06/10/2022-19:21:31] [V] [TRT] Cast_1363 [Cast] inputs: [1855 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1363 for ONNX node: Cast_1363
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1856 for ONNX tensor: 1856
[06/10/2022-19:21:31] [V] [TRT] Cast_1363 [Cast] outputs: [1856 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1364 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1856
[06/10/2022-19:21:31] [V] [TRT] Cast_1364 [Cast] inputs: [1856 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1364 for ONNX node: Cast_1364
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1857 for ONNX tensor: 1857
[06/10/2022-19:21:31] [V] [TRT] Cast_1364 [Cast] outputs: [1857 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1365 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1844
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1365 [Unsqueeze] inputs: [1844 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1365 for ONNX node: Unsqueeze_1365
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1859 for ONNX tensor: 1859
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1365 [Unsqueeze] outputs: [1859 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1366 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1847
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1366 [Unsqueeze] inputs: [1847 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1366 for ONNX node: Unsqueeze_1366
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1860 for ONNX tensor: 1860
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1366 [Unsqueeze] outputs: [1860 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1367 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1857
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1367 [Unsqueeze] inputs: [1857 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1367 for ONNX node: Unsqueeze_1367
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1862 for ONNX tensor: 1862
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1367 [Unsqueeze] outputs: [1862 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1368 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1859
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1860
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3152
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1862
[06/10/2022-19:21:31] [V] [TRT] Concat_1368 [Concat] inputs: [1859 -> (1)[INT32]], [1860 -> (1)[INT32]], [3152 -> (1)[INT32]], [1862 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3152 for ONNX node: 3152
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1368 for ONNX node: Concat_1368
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1863 for ONNX tensor: 1863
[06/10/2022-19:21:31] [V] [TRT] Concat_1368 [Concat] outputs: [1863 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1369 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1853
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1863
[06/10/2022-19:21:31] [V] [TRT] Reshape_1369 [Reshape] inputs: [1853 -> (-1, 4096, 320)[FLOAT]], [1863 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1369 for ONNX node: Reshape_1369
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1864 for ONNX tensor: 1864
[06/10/2022-19:21:31] [V] [TRT] Reshape_1369 [Reshape] outputs: [1864 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1370 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1864
[06/10/2022-19:21:31] [V] [TRT] Transpose_1370 [Transpose] inputs: [1864 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1370 for ONNX node: Transpose_1370
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1865 for ONNX tensor: 1865
[06/10/2022-19:21:31] [V] [TRT] Transpose_1370 [Transpose] outputs: [1865 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1371 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1841
[06/10/2022-19:21:31] [V] [TRT] Transpose_1371 [Transpose] inputs: [1841 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1371 for ONNX node: Transpose_1371
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1866 for ONNX tensor: 1866
[06/10/2022-19:21:31] [V] [TRT] Transpose_1371 [Transpose] outputs: [1866 -> (-1, 320, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1372 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1844
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1372 [Unsqueeze] inputs: [1844 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1372 for ONNX node: Unsqueeze_1372
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1867 for ONNX tensor: 1867
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1372 [Unsqueeze] outputs: [1867 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1373 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1850
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1373 [Unsqueeze] inputs: [1850 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1373 for ONNX node: Unsqueeze_1373
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1868 for ONNX tensor: 1868
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1373 [Unsqueeze] outputs: [1868 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1374 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1374 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1374 for ONNX node: Unsqueeze_1374
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1869 for ONNX tensor: 1869
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1374 [Unsqueeze] outputs: [1869 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1375 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1375 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1375 for ONNX node: Unsqueeze_1375
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1870 for ONNX tensor: 1870
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1375 [Unsqueeze] outputs: [1870 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1376 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1867
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1868
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1869
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1870
[06/10/2022-19:21:31] [V] [TRT] Concat_1376 [Concat] inputs: [1867 -> (1)[INT32]], [1868 -> (1)[INT32]], [1869 -> (1)[INT32]], [1870 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1376 for ONNX node: Concat_1376
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1871 for ONNX tensor: 1871
[06/10/2022-19:21:31] [V] [TRT] Concat_1376 [Concat] outputs: [1871 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1377 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1866
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1871
[06/10/2022-19:21:31] [V] [TRT] Reshape_1377 [Reshape] inputs: [1866 -> (-1, 320, 4096)[FLOAT]], [1871 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1377 for ONNX node: Reshape_1377
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1872 for ONNX tensor: 1872
[06/10/2022-19:21:31] [V] [TRT] Reshape_1377 [Reshape] outputs: [1872 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Conv_1378 [Conv]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1872
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.attn.sr.weight
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.attn.sr.bias
[06/10/2022-19:21:31] [V] [TRT] Conv_1378 [Conv] inputs: [1872 -> (-1, 320, 64, 64)[FLOAT]], [backbone.block3.2.attn.sr.weight -> (320, 320, 2, 2)[FLOAT]], [backbone.block3.2.attn.sr.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Convolution input dimensions: (-1, 320, 64, 64)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Conv_1378 for ONNX node: Conv_1378
[06/10/2022-19:21:31] [V] [TRT] Using kernel: (2, 2), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 320
[06/10/2022-19:21:31] [V] [TRT] Convolution output dimensions: (-1, 320, 32, 32)
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1873 for ONNX tensor: 1873
[06/10/2022-19:21:31] [V] [TRT] Conv_1378 [Conv] outputs: [1873 -> (-1, 320, 32, 32)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1379 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1844
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1379 [Unsqueeze] inputs: [1844 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1379 for ONNX node: Unsqueeze_1379
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1875 for ONNX tensor: 1875
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1379 [Unsqueeze] outputs: [1875 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1380 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1850
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1380 [Unsqueeze] inputs: [1850 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1380 for ONNX node: Unsqueeze_1380
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1876 for ONNX tensor: 1876
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1380 [Unsqueeze] outputs: [1876 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1381 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1875
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1876
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3153
[06/10/2022-19:21:31] [V] [TRT] Concat_1381 [Concat] inputs: [1875 -> (1)[INT32]], [1876 -> (1)[INT32]], [3153 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3153 for ONNX node: 3153
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1381 for ONNX node: Concat_1381
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1878 for ONNX tensor: 1878
[06/10/2022-19:21:31] [V] [TRT] Concat_1381 [Concat] outputs: [1878 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1382 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1873
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1878
[06/10/2022-19:21:31] [V] [TRT] Reshape_1382 [Reshape] inputs: [1873 -> (-1, 320, 32, 32)[FLOAT]], [1878 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1382 for ONNX node: Reshape_1382
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1879 for ONNX tensor: 1879
[06/10/2022-19:21:31] [V] [TRT] Reshape_1382 [Reshape] outputs: [1879 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1383 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1879
[06/10/2022-19:21:31] [V] [TRT] Transpose_1383 [Transpose] inputs: [1879 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1383 for ONNX node: Transpose_1383
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1880 for ONNX tensor: 1880
[06/10/2022-19:21:31] [V] [TRT] Transpose_1383 [Transpose] outputs: [1880 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1384 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1880
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1384 [ReduceMean] inputs: [1880 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1384 for ONNX node: ReduceMean_1384
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1881 for ONNX tensor: 1881
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1384 [ReduceMean] outputs: [1881 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sub_1385 [Sub]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1880
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1881
[06/10/2022-19:21:31] [V] [TRT] Sub_1385 [Sub] inputs: [1880 -> (-1, 1024, 320)[FLOAT]], [1881 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sub_1385 for ONNX node: Sub_1385
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1882 for ONNX tensor: 1882
[06/10/2022-19:21:31] [V] [TRT] Sub_1385 [Sub] outputs: [1882 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Pow_1387 [Pow]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1882
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1883
[06/10/2022-19:21:31] [V] [TRT] Pow_1387 [Pow] inputs: [1882 -> (-1, 1024, 320)[FLOAT]], [1883 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1883 for ONNX node: 1883
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Pow_1387 for ONNX node: Pow_1387
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1884 for ONNX tensor: 1884
[06/10/2022-19:21:31] [V] [TRT] Pow_1387 [Pow] outputs: [1884 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1388 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1884
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1388 [ReduceMean] inputs: [1884 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1388 for ONNX node: ReduceMean_1388
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1885 for ONNX tensor: 1885
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1388 [ReduceMean] outputs: [1885 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1390 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1885
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1886
[06/10/2022-19:21:31] [V] [TRT] Add_1390 [Add] inputs: [1885 -> (-1, 1024, 1)[FLOAT]], [1886 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1886 for ONNX node: 1886
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1390 for ONNX node: Add_1390
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1887 for ONNX tensor: 1887
[06/10/2022-19:21:31] [V] [TRT] Add_1390 [Add] outputs: [1887 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sqrt_1391 [Sqrt]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1887
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1391 [Sqrt] inputs: [1887 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sqrt_1391 for ONNX node: Sqrt_1391
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1888 for ONNX tensor: 1888
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1391 [Sqrt] outputs: [1888 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1392 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1882
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1888
[06/10/2022-19:21:31] [V] [TRT] Div_1392 [Div] inputs: [1882 -> (-1, 1024, 320)[FLOAT]], [1888 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1392 for ONNX node: Div_1392
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1889 for ONNX tensor: 1889
[06/10/2022-19:21:31] [V] [TRT] Div_1392 [Div] outputs: [1889 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1393 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1889
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.attn.norm.weight
[06/10/2022-19:21:31] [V] [TRT] Mul_1393 [Mul] inputs: [1889 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.2.attn.norm.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.2.attn.norm.weight for ONNX node: backbone.block3.2.attn.norm.weight
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1393 for ONNX node: Mul_1393
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1890 for ONNX tensor: 1890
[06/10/2022-19:21:31] [V] [TRT] Mul_1393 [Mul] outputs: [1890 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1394 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1890
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.attn.norm.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1394 [Add] inputs: [1890 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.2.attn.norm.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.2.attn.norm.bias for ONNX node: backbone.block3.2.attn.norm.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1394 for ONNX node: Add_1394
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1891 for ONNX tensor: 1891
[06/10/2022-19:21:31] [V] [TRT] Add_1394 [Add] outputs: [1891 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1395 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1891
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3154
[06/10/2022-19:21:31] [V] [TRT] MatMul_1395 [MatMul] inputs: [1891 -> (-1, 1024, 320)[FLOAT]], [3154 -> (320, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3154 for ONNX node: 3154
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1395 for ONNX node: MatMul_1395
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1893 for ONNX tensor: 1893
[06/10/2022-19:21:31] [V] [TRT] MatMul_1395 [MatMul] outputs: [1893 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1396 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1893
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.attn.kv.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1396 [Add] inputs: [1893 -> (-1, 1024, 640)[FLOAT]], [backbone.block3.2.attn.kv.bias -> (640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.2.attn.kv.bias for ONNX node: backbone.block3.2.attn.kv.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1396 for ONNX node: Add_1396
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1894 for ONNX tensor: 1894
[06/10/2022-19:21:31] [V] [TRT] Add_1396 [Add] outputs: [1894 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1398 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1850
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1895
[06/10/2022-19:21:31] [V] [TRT] Div_1398 [Div] inputs: [1850 -> ()[INT32]], [1895 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1895 for ONNX node: 1895
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1398 for ONNX node: Div_1398
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1896 for ONNX tensor: 1896
[06/10/2022-19:21:31] [V] [TRT] Div_1398 [Div] outputs: [1896 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1399 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1896
[06/10/2022-19:21:31] [V] [TRT] Cast_1399 [Cast] inputs: [1896 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1399 for ONNX node: Cast_1399
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1897 for ONNX tensor: 1897
[06/10/2022-19:21:31] [V] [TRT] Cast_1399 [Cast] outputs: [1897 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1400 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1897
[06/10/2022-19:21:31] [V] [TRT] Cast_1400 [Cast] inputs: [1897 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1400 for ONNX node: Cast_1400
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1898 for ONNX tensor: 1898
[06/10/2022-19:21:31] [V] [TRT] Cast_1400 [Cast] outputs: [1898 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1401 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1844
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1401 [Unsqueeze] inputs: [1844 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1401 for ONNX node: Unsqueeze_1401
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1902 for ONNX tensor: 1902
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1401 [Unsqueeze] outputs: [1902 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1402 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1898
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1402 [Unsqueeze] inputs: [1898 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1402 for ONNX node: Unsqueeze_1402
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1906 for ONNX tensor: 1906
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1402 [Unsqueeze] outputs: [1906 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1403 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1902
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3155
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3156
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3157
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1906
[06/10/2022-19:21:31] [V] [TRT] Concat_1403 [Concat] inputs: [1902 -> (1)[INT32]], [3155 -> (1)[INT32]], [3156 -> (1)[INT32]], [3157 -> (1)[INT32]], [1906 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3155 for ONNX node: 3155
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3156 for ONNX node: 3156
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3157 for ONNX node: 3157
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1403 for ONNX node: Concat_1403
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1907 for ONNX tensor: 1907
[06/10/2022-19:21:31] [V] [TRT] Concat_1403 [Concat] outputs: [1907 -> (5)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1404 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1894
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1907
[06/10/2022-19:21:31] [V] [TRT] Reshape_1404 [Reshape] inputs: [1894 -> (-1, 1024, 640)[FLOAT]], [1907 -> (5)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1404 for ONNX node: Reshape_1404
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1908 for ONNX tensor: 1908
[06/10/2022-19:21:31] [V] [TRT] Reshape_1404 [Reshape] outputs: [1908 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1405 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1908
[06/10/2022-19:21:31] [V] [TRT] Transpose_1405 [Transpose] inputs: [1908 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1405 for ONNX node: Transpose_1405
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1909 for ONNX tensor: 1909
[06/10/2022-19:21:31] [V] [TRT] Transpose_1405 [Transpose] outputs: [1909 -> (2, -1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1407 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1909
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1910
[06/10/2022-19:21:31] [V] [TRT] Gather_1407 [Gather] inputs: [1909 -> (2, -1, 5, 1024, 64)[FLOAT]], [1910 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1910 for ONNX node: 1910
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1407 for ONNX node: Gather_1407
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1911 for ONNX tensor: 1911
[06/10/2022-19:21:31] [V] [TRT] Gather_1407 [Gather] outputs: [1911 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1409 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1909
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1912
[06/10/2022-19:21:31] [V] [TRT] Gather_1409 [Gather] inputs: [1909 -> (2, -1, 5, 1024, 64)[FLOAT]], [1912 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1912 for ONNX node: 1912
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1409 for ONNX node: Gather_1409
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1913 for ONNX tensor: 1913
[06/10/2022-19:21:31] [V] [TRT] Gather_1409 [Gather] outputs: [1913 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1410 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1911
[06/10/2022-19:21:31] [V] [TRT] Transpose_1410 [Transpose] inputs: [1911 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1410 for ONNX node: Transpose_1410
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1914 for ONNX tensor: 1914
[06/10/2022-19:21:31] [V] [TRT] Transpose_1410 [Transpose] outputs: [1914 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1411 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1865
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1914
[06/10/2022-19:21:31] [V] [TRT] MatMul_1411 [MatMul] inputs: [1865 -> (-1, 5, 4096, 64)[FLOAT]], [1914 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1411 for ONNX node: MatMul_1411
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1915 for ONNX tensor: 1915
[06/10/2022-19:21:31] [V] [TRT] MatMul_1411 [MatMul] outputs: [1915 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1413 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1915
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1916
[06/10/2022-19:21:31] [V] [TRT] Mul_1413 [Mul] inputs: [1915 -> (-1, 5, 4096, 1024)[FLOAT]], [1916 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1916 for ONNX node: 1916
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1413 for ONNX node: Mul_1413
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1917 for ONNX tensor: 1917
[06/10/2022-19:21:31] [V] [TRT] Mul_1413 [Mul] outputs: [1917 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Softmax_1414 [Softmax]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1917
[06/10/2022-19:21:31] [V] [TRT] Softmax_1414 [Softmax] inputs: [1917 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Softmax_1414 for ONNX node: Softmax_1414
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1918 for ONNX tensor: 1918
[06/10/2022-19:21:31] [V] [TRT] Softmax_1414 [Softmax] outputs: [1918 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1415 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1918
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1913
[06/10/2022-19:21:31] [V] [TRT] MatMul_1415 [MatMul] inputs: [1918 -> (-1, 5, 4096, 1024)[FLOAT]], [1913 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1415 for ONNX node: MatMul_1415
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1919 for ONNX tensor: 1919
[06/10/2022-19:21:31] [V] [TRT] MatMul_1415 [MatMul] outputs: [1919 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1416 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1919
[06/10/2022-19:21:31] [V] [TRT] Transpose_1416 [Transpose] inputs: [1919 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1416 for ONNX node: Transpose_1416
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1920 for ONNX tensor: 1920
[06/10/2022-19:21:31] [V] [TRT] Transpose_1416 [Transpose] outputs: [1920 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1417 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1844
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1417 [Unsqueeze] inputs: [1844 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1417 for ONNX node: Unsqueeze_1417
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1921 for ONNX tensor: 1921
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1417 [Unsqueeze] outputs: [1921 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1418 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1847
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1418 [Unsqueeze] inputs: [1847 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1418 for ONNX node: Unsqueeze_1418
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1922 for ONNX tensor: 1922
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1418 [Unsqueeze] outputs: [1922 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1419 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1850
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1419 [Unsqueeze] inputs: [1850 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1419 for ONNX node: Unsqueeze_1419
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1923 for ONNX tensor: 1923
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1419 [Unsqueeze] outputs: [1923 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1420 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1921
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1922
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1923
[06/10/2022-19:21:31] [V] [TRT] Concat_1420 [Concat] inputs: [1921 -> (1)[INT32]], [1922 -> (1)[INT32]], [1923 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1420 for ONNX node: Concat_1420
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1924 for ONNX tensor: 1924
[06/10/2022-19:21:31] [V] [TRT] Concat_1420 [Concat] outputs: [1924 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1421 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1920
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1924
[06/10/2022-19:21:31] [V] [TRT] Reshape_1421 [Reshape] inputs: [1920 -> (-1, 4096, 5, 64)[FLOAT]], [1924 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1421 for ONNX node: Reshape_1421
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1925 for ONNX tensor: 1925
[06/10/2022-19:21:31] [V] [TRT] Reshape_1421 [Reshape] outputs: [1925 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1422 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1925
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3158
[06/10/2022-19:21:31] [V] [TRT] MatMul_1422 [MatMul] inputs: [1925 -> (-1, 4096, 320)[FLOAT]], [3158 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3158 for ONNX node: 3158
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1422 for ONNX node: MatMul_1422
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1927 for ONNX tensor: 1927
[06/10/2022-19:21:31] [V] [TRT] MatMul_1422 [MatMul] outputs: [1927 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1423 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1927
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.attn.proj.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1423 [Add] inputs: [1927 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.2.attn.proj.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.2.attn.proj.bias for ONNX node: backbone.block3.2.attn.proj.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1423 for ONNX node: Add_1423
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1928 for ONNX tensor: 1928
[06/10/2022-19:21:31] [V] [TRT] Add_1423 [Add] outputs: [1928 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1424 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1830
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1928
[06/10/2022-19:21:31] [V] [TRT] Add_1424 [Add] inputs: [1830 -> (-1, 4096, 320)[FLOAT]], [1928 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1424 for ONNX node: Add_1424
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1929 for ONNX tensor: 1929
[06/10/2022-19:21:31] [V] [TRT] Add_1424 [Add] outputs: [1929 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1425 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1929
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1425 [ReduceMean] inputs: [1929 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1425 for ONNX node: ReduceMean_1425
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1930 for ONNX tensor: 1930
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1425 [ReduceMean] outputs: [1930 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sub_1426 [Sub]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1929
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1930
[06/10/2022-19:21:31] [V] [TRT] Sub_1426 [Sub] inputs: [1929 -> (-1, 4096, 320)[FLOAT]], [1930 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sub_1426 for ONNX node: Sub_1426
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1931 for ONNX tensor: 1931
[06/10/2022-19:21:31] [V] [TRT] Sub_1426 [Sub] outputs: [1931 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Pow_1428 [Pow]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1931
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1932
[06/10/2022-19:21:31] [V] [TRT] Pow_1428 [Pow] inputs: [1931 -> (-1, 4096, 320)[FLOAT]], [1932 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1932 for ONNX node: 1932
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Pow_1428 for ONNX node: Pow_1428
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1933 for ONNX tensor: 1933
[06/10/2022-19:21:31] [V] [TRT] Pow_1428 [Pow] outputs: [1933 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1429 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1933
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1429 [ReduceMean] inputs: [1933 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1429 for ONNX node: ReduceMean_1429
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1934 for ONNX tensor: 1934
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1429 [ReduceMean] outputs: [1934 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1431 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1934
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1935
[06/10/2022-19:21:31] [V] [TRT] Add_1431 [Add] inputs: [1934 -> (-1, 4096, 1)[FLOAT]], [1935 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1935 for ONNX node: 1935
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1431 for ONNX node: Add_1431
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1936 for ONNX tensor: 1936
[06/10/2022-19:21:31] [V] [TRT] Add_1431 [Add] outputs: [1936 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sqrt_1432 [Sqrt]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1936
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1432 [Sqrt] inputs: [1936 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sqrt_1432 for ONNX node: Sqrt_1432
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1937 for ONNX tensor: 1937
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1432 [Sqrt] outputs: [1937 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1433 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1931
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1937
[06/10/2022-19:21:31] [V] [TRT] Div_1433 [Div] inputs: [1931 -> (-1, 4096, 320)[FLOAT]], [1937 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1433 for ONNX node: Div_1433
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1938 for ONNX tensor: 1938
[06/10/2022-19:21:31] [V] [TRT] Div_1433 [Div] outputs: [1938 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1434 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1938
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.norm2.weight
[06/10/2022-19:21:31] [V] [TRT] Mul_1434 [Mul] inputs: [1938 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.2.norm2.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.2.norm2.weight for ONNX node: backbone.block3.2.norm2.weight
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1434 for ONNX node: Mul_1434
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1939 for ONNX tensor: 1939
[06/10/2022-19:21:31] [V] [TRT] Mul_1434 [Mul] outputs: [1939 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1435 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1939
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.norm2.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1435 [Add] inputs: [1939 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.2.norm2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.2.norm2.bias for ONNX node: backbone.block3.2.norm2.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1435 for ONNX node: Add_1435
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1940 for ONNX tensor: 1940
[06/10/2022-19:21:31] [V] [TRT] Add_1435 [Add] outputs: [1940 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1436 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1940
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3159
[06/10/2022-19:21:31] [V] [TRT] MatMul_1436 [MatMul] inputs: [1940 -> (-1, 4096, 320)[FLOAT]], [3159 -> (320, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3159 for ONNX node: 3159
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1436 for ONNX node: MatMul_1436
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1942 for ONNX tensor: 1942
[06/10/2022-19:21:31] [V] [TRT] MatMul_1436 [MatMul] outputs: [1942 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1437 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1942
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.mlp.fc1.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1437 [Add] inputs: [1942 -> (-1, 4096, 1280)[FLOAT]], [backbone.block3.2.mlp.fc1.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.2.mlp.fc1.bias for ONNX node: backbone.block3.2.mlp.fc1.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1437 for ONNX node: Add_1437
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1943 for ONNX tensor: 1943
[06/10/2022-19:21:31] [V] [TRT] Add_1437 [Add] outputs: [1943 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1438 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1943
[06/10/2022-19:21:31] [V] [TRT] Shape_1438 [Shape] inputs: [1943 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1438 for ONNX node: Shape_1438
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1944 for ONNX tensor: 1944
[06/10/2022-19:21:31] [V] [TRT] Shape_1438 [Shape] outputs: [1944 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1440 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1944
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1945
[06/10/2022-19:21:31] [V] [TRT] Gather_1440 [Gather] inputs: [1944 -> (3)[INT32]], [1945 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1945 for ONNX node: 1945
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1440 for ONNX node: Gather_1440
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1946 for ONNX tensor: 1946
[06/10/2022-19:21:31] [V] [TRT] Gather_1440 [Gather] outputs: [1946 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1441 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1943
[06/10/2022-19:21:31] [V] [TRT] Shape_1441 [Shape] inputs: [1943 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1441 for ONNX node: Shape_1441
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1947 for ONNX tensor: 1947
[06/10/2022-19:21:31] [V] [TRT] Shape_1441 [Shape] outputs: [1947 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1443 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1947
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1948
[06/10/2022-19:21:31] [V] [TRT] Gather_1443 [Gather] inputs: [1947 -> (3)[INT32]], [1948 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1948 for ONNX node: 1948
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1443 for ONNX node: Gather_1443
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1949 for ONNX tensor: 1949
[06/10/2022-19:21:31] [V] [TRT] Gather_1443 [Gather] outputs: [1949 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1444 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1943
[06/10/2022-19:21:31] [V] [TRT] Transpose_1444 [Transpose] inputs: [1943 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1444 for ONNX node: Transpose_1444
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1950 for ONNX tensor: 1950
[06/10/2022-19:21:31] [V] [TRT] Transpose_1444 [Transpose] outputs: [1950 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1445 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1946
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1445 [Unsqueeze] inputs: [1946 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1445 for ONNX node: Unsqueeze_1445
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1951 for ONNX tensor: 1951
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1445 [Unsqueeze] outputs: [1951 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1446 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1949
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1446 [Unsqueeze] inputs: [1949 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1446 for ONNX node: Unsqueeze_1446
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1952 for ONNX tensor: 1952
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1446 [Unsqueeze] outputs: [1952 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1447 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1447 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1447 for ONNX node: Unsqueeze_1447
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1953 for ONNX tensor: 1953
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1447 [Unsqueeze] outputs: [1953 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1448 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1448 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1448 for ONNX node: Unsqueeze_1448
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1954 for ONNX tensor: 1954
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1448 [Unsqueeze] outputs: [1954 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1449 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1951
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1952
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1953
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1954
[06/10/2022-19:21:31] [V] [TRT] Concat_1449 [Concat] inputs: [1951 -> (1)[INT32]], [1952 -> (1)[INT32]], [1953 -> (1)[INT32]], [1954 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1449 for ONNX node: Concat_1449
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1955 for ONNX tensor: 1955
[06/10/2022-19:21:31] [V] [TRT] Concat_1449 [Concat] outputs: [1955 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1450 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1950
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1955
[06/10/2022-19:21:31] [V] [TRT] Reshape_1450 [Reshape] inputs: [1950 -> (-1, 1280, 4096)[FLOAT]], [1955 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1450 for ONNX node: Reshape_1450
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1956 for ONNX tensor: 1956
[06/10/2022-19:21:31] [V] [TRT] Reshape_1450 [Reshape] outputs: [1956 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Conv_1451 [Conv]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1956
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:31] [V] [TRT] Conv_1451 [Conv] inputs: [1956 -> (-1, 1280, 64, 64)[FLOAT]], [backbone.block3.2.mlp.dwconv.dwconv.weight -> (1280, 1, 3, 3)[FLOAT]], [backbone.block3.2.mlp.dwconv.dwconv.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Convolution input dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Conv_1451 for ONNX node: Conv_1451
[06/10/2022-19:21:31] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1280
[06/10/2022-19:21:31] [V] [TRT] Convolution output dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1957 for ONNX tensor: 1957
[06/10/2022-19:21:31] [V] [TRT] Conv_1451 [Conv] outputs: [1957 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1452 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1957
[06/10/2022-19:21:31] [V] [TRT] Shape_1452 [Shape] inputs: [1957 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1452 for ONNX node: Shape_1452
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1958 for ONNX tensor: 1958
[06/10/2022-19:21:31] [V] [TRT] Shape_1452 [Shape] outputs: [1958 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Slice_1456 [Slice]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1958
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1960
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1961
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1959
[06/10/2022-19:21:31] [V] [TRT] Slice_1456 [Slice] inputs: [1958 -> (4)[INT32]], [1960 -> (1)[INT32]], [1961 -> (1)[INT32]], [1959 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Slice_1456 for ONNX node: Slice_1456
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1962 for ONNX tensor: 1962
[06/10/2022-19:21:31] [V] [TRT] Slice_1456 [Slice] outputs: [1962 -> (2)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1458 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1962
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1963
[06/10/2022-19:21:31] [V] [TRT] Concat_1458 [Concat] inputs: [1962 -> (2)[INT32]], [1963 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1963 for ONNX node: 1963
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1458 for ONNX node: Concat_1458
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1964 for ONNX tensor: 1964
[06/10/2022-19:21:31] [V] [TRT] Concat_1458 [Concat] outputs: [1964 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1459 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1957
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1964
[06/10/2022-19:21:31] [V] [TRT] Reshape_1459 [Reshape] inputs: [1957 -> (-1, 1280, 64, 64)[FLOAT]], [1964 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1459 for ONNX node: Reshape_1459
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1965 for ONNX tensor: 1965
[06/10/2022-19:21:31] [V] [TRT] Reshape_1459 [Reshape] outputs: [1965 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1460 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1965
[06/10/2022-19:21:31] [V] [TRT] Transpose_1460 [Transpose] inputs: [1965 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1460 for ONNX node: Transpose_1460
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1966 for ONNX tensor: 1966
[06/10/2022-19:21:31] [V] [TRT] Transpose_1460 [Transpose] outputs: [1966 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1462 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1966
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1967
[06/10/2022-19:21:31] [V] [TRT] Div_1462 [Div] inputs: [1966 -> (-1, 4096, 1280)[FLOAT]], [1967 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1967 for ONNX node: 1967
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1462 for ONNX node: Div_1462
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1968 for ONNX tensor: 1968
[06/10/2022-19:21:31] [V] [TRT] Div_1462 [Div] outputs: [1968 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Erf_1463 [Erf]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1968
[06/10/2022-19:21:31] [V] [TRT] Erf_1463 [Erf] inputs: [1968 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Erf_1463 for ONNX node: Erf_1463
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1969 for ONNX tensor: 1969
[06/10/2022-19:21:31] [V] [TRT] Erf_1463 [Erf] outputs: [1969 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1465 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1969
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1970
[06/10/2022-19:21:31] [V] [TRT] Add_1465 [Add] inputs: [1969 -> (-1, 4096, 1280)[FLOAT]], [1970 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1970 for ONNX node: 1970
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1465 for ONNX node: Add_1465
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1971 for ONNX tensor: 1971
[06/10/2022-19:21:31] [V] [TRT] Add_1465 [Add] outputs: [1971 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1466 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1966
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1971
[06/10/2022-19:21:31] [V] [TRT] Mul_1466 [Mul] inputs: [1966 -> (-1, 4096, 1280)[FLOAT]], [1971 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1466 for ONNX node: Mul_1466
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1972 for ONNX tensor: 1972
[06/10/2022-19:21:31] [V] [TRT] Mul_1466 [Mul] outputs: [1972 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1468 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1972
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1973
[06/10/2022-19:21:31] [V] [TRT] Mul_1468 [Mul] inputs: [1972 -> (-1, 4096, 1280)[FLOAT]], [1973 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1973 for ONNX node: 1973
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1468 for ONNX node: Mul_1468
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1974 for ONNX tensor: 1974
[06/10/2022-19:21:31] [V] [TRT] Mul_1468 [Mul] outputs: [1974 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1469 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1974
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3160
[06/10/2022-19:21:31] [V] [TRT] MatMul_1469 [MatMul] inputs: [1974 -> (-1, 4096, 1280)[FLOAT]], [3160 -> (1280, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3160 for ONNX node: 3160
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1469 for ONNX node: MatMul_1469
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1976 for ONNX tensor: 1976
[06/10/2022-19:21:31] [V] [TRT] MatMul_1469 [MatMul] outputs: [1976 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1470 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1976
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.2.mlp.fc2.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1470 [Add] inputs: [1976 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.2.mlp.fc2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.2.mlp.fc2.bias for ONNX node: backbone.block3.2.mlp.fc2.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1470 for ONNX node: Add_1470
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1977 for ONNX tensor: 1977
[06/10/2022-19:21:31] [V] [TRT] Add_1470 [Add] outputs: [1977 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1471 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1929
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1977
[06/10/2022-19:21:31] [V] [TRT] Add_1471 [Add] inputs: [1929 -> (-1, 4096, 320)[FLOAT]], [1977 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1471 for ONNX node: Add_1471
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1978 for ONNX tensor: 1978
[06/10/2022-19:21:31] [V] [TRT] Add_1471 [Add] outputs: [1978 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1472 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1978
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1472 [ReduceMean] inputs: [1978 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1472 for ONNX node: ReduceMean_1472
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1979 for ONNX tensor: 1979
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1472 [ReduceMean] outputs: [1979 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sub_1473 [Sub]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1978
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1979
[06/10/2022-19:21:31] [V] [TRT] Sub_1473 [Sub] inputs: [1978 -> (-1, 4096, 320)[FLOAT]], [1979 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sub_1473 for ONNX node: Sub_1473
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1980 for ONNX tensor: 1980
[06/10/2022-19:21:31] [V] [TRT] Sub_1473 [Sub] outputs: [1980 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Pow_1475 [Pow]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1980
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1981
[06/10/2022-19:21:31] [V] [TRT] Pow_1475 [Pow] inputs: [1980 -> (-1, 4096, 320)[FLOAT]], [1981 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1981 for ONNX node: 1981
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Pow_1475 for ONNX node: Pow_1475
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1982 for ONNX tensor: 1982
[06/10/2022-19:21:31] [V] [TRT] Pow_1475 [Pow] outputs: [1982 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1476 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1982
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1476 [ReduceMean] inputs: [1982 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1476 for ONNX node: ReduceMean_1476
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1983 for ONNX tensor: 1983
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1476 [ReduceMean] outputs: [1983 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1478 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1983
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1984
[06/10/2022-19:21:31] [V] [TRT] Add_1478 [Add] inputs: [1983 -> (-1, 4096, 1)[FLOAT]], [1984 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1984 for ONNX node: 1984
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1478 for ONNX node: Add_1478
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1985 for ONNX tensor: 1985
[06/10/2022-19:21:31] [V] [TRT] Add_1478 [Add] outputs: [1985 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sqrt_1479 [Sqrt]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1985
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1479 [Sqrt] inputs: [1985 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sqrt_1479 for ONNX node: Sqrt_1479
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1986 for ONNX tensor: 1986
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1479 [Sqrt] outputs: [1986 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1480 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1980
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1986
[06/10/2022-19:21:31] [V] [TRT] Div_1480 [Div] inputs: [1980 -> (-1, 4096, 320)[FLOAT]], [1986 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1480 for ONNX node: Div_1480
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1987 for ONNX tensor: 1987
[06/10/2022-19:21:31] [V] [TRT] Div_1480 [Div] outputs: [1987 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1481 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1987
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.norm1.weight
[06/10/2022-19:21:31] [V] [TRT] Mul_1481 [Mul] inputs: [1987 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.3.norm1.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.3.norm1.weight for ONNX node: backbone.block3.3.norm1.weight
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1481 for ONNX node: Mul_1481
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1988 for ONNX tensor: 1988
[06/10/2022-19:21:31] [V] [TRT] Mul_1481 [Mul] outputs: [1988 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1482 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1988
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.norm1.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1482 [Add] inputs: [1988 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.3.norm1.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.3.norm1.bias for ONNX node: backbone.block3.3.norm1.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1482 for ONNX node: Add_1482
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1989 for ONNX tensor: 1989
[06/10/2022-19:21:31] [V] [TRT] Add_1482 [Add] outputs: [1989 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1483 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1989
[06/10/2022-19:21:31] [V] [TRT] Shape_1483 [Shape] inputs: [1989 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1483 for ONNX node: Shape_1483
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1990 for ONNX tensor: 1990
[06/10/2022-19:21:31] [V] [TRT] Shape_1483 [Shape] outputs: [1990 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1485 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1990
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1991
[06/10/2022-19:21:31] [V] [TRT] Gather_1485 [Gather] inputs: [1990 -> (3)[INT32]], [1991 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1991 for ONNX node: 1991
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1485 for ONNX node: Gather_1485
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1992 for ONNX tensor: 1992
[06/10/2022-19:21:31] [V] [TRT] Gather_1485 [Gather] outputs: [1992 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1486 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1989
[06/10/2022-19:21:31] [V] [TRT] Shape_1486 [Shape] inputs: [1989 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1486 for ONNX node: Shape_1486
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1993 for ONNX tensor: 1993
[06/10/2022-19:21:31] [V] [TRT] Shape_1486 [Shape] outputs: [1993 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1488 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1993
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1994
[06/10/2022-19:21:31] [V] [TRT] Gather_1488 [Gather] inputs: [1993 -> (3)[INT32]], [1994 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1994 for ONNX node: 1994
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1488 for ONNX node: Gather_1488
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1995 for ONNX tensor: 1995
[06/10/2022-19:21:31] [V] [TRT] Gather_1488 [Gather] outputs: [1995 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1489 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1989
[06/10/2022-19:21:31] [V] [TRT] Shape_1489 [Shape] inputs: [1989 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1489 for ONNX node: Shape_1489
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1996 for ONNX tensor: 1996
[06/10/2022-19:21:31] [V] [TRT] Shape_1489 [Shape] outputs: [1996 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1491 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1996
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1997
[06/10/2022-19:21:31] [V] [TRT] Gather_1491 [Gather] inputs: [1996 -> (3)[INT32]], [1997 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 1997 for ONNX node: 1997
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1491 for ONNX node: Gather_1491
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 1998 for ONNX tensor: 1998
[06/10/2022-19:21:31] [V] [TRT] Gather_1491 [Gather] outputs: [1998 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1492 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1989
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3161
[06/10/2022-19:21:31] [V] [TRT] MatMul_1492 [MatMul] inputs: [1989 -> (-1, 4096, 320)[FLOAT]], [3161 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3161 for ONNX node: 3161
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1492 for ONNX node: MatMul_1492
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2000 for ONNX tensor: 2000
[06/10/2022-19:21:31] [V] [TRT] MatMul_1492 [MatMul] outputs: [2000 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1493 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2000
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.attn.q.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1493 [Add] inputs: [2000 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.3.attn.q.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.3.attn.q.bias for ONNX node: backbone.block3.3.attn.q.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1493 for ONNX node: Add_1493
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2001 for ONNX tensor: 2001
[06/10/2022-19:21:31] [V] [TRT] Add_1493 [Add] outputs: [2001 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1495 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1998
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2002
[06/10/2022-19:21:31] [V] [TRT] Div_1495 [Div] inputs: [1998 -> ()[INT32]], [2002 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2002 for ONNX node: 2002
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1495 for ONNX node: Div_1495
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2003 for ONNX tensor: 2003
[06/10/2022-19:21:31] [V] [TRT] Div_1495 [Div] outputs: [2003 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1496 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2003
[06/10/2022-19:21:31] [V] [TRT] Cast_1496 [Cast] inputs: [2003 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1496 for ONNX node: Cast_1496
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2004 for ONNX tensor: 2004
[06/10/2022-19:21:31] [V] [TRT] Cast_1496 [Cast] outputs: [2004 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1497 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2004
[06/10/2022-19:21:31] [V] [TRT] Cast_1497 [Cast] inputs: [2004 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1497 for ONNX node: Cast_1497
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2005 for ONNX tensor: 2005
[06/10/2022-19:21:31] [V] [TRT] Cast_1497 [Cast] outputs: [2005 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1498 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1992
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1498 [Unsqueeze] inputs: [1992 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1498 for ONNX node: Unsqueeze_1498
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2007 for ONNX tensor: 2007
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1498 [Unsqueeze] outputs: [2007 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1499 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1995
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1499 [Unsqueeze] inputs: [1995 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1499 for ONNX node: Unsqueeze_1499
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2008 for ONNX tensor: 2008
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1499 [Unsqueeze] outputs: [2008 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1500 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2005
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1500 [Unsqueeze] inputs: [2005 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1500 for ONNX node: Unsqueeze_1500
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2010 for ONNX tensor: 2010
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1500 [Unsqueeze] outputs: [2010 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1501 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2007
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2008
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3162
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2010
[06/10/2022-19:21:31] [V] [TRT] Concat_1501 [Concat] inputs: [2007 -> (1)[INT32]], [2008 -> (1)[INT32]], [3162 -> (1)[INT32]], [2010 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3162 for ONNX node: 3162
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1501 for ONNX node: Concat_1501
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2011 for ONNX tensor: 2011
[06/10/2022-19:21:31] [V] [TRT] Concat_1501 [Concat] outputs: [2011 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1502 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2001
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2011
[06/10/2022-19:21:31] [V] [TRT] Reshape_1502 [Reshape] inputs: [2001 -> (-1, 4096, 320)[FLOAT]], [2011 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1502 for ONNX node: Reshape_1502
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2012 for ONNX tensor: 2012
[06/10/2022-19:21:31] [V] [TRT] Reshape_1502 [Reshape] outputs: [2012 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1503 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2012
[06/10/2022-19:21:31] [V] [TRT] Transpose_1503 [Transpose] inputs: [2012 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1503 for ONNX node: Transpose_1503
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2013 for ONNX tensor: 2013
[06/10/2022-19:21:31] [V] [TRT] Transpose_1503 [Transpose] outputs: [2013 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1504 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1989
[06/10/2022-19:21:31] [V] [TRT] Transpose_1504 [Transpose] inputs: [1989 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1504 for ONNX node: Transpose_1504
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2014 for ONNX tensor: 2014
[06/10/2022-19:21:31] [V] [TRT] Transpose_1504 [Transpose] outputs: [2014 -> (-1, 320, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1505 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1992
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1505 [Unsqueeze] inputs: [1992 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1505 for ONNX node: Unsqueeze_1505
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2015 for ONNX tensor: 2015
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1505 [Unsqueeze] outputs: [2015 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1506 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1998
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1506 [Unsqueeze] inputs: [1998 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1506 for ONNX node: Unsqueeze_1506
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2016 for ONNX tensor: 2016
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1506 [Unsqueeze] outputs: [2016 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1507 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1507 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1507 for ONNX node: Unsqueeze_1507
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2017 for ONNX tensor: 2017
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1507 [Unsqueeze] outputs: [2017 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1508 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1508 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1508 for ONNX node: Unsqueeze_1508
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2018 for ONNX tensor: 2018
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1508 [Unsqueeze] outputs: [2018 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1509 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2015
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2016
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2017
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2018
[06/10/2022-19:21:31] [V] [TRT] Concat_1509 [Concat] inputs: [2015 -> (1)[INT32]], [2016 -> (1)[INT32]], [2017 -> (1)[INT32]], [2018 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1509 for ONNX node: Concat_1509
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2019 for ONNX tensor: 2019
[06/10/2022-19:21:31] [V] [TRT] Concat_1509 [Concat] outputs: [2019 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1510 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2014
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2019
[06/10/2022-19:21:31] [V] [TRT] Reshape_1510 [Reshape] inputs: [2014 -> (-1, 320, 4096)[FLOAT]], [2019 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1510 for ONNX node: Reshape_1510
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2020 for ONNX tensor: 2020
[06/10/2022-19:21:31] [V] [TRT] Reshape_1510 [Reshape] outputs: [2020 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Conv_1511 [Conv]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2020
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.attn.sr.weight
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.attn.sr.bias
[06/10/2022-19:21:31] [V] [TRT] Conv_1511 [Conv] inputs: [2020 -> (-1, 320, 64, 64)[FLOAT]], [backbone.block3.3.attn.sr.weight -> (320, 320, 2, 2)[FLOAT]], [backbone.block3.3.attn.sr.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Convolution input dimensions: (-1, 320, 64, 64)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Conv_1511 for ONNX node: Conv_1511
[06/10/2022-19:21:31] [V] [TRT] Using kernel: (2, 2), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 320
[06/10/2022-19:21:31] [V] [TRT] Convolution output dimensions: (-1, 320, 32, 32)
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2021 for ONNX tensor: 2021
[06/10/2022-19:21:31] [V] [TRT] Conv_1511 [Conv] outputs: [2021 -> (-1, 320, 32, 32)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1512 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1992
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1512 [Unsqueeze] inputs: [1992 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1512 for ONNX node: Unsqueeze_1512
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2023 for ONNX tensor: 2023
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1512 [Unsqueeze] outputs: [2023 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1513 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1998
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1513 [Unsqueeze] inputs: [1998 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1513 for ONNX node: Unsqueeze_1513
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2024 for ONNX tensor: 2024
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1513 [Unsqueeze] outputs: [2024 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1514 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2023
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2024
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3163
[06/10/2022-19:21:31] [V] [TRT] Concat_1514 [Concat] inputs: [2023 -> (1)[INT32]], [2024 -> (1)[INT32]], [3163 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3163 for ONNX node: 3163
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1514 for ONNX node: Concat_1514
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2026 for ONNX tensor: 2026
[06/10/2022-19:21:31] [V] [TRT] Concat_1514 [Concat] outputs: [2026 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1515 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2021
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2026
[06/10/2022-19:21:31] [V] [TRT] Reshape_1515 [Reshape] inputs: [2021 -> (-1, 320, 32, 32)[FLOAT]], [2026 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1515 for ONNX node: Reshape_1515
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2027 for ONNX tensor: 2027
[06/10/2022-19:21:31] [V] [TRT] Reshape_1515 [Reshape] outputs: [2027 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1516 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2027
[06/10/2022-19:21:31] [V] [TRT] Transpose_1516 [Transpose] inputs: [2027 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1516 for ONNX node: Transpose_1516
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2028 for ONNX tensor: 2028
[06/10/2022-19:21:31] [V] [TRT] Transpose_1516 [Transpose] outputs: [2028 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1517 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2028
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1517 [ReduceMean] inputs: [2028 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1517 for ONNX node: ReduceMean_1517
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2029 for ONNX tensor: 2029
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1517 [ReduceMean] outputs: [2029 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sub_1518 [Sub]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2028
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2029
[06/10/2022-19:21:31] [V] [TRT] Sub_1518 [Sub] inputs: [2028 -> (-1, 1024, 320)[FLOAT]], [2029 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sub_1518 for ONNX node: Sub_1518
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2030 for ONNX tensor: 2030
[06/10/2022-19:21:31] [V] [TRT] Sub_1518 [Sub] outputs: [2030 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Pow_1520 [Pow]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2030
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2031
[06/10/2022-19:21:31] [V] [TRT] Pow_1520 [Pow] inputs: [2030 -> (-1, 1024, 320)[FLOAT]], [2031 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2031 for ONNX node: 2031
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Pow_1520 for ONNX node: Pow_1520
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2032 for ONNX tensor: 2032
[06/10/2022-19:21:31] [V] [TRT] Pow_1520 [Pow] outputs: [2032 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1521 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2032
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1521 [ReduceMean] inputs: [2032 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1521 for ONNX node: ReduceMean_1521
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2033 for ONNX tensor: 2033
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1521 [ReduceMean] outputs: [2033 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1523 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2033
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2034
[06/10/2022-19:21:31] [V] [TRT] Add_1523 [Add] inputs: [2033 -> (-1, 1024, 1)[FLOAT]], [2034 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2034 for ONNX node: 2034
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1523 for ONNX node: Add_1523
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2035 for ONNX tensor: 2035
[06/10/2022-19:21:31] [V] [TRT] Add_1523 [Add] outputs: [2035 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sqrt_1524 [Sqrt]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2035
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1524 [Sqrt] inputs: [2035 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sqrt_1524 for ONNX node: Sqrt_1524
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2036 for ONNX tensor: 2036
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1524 [Sqrt] outputs: [2036 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1525 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2030
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2036
[06/10/2022-19:21:31] [V] [TRT] Div_1525 [Div] inputs: [2030 -> (-1, 1024, 320)[FLOAT]], [2036 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1525 for ONNX node: Div_1525
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2037 for ONNX tensor: 2037
[06/10/2022-19:21:31] [V] [TRT] Div_1525 [Div] outputs: [2037 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1526 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2037
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.attn.norm.weight
[06/10/2022-19:21:31] [V] [TRT] Mul_1526 [Mul] inputs: [2037 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.3.attn.norm.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.3.attn.norm.weight for ONNX node: backbone.block3.3.attn.norm.weight
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1526 for ONNX node: Mul_1526
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2038 for ONNX tensor: 2038
[06/10/2022-19:21:31] [V] [TRT] Mul_1526 [Mul] outputs: [2038 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1527 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2038
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.attn.norm.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1527 [Add] inputs: [2038 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.3.attn.norm.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.3.attn.norm.bias for ONNX node: backbone.block3.3.attn.norm.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1527 for ONNX node: Add_1527
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2039 for ONNX tensor: 2039
[06/10/2022-19:21:31] [V] [TRT] Add_1527 [Add] outputs: [2039 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1528 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2039
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3164
[06/10/2022-19:21:31] [V] [TRT] MatMul_1528 [MatMul] inputs: [2039 -> (-1, 1024, 320)[FLOAT]], [3164 -> (320, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3164 for ONNX node: 3164
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1528 for ONNX node: MatMul_1528
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2041 for ONNX tensor: 2041
[06/10/2022-19:21:31] [V] [TRT] MatMul_1528 [MatMul] outputs: [2041 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1529 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2041
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.attn.kv.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1529 [Add] inputs: [2041 -> (-1, 1024, 640)[FLOAT]], [backbone.block3.3.attn.kv.bias -> (640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.3.attn.kv.bias for ONNX node: backbone.block3.3.attn.kv.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1529 for ONNX node: Add_1529
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2042 for ONNX tensor: 2042
[06/10/2022-19:21:31] [V] [TRT] Add_1529 [Add] outputs: [2042 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1531 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1998
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2043
[06/10/2022-19:21:31] [V] [TRT] Div_1531 [Div] inputs: [1998 -> ()[INT32]], [2043 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2043 for ONNX node: 2043
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1531 for ONNX node: Div_1531
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2044 for ONNX tensor: 2044
[06/10/2022-19:21:31] [V] [TRT] Div_1531 [Div] outputs: [2044 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1532 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2044
[06/10/2022-19:21:31] [V] [TRT] Cast_1532 [Cast] inputs: [2044 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1532 for ONNX node: Cast_1532
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2045 for ONNX tensor: 2045
[06/10/2022-19:21:31] [V] [TRT] Cast_1532 [Cast] outputs: [2045 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1533 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2045
[06/10/2022-19:21:31] [V] [TRT] Cast_1533 [Cast] inputs: [2045 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1533 for ONNX node: Cast_1533
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2046 for ONNX tensor: 2046
[06/10/2022-19:21:31] [V] [TRT] Cast_1533 [Cast] outputs: [2046 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1534 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1992
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1534 [Unsqueeze] inputs: [1992 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1534 for ONNX node: Unsqueeze_1534
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2050 for ONNX tensor: 2050
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1534 [Unsqueeze] outputs: [2050 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1535 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2046
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1535 [Unsqueeze] inputs: [2046 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1535 for ONNX node: Unsqueeze_1535
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2054 for ONNX tensor: 2054
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1535 [Unsqueeze] outputs: [2054 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1536 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2050
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3165
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3166
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3167
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2054
[06/10/2022-19:21:31] [V] [TRT] Concat_1536 [Concat] inputs: [2050 -> (1)[INT32]], [3165 -> (1)[INT32]], [3166 -> (1)[INT32]], [3167 -> (1)[INT32]], [2054 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3165 for ONNX node: 3165
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3166 for ONNX node: 3166
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3167 for ONNX node: 3167
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1536 for ONNX node: Concat_1536
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2055 for ONNX tensor: 2055
[06/10/2022-19:21:31] [V] [TRT] Concat_1536 [Concat] outputs: [2055 -> (5)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1537 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2042
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2055
[06/10/2022-19:21:31] [V] [TRT] Reshape_1537 [Reshape] inputs: [2042 -> (-1, 1024, 640)[FLOAT]], [2055 -> (5)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1537 for ONNX node: Reshape_1537
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2056 for ONNX tensor: 2056
[06/10/2022-19:21:31] [V] [TRT] Reshape_1537 [Reshape] outputs: [2056 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1538 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2056
[06/10/2022-19:21:31] [V] [TRT] Transpose_1538 [Transpose] inputs: [2056 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1538 for ONNX node: Transpose_1538
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2057 for ONNX tensor: 2057
[06/10/2022-19:21:31] [V] [TRT] Transpose_1538 [Transpose] outputs: [2057 -> (2, -1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1540 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2057
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2058
[06/10/2022-19:21:31] [V] [TRT] Gather_1540 [Gather] inputs: [2057 -> (2, -1, 5, 1024, 64)[FLOAT]], [2058 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2058 for ONNX node: 2058
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1540 for ONNX node: Gather_1540
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2059 for ONNX tensor: 2059
[06/10/2022-19:21:31] [V] [TRT] Gather_1540 [Gather] outputs: [2059 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1542 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2057
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2060
[06/10/2022-19:21:31] [V] [TRT] Gather_1542 [Gather] inputs: [2057 -> (2, -1, 5, 1024, 64)[FLOAT]], [2060 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2060 for ONNX node: 2060
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1542 for ONNX node: Gather_1542
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2061 for ONNX tensor: 2061
[06/10/2022-19:21:31] [V] [TRT] Gather_1542 [Gather] outputs: [2061 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1543 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2059
[06/10/2022-19:21:31] [V] [TRT] Transpose_1543 [Transpose] inputs: [2059 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1543 for ONNX node: Transpose_1543
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2062 for ONNX tensor: 2062
[06/10/2022-19:21:31] [V] [TRT] Transpose_1543 [Transpose] outputs: [2062 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1544 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2013
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2062
[06/10/2022-19:21:31] [V] [TRT] MatMul_1544 [MatMul] inputs: [2013 -> (-1, 5, 4096, 64)[FLOAT]], [2062 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1544 for ONNX node: MatMul_1544
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2063 for ONNX tensor: 2063
[06/10/2022-19:21:31] [V] [TRT] MatMul_1544 [MatMul] outputs: [2063 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1546 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2063
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2064
[06/10/2022-19:21:31] [V] [TRT] Mul_1546 [Mul] inputs: [2063 -> (-1, 5, 4096, 1024)[FLOAT]], [2064 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2064 for ONNX node: 2064
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1546 for ONNX node: Mul_1546
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2065 for ONNX tensor: 2065
[06/10/2022-19:21:31] [V] [TRT] Mul_1546 [Mul] outputs: [2065 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Softmax_1547 [Softmax]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2065
[06/10/2022-19:21:31] [V] [TRT] Softmax_1547 [Softmax] inputs: [2065 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Softmax_1547 for ONNX node: Softmax_1547
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2066 for ONNX tensor: 2066
[06/10/2022-19:21:31] [V] [TRT] Softmax_1547 [Softmax] outputs: [2066 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1548 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2066
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2061
[06/10/2022-19:21:31] [V] [TRT] MatMul_1548 [MatMul] inputs: [2066 -> (-1, 5, 4096, 1024)[FLOAT]], [2061 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1548 for ONNX node: MatMul_1548
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2067 for ONNX tensor: 2067
[06/10/2022-19:21:31] [V] [TRT] MatMul_1548 [MatMul] outputs: [2067 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1549 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2067
[06/10/2022-19:21:31] [V] [TRT] Transpose_1549 [Transpose] inputs: [2067 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1549 for ONNX node: Transpose_1549
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2068 for ONNX tensor: 2068
[06/10/2022-19:21:31] [V] [TRT] Transpose_1549 [Transpose] outputs: [2068 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1550 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1992
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1550 [Unsqueeze] inputs: [1992 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1550 for ONNX node: Unsqueeze_1550
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2069 for ONNX tensor: 2069
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1550 [Unsqueeze] outputs: [2069 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1551 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1995
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1551 [Unsqueeze] inputs: [1995 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1551 for ONNX node: Unsqueeze_1551
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2070 for ONNX tensor: 2070
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1551 [Unsqueeze] outputs: [2070 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1552 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1998
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1552 [Unsqueeze] inputs: [1998 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1552 for ONNX node: Unsqueeze_1552
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2071 for ONNX tensor: 2071
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1552 [Unsqueeze] outputs: [2071 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1553 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2069
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2070
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2071
[06/10/2022-19:21:31] [V] [TRT] Concat_1553 [Concat] inputs: [2069 -> (1)[INT32]], [2070 -> (1)[INT32]], [2071 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1553 for ONNX node: Concat_1553
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2072 for ONNX tensor: 2072
[06/10/2022-19:21:31] [V] [TRT] Concat_1553 [Concat] outputs: [2072 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1554 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2068
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2072
[06/10/2022-19:21:31] [V] [TRT] Reshape_1554 [Reshape] inputs: [2068 -> (-1, 4096, 5, 64)[FLOAT]], [2072 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1554 for ONNX node: Reshape_1554
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2073 for ONNX tensor: 2073
[06/10/2022-19:21:31] [V] [TRT] Reshape_1554 [Reshape] outputs: [2073 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1555 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2073
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3168
[06/10/2022-19:21:31] [V] [TRT] MatMul_1555 [MatMul] inputs: [2073 -> (-1, 4096, 320)[FLOAT]], [3168 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3168 for ONNX node: 3168
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1555 for ONNX node: MatMul_1555
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2075 for ONNX tensor: 2075
[06/10/2022-19:21:31] [V] [TRT] MatMul_1555 [MatMul] outputs: [2075 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1556 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2075
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.attn.proj.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1556 [Add] inputs: [2075 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.3.attn.proj.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.3.attn.proj.bias for ONNX node: backbone.block3.3.attn.proj.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1556 for ONNX node: Add_1556
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2076 for ONNX tensor: 2076
[06/10/2022-19:21:31] [V] [TRT] Add_1556 [Add] outputs: [2076 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1557 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1978
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2076
[06/10/2022-19:21:31] [V] [TRT] Add_1557 [Add] inputs: [1978 -> (-1, 4096, 320)[FLOAT]], [2076 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1557 for ONNX node: Add_1557
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2077 for ONNX tensor: 2077
[06/10/2022-19:21:31] [V] [TRT] Add_1557 [Add] outputs: [2077 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1558 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2077
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1558 [ReduceMean] inputs: [2077 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1558 for ONNX node: ReduceMean_1558
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2078 for ONNX tensor: 2078
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1558 [ReduceMean] outputs: [2078 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sub_1559 [Sub]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2077
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2078
[06/10/2022-19:21:31] [V] [TRT] Sub_1559 [Sub] inputs: [2077 -> (-1, 4096, 320)[FLOAT]], [2078 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sub_1559 for ONNX node: Sub_1559
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2079 for ONNX tensor: 2079
[06/10/2022-19:21:31] [V] [TRT] Sub_1559 [Sub] outputs: [2079 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Pow_1561 [Pow]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2079
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2080
[06/10/2022-19:21:31] [V] [TRT] Pow_1561 [Pow] inputs: [2079 -> (-1, 4096, 320)[FLOAT]], [2080 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2080 for ONNX node: 2080
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Pow_1561 for ONNX node: Pow_1561
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2081 for ONNX tensor: 2081
[06/10/2022-19:21:31] [V] [TRT] Pow_1561 [Pow] outputs: [2081 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1562 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2081
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1562 [ReduceMean] inputs: [2081 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1562 for ONNX node: ReduceMean_1562
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2082 for ONNX tensor: 2082
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1562 [ReduceMean] outputs: [2082 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1564 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2082
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2083
[06/10/2022-19:21:31] [V] [TRT] Add_1564 [Add] inputs: [2082 -> (-1, 4096, 1)[FLOAT]], [2083 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2083 for ONNX node: 2083
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1564 for ONNX node: Add_1564
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2084 for ONNX tensor: 2084
[06/10/2022-19:21:31] [V] [TRT] Add_1564 [Add] outputs: [2084 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sqrt_1565 [Sqrt]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2084
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1565 [Sqrt] inputs: [2084 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sqrt_1565 for ONNX node: Sqrt_1565
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2085 for ONNX tensor: 2085
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1565 [Sqrt] outputs: [2085 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1566 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2079
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2085
[06/10/2022-19:21:31] [V] [TRT] Div_1566 [Div] inputs: [2079 -> (-1, 4096, 320)[FLOAT]], [2085 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1566 for ONNX node: Div_1566
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2086 for ONNX tensor: 2086
[06/10/2022-19:21:31] [V] [TRT] Div_1566 [Div] outputs: [2086 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1567 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2086
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.norm2.weight
[06/10/2022-19:21:31] [V] [TRT] Mul_1567 [Mul] inputs: [2086 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.3.norm2.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.3.norm2.weight for ONNX node: backbone.block3.3.norm2.weight
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1567 for ONNX node: Mul_1567
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2087 for ONNX tensor: 2087
[06/10/2022-19:21:31] [V] [TRT] Mul_1567 [Mul] outputs: [2087 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1568 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2087
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.norm2.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1568 [Add] inputs: [2087 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.3.norm2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.3.norm2.bias for ONNX node: backbone.block3.3.norm2.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1568 for ONNX node: Add_1568
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2088 for ONNX tensor: 2088
[06/10/2022-19:21:31] [V] [TRT] Add_1568 [Add] outputs: [2088 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1569 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2088
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3169
[06/10/2022-19:21:31] [V] [TRT] MatMul_1569 [MatMul] inputs: [2088 -> (-1, 4096, 320)[FLOAT]], [3169 -> (320, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3169 for ONNX node: 3169
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1569 for ONNX node: MatMul_1569
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2090 for ONNX tensor: 2090
[06/10/2022-19:21:31] [V] [TRT] MatMul_1569 [MatMul] outputs: [2090 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1570 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2090
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.mlp.fc1.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1570 [Add] inputs: [2090 -> (-1, 4096, 1280)[FLOAT]], [backbone.block3.3.mlp.fc1.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.3.mlp.fc1.bias for ONNX node: backbone.block3.3.mlp.fc1.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1570 for ONNX node: Add_1570
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2091 for ONNX tensor: 2091
[06/10/2022-19:21:31] [V] [TRT] Add_1570 [Add] outputs: [2091 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1571 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2091
[06/10/2022-19:21:31] [V] [TRT] Shape_1571 [Shape] inputs: [2091 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1571 for ONNX node: Shape_1571
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2092 for ONNX tensor: 2092
[06/10/2022-19:21:31] [V] [TRT] Shape_1571 [Shape] outputs: [2092 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1573 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2092
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2093
[06/10/2022-19:21:31] [V] [TRT] Gather_1573 [Gather] inputs: [2092 -> (3)[INT32]], [2093 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2093 for ONNX node: 2093
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1573 for ONNX node: Gather_1573
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2094 for ONNX tensor: 2094
[06/10/2022-19:21:31] [V] [TRT] Gather_1573 [Gather] outputs: [2094 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1574 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2091
[06/10/2022-19:21:31] [V] [TRT] Shape_1574 [Shape] inputs: [2091 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1574 for ONNX node: Shape_1574
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2095 for ONNX tensor: 2095
[06/10/2022-19:21:31] [V] [TRT] Shape_1574 [Shape] outputs: [2095 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1576 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2095
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2096
[06/10/2022-19:21:31] [V] [TRT] Gather_1576 [Gather] inputs: [2095 -> (3)[INT32]], [2096 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2096 for ONNX node: 2096
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1576 for ONNX node: Gather_1576
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2097 for ONNX tensor: 2097
[06/10/2022-19:21:31] [V] [TRT] Gather_1576 [Gather] outputs: [2097 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1577 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2091
[06/10/2022-19:21:31] [V] [TRT] Transpose_1577 [Transpose] inputs: [2091 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1577 for ONNX node: Transpose_1577
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2098 for ONNX tensor: 2098
[06/10/2022-19:21:31] [V] [TRT] Transpose_1577 [Transpose] outputs: [2098 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1578 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2094
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1578 [Unsqueeze] inputs: [2094 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1578 for ONNX node: Unsqueeze_1578
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2099 for ONNX tensor: 2099
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1578 [Unsqueeze] outputs: [2099 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1579 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2097
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1579 [Unsqueeze] inputs: [2097 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1579 for ONNX node: Unsqueeze_1579
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2100 for ONNX tensor: 2100
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1579 [Unsqueeze] outputs: [2100 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1580 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1580 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1580 for ONNX node: Unsqueeze_1580
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2101 for ONNX tensor: 2101
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1580 [Unsqueeze] outputs: [2101 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1581 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1581 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1581 for ONNX node: Unsqueeze_1581
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2102 for ONNX tensor: 2102
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1581 [Unsqueeze] outputs: [2102 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1582 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2099
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2100
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2101
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2102
[06/10/2022-19:21:31] [V] [TRT] Concat_1582 [Concat] inputs: [2099 -> (1)[INT32]], [2100 -> (1)[INT32]], [2101 -> (1)[INT32]], [2102 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1582 for ONNX node: Concat_1582
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2103 for ONNX tensor: 2103
[06/10/2022-19:21:31] [V] [TRT] Concat_1582 [Concat] outputs: [2103 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1583 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2098
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2103
[06/10/2022-19:21:31] [V] [TRT] Reshape_1583 [Reshape] inputs: [2098 -> (-1, 1280, 4096)[FLOAT]], [2103 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1583 for ONNX node: Reshape_1583
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2104 for ONNX tensor: 2104
[06/10/2022-19:21:31] [V] [TRT] Reshape_1583 [Reshape] outputs: [2104 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Conv_1584 [Conv]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2104
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:31] [V] [TRT] Conv_1584 [Conv] inputs: [2104 -> (-1, 1280, 64, 64)[FLOAT]], [backbone.block3.3.mlp.dwconv.dwconv.weight -> (1280, 1, 3, 3)[FLOAT]], [backbone.block3.3.mlp.dwconv.dwconv.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Convolution input dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Conv_1584 for ONNX node: Conv_1584
[06/10/2022-19:21:31] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1280
[06/10/2022-19:21:31] [V] [TRT] Convolution output dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2105 for ONNX tensor: 2105
[06/10/2022-19:21:31] [V] [TRT] Conv_1584 [Conv] outputs: [2105 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1585 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2105
[06/10/2022-19:21:31] [V] [TRT] Shape_1585 [Shape] inputs: [2105 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1585 for ONNX node: Shape_1585
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2106 for ONNX tensor: 2106
[06/10/2022-19:21:31] [V] [TRT] Shape_1585 [Shape] outputs: [2106 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Slice_1589 [Slice]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2106
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2108
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2109
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2107
[06/10/2022-19:21:31] [V] [TRT] Slice_1589 [Slice] inputs: [2106 -> (4)[INT32]], [2108 -> (1)[INT32]], [2109 -> (1)[INT32]], [2107 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Slice_1589 for ONNX node: Slice_1589
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2110 for ONNX tensor: 2110
[06/10/2022-19:21:31] [V] [TRT] Slice_1589 [Slice] outputs: [2110 -> (2)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1591 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2110
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2111
[06/10/2022-19:21:31] [V] [TRT] Concat_1591 [Concat] inputs: [2110 -> (2)[INT32]], [2111 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2111 for ONNX node: 2111
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1591 for ONNX node: Concat_1591
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2112 for ONNX tensor: 2112
[06/10/2022-19:21:31] [V] [TRT] Concat_1591 [Concat] outputs: [2112 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1592 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2105
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2112
[06/10/2022-19:21:31] [V] [TRT] Reshape_1592 [Reshape] inputs: [2105 -> (-1, 1280, 64, 64)[FLOAT]], [2112 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1592 for ONNX node: Reshape_1592
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2113 for ONNX tensor: 2113
[06/10/2022-19:21:31] [V] [TRT] Reshape_1592 [Reshape] outputs: [2113 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1593 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2113
[06/10/2022-19:21:31] [V] [TRT] Transpose_1593 [Transpose] inputs: [2113 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1593 for ONNX node: Transpose_1593
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2114 for ONNX tensor: 2114
[06/10/2022-19:21:31] [V] [TRT] Transpose_1593 [Transpose] outputs: [2114 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1595 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2114
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2115
[06/10/2022-19:21:31] [V] [TRT] Div_1595 [Div] inputs: [2114 -> (-1, 4096, 1280)[FLOAT]], [2115 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2115 for ONNX node: 2115
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1595 for ONNX node: Div_1595
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2116 for ONNX tensor: 2116
[06/10/2022-19:21:31] [V] [TRT] Div_1595 [Div] outputs: [2116 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Erf_1596 [Erf]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2116
[06/10/2022-19:21:31] [V] [TRT] Erf_1596 [Erf] inputs: [2116 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Erf_1596 for ONNX node: Erf_1596
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2117 for ONNX tensor: 2117
[06/10/2022-19:21:31] [V] [TRT] Erf_1596 [Erf] outputs: [2117 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1598 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2117
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2118
[06/10/2022-19:21:31] [V] [TRT] Add_1598 [Add] inputs: [2117 -> (-1, 4096, 1280)[FLOAT]], [2118 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2118 for ONNX node: 2118
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1598 for ONNX node: Add_1598
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2119 for ONNX tensor: 2119
[06/10/2022-19:21:31] [V] [TRT] Add_1598 [Add] outputs: [2119 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1599 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2114
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2119
[06/10/2022-19:21:31] [V] [TRT] Mul_1599 [Mul] inputs: [2114 -> (-1, 4096, 1280)[FLOAT]], [2119 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1599 for ONNX node: Mul_1599
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2120 for ONNX tensor: 2120
[06/10/2022-19:21:31] [V] [TRT] Mul_1599 [Mul] outputs: [2120 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1601 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2120
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2121
[06/10/2022-19:21:31] [V] [TRT] Mul_1601 [Mul] inputs: [2120 -> (-1, 4096, 1280)[FLOAT]], [2121 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2121 for ONNX node: 2121
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1601 for ONNX node: Mul_1601
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2122 for ONNX tensor: 2122
[06/10/2022-19:21:31] [V] [TRT] Mul_1601 [Mul] outputs: [2122 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1602 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2122
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3170
[06/10/2022-19:21:31] [V] [TRT] MatMul_1602 [MatMul] inputs: [2122 -> (-1, 4096, 1280)[FLOAT]], [3170 -> (1280, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3170 for ONNX node: 3170
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1602 for ONNX node: MatMul_1602
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2124 for ONNX tensor: 2124
[06/10/2022-19:21:31] [V] [TRT] MatMul_1602 [MatMul] outputs: [2124 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1603 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2124
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.3.mlp.fc2.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1603 [Add] inputs: [2124 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.3.mlp.fc2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.3.mlp.fc2.bias for ONNX node: backbone.block3.3.mlp.fc2.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1603 for ONNX node: Add_1603
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2125 for ONNX tensor: 2125
[06/10/2022-19:21:31] [V] [TRT] Add_1603 [Add] outputs: [2125 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1604 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2077
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2125
[06/10/2022-19:21:31] [V] [TRT] Add_1604 [Add] inputs: [2077 -> (-1, 4096, 320)[FLOAT]], [2125 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1604 for ONNX node: Add_1604
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2126 for ONNX tensor: 2126
[06/10/2022-19:21:31] [V] [TRT] Add_1604 [Add] outputs: [2126 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1605 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2126
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1605 [ReduceMean] inputs: [2126 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1605 for ONNX node: ReduceMean_1605
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2127 for ONNX tensor: 2127
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1605 [ReduceMean] outputs: [2127 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sub_1606 [Sub]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2126
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2127
[06/10/2022-19:21:31] [V] [TRT] Sub_1606 [Sub] inputs: [2126 -> (-1, 4096, 320)[FLOAT]], [2127 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sub_1606 for ONNX node: Sub_1606
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2128 for ONNX tensor: 2128
[06/10/2022-19:21:31] [V] [TRT] Sub_1606 [Sub] outputs: [2128 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Pow_1608 [Pow]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2128
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2129
[06/10/2022-19:21:31] [V] [TRT] Pow_1608 [Pow] inputs: [2128 -> (-1, 4096, 320)[FLOAT]], [2129 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2129 for ONNX node: 2129
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Pow_1608 for ONNX node: Pow_1608
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2130 for ONNX tensor: 2130
[06/10/2022-19:21:31] [V] [TRT] Pow_1608 [Pow] outputs: [2130 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1609 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2130
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1609 [ReduceMean] inputs: [2130 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1609 for ONNX node: ReduceMean_1609
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2131 for ONNX tensor: 2131
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1609 [ReduceMean] outputs: [2131 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1611 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2131
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2132
[06/10/2022-19:21:31] [V] [TRT] Add_1611 [Add] inputs: [2131 -> (-1, 4096, 1)[FLOAT]], [2132 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2132 for ONNX node: 2132
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1611 for ONNX node: Add_1611
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2133 for ONNX tensor: 2133
[06/10/2022-19:21:31] [V] [TRT] Add_1611 [Add] outputs: [2133 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sqrt_1612 [Sqrt]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2133
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1612 [Sqrt] inputs: [2133 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sqrt_1612 for ONNX node: Sqrt_1612
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2134 for ONNX tensor: 2134
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1612 [Sqrt] outputs: [2134 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1613 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2128
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2134
[06/10/2022-19:21:31] [V] [TRT] Div_1613 [Div] inputs: [2128 -> (-1, 4096, 320)[FLOAT]], [2134 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1613 for ONNX node: Div_1613
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2135 for ONNX tensor: 2135
[06/10/2022-19:21:31] [V] [TRT] Div_1613 [Div] outputs: [2135 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1614 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2135
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.4.norm1.weight
[06/10/2022-19:21:31] [V] [TRT] Mul_1614 [Mul] inputs: [2135 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.4.norm1.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.4.norm1.weight for ONNX node: backbone.block3.4.norm1.weight
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1614 for ONNX node: Mul_1614
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2136 for ONNX tensor: 2136
[06/10/2022-19:21:31] [V] [TRT] Mul_1614 [Mul] outputs: [2136 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1615 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2136
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.4.norm1.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1615 [Add] inputs: [2136 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.4.norm1.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.4.norm1.bias for ONNX node: backbone.block3.4.norm1.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1615 for ONNX node: Add_1615
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2137 for ONNX tensor: 2137
[06/10/2022-19:21:31] [V] [TRT] Add_1615 [Add] outputs: [2137 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1616 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2137
[06/10/2022-19:21:31] [V] [TRT] Shape_1616 [Shape] inputs: [2137 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1616 for ONNX node: Shape_1616
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2138 for ONNX tensor: 2138
[06/10/2022-19:21:31] [V] [TRT] Shape_1616 [Shape] outputs: [2138 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1618 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2138
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2139
[06/10/2022-19:21:31] [V] [TRT] Gather_1618 [Gather] inputs: [2138 -> (3)[INT32]], [2139 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2139 for ONNX node: 2139
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1618 for ONNX node: Gather_1618
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2140 for ONNX tensor: 2140
[06/10/2022-19:21:31] [V] [TRT] Gather_1618 [Gather] outputs: [2140 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1619 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2137
[06/10/2022-19:21:31] [V] [TRT] Shape_1619 [Shape] inputs: [2137 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1619 for ONNX node: Shape_1619
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2141 for ONNX tensor: 2141
[06/10/2022-19:21:31] [V] [TRT] Shape_1619 [Shape] outputs: [2141 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1621 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2141
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2142
[06/10/2022-19:21:31] [V] [TRT] Gather_1621 [Gather] inputs: [2141 -> (3)[INT32]], [2142 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2142 for ONNX node: 2142
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1621 for ONNX node: Gather_1621
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2143 for ONNX tensor: 2143
[06/10/2022-19:21:31] [V] [TRT] Gather_1621 [Gather] outputs: [2143 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Shape_1622 [Shape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2137
[06/10/2022-19:21:31] [V] [TRT] Shape_1622 [Shape] inputs: [2137 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Shape_1622 for ONNX node: Shape_1622
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2144 for ONNX tensor: 2144
[06/10/2022-19:21:31] [V] [TRT] Shape_1622 [Shape] outputs: [2144 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1624 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2144
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2145
[06/10/2022-19:21:31] [V] [TRT] Gather_1624 [Gather] inputs: [2144 -> (3)[INT32]], [2145 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2145 for ONNX node: 2145
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1624 for ONNX node: Gather_1624
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2146 for ONNX tensor: 2146
[06/10/2022-19:21:31] [V] [TRT] Gather_1624 [Gather] outputs: [2146 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1625 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2137
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3171
[06/10/2022-19:21:31] [V] [TRT] MatMul_1625 [MatMul] inputs: [2137 -> (-1, 4096, 320)[FLOAT]], [3171 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3171 for ONNX node: 3171
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1625 for ONNX node: MatMul_1625
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2148 for ONNX tensor: 2148
[06/10/2022-19:21:31] [V] [TRT] MatMul_1625 [MatMul] outputs: [2148 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1626 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2148
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.4.attn.q.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1626 [Add] inputs: [2148 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.4.attn.q.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.4.attn.q.bias for ONNX node: backbone.block3.4.attn.q.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1626 for ONNX node: Add_1626
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2149 for ONNX tensor: 2149
[06/10/2022-19:21:31] [V] [TRT] Add_1626 [Add] outputs: [2149 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1628 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2146
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2150
[06/10/2022-19:21:31] [V] [TRT] Div_1628 [Div] inputs: [2146 -> ()[INT32]], [2150 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2150 for ONNX node: 2150
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1628 for ONNX node: Div_1628
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2151 for ONNX tensor: 2151
[06/10/2022-19:21:31] [V] [TRT] Div_1628 [Div] outputs: [2151 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1629 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2151
[06/10/2022-19:21:31] [V] [TRT] Cast_1629 [Cast] inputs: [2151 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1629 for ONNX node: Cast_1629
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2152 for ONNX tensor: 2152
[06/10/2022-19:21:31] [V] [TRT] Cast_1629 [Cast] outputs: [2152 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1630 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2152
[06/10/2022-19:21:31] [V] [TRT] Cast_1630 [Cast] inputs: [2152 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1630 for ONNX node: Cast_1630
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2153 for ONNX tensor: 2153
[06/10/2022-19:21:31] [V] [TRT] Cast_1630 [Cast] outputs: [2153 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1631 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2140
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1631 [Unsqueeze] inputs: [2140 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1631 for ONNX node: Unsqueeze_1631
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2155 for ONNX tensor: 2155
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1631 [Unsqueeze] outputs: [2155 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1632 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2143
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1632 [Unsqueeze] inputs: [2143 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1632 for ONNX node: Unsqueeze_1632
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2156 for ONNX tensor: 2156
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1632 [Unsqueeze] outputs: [2156 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1633 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2153
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1633 [Unsqueeze] inputs: [2153 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1633 for ONNX node: Unsqueeze_1633
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2158 for ONNX tensor: 2158
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1633 [Unsqueeze] outputs: [2158 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1634 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2155
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2156
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3172
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2158
[06/10/2022-19:21:31] [V] [TRT] Concat_1634 [Concat] inputs: [2155 -> (1)[INT32]], [2156 -> (1)[INT32]], [3172 -> (1)[INT32]], [2158 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3172 for ONNX node: 3172
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1634 for ONNX node: Concat_1634
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2159 for ONNX tensor: 2159
[06/10/2022-19:21:31] [V] [TRT] Concat_1634 [Concat] outputs: [2159 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1635 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2149
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2159
[06/10/2022-19:21:31] [V] [TRT] Reshape_1635 [Reshape] inputs: [2149 -> (-1, 4096, 320)[FLOAT]], [2159 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1635 for ONNX node: Reshape_1635
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2160 for ONNX tensor: 2160
[06/10/2022-19:21:31] [V] [TRT] Reshape_1635 [Reshape] outputs: [2160 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1636 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2160
[06/10/2022-19:21:31] [V] [TRT] Transpose_1636 [Transpose] inputs: [2160 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1636 for ONNX node: Transpose_1636
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2161 for ONNX tensor: 2161
[06/10/2022-19:21:31] [V] [TRT] Transpose_1636 [Transpose] outputs: [2161 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1637 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2137
[06/10/2022-19:21:31] [V] [TRT] Transpose_1637 [Transpose] inputs: [2137 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1637 for ONNX node: Transpose_1637
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2162 for ONNX tensor: 2162
[06/10/2022-19:21:31] [V] [TRT] Transpose_1637 [Transpose] outputs: [2162 -> (-1, 320, 4096)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1638 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2140
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1638 [Unsqueeze] inputs: [2140 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1638 for ONNX node: Unsqueeze_1638
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2163 for ONNX tensor: 2163
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1638 [Unsqueeze] outputs: [2163 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1639 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2146
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1639 [Unsqueeze] inputs: [2146 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1639 for ONNX node: Unsqueeze_1639
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2164 for ONNX tensor: 2164
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1639 [Unsqueeze] outputs: [2164 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1640 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1640 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1640 for ONNX node: Unsqueeze_1640
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2165 for ONNX tensor: 2165
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1640 [Unsqueeze] outputs: [2165 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1641 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1641 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1641 for ONNX node: Unsqueeze_1641
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2166 for ONNX tensor: 2166
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1641 [Unsqueeze] outputs: [2166 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1642 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2163
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2164
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2165
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2166
[06/10/2022-19:21:31] [V] [TRT] Concat_1642 [Concat] inputs: [2163 -> (1)[INT32]], [2164 -> (1)[INT32]], [2165 -> (1)[INT32]], [2166 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1642 for ONNX node: Concat_1642
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2167 for ONNX tensor: 2167
[06/10/2022-19:21:31] [V] [TRT] Concat_1642 [Concat] outputs: [2167 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1643 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2162
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2167
[06/10/2022-19:21:31] [V] [TRT] Reshape_1643 [Reshape] inputs: [2162 -> (-1, 320, 4096)[FLOAT]], [2167 -> (4)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1643 for ONNX node: Reshape_1643
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2168 for ONNX tensor: 2168
[06/10/2022-19:21:31] [V] [TRT] Reshape_1643 [Reshape] outputs: [2168 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Conv_1644 [Conv]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2168
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.4.attn.sr.weight
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.4.attn.sr.bias
[06/10/2022-19:21:31] [V] [TRT] Conv_1644 [Conv] inputs: [2168 -> (-1, 320, 64, 64)[FLOAT]], [backbone.block3.4.attn.sr.weight -> (320, 320, 2, 2)[FLOAT]], [backbone.block3.4.attn.sr.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Convolution input dimensions: (-1, 320, 64, 64)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Conv_1644 for ONNX node: Conv_1644
[06/10/2022-19:21:31] [V] [TRT] Using kernel: (2, 2), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 320
[06/10/2022-19:21:31] [V] [TRT] Convolution output dimensions: (-1, 320, 32, 32)
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2169 for ONNX tensor: 2169
[06/10/2022-19:21:31] [V] [TRT] Conv_1644 [Conv] outputs: [2169 -> (-1, 320, 32, 32)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1645 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2140
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1645 [Unsqueeze] inputs: [2140 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1645 for ONNX node: Unsqueeze_1645
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2171 for ONNX tensor: 2171
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1645 [Unsqueeze] outputs: [2171 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1646 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2146
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1646 [Unsqueeze] inputs: [2146 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1646 for ONNX node: Unsqueeze_1646
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2172 for ONNX tensor: 2172
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1646 [Unsqueeze] outputs: [2172 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1647 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2171
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2172
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3173
[06/10/2022-19:21:31] [V] [TRT] Concat_1647 [Concat] inputs: [2171 -> (1)[INT32]], [2172 -> (1)[INT32]], [3173 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3173 for ONNX node: 3173
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1647 for ONNX node: Concat_1647
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2174 for ONNX tensor: 2174
[06/10/2022-19:21:31] [V] [TRT] Concat_1647 [Concat] outputs: [2174 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1648 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2169
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2174
[06/10/2022-19:21:31] [V] [TRT] Reshape_1648 [Reshape] inputs: [2169 -> (-1, 320, 32, 32)[FLOAT]], [2174 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1648 for ONNX node: Reshape_1648
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2175 for ONNX tensor: 2175
[06/10/2022-19:21:31] [V] [TRT] Reshape_1648 [Reshape] outputs: [2175 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1649 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2175
[06/10/2022-19:21:31] [V] [TRT] Transpose_1649 [Transpose] inputs: [2175 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1649 for ONNX node: Transpose_1649
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2176 for ONNX tensor: 2176
[06/10/2022-19:21:31] [V] [TRT] Transpose_1649 [Transpose] outputs: [2176 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1650 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2176
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1650 [ReduceMean] inputs: [2176 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1650 for ONNX node: ReduceMean_1650
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2177 for ONNX tensor: 2177
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1650 [ReduceMean] outputs: [2177 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sub_1651 [Sub]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2176
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2177
[06/10/2022-19:21:31] [V] [TRT] Sub_1651 [Sub] inputs: [2176 -> (-1, 1024, 320)[FLOAT]], [2177 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sub_1651 for ONNX node: Sub_1651
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2178 for ONNX tensor: 2178
[06/10/2022-19:21:31] [V] [TRT] Sub_1651 [Sub] outputs: [2178 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Pow_1653 [Pow]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2178
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2179
[06/10/2022-19:21:31] [V] [TRT] Pow_1653 [Pow] inputs: [2178 -> (-1, 1024, 320)[FLOAT]], [2179 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2179 for ONNX node: 2179
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Pow_1653 for ONNX node: Pow_1653
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2180 for ONNX tensor: 2180
[06/10/2022-19:21:31] [V] [TRT] Pow_1653 [Pow] outputs: [2180 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1654 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2180
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1654 [ReduceMean] inputs: [2180 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1654 for ONNX node: ReduceMean_1654
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2181 for ONNX tensor: 2181
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1654 [ReduceMean] outputs: [2181 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1656 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2181
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2182
[06/10/2022-19:21:31] [V] [TRT] Add_1656 [Add] inputs: [2181 -> (-1, 1024, 1)[FLOAT]], [2182 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2182 for ONNX node: 2182
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1656 for ONNX node: Add_1656
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2183 for ONNX tensor: 2183
[06/10/2022-19:21:31] [V] [TRT] Add_1656 [Add] outputs: [2183 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sqrt_1657 [Sqrt]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2183
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1657 [Sqrt] inputs: [2183 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sqrt_1657 for ONNX node: Sqrt_1657
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2184 for ONNX tensor: 2184
[06/10/2022-19:21:31] [V] [TRT] Sqrt_1657 [Sqrt] outputs: [2184 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1658 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2178
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2184
[06/10/2022-19:21:31] [V] [TRT] Div_1658 [Div] inputs: [2178 -> (-1, 1024, 320)[FLOAT]], [2184 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1658 for ONNX node: Div_1658
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2185 for ONNX tensor: 2185
[06/10/2022-19:21:31] [V] [TRT] Div_1658 [Div] outputs: [2185 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1659 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2185
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.4.attn.norm.weight
[06/10/2022-19:21:31] [V] [TRT] Mul_1659 [Mul] inputs: [2185 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.4.attn.norm.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.4.attn.norm.weight for ONNX node: backbone.block3.4.attn.norm.weight
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1659 for ONNX node: Mul_1659
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2186 for ONNX tensor: 2186
[06/10/2022-19:21:31] [V] [TRT] Mul_1659 [Mul] outputs: [2186 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1660 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2186
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.4.attn.norm.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1660 [Add] inputs: [2186 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.4.attn.norm.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.4.attn.norm.bias for ONNX node: backbone.block3.4.attn.norm.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1660 for ONNX node: Add_1660
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2187 for ONNX tensor: 2187
[06/10/2022-19:21:31] [V] [TRT] Add_1660 [Add] outputs: [2187 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1661 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2187
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3174
[06/10/2022-19:21:31] [V] [TRT] MatMul_1661 [MatMul] inputs: [2187 -> (-1, 1024, 320)[FLOAT]], [3174 -> (320, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3174 for ONNX node: 3174
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1661 for ONNX node: MatMul_1661
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2189 for ONNX tensor: 2189
[06/10/2022-19:21:31] [V] [TRT] MatMul_1661 [MatMul] outputs: [2189 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1662 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2189
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.4.attn.kv.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1662 [Add] inputs: [2189 -> (-1, 1024, 640)[FLOAT]], [backbone.block3.4.attn.kv.bias -> (640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.4.attn.kv.bias for ONNX node: backbone.block3.4.attn.kv.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1662 for ONNX node: Add_1662
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2190 for ONNX tensor: 2190
[06/10/2022-19:21:31] [V] [TRT] Add_1662 [Add] outputs: [2190 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Div_1664 [Div]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2146
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2191
[06/10/2022-19:21:31] [V] [TRT] Div_1664 [Div] inputs: [2146 -> ()[INT32]], [2191 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2191 for ONNX node: 2191
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Div_1664 for ONNX node: Div_1664
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2192 for ONNX tensor: 2192
[06/10/2022-19:21:31] [V] [TRT] Div_1664 [Div] outputs: [2192 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1665 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2192
[06/10/2022-19:21:31] [V] [TRT] Cast_1665 [Cast] inputs: [2192 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1665 for ONNX node: Cast_1665
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2193 for ONNX tensor: 2193
[06/10/2022-19:21:31] [V] [TRT] Cast_1665 [Cast] outputs: [2193 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Cast_1666 [Cast]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2193
[06/10/2022-19:21:31] [V] [TRT] Cast_1666 [Cast] inputs: [2193 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Cast_1666 for ONNX node: Cast_1666
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2194 for ONNX tensor: 2194
[06/10/2022-19:21:31] [V] [TRT] Cast_1666 [Cast] outputs: [2194 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1667 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2140
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1667 [Unsqueeze] inputs: [2140 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1667 for ONNX node: Unsqueeze_1667
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2198 for ONNX tensor: 2198
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1667 [Unsqueeze] outputs: [2198 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1668 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2194
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1668 [Unsqueeze] inputs: [2194 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1668 for ONNX node: Unsqueeze_1668
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2202 for ONNX tensor: 2202
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1668 [Unsqueeze] outputs: [2202 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1669 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2198
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3175
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3176
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3177
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2202
[06/10/2022-19:21:31] [V] [TRT] Concat_1669 [Concat] inputs: [2198 -> (1)[INT32]], [3175 -> (1)[INT32]], [3176 -> (1)[INT32]], [3177 -> (1)[INT32]], [2202 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3175 for ONNX node: 3175
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3176 for ONNX node: 3176
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3177 for ONNX node: 3177
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1669 for ONNX node: Concat_1669
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2203 for ONNX tensor: 2203
[06/10/2022-19:21:31] [V] [TRT] Concat_1669 [Concat] outputs: [2203 -> (5)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1670 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2190
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2203
[06/10/2022-19:21:31] [V] [TRT] Reshape_1670 [Reshape] inputs: [2190 -> (-1, 1024, 640)[FLOAT]], [2203 -> (5)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1670 for ONNX node: Reshape_1670
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2204 for ONNX tensor: 2204
[06/10/2022-19:21:31] [V] [TRT] Reshape_1670 [Reshape] outputs: [2204 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1671 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2204
[06/10/2022-19:21:31] [V] [TRT] Transpose_1671 [Transpose] inputs: [2204 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1671 for ONNX node: Transpose_1671
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2205 for ONNX tensor: 2205
[06/10/2022-19:21:31] [V] [TRT] Transpose_1671 [Transpose] outputs: [2205 -> (2, -1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1673 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2205
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2206
[06/10/2022-19:21:31] [V] [TRT] Gather_1673 [Gather] inputs: [2205 -> (2, -1, 5, 1024, 64)[FLOAT]], [2206 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2206 for ONNX node: 2206
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1673 for ONNX node: Gather_1673
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2207 for ONNX tensor: 2207
[06/10/2022-19:21:31] [V] [TRT] Gather_1673 [Gather] outputs: [2207 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Gather_1675 [Gather]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2205
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2208
[06/10/2022-19:21:31] [V] [TRT] Gather_1675 [Gather] inputs: [2205 -> (2, -1, 5, 1024, 64)[FLOAT]], [2208 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2208 for ONNX node: 2208
[06/10/2022-19:21:31] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Gather_1675 for ONNX node: Gather_1675
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2209 for ONNX tensor: 2209
[06/10/2022-19:21:31] [V] [TRT] Gather_1675 [Gather] outputs: [2209 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1676 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2207
[06/10/2022-19:21:31] [V] [TRT] Transpose_1676 [Transpose] inputs: [2207 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1676 for ONNX node: Transpose_1676
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2210 for ONNX tensor: 2210
[06/10/2022-19:21:31] [V] [TRT] Transpose_1676 [Transpose] outputs: [2210 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1677 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2161
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2210
[06/10/2022-19:21:31] [V] [TRT] MatMul_1677 [MatMul] inputs: [2161 -> (-1, 5, 4096, 64)[FLOAT]], [2210 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1677 for ONNX node: MatMul_1677
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2211 for ONNX tensor: 2211
[06/10/2022-19:21:31] [V] [TRT] MatMul_1677 [MatMul] outputs: [2211 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Mul_1679 [Mul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2211
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2212
[06/10/2022-19:21:31] [V] [TRT] Mul_1679 [Mul] inputs: [2211 -> (-1, 5, 4096, 1024)[FLOAT]], [2212 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2212 for ONNX node: 2212
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Mul_1679 for ONNX node: Mul_1679
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2213 for ONNX tensor: 2213
[06/10/2022-19:21:31] [V] [TRT] Mul_1679 [Mul] outputs: [2213 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Softmax_1680 [Softmax]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2213
[06/10/2022-19:21:31] [V] [TRT] Softmax_1680 [Softmax] inputs: [2213 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Softmax_1680 for ONNX node: Softmax_1680
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2214 for ONNX tensor: 2214
[06/10/2022-19:21:31] [V] [TRT] Softmax_1680 [Softmax] outputs: [2214 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1681 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2214
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2209
[06/10/2022-19:21:31] [V] [TRT] MatMul_1681 [MatMul] inputs: [2214 -> (-1, 5, 4096, 1024)[FLOAT]], [2209 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1681 for ONNX node: MatMul_1681
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2215 for ONNX tensor: 2215
[06/10/2022-19:21:31] [V] [TRT] MatMul_1681 [MatMul] outputs: [2215 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Transpose_1682 [Transpose]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2215
[06/10/2022-19:21:31] [V] [TRT] Transpose_1682 [Transpose] inputs: [2215 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Transpose_1682 for ONNX node: Transpose_1682
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2216 for ONNX tensor: 2216
[06/10/2022-19:21:31] [V] [TRT] Transpose_1682 [Transpose] outputs: [2216 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1683 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2140
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1683 [Unsqueeze] inputs: [2140 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1683 for ONNX node: Unsqueeze_1683
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2217 for ONNX tensor: 2217
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1683 [Unsqueeze] outputs: [2217 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1684 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2143
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1684 [Unsqueeze] inputs: [2143 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1684 for ONNX node: Unsqueeze_1684
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2218 for ONNX tensor: 2218
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1684 [Unsqueeze] outputs: [2218 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Unsqueeze_1685 [Unsqueeze]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2146
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1685 [Unsqueeze] inputs: [2146 -> ()[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Unsqueeze_1685 for ONNX node: Unsqueeze_1685
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2219 for ONNX tensor: 2219
[06/10/2022-19:21:31] [V] [TRT] Unsqueeze_1685 [Unsqueeze] outputs: [2219 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Concat_1686 [Concat]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2217
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2218
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2219
[06/10/2022-19:21:31] [V] [TRT] Concat_1686 [Concat] inputs: [2217 -> (1)[INT32]], [2218 -> (1)[INT32]], [2219 -> (1)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Concat_1686 for ONNX node: Concat_1686
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2220 for ONNX tensor: 2220
[06/10/2022-19:21:31] [V] [TRT] Concat_1686 [Concat] outputs: [2220 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Reshape_1687 [Reshape]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2216
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2220
[06/10/2022-19:21:31] [V] [TRT] Reshape_1687 [Reshape] inputs: [2216 -> (-1, 4096, 5, 64)[FLOAT]], [2220 -> (3)[INT32]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Reshape_1687 for ONNX node: Reshape_1687
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2221 for ONNX tensor: 2221
[06/10/2022-19:21:31] [V] [TRT] Reshape_1687 [Reshape] outputs: [2221 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: MatMul_1688 [MatMul]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2221
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 3178
[06/10/2022-19:21:31] [V] [TRT] MatMul_1688 [MatMul] inputs: [2221 -> (-1, 4096, 320)[FLOAT]], [3178 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 3178 for ONNX node: 3178
[06/10/2022-19:21:31] [V] [TRT] Registering layer: MatMul_1688 for ONNX node: MatMul_1688
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2223 for ONNX tensor: 2223
[06/10/2022-19:21:31] [V] [TRT] MatMul_1688 [MatMul] outputs: [2223 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1689 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2223
[06/10/2022-19:21:31] [V] [TRT] Searching for input: backbone.block3.4.attn.proj.bias
[06/10/2022-19:21:31] [V] [TRT] Add_1689 [Add] inputs: [2223 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.4.attn.proj.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: backbone.block3.4.attn.proj.bias for ONNX node: backbone.block3.4.attn.proj.bias
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1689 for ONNX node: Add_1689
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2224 for ONNX tensor: 2224
[06/10/2022-19:21:31] [V] [TRT] Add_1689 [Add] outputs: [2224 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Add_1690 [Add]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2126
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2224
[06/10/2022-19:21:31] [V] [TRT] Add_1690 [Add] inputs: [2126 -> (-1, 4096, 320)[FLOAT]], [2224 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Add_1690 for ONNX node: Add_1690
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2225 for ONNX tensor: 2225
[06/10/2022-19:21:31] [V] [TRT] Add_1690 [Add] outputs: [2225 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: ReduceMean_1691 [ReduceMean]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2225
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1691 [ReduceMean] inputs: [2225 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: ReduceMean_1691 for ONNX node: ReduceMean_1691
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2226 for ONNX tensor: 2226
[06/10/2022-19:21:31] [V] [TRT] ReduceMean_1691 [ReduceMean] outputs: [2226 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Sub_1692 [Sub]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2225
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2226
[06/10/2022-19:21:31] [V] [TRT] Sub_1692 [Sub] inputs: [2225 -> (-1, 4096, 320)[FLOAT]], [2226 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: Sub_1692 for ONNX node: Sub_1692
[06/10/2022-19:21:31] [V] [TRT] Registering tensor: 2227 for ONNX tensor: 2227
[06/10/2022-19:21:31] [V] [TRT] Sub_1692 [Sub] outputs: [2227 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Parsing node: Pow_1694 [Pow]
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2227
[06/10/2022-19:21:31] [V] [TRT] Searching for input: 2228
[06/10/2022-19:21:31] [V] [TRT] Pow_1694 [Pow] inputs: [2227 -> (-1, 4096, 320)[FLOAT]], [2228 -> ()[FLOAT]], 
[06/10/2022-19:21:31] [V] [TRT] Registering layer: 2228 for ONNX node: 2228
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Pow_1694 for ONNX node: Pow_1694
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2229 for ONNX tensor: 2229
[06/10/2022-19:21:32] [V] [TRT] Pow_1694 [Pow] outputs: [2229 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1695 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2229
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1695 [ReduceMean] inputs: [2229 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1695 for ONNX node: ReduceMean_1695
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2230 for ONNX tensor: 2230
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1695 [ReduceMean] outputs: [2230 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1697 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2230
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2231
[06/10/2022-19:21:32] [V] [TRT] Add_1697 [Add] inputs: [2230 -> (-1, 4096, 1)[FLOAT]], [2231 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2231 for ONNX node: 2231
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1697 for ONNX node: Add_1697
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2232 for ONNX tensor: 2232
[06/10/2022-19:21:32] [V] [TRT] Add_1697 [Add] outputs: [2232 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sqrt_1698 [Sqrt]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2232
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1698 [Sqrt] inputs: [2232 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sqrt_1698 for ONNX node: Sqrt_1698
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2233 for ONNX tensor: 2233
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1698 [Sqrt] outputs: [2233 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1699 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2227
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2233
[06/10/2022-19:21:32] [V] [TRT] Div_1699 [Div] inputs: [2227 -> (-1, 4096, 320)[FLOAT]], [2233 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1699 for ONNX node: Div_1699
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2234 for ONNX tensor: 2234
[06/10/2022-19:21:32] [V] [TRT] Div_1699 [Div] outputs: [2234 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1700 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2234
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.4.norm2.weight
[06/10/2022-19:21:32] [V] [TRT] Mul_1700 [Mul] inputs: [2234 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.4.norm2.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.4.norm2.weight for ONNX node: backbone.block3.4.norm2.weight
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1700 for ONNX node: Mul_1700
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2235 for ONNX tensor: 2235
[06/10/2022-19:21:32] [V] [TRT] Mul_1700 [Mul] outputs: [2235 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1701 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2235
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.4.norm2.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1701 [Add] inputs: [2235 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.4.norm2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.4.norm2.bias for ONNX node: backbone.block3.4.norm2.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1701 for ONNX node: Add_1701
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2236 for ONNX tensor: 2236
[06/10/2022-19:21:32] [V] [TRT] Add_1701 [Add] outputs: [2236 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1702 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2236
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3179
[06/10/2022-19:21:32] [V] [TRT] MatMul_1702 [MatMul] inputs: [2236 -> (-1, 4096, 320)[FLOAT]], [3179 -> (320, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3179 for ONNX node: 3179
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1702 for ONNX node: MatMul_1702
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2238 for ONNX tensor: 2238
[06/10/2022-19:21:32] [V] [TRT] MatMul_1702 [MatMul] outputs: [2238 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1703 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2238
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.4.mlp.fc1.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1703 [Add] inputs: [2238 -> (-1, 4096, 1280)[FLOAT]], [backbone.block3.4.mlp.fc1.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.4.mlp.fc1.bias for ONNX node: backbone.block3.4.mlp.fc1.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1703 for ONNX node: Add_1703
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2239 for ONNX tensor: 2239
[06/10/2022-19:21:32] [V] [TRT] Add_1703 [Add] outputs: [2239 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1704 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2239
[06/10/2022-19:21:32] [V] [TRT] Shape_1704 [Shape] inputs: [2239 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1704 for ONNX node: Shape_1704
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2240 for ONNX tensor: 2240
[06/10/2022-19:21:32] [V] [TRT] Shape_1704 [Shape] outputs: [2240 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1706 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2240
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2241
[06/10/2022-19:21:32] [V] [TRT] Gather_1706 [Gather] inputs: [2240 -> (3)[INT32]], [2241 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2241 for ONNX node: 2241
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1706 for ONNX node: Gather_1706
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2242 for ONNX tensor: 2242
[06/10/2022-19:21:32] [V] [TRT] Gather_1706 [Gather] outputs: [2242 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1707 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2239
[06/10/2022-19:21:32] [V] [TRT] Shape_1707 [Shape] inputs: [2239 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1707 for ONNX node: Shape_1707
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2243 for ONNX tensor: 2243
[06/10/2022-19:21:32] [V] [TRT] Shape_1707 [Shape] outputs: [2243 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1709 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2243
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2244
[06/10/2022-19:21:32] [V] [TRT] Gather_1709 [Gather] inputs: [2243 -> (3)[INT32]], [2244 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2244 for ONNX node: 2244
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1709 for ONNX node: Gather_1709
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2245 for ONNX tensor: 2245
[06/10/2022-19:21:32] [V] [TRT] Gather_1709 [Gather] outputs: [2245 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1710 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2239
[06/10/2022-19:21:32] [V] [TRT] Transpose_1710 [Transpose] inputs: [2239 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1710 for ONNX node: Transpose_1710
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2246 for ONNX tensor: 2246
[06/10/2022-19:21:32] [V] [TRT] Transpose_1710 [Transpose] outputs: [2246 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1711 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2242
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1711 [Unsqueeze] inputs: [2242 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1711 for ONNX node: Unsqueeze_1711
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2247 for ONNX tensor: 2247
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1711 [Unsqueeze] outputs: [2247 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1712 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2245
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1712 [Unsqueeze] inputs: [2245 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1712 for ONNX node: Unsqueeze_1712
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2248 for ONNX tensor: 2248
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1712 [Unsqueeze] outputs: [2248 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1713 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1713 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1713 for ONNX node: Unsqueeze_1713
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2249 for ONNX tensor: 2249
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1713 [Unsqueeze] outputs: [2249 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1714 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1714 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1714 for ONNX node: Unsqueeze_1714
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2250 for ONNX tensor: 2250
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1714 [Unsqueeze] outputs: [2250 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1715 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2247
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2248
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2249
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2250
[06/10/2022-19:21:32] [V] [TRT] Concat_1715 [Concat] inputs: [2247 -> (1)[INT32]], [2248 -> (1)[INT32]], [2249 -> (1)[INT32]], [2250 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1715 for ONNX node: Concat_1715
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2251 for ONNX tensor: 2251
[06/10/2022-19:21:32] [V] [TRT] Concat_1715 [Concat] outputs: [2251 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1716 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2246
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2251
[06/10/2022-19:21:32] [V] [TRT] Reshape_1716 [Reshape] inputs: [2246 -> (-1, 1280, 4096)[FLOAT]], [2251 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1716 for ONNX node: Reshape_1716
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2252 for ONNX tensor: 2252
[06/10/2022-19:21:32] [V] [TRT] Reshape_1716 [Reshape] outputs: [2252 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Conv_1717 [Conv]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2252
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.4.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.4.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:32] [V] [TRT] Conv_1717 [Conv] inputs: [2252 -> (-1, 1280, 64, 64)[FLOAT]], [backbone.block3.4.mlp.dwconv.dwconv.weight -> (1280, 1, 3, 3)[FLOAT]], [backbone.block3.4.mlp.dwconv.dwconv.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Convolution input dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Conv_1717 for ONNX node: Conv_1717
[06/10/2022-19:21:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1280
[06/10/2022-19:21:32] [V] [TRT] Convolution output dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2253 for ONNX tensor: 2253
[06/10/2022-19:21:32] [V] [TRT] Conv_1717 [Conv] outputs: [2253 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1718 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2253
[06/10/2022-19:21:32] [V] [TRT] Shape_1718 [Shape] inputs: [2253 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1718 for ONNX node: Shape_1718
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2254 for ONNX tensor: 2254
[06/10/2022-19:21:32] [V] [TRT] Shape_1718 [Shape] outputs: [2254 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Slice_1722 [Slice]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2254
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2256
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2257
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2255
[06/10/2022-19:21:32] [V] [TRT] Slice_1722 [Slice] inputs: [2254 -> (4)[INT32]], [2256 -> (1)[INT32]], [2257 -> (1)[INT32]], [2255 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Slice_1722 for ONNX node: Slice_1722
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2258 for ONNX tensor: 2258
[06/10/2022-19:21:32] [V] [TRT] Slice_1722 [Slice] outputs: [2258 -> (2)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1724 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2258
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2259
[06/10/2022-19:21:32] [V] [TRT] Concat_1724 [Concat] inputs: [2258 -> (2)[INT32]], [2259 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2259 for ONNX node: 2259
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1724 for ONNX node: Concat_1724
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2260 for ONNX tensor: 2260
[06/10/2022-19:21:32] [V] [TRT] Concat_1724 [Concat] outputs: [2260 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1725 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2253
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2260
[06/10/2022-19:21:32] [V] [TRT] Reshape_1725 [Reshape] inputs: [2253 -> (-1, 1280, 64, 64)[FLOAT]], [2260 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1725 for ONNX node: Reshape_1725
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2261 for ONNX tensor: 2261
[06/10/2022-19:21:32] [V] [TRT] Reshape_1725 [Reshape] outputs: [2261 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1726 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2261
[06/10/2022-19:21:32] [V] [TRT] Transpose_1726 [Transpose] inputs: [2261 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1726 for ONNX node: Transpose_1726
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2262 for ONNX tensor: 2262
[06/10/2022-19:21:32] [V] [TRT] Transpose_1726 [Transpose] outputs: [2262 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1728 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2262
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2263
[06/10/2022-19:21:32] [V] [TRT] Div_1728 [Div] inputs: [2262 -> (-1, 4096, 1280)[FLOAT]], [2263 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2263 for ONNX node: 2263
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1728 for ONNX node: Div_1728
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2264 for ONNX tensor: 2264
[06/10/2022-19:21:32] [V] [TRT] Div_1728 [Div] outputs: [2264 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Erf_1729 [Erf]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2264
[06/10/2022-19:21:32] [V] [TRT] Erf_1729 [Erf] inputs: [2264 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Erf_1729 for ONNX node: Erf_1729
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2265 for ONNX tensor: 2265
[06/10/2022-19:21:32] [V] [TRT] Erf_1729 [Erf] outputs: [2265 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1731 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2265
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2266
[06/10/2022-19:21:32] [V] [TRT] Add_1731 [Add] inputs: [2265 -> (-1, 4096, 1280)[FLOAT]], [2266 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2266 for ONNX node: 2266
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1731 for ONNX node: Add_1731
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2267 for ONNX tensor: 2267
[06/10/2022-19:21:32] [V] [TRT] Add_1731 [Add] outputs: [2267 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1732 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2262
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2267
[06/10/2022-19:21:32] [V] [TRT] Mul_1732 [Mul] inputs: [2262 -> (-1, 4096, 1280)[FLOAT]], [2267 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1732 for ONNX node: Mul_1732
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2268 for ONNX tensor: 2268
[06/10/2022-19:21:32] [V] [TRT] Mul_1732 [Mul] outputs: [2268 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1734 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2268
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2269
[06/10/2022-19:21:32] [V] [TRT] Mul_1734 [Mul] inputs: [2268 -> (-1, 4096, 1280)[FLOAT]], [2269 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2269 for ONNX node: 2269
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1734 for ONNX node: Mul_1734
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2270 for ONNX tensor: 2270
[06/10/2022-19:21:32] [V] [TRT] Mul_1734 [Mul] outputs: [2270 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1735 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2270
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3180
[06/10/2022-19:21:32] [V] [TRT] MatMul_1735 [MatMul] inputs: [2270 -> (-1, 4096, 1280)[FLOAT]], [3180 -> (1280, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3180 for ONNX node: 3180
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1735 for ONNX node: MatMul_1735
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2272 for ONNX tensor: 2272
[06/10/2022-19:21:32] [V] [TRT] MatMul_1735 [MatMul] outputs: [2272 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1736 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2272
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.4.mlp.fc2.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1736 [Add] inputs: [2272 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.4.mlp.fc2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.4.mlp.fc2.bias for ONNX node: backbone.block3.4.mlp.fc2.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1736 for ONNX node: Add_1736
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2273 for ONNX tensor: 2273
[06/10/2022-19:21:32] [V] [TRT] Add_1736 [Add] outputs: [2273 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1737 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2225
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2273
[06/10/2022-19:21:32] [V] [TRT] Add_1737 [Add] inputs: [2225 -> (-1, 4096, 320)[FLOAT]], [2273 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1737 for ONNX node: Add_1737
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2274 for ONNX tensor: 2274
[06/10/2022-19:21:32] [V] [TRT] Add_1737 [Add] outputs: [2274 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1738 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2274
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1738 [ReduceMean] inputs: [2274 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1738 for ONNX node: ReduceMean_1738
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2275 for ONNX tensor: 2275
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1738 [ReduceMean] outputs: [2275 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sub_1739 [Sub]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2274
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2275
[06/10/2022-19:21:32] [V] [TRT] Sub_1739 [Sub] inputs: [2274 -> (-1, 4096, 320)[FLOAT]], [2275 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sub_1739 for ONNX node: Sub_1739
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2276 for ONNX tensor: 2276
[06/10/2022-19:21:32] [V] [TRT] Sub_1739 [Sub] outputs: [2276 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Pow_1741 [Pow]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2276
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2277
[06/10/2022-19:21:32] [V] [TRT] Pow_1741 [Pow] inputs: [2276 -> (-1, 4096, 320)[FLOAT]], [2277 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2277 for ONNX node: 2277
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Pow_1741 for ONNX node: Pow_1741
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2278 for ONNX tensor: 2278
[06/10/2022-19:21:32] [V] [TRT] Pow_1741 [Pow] outputs: [2278 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1742 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2278
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1742 [ReduceMean] inputs: [2278 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1742 for ONNX node: ReduceMean_1742
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2279 for ONNX tensor: 2279
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1742 [ReduceMean] outputs: [2279 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1744 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2279
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2280
[06/10/2022-19:21:32] [V] [TRT] Add_1744 [Add] inputs: [2279 -> (-1, 4096, 1)[FLOAT]], [2280 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2280 for ONNX node: 2280
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1744 for ONNX node: Add_1744
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2281 for ONNX tensor: 2281
[06/10/2022-19:21:32] [V] [TRT] Add_1744 [Add] outputs: [2281 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sqrt_1745 [Sqrt]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2281
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1745 [Sqrt] inputs: [2281 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sqrt_1745 for ONNX node: Sqrt_1745
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2282 for ONNX tensor: 2282
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1745 [Sqrt] outputs: [2282 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1746 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2276
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2282
[06/10/2022-19:21:32] [V] [TRT] Div_1746 [Div] inputs: [2276 -> (-1, 4096, 320)[FLOAT]], [2282 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1746 for ONNX node: Div_1746
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2283 for ONNX tensor: 2283
[06/10/2022-19:21:32] [V] [TRT] Div_1746 [Div] outputs: [2283 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1747 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2283
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.norm1.weight
[06/10/2022-19:21:32] [V] [TRT] Mul_1747 [Mul] inputs: [2283 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.5.norm1.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.5.norm1.weight for ONNX node: backbone.block3.5.norm1.weight
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1747 for ONNX node: Mul_1747
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2284 for ONNX tensor: 2284
[06/10/2022-19:21:32] [V] [TRT] Mul_1747 [Mul] outputs: [2284 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1748 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2284
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.norm1.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1748 [Add] inputs: [2284 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.5.norm1.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.5.norm1.bias for ONNX node: backbone.block3.5.norm1.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1748 for ONNX node: Add_1748
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2285 for ONNX tensor: 2285
[06/10/2022-19:21:32] [V] [TRT] Add_1748 [Add] outputs: [2285 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1749 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2285
[06/10/2022-19:21:32] [V] [TRT] Shape_1749 [Shape] inputs: [2285 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1749 for ONNX node: Shape_1749
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2286 for ONNX tensor: 2286
[06/10/2022-19:21:32] [V] [TRT] Shape_1749 [Shape] outputs: [2286 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1751 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2286
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2287
[06/10/2022-19:21:32] [V] [TRT] Gather_1751 [Gather] inputs: [2286 -> (3)[INT32]], [2287 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2287 for ONNX node: 2287
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1751 for ONNX node: Gather_1751
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2288 for ONNX tensor: 2288
[06/10/2022-19:21:32] [V] [TRT] Gather_1751 [Gather] outputs: [2288 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1752 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2285
[06/10/2022-19:21:32] [V] [TRT] Shape_1752 [Shape] inputs: [2285 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1752 for ONNX node: Shape_1752
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2289 for ONNX tensor: 2289
[06/10/2022-19:21:32] [V] [TRT] Shape_1752 [Shape] outputs: [2289 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1754 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2289
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2290
[06/10/2022-19:21:32] [V] [TRT] Gather_1754 [Gather] inputs: [2289 -> (3)[INT32]], [2290 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2290 for ONNX node: 2290
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1754 for ONNX node: Gather_1754
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2291 for ONNX tensor: 2291
[06/10/2022-19:21:32] [V] [TRT] Gather_1754 [Gather] outputs: [2291 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1755 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2285
[06/10/2022-19:21:32] [V] [TRT] Shape_1755 [Shape] inputs: [2285 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1755 for ONNX node: Shape_1755
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2292 for ONNX tensor: 2292
[06/10/2022-19:21:32] [V] [TRT] Shape_1755 [Shape] outputs: [2292 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1757 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2292
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2293
[06/10/2022-19:21:32] [V] [TRT] Gather_1757 [Gather] inputs: [2292 -> (3)[INT32]], [2293 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2293 for ONNX node: 2293
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1757 for ONNX node: Gather_1757
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2294 for ONNX tensor: 2294
[06/10/2022-19:21:32] [V] [TRT] Gather_1757 [Gather] outputs: [2294 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1758 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2285
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3181
[06/10/2022-19:21:32] [V] [TRT] MatMul_1758 [MatMul] inputs: [2285 -> (-1, 4096, 320)[FLOAT]], [3181 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3181 for ONNX node: 3181
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1758 for ONNX node: MatMul_1758
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2296 for ONNX tensor: 2296
[06/10/2022-19:21:32] [V] [TRT] MatMul_1758 [MatMul] outputs: [2296 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1759 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2296
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.attn.q.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1759 [Add] inputs: [2296 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.5.attn.q.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.5.attn.q.bias for ONNX node: backbone.block3.5.attn.q.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1759 for ONNX node: Add_1759
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2297 for ONNX tensor: 2297
[06/10/2022-19:21:32] [V] [TRT] Add_1759 [Add] outputs: [2297 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1761 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2294
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2298
[06/10/2022-19:21:32] [V] [TRT] Div_1761 [Div] inputs: [2294 -> ()[INT32]], [2298 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2298 for ONNX node: 2298
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1761 for ONNX node: Div_1761
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2299 for ONNX tensor: 2299
[06/10/2022-19:21:32] [V] [TRT] Div_1761 [Div] outputs: [2299 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_1762 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2299
[06/10/2022-19:21:32] [V] [TRT] Cast_1762 [Cast] inputs: [2299 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_1762 for ONNX node: Cast_1762
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2300 for ONNX tensor: 2300
[06/10/2022-19:21:32] [V] [TRT] Cast_1762 [Cast] outputs: [2300 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_1763 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2300
[06/10/2022-19:21:32] [V] [TRT] Cast_1763 [Cast] inputs: [2300 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_1763 for ONNX node: Cast_1763
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2301 for ONNX tensor: 2301
[06/10/2022-19:21:32] [V] [TRT] Cast_1763 [Cast] outputs: [2301 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1764 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2288
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1764 [Unsqueeze] inputs: [2288 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1764 for ONNX node: Unsqueeze_1764
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2303 for ONNX tensor: 2303
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1764 [Unsqueeze] outputs: [2303 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1765 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2291
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1765 [Unsqueeze] inputs: [2291 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1765 for ONNX node: Unsqueeze_1765
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2304 for ONNX tensor: 2304
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1765 [Unsqueeze] outputs: [2304 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1766 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2301
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1766 [Unsqueeze] inputs: [2301 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1766 for ONNX node: Unsqueeze_1766
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2306 for ONNX tensor: 2306
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1766 [Unsqueeze] outputs: [2306 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1767 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2303
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2304
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3182
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2306
[06/10/2022-19:21:32] [V] [TRT] Concat_1767 [Concat] inputs: [2303 -> (1)[INT32]], [2304 -> (1)[INT32]], [3182 -> (1)[INT32]], [2306 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3182 for ONNX node: 3182
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1767 for ONNX node: Concat_1767
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2307 for ONNX tensor: 2307
[06/10/2022-19:21:32] [V] [TRT] Concat_1767 [Concat] outputs: [2307 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1768 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2297
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2307
[06/10/2022-19:21:32] [V] [TRT] Reshape_1768 [Reshape] inputs: [2297 -> (-1, 4096, 320)[FLOAT]], [2307 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1768 for ONNX node: Reshape_1768
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2308 for ONNX tensor: 2308
[06/10/2022-19:21:32] [V] [TRT] Reshape_1768 [Reshape] outputs: [2308 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1769 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2308
[06/10/2022-19:21:32] [V] [TRT] Transpose_1769 [Transpose] inputs: [2308 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1769 for ONNX node: Transpose_1769
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2309 for ONNX tensor: 2309
[06/10/2022-19:21:32] [V] [TRT] Transpose_1769 [Transpose] outputs: [2309 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1770 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2285
[06/10/2022-19:21:32] [V] [TRT] Transpose_1770 [Transpose] inputs: [2285 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1770 for ONNX node: Transpose_1770
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2310 for ONNX tensor: 2310
[06/10/2022-19:21:32] [V] [TRT] Transpose_1770 [Transpose] outputs: [2310 -> (-1, 320, 4096)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1771 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2288
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1771 [Unsqueeze] inputs: [2288 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1771 for ONNX node: Unsqueeze_1771
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2311 for ONNX tensor: 2311
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1771 [Unsqueeze] outputs: [2311 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1772 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2294
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1772 [Unsqueeze] inputs: [2294 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1772 for ONNX node: Unsqueeze_1772
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2312 for ONNX tensor: 2312
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1772 [Unsqueeze] outputs: [2312 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1773 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1773 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1773 for ONNX node: Unsqueeze_1773
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2313 for ONNX tensor: 2313
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1773 [Unsqueeze] outputs: [2313 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1774 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1774 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1774 for ONNX node: Unsqueeze_1774
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2314 for ONNX tensor: 2314
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1774 [Unsqueeze] outputs: [2314 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1775 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2311
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2312
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2313
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2314
[06/10/2022-19:21:32] [V] [TRT] Concat_1775 [Concat] inputs: [2311 -> (1)[INT32]], [2312 -> (1)[INT32]], [2313 -> (1)[INT32]], [2314 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1775 for ONNX node: Concat_1775
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2315 for ONNX tensor: 2315
[06/10/2022-19:21:32] [V] [TRT] Concat_1775 [Concat] outputs: [2315 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1776 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2310
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2315
[06/10/2022-19:21:32] [V] [TRT] Reshape_1776 [Reshape] inputs: [2310 -> (-1, 320, 4096)[FLOAT]], [2315 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1776 for ONNX node: Reshape_1776
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2316 for ONNX tensor: 2316
[06/10/2022-19:21:32] [V] [TRT] Reshape_1776 [Reshape] outputs: [2316 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Conv_1777 [Conv]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2316
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.attn.sr.weight
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.attn.sr.bias
[06/10/2022-19:21:32] [V] [TRT] Conv_1777 [Conv] inputs: [2316 -> (-1, 320, 64, 64)[FLOAT]], [backbone.block3.5.attn.sr.weight -> (320, 320, 2, 2)[FLOAT]], [backbone.block3.5.attn.sr.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Convolution input dimensions: (-1, 320, 64, 64)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Conv_1777 for ONNX node: Conv_1777
[06/10/2022-19:21:32] [V] [TRT] Using kernel: (2, 2), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 320
[06/10/2022-19:21:32] [V] [TRT] Convolution output dimensions: (-1, 320, 32, 32)
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2317 for ONNX tensor: 2317
[06/10/2022-19:21:32] [V] [TRT] Conv_1777 [Conv] outputs: [2317 -> (-1, 320, 32, 32)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1778 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2288
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1778 [Unsqueeze] inputs: [2288 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1778 for ONNX node: Unsqueeze_1778
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2319 for ONNX tensor: 2319
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1778 [Unsqueeze] outputs: [2319 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1779 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2294
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1779 [Unsqueeze] inputs: [2294 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1779 for ONNX node: Unsqueeze_1779
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2320 for ONNX tensor: 2320
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1779 [Unsqueeze] outputs: [2320 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1780 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2319
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2320
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3183
[06/10/2022-19:21:32] [V] [TRT] Concat_1780 [Concat] inputs: [2319 -> (1)[INT32]], [2320 -> (1)[INT32]], [3183 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3183 for ONNX node: 3183
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1780 for ONNX node: Concat_1780
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2322 for ONNX tensor: 2322
[06/10/2022-19:21:32] [V] [TRT] Concat_1780 [Concat] outputs: [2322 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1781 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2317
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2322
[06/10/2022-19:21:32] [V] [TRT] Reshape_1781 [Reshape] inputs: [2317 -> (-1, 320, 32, 32)[FLOAT]], [2322 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1781 for ONNX node: Reshape_1781
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2323 for ONNX tensor: 2323
[06/10/2022-19:21:32] [V] [TRT] Reshape_1781 [Reshape] outputs: [2323 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1782 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2323
[06/10/2022-19:21:32] [V] [TRT] Transpose_1782 [Transpose] inputs: [2323 -> (-1, 320, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1782 for ONNX node: Transpose_1782
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2324 for ONNX tensor: 2324
[06/10/2022-19:21:32] [V] [TRT] Transpose_1782 [Transpose] outputs: [2324 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1783 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2324
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1783 [ReduceMean] inputs: [2324 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1783 for ONNX node: ReduceMean_1783
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2325 for ONNX tensor: 2325
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1783 [ReduceMean] outputs: [2325 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sub_1784 [Sub]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2324
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2325
[06/10/2022-19:21:32] [V] [TRT] Sub_1784 [Sub] inputs: [2324 -> (-1, 1024, 320)[FLOAT]], [2325 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sub_1784 for ONNX node: Sub_1784
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2326 for ONNX tensor: 2326
[06/10/2022-19:21:32] [V] [TRT] Sub_1784 [Sub] outputs: [2326 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Pow_1786 [Pow]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2326
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2327
[06/10/2022-19:21:32] [V] [TRT] Pow_1786 [Pow] inputs: [2326 -> (-1, 1024, 320)[FLOAT]], [2327 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2327 for ONNX node: 2327
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Pow_1786 for ONNX node: Pow_1786
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2328 for ONNX tensor: 2328
[06/10/2022-19:21:32] [V] [TRT] Pow_1786 [Pow] outputs: [2328 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1787 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2328
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1787 [ReduceMean] inputs: [2328 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1787 for ONNX node: ReduceMean_1787
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2329 for ONNX tensor: 2329
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1787 [ReduceMean] outputs: [2329 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1789 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2329
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2330
[06/10/2022-19:21:32] [V] [TRT] Add_1789 [Add] inputs: [2329 -> (-1, 1024, 1)[FLOAT]], [2330 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2330 for ONNX node: 2330
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1789 for ONNX node: Add_1789
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2331 for ONNX tensor: 2331
[06/10/2022-19:21:32] [V] [TRT] Add_1789 [Add] outputs: [2331 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sqrt_1790 [Sqrt]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2331
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1790 [Sqrt] inputs: [2331 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sqrt_1790 for ONNX node: Sqrt_1790
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2332 for ONNX tensor: 2332
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1790 [Sqrt] outputs: [2332 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1791 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2326
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2332
[06/10/2022-19:21:32] [V] [TRT] Div_1791 [Div] inputs: [2326 -> (-1, 1024, 320)[FLOAT]], [2332 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1791 for ONNX node: Div_1791
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2333 for ONNX tensor: 2333
[06/10/2022-19:21:32] [V] [TRT] Div_1791 [Div] outputs: [2333 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1792 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2333
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.attn.norm.weight
[06/10/2022-19:21:32] [V] [TRT] Mul_1792 [Mul] inputs: [2333 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.5.attn.norm.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.5.attn.norm.weight for ONNX node: backbone.block3.5.attn.norm.weight
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1792 for ONNX node: Mul_1792
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2334 for ONNX tensor: 2334
[06/10/2022-19:21:32] [V] [TRT] Mul_1792 [Mul] outputs: [2334 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1793 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2334
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.attn.norm.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1793 [Add] inputs: [2334 -> (-1, 1024, 320)[FLOAT]], [backbone.block3.5.attn.norm.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.5.attn.norm.bias for ONNX node: backbone.block3.5.attn.norm.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1793 for ONNX node: Add_1793
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2335 for ONNX tensor: 2335
[06/10/2022-19:21:32] [V] [TRT] Add_1793 [Add] outputs: [2335 -> (-1, 1024, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1794 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2335
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3184
[06/10/2022-19:21:32] [V] [TRT] MatMul_1794 [MatMul] inputs: [2335 -> (-1, 1024, 320)[FLOAT]], [3184 -> (320, 640)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3184 for ONNX node: 3184
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1794 for ONNX node: MatMul_1794
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2337 for ONNX tensor: 2337
[06/10/2022-19:21:32] [V] [TRT] MatMul_1794 [MatMul] outputs: [2337 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1795 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2337
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.attn.kv.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1795 [Add] inputs: [2337 -> (-1, 1024, 640)[FLOAT]], [backbone.block3.5.attn.kv.bias -> (640)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.5.attn.kv.bias for ONNX node: backbone.block3.5.attn.kv.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1795 for ONNX node: Add_1795
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2338 for ONNX tensor: 2338
[06/10/2022-19:21:32] [V] [TRT] Add_1795 [Add] outputs: [2338 -> (-1, 1024, 640)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1797 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2294
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2339
[06/10/2022-19:21:32] [V] [TRT] Div_1797 [Div] inputs: [2294 -> ()[INT32]], [2339 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2339 for ONNX node: 2339
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1797 for ONNX node: Div_1797
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2340 for ONNX tensor: 2340
[06/10/2022-19:21:32] [V] [TRT] Div_1797 [Div] outputs: [2340 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_1798 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2340
[06/10/2022-19:21:32] [V] [TRT] Cast_1798 [Cast] inputs: [2340 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_1798 for ONNX node: Cast_1798
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2341 for ONNX tensor: 2341
[06/10/2022-19:21:32] [V] [TRT] Cast_1798 [Cast] outputs: [2341 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_1799 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2341
[06/10/2022-19:21:32] [V] [TRT] Cast_1799 [Cast] inputs: [2341 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_1799 for ONNX node: Cast_1799
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2342 for ONNX tensor: 2342
[06/10/2022-19:21:32] [V] [TRT] Cast_1799 [Cast] outputs: [2342 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1800 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2288
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1800 [Unsqueeze] inputs: [2288 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1800 for ONNX node: Unsqueeze_1800
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2346 for ONNX tensor: 2346
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1800 [Unsqueeze] outputs: [2346 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1801 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2342
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1801 [Unsqueeze] inputs: [2342 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1801 for ONNX node: Unsqueeze_1801
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2350 for ONNX tensor: 2350
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1801 [Unsqueeze] outputs: [2350 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1802 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2346
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3185
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3186
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3187
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2350
[06/10/2022-19:21:32] [V] [TRT] Concat_1802 [Concat] inputs: [2346 -> (1)[INT32]], [3185 -> (1)[INT32]], [3186 -> (1)[INT32]], [3187 -> (1)[INT32]], [2350 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3185 for ONNX node: 3185
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3186 for ONNX node: 3186
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3187 for ONNX node: 3187
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1802 for ONNX node: Concat_1802
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2351 for ONNX tensor: 2351
[06/10/2022-19:21:32] [V] [TRT] Concat_1802 [Concat] outputs: [2351 -> (5)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1803 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2338
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2351
[06/10/2022-19:21:32] [V] [TRT] Reshape_1803 [Reshape] inputs: [2338 -> (-1, 1024, 640)[FLOAT]], [2351 -> (5)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1803 for ONNX node: Reshape_1803
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2352 for ONNX tensor: 2352
[06/10/2022-19:21:32] [V] [TRT] Reshape_1803 [Reshape] outputs: [2352 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1804 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2352
[06/10/2022-19:21:32] [V] [TRT] Transpose_1804 [Transpose] inputs: [2352 -> (-1, 1024, 2, 5, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1804 for ONNX node: Transpose_1804
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2353 for ONNX tensor: 2353
[06/10/2022-19:21:32] [V] [TRT] Transpose_1804 [Transpose] outputs: [2353 -> (2, -1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1806 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2353
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2354
[06/10/2022-19:21:32] [V] [TRT] Gather_1806 [Gather] inputs: [2353 -> (2, -1, 5, 1024, 64)[FLOAT]], [2354 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2354 for ONNX node: 2354
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1806 for ONNX node: Gather_1806
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2355 for ONNX tensor: 2355
[06/10/2022-19:21:32] [V] [TRT] Gather_1806 [Gather] outputs: [2355 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1808 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2353
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2356
[06/10/2022-19:21:32] [V] [TRT] Gather_1808 [Gather] inputs: [2353 -> (2, -1, 5, 1024, 64)[FLOAT]], [2356 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2356 for ONNX node: 2356
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1808 for ONNX node: Gather_1808
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2357 for ONNX tensor: 2357
[06/10/2022-19:21:32] [V] [TRT] Gather_1808 [Gather] outputs: [2357 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1809 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2355
[06/10/2022-19:21:32] [V] [TRT] Transpose_1809 [Transpose] inputs: [2355 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1809 for ONNX node: Transpose_1809
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2358 for ONNX tensor: 2358
[06/10/2022-19:21:32] [V] [TRT] Transpose_1809 [Transpose] outputs: [2358 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1810 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2309
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2358
[06/10/2022-19:21:32] [V] [TRT] MatMul_1810 [MatMul] inputs: [2309 -> (-1, 5, 4096, 64)[FLOAT]], [2358 -> (-1, 5, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1810 for ONNX node: MatMul_1810
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2359 for ONNX tensor: 2359
[06/10/2022-19:21:32] [V] [TRT] MatMul_1810 [MatMul] outputs: [2359 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1812 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2359
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2360
[06/10/2022-19:21:32] [V] [TRT] Mul_1812 [Mul] inputs: [2359 -> (-1, 5, 4096, 1024)[FLOAT]], [2360 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2360 for ONNX node: 2360
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1812 for ONNX node: Mul_1812
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2361 for ONNX tensor: 2361
[06/10/2022-19:21:32] [V] [TRT] Mul_1812 [Mul] outputs: [2361 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Softmax_1813 [Softmax]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2361
[06/10/2022-19:21:32] [V] [TRT] Softmax_1813 [Softmax] inputs: [2361 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Softmax_1813 for ONNX node: Softmax_1813
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2362 for ONNX tensor: 2362
[06/10/2022-19:21:32] [V] [TRT] Softmax_1813 [Softmax] outputs: [2362 -> (-1, 5, 4096, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1814 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2362
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2357
[06/10/2022-19:21:32] [V] [TRT] MatMul_1814 [MatMul] inputs: [2362 -> (-1, 5, 4096, 1024)[FLOAT]], [2357 -> (-1, 5, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1814 for ONNX node: MatMul_1814
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2363 for ONNX tensor: 2363
[06/10/2022-19:21:32] [V] [TRT] MatMul_1814 [MatMul] outputs: [2363 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1815 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2363
[06/10/2022-19:21:32] [V] [TRT] Transpose_1815 [Transpose] inputs: [2363 -> (-1, 5, 4096, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1815 for ONNX node: Transpose_1815
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2364 for ONNX tensor: 2364
[06/10/2022-19:21:32] [V] [TRT] Transpose_1815 [Transpose] outputs: [2364 -> (-1, 4096, 5, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1816 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2288
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1816 [Unsqueeze] inputs: [2288 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1816 for ONNX node: Unsqueeze_1816
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2365 for ONNX tensor: 2365
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1816 [Unsqueeze] outputs: [2365 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1817 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2291
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1817 [Unsqueeze] inputs: [2291 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1817 for ONNX node: Unsqueeze_1817
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2366 for ONNX tensor: 2366
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1817 [Unsqueeze] outputs: [2366 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1818 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2294
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1818 [Unsqueeze] inputs: [2294 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1818 for ONNX node: Unsqueeze_1818
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2367 for ONNX tensor: 2367
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1818 [Unsqueeze] outputs: [2367 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1819 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2365
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2366
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2367
[06/10/2022-19:21:32] [V] [TRT] Concat_1819 [Concat] inputs: [2365 -> (1)[INT32]], [2366 -> (1)[INT32]], [2367 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1819 for ONNX node: Concat_1819
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2368 for ONNX tensor: 2368
[06/10/2022-19:21:32] [V] [TRT] Concat_1819 [Concat] outputs: [2368 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1820 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2364
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2368
[06/10/2022-19:21:32] [V] [TRT] Reshape_1820 [Reshape] inputs: [2364 -> (-1, 4096, 5, 64)[FLOAT]], [2368 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1820 for ONNX node: Reshape_1820
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2369 for ONNX tensor: 2369
[06/10/2022-19:21:32] [V] [TRT] Reshape_1820 [Reshape] outputs: [2369 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1821 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2369
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3188
[06/10/2022-19:21:32] [V] [TRT] MatMul_1821 [MatMul] inputs: [2369 -> (-1, 4096, 320)[FLOAT]], [3188 -> (320, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3188 for ONNX node: 3188
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1821 for ONNX node: MatMul_1821
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2371 for ONNX tensor: 2371
[06/10/2022-19:21:32] [V] [TRT] MatMul_1821 [MatMul] outputs: [2371 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1822 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2371
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.attn.proj.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1822 [Add] inputs: [2371 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.5.attn.proj.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.5.attn.proj.bias for ONNX node: backbone.block3.5.attn.proj.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1822 for ONNX node: Add_1822
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2372 for ONNX tensor: 2372
[06/10/2022-19:21:32] [V] [TRT] Add_1822 [Add] outputs: [2372 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1823 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2274
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2372
[06/10/2022-19:21:32] [V] [TRT] Add_1823 [Add] inputs: [2274 -> (-1, 4096, 320)[FLOAT]], [2372 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1823 for ONNX node: Add_1823
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2373 for ONNX tensor: 2373
[06/10/2022-19:21:32] [V] [TRT] Add_1823 [Add] outputs: [2373 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1824 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2373
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1824 [ReduceMean] inputs: [2373 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1824 for ONNX node: ReduceMean_1824
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2374 for ONNX tensor: 2374
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1824 [ReduceMean] outputs: [2374 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sub_1825 [Sub]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2373
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2374
[06/10/2022-19:21:32] [V] [TRT] Sub_1825 [Sub] inputs: [2373 -> (-1, 4096, 320)[FLOAT]], [2374 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sub_1825 for ONNX node: Sub_1825
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2375 for ONNX tensor: 2375
[06/10/2022-19:21:32] [V] [TRT] Sub_1825 [Sub] outputs: [2375 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Pow_1827 [Pow]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2375
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2376
[06/10/2022-19:21:32] [V] [TRT] Pow_1827 [Pow] inputs: [2375 -> (-1, 4096, 320)[FLOAT]], [2376 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2376 for ONNX node: 2376
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Pow_1827 for ONNX node: Pow_1827
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2377 for ONNX tensor: 2377
[06/10/2022-19:21:32] [V] [TRT] Pow_1827 [Pow] outputs: [2377 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1828 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2377
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1828 [ReduceMean] inputs: [2377 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1828 for ONNX node: ReduceMean_1828
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2378 for ONNX tensor: 2378
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1828 [ReduceMean] outputs: [2378 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1830 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2378
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2379
[06/10/2022-19:21:32] [V] [TRT] Add_1830 [Add] inputs: [2378 -> (-1, 4096, 1)[FLOAT]], [2379 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2379 for ONNX node: 2379
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1830 for ONNX node: Add_1830
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2380 for ONNX tensor: 2380
[06/10/2022-19:21:32] [V] [TRT] Add_1830 [Add] outputs: [2380 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sqrt_1831 [Sqrt]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2380
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1831 [Sqrt] inputs: [2380 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sqrt_1831 for ONNX node: Sqrt_1831
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2381 for ONNX tensor: 2381
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1831 [Sqrt] outputs: [2381 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1832 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2375
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2381
[06/10/2022-19:21:32] [V] [TRT] Div_1832 [Div] inputs: [2375 -> (-1, 4096, 320)[FLOAT]], [2381 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1832 for ONNX node: Div_1832
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2382 for ONNX tensor: 2382
[06/10/2022-19:21:32] [V] [TRT] Div_1832 [Div] outputs: [2382 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1833 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2382
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.norm2.weight
[06/10/2022-19:21:32] [V] [TRT] Mul_1833 [Mul] inputs: [2382 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.5.norm2.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.5.norm2.weight for ONNX node: backbone.block3.5.norm2.weight
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1833 for ONNX node: Mul_1833
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2383 for ONNX tensor: 2383
[06/10/2022-19:21:32] [V] [TRT] Mul_1833 [Mul] outputs: [2383 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1834 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2383
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.norm2.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1834 [Add] inputs: [2383 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.5.norm2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.5.norm2.bias for ONNX node: backbone.block3.5.norm2.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1834 for ONNX node: Add_1834
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2384 for ONNX tensor: 2384
[06/10/2022-19:21:32] [V] [TRT] Add_1834 [Add] outputs: [2384 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1835 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2384
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3189
[06/10/2022-19:21:32] [V] [TRT] MatMul_1835 [MatMul] inputs: [2384 -> (-1, 4096, 320)[FLOAT]], [3189 -> (320, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3189 for ONNX node: 3189
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1835 for ONNX node: MatMul_1835
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2386 for ONNX tensor: 2386
[06/10/2022-19:21:32] [V] [TRT] MatMul_1835 [MatMul] outputs: [2386 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1836 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2386
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.mlp.fc1.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1836 [Add] inputs: [2386 -> (-1, 4096, 1280)[FLOAT]], [backbone.block3.5.mlp.fc1.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.5.mlp.fc1.bias for ONNX node: backbone.block3.5.mlp.fc1.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1836 for ONNX node: Add_1836
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2387 for ONNX tensor: 2387
[06/10/2022-19:21:32] [V] [TRT] Add_1836 [Add] outputs: [2387 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1837 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2387
[06/10/2022-19:21:32] [V] [TRT] Shape_1837 [Shape] inputs: [2387 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1837 for ONNX node: Shape_1837
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2388 for ONNX tensor: 2388
[06/10/2022-19:21:32] [V] [TRT] Shape_1837 [Shape] outputs: [2388 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1839 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2388
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2389
[06/10/2022-19:21:32] [V] [TRT] Gather_1839 [Gather] inputs: [2388 -> (3)[INT32]], [2389 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2389 for ONNX node: 2389
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1839 for ONNX node: Gather_1839
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2390 for ONNX tensor: 2390
[06/10/2022-19:21:32] [V] [TRT] Gather_1839 [Gather] outputs: [2390 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1840 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2387
[06/10/2022-19:21:32] [V] [TRT] Shape_1840 [Shape] inputs: [2387 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1840 for ONNX node: Shape_1840
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2391 for ONNX tensor: 2391
[06/10/2022-19:21:32] [V] [TRT] Shape_1840 [Shape] outputs: [2391 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1842 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2391
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2392
[06/10/2022-19:21:32] [V] [TRT] Gather_1842 [Gather] inputs: [2391 -> (3)[INT32]], [2392 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2392 for ONNX node: 2392
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1842 for ONNX node: Gather_1842
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2393 for ONNX tensor: 2393
[06/10/2022-19:21:32] [V] [TRT] Gather_1842 [Gather] outputs: [2393 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1843 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2387
[06/10/2022-19:21:32] [V] [TRT] Transpose_1843 [Transpose] inputs: [2387 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1843 for ONNX node: Transpose_1843
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2394 for ONNX tensor: 2394
[06/10/2022-19:21:32] [V] [TRT] Transpose_1843 [Transpose] outputs: [2394 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1844 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2390
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1844 [Unsqueeze] inputs: [2390 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1844 for ONNX node: Unsqueeze_1844
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2395 for ONNX tensor: 2395
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1844 [Unsqueeze] outputs: [2395 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1845 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2393
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1845 [Unsqueeze] inputs: [2393 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1845 for ONNX node: Unsqueeze_1845
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2396 for ONNX tensor: 2396
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1845 [Unsqueeze] outputs: [2396 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1846 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1846 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1846 for ONNX node: Unsqueeze_1846
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2397 for ONNX tensor: 2397
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1846 [Unsqueeze] outputs: [2397 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1847 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1847 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1847 for ONNX node: Unsqueeze_1847
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2398 for ONNX tensor: 2398
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1847 [Unsqueeze] outputs: [2398 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1848 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2395
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2396
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2397
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2398
[06/10/2022-19:21:32] [V] [TRT] Concat_1848 [Concat] inputs: [2395 -> (1)[INT32]], [2396 -> (1)[INT32]], [2397 -> (1)[INT32]], [2398 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1848 for ONNX node: Concat_1848
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2399 for ONNX tensor: 2399
[06/10/2022-19:21:32] [V] [TRT] Concat_1848 [Concat] outputs: [2399 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1849 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2394
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2399
[06/10/2022-19:21:32] [V] [TRT] Reshape_1849 [Reshape] inputs: [2394 -> (-1, 1280, 4096)[FLOAT]], [2399 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1849 for ONNX node: Reshape_1849
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2400 for ONNX tensor: 2400
[06/10/2022-19:21:32] [V] [TRT] Reshape_1849 [Reshape] outputs: [2400 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Conv_1850 [Conv]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2400
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:32] [V] [TRT] Conv_1850 [Conv] inputs: [2400 -> (-1, 1280, 64, 64)[FLOAT]], [backbone.block3.5.mlp.dwconv.dwconv.weight -> (1280, 1, 3, 3)[FLOAT]], [backbone.block3.5.mlp.dwconv.dwconv.bias -> (1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Convolution input dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Conv_1850 for ONNX node: Conv_1850
[06/10/2022-19:21:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1280
[06/10/2022-19:21:32] [V] [TRT] Convolution output dimensions: (-1, 1280, 64, 64)
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2401 for ONNX tensor: 2401
[06/10/2022-19:21:32] [V] [TRT] Conv_1850 [Conv] outputs: [2401 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1851 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2401
[06/10/2022-19:21:32] [V] [TRT] Shape_1851 [Shape] inputs: [2401 -> (-1, 1280, 64, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1851 for ONNX node: Shape_1851
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2402 for ONNX tensor: 2402
[06/10/2022-19:21:32] [V] [TRT] Shape_1851 [Shape] outputs: [2402 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Slice_1855 [Slice]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2402
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2404
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2405
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2403
[06/10/2022-19:21:32] [V] [TRT] Slice_1855 [Slice] inputs: [2402 -> (4)[INT32]], [2404 -> (1)[INT32]], [2405 -> (1)[INT32]], [2403 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Slice_1855 for ONNX node: Slice_1855
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2406 for ONNX tensor: 2406
[06/10/2022-19:21:32] [V] [TRT] Slice_1855 [Slice] outputs: [2406 -> (2)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1857 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2406
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2407
[06/10/2022-19:21:32] [V] [TRT] Concat_1857 [Concat] inputs: [2406 -> (2)[INT32]], [2407 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2407 for ONNX node: 2407
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1857 for ONNX node: Concat_1857
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2408 for ONNX tensor: 2408
[06/10/2022-19:21:32] [V] [TRT] Concat_1857 [Concat] outputs: [2408 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1858 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2401
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2408
[06/10/2022-19:21:32] [V] [TRT] Reshape_1858 [Reshape] inputs: [2401 -> (-1, 1280, 64, 64)[FLOAT]], [2408 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1858 for ONNX node: Reshape_1858
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2409 for ONNX tensor: 2409
[06/10/2022-19:21:32] [V] [TRT] Reshape_1858 [Reshape] outputs: [2409 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1859 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2409
[06/10/2022-19:21:32] [V] [TRT] Transpose_1859 [Transpose] inputs: [2409 -> (-1, 1280, 4096)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1859 for ONNX node: Transpose_1859
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2410 for ONNX tensor: 2410
[06/10/2022-19:21:32] [V] [TRT] Transpose_1859 [Transpose] outputs: [2410 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1861 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2410
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2411
[06/10/2022-19:21:32] [V] [TRT] Div_1861 [Div] inputs: [2410 -> (-1, 4096, 1280)[FLOAT]], [2411 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2411 for ONNX node: 2411
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1861 for ONNX node: Div_1861
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2412 for ONNX tensor: 2412
[06/10/2022-19:21:32] [V] [TRT] Div_1861 [Div] outputs: [2412 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Erf_1862 [Erf]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2412
[06/10/2022-19:21:32] [V] [TRT] Erf_1862 [Erf] inputs: [2412 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Erf_1862 for ONNX node: Erf_1862
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2413 for ONNX tensor: 2413
[06/10/2022-19:21:32] [V] [TRT] Erf_1862 [Erf] outputs: [2413 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1864 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2413
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2414
[06/10/2022-19:21:32] [V] [TRT] Add_1864 [Add] inputs: [2413 -> (-1, 4096, 1280)[FLOAT]], [2414 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2414 for ONNX node: 2414
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1864 for ONNX node: Add_1864
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2415 for ONNX tensor: 2415
[06/10/2022-19:21:32] [V] [TRT] Add_1864 [Add] outputs: [2415 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1865 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2410
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2415
[06/10/2022-19:21:32] [V] [TRT] Mul_1865 [Mul] inputs: [2410 -> (-1, 4096, 1280)[FLOAT]], [2415 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1865 for ONNX node: Mul_1865
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2416 for ONNX tensor: 2416
[06/10/2022-19:21:32] [V] [TRT] Mul_1865 [Mul] outputs: [2416 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1867 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2416
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2417
[06/10/2022-19:21:32] [V] [TRT] Mul_1867 [Mul] inputs: [2416 -> (-1, 4096, 1280)[FLOAT]], [2417 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2417 for ONNX node: 2417
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1867 for ONNX node: Mul_1867
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2418 for ONNX tensor: 2418
[06/10/2022-19:21:32] [V] [TRT] Mul_1867 [Mul] outputs: [2418 -> (-1, 4096, 1280)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1868 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2418
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3190
[06/10/2022-19:21:32] [V] [TRT] MatMul_1868 [MatMul] inputs: [2418 -> (-1, 4096, 1280)[FLOAT]], [3190 -> (1280, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3190 for ONNX node: 3190
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1868 for ONNX node: MatMul_1868
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2420 for ONNX tensor: 2420
[06/10/2022-19:21:32] [V] [TRT] MatMul_1868 [MatMul] outputs: [2420 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1869 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2420
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block3.5.mlp.fc2.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1869 [Add] inputs: [2420 -> (-1, 4096, 320)[FLOAT]], [backbone.block3.5.mlp.fc2.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block3.5.mlp.fc2.bias for ONNX node: backbone.block3.5.mlp.fc2.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1869 for ONNX node: Add_1869
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2421 for ONNX tensor: 2421
[06/10/2022-19:21:32] [V] [TRT] Add_1869 [Add] outputs: [2421 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1870 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2373
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2421
[06/10/2022-19:21:32] [V] [TRT] Add_1870 [Add] inputs: [2373 -> (-1, 4096, 320)[FLOAT]], [2421 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1870 for ONNX node: Add_1870
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2422 for ONNX tensor: 2422
[06/10/2022-19:21:32] [V] [TRT] Add_1870 [Add] outputs: [2422 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1871 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2422
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1871 [ReduceMean] inputs: [2422 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1871 for ONNX node: ReduceMean_1871
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2423 for ONNX tensor: 2423
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1871 [ReduceMean] outputs: [2423 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sub_1872 [Sub]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2422
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2423
[06/10/2022-19:21:32] [V] [TRT] Sub_1872 [Sub] inputs: [2422 -> (-1, 4096, 320)[FLOAT]], [2423 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sub_1872 for ONNX node: Sub_1872
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2424 for ONNX tensor: 2424
[06/10/2022-19:21:32] [V] [TRT] Sub_1872 [Sub] outputs: [2424 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Pow_1874 [Pow]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2424
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2425
[06/10/2022-19:21:32] [V] [TRT] Pow_1874 [Pow] inputs: [2424 -> (-1, 4096, 320)[FLOAT]], [2425 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2425 for ONNX node: 2425
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Pow_1874 for ONNX node: Pow_1874
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2426 for ONNX tensor: 2426
[06/10/2022-19:21:32] [V] [TRT] Pow_1874 [Pow] outputs: [2426 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1875 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2426
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1875 [ReduceMean] inputs: [2426 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1875 for ONNX node: ReduceMean_1875
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2427 for ONNX tensor: 2427
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1875 [ReduceMean] outputs: [2427 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1877 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2427
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2428
[06/10/2022-19:21:32] [V] [TRT] Add_1877 [Add] inputs: [2427 -> (-1, 4096, 1)[FLOAT]], [2428 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2428 for ONNX node: 2428
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1877 for ONNX node: Add_1877
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2429 for ONNX tensor: 2429
[06/10/2022-19:21:32] [V] [TRT] Add_1877 [Add] outputs: [2429 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sqrt_1878 [Sqrt]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2429
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1878 [Sqrt] inputs: [2429 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sqrt_1878 for ONNX node: Sqrt_1878
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2430 for ONNX tensor: 2430
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1878 [Sqrt] outputs: [2430 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1879 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2424
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2430
[06/10/2022-19:21:32] [V] [TRT] Div_1879 [Div] inputs: [2424 -> (-1, 4096, 320)[FLOAT]], [2430 -> (-1, 4096, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1879 for ONNX node: Div_1879
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2431 for ONNX tensor: 2431
[06/10/2022-19:21:32] [V] [TRT] Div_1879 [Div] outputs: [2431 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1880 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2431
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.norm3.weight
[06/10/2022-19:21:32] [V] [TRT] Mul_1880 [Mul] inputs: [2431 -> (-1, 4096, 320)[FLOAT]], [backbone.norm3.weight -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.norm3.weight for ONNX node: backbone.norm3.weight
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1880 for ONNX node: Mul_1880
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2432 for ONNX tensor: 2432
[06/10/2022-19:21:32] [V] [TRT] Mul_1880 [Mul] outputs: [2432 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1881 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2432
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.norm3.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1881 [Add] inputs: [2432 -> (-1, 4096, 320)[FLOAT]], [backbone.norm3.bias -> (320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.norm3.bias for ONNX node: backbone.norm3.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1881 for ONNX node: Add_1881
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2433 for ONNX tensor: 2433
[06/10/2022-19:21:32] [V] [TRT] Add_1881 [Add] outputs: [2433 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1882 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 379
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1882 [Unsqueeze] inputs: [379 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1882 for ONNX node: Unsqueeze_1882
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2435 for ONNX tensor: 2435
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1882 [Unsqueeze] outputs: [2435 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1883 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 1511
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1883 [Unsqueeze] inputs: [1511 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1883 for ONNX node: Unsqueeze_1883
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2436 for ONNX tensor: 2436
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1883 [Unsqueeze] outputs: [2436 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1884 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 1514
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1884 [Unsqueeze] inputs: [1514 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1884 for ONNX node: Unsqueeze_1884
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2437 for ONNX tensor: 2437
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1884 [Unsqueeze] outputs: [2437 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1885 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2435
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2436
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2437
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3191
[06/10/2022-19:21:32] [V] [TRT] Concat_1885 [Concat] inputs: [2435 -> (1)[INT32]], [2436 -> (1)[INT32]], [2437 -> (1)[INT32]], [3191 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3191 for ONNX node: 3191
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1885 for ONNX node: Concat_1885
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2439 for ONNX tensor: 2439
[06/10/2022-19:21:32] [V] [TRT] Concat_1885 [Concat] outputs: [2439 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1886 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2433
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2439
[06/10/2022-19:21:32] [V] [TRT] Reshape_1886 [Reshape] inputs: [2433 -> (-1, 4096, 320)[FLOAT]], [2439 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1886 for ONNX node: Reshape_1886
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2440 for ONNX tensor: 2440
[06/10/2022-19:21:32] [V] [TRT] Reshape_1886 [Reshape] outputs: [2440 -> (-1, 64, 64, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1887 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2440
[06/10/2022-19:21:32] [V] [TRT] Transpose_1887 [Transpose] inputs: [2440 -> (-1, 64, 64, 320)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1887 for ONNX node: Transpose_1887
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2441 for ONNX tensor: 2441
[06/10/2022-19:21:32] [V] [TRT] Transpose_1887 [Transpose] outputs: [2441 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Conv_1888 [Conv]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2441
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.patch_embed4.proj.weight
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.patch_embed4.proj.bias
[06/10/2022-19:21:32] [V] [TRT] Conv_1888 [Conv] inputs: [2441 -> (-1, 320, 64, 64)[FLOAT]], [backbone.patch_embed4.proj.weight -> (512, 320, 3, 3)[FLOAT]], [backbone.patch_embed4.proj.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Convolution input dimensions: (-1, 320, 64, 64)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Conv_1888 for ONNX node: Conv_1888
[06/10/2022-19:21:32] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[06/10/2022-19:21:32] [V] [TRT] Convolution output dimensions: (-1, 512, 32, 32)
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2442 for ONNX tensor: 2442
[06/10/2022-19:21:32] [V] [TRT] Conv_1888 [Conv] outputs: [2442 -> (-1, 512, 32, 32)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1889 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2442
[06/10/2022-19:21:32] [V] [TRT] Shape_1889 [Shape] inputs: [2442 -> (-1, 512, 32, 32)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1889 for ONNX node: Shape_1889
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2443 for ONNX tensor: 2443
[06/10/2022-19:21:32] [V] [TRT] Shape_1889 [Shape] outputs: [2443 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1891 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2443
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2444
[06/10/2022-19:21:32] [V] [TRT] Gather_1891 [Gather] inputs: [2443 -> (4)[INT32]], [2444 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2444 for ONNX node: 2444
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1891 for ONNX node: Gather_1891
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2445 for ONNX tensor: 2445
[06/10/2022-19:21:32] [V] [TRT] Gather_1891 [Gather] outputs: [2445 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1892 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2442
[06/10/2022-19:21:32] [V] [TRT] Shape_1892 [Shape] inputs: [2442 -> (-1, 512, 32, 32)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1892 for ONNX node: Shape_1892
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2446 for ONNX tensor: 2446
[06/10/2022-19:21:32] [V] [TRT] Shape_1892 [Shape] outputs: [2446 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1894 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2446
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2447
[06/10/2022-19:21:32] [V] [TRT] Gather_1894 [Gather] inputs: [2446 -> (4)[INT32]], [2447 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2447 for ONNX node: 2447
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1894 for ONNX node: Gather_1894
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2448 for ONNX tensor: 2448
[06/10/2022-19:21:32] [V] [TRT] Gather_1894 [Gather] outputs: [2448 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1895 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2442
[06/10/2022-19:21:32] [V] [TRT] Shape_1895 [Shape] inputs: [2442 -> (-1, 512, 32, 32)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1895 for ONNX node: Shape_1895
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2449 for ONNX tensor: 2449
[06/10/2022-19:21:32] [V] [TRT] Shape_1895 [Shape] outputs: [2449 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Slice_1899 [Slice]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2449
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2451
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2452
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2450
[06/10/2022-19:21:32] [V] [TRT] Slice_1899 [Slice] inputs: [2449 -> (4)[INT32]], [2451 -> (1)[INT32]], [2452 -> (1)[INT32]], [2450 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Slice_1899 for ONNX node: Slice_1899
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2453 for ONNX tensor: 2453
[06/10/2022-19:21:32] [V] [TRT] Slice_1899 [Slice] outputs: [2453 -> (2)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1901 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2453
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2454
[06/10/2022-19:21:32] [V] [TRT] Concat_1901 [Concat] inputs: [2453 -> (2)[INT32]], [2454 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2454 for ONNX node: 2454
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1901 for ONNX node: Concat_1901
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2455 for ONNX tensor: 2455
[06/10/2022-19:21:32] [V] [TRT] Concat_1901 [Concat] outputs: [2455 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1902 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2442
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2455
[06/10/2022-19:21:32] [V] [TRT] Reshape_1902 [Reshape] inputs: [2442 -> (-1, 512, 32, 32)[FLOAT]], [2455 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1902 for ONNX node: Reshape_1902
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2456 for ONNX tensor: 2456
[06/10/2022-19:21:32] [V] [TRT] Reshape_1902 [Reshape] outputs: [2456 -> (-1, 512, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1903 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2456
[06/10/2022-19:21:32] [V] [TRT] Transpose_1903 [Transpose] inputs: [2456 -> (-1, 512, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1903 for ONNX node: Transpose_1903
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2457 for ONNX tensor: 2457
[06/10/2022-19:21:32] [V] [TRT] Transpose_1903 [Transpose] outputs: [2457 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1904 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2457
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1904 [ReduceMean] inputs: [2457 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1904 for ONNX node: ReduceMean_1904
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2458 for ONNX tensor: 2458
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1904 [ReduceMean] outputs: [2458 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sub_1905 [Sub]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2457
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2458
[06/10/2022-19:21:32] [V] [TRT] Sub_1905 [Sub] inputs: [2457 -> (-1, 1024, 512)[FLOAT]], [2458 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sub_1905 for ONNX node: Sub_1905
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2459 for ONNX tensor: 2459
[06/10/2022-19:21:32] [V] [TRT] Sub_1905 [Sub] outputs: [2459 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Pow_1907 [Pow]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2459
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2460
[06/10/2022-19:21:32] [V] [TRT] Pow_1907 [Pow] inputs: [2459 -> (-1, 1024, 512)[FLOAT]], [2460 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2460 for ONNX node: 2460
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Pow_1907 for ONNX node: Pow_1907
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2461 for ONNX tensor: 2461
[06/10/2022-19:21:32] [V] [TRT] Pow_1907 [Pow] outputs: [2461 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1908 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2461
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1908 [ReduceMean] inputs: [2461 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1908 for ONNX node: ReduceMean_1908
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2462 for ONNX tensor: 2462
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1908 [ReduceMean] outputs: [2462 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1910 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2462
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2463
[06/10/2022-19:21:32] [V] [TRT] Add_1910 [Add] inputs: [2462 -> (-1, 1024, 1)[FLOAT]], [2463 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2463 for ONNX node: 2463
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1910 for ONNX node: Add_1910
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2464 for ONNX tensor: 2464
[06/10/2022-19:21:32] [V] [TRT] Add_1910 [Add] outputs: [2464 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sqrt_1911 [Sqrt]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2464
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1911 [Sqrt] inputs: [2464 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sqrt_1911 for ONNX node: Sqrt_1911
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2465 for ONNX tensor: 2465
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1911 [Sqrt] outputs: [2465 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1912 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2459
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2465
[06/10/2022-19:21:32] [V] [TRT] Div_1912 [Div] inputs: [2459 -> (-1, 1024, 512)[FLOAT]], [2465 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1912 for ONNX node: Div_1912
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2466 for ONNX tensor: 2466
[06/10/2022-19:21:32] [V] [TRT] Div_1912 [Div] outputs: [2466 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1913 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2466
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.patch_embed4.norm.weight
[06/10/2022-19:21:32] [V] [TRT] Mul_1913 [Mul] inputs: [2466 -> (-1, 1024, 512)[FLOAT]], [backbone.patch_embed4.norm.weight -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.patch_embed4.norm.weight for ONNX node: backbone.patch_embed4.norm.weight
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1913 for ONNX node: Mul_1913
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2467 for ONNX tensor: 2467
[06/10/2022-19:21:32] [V] [TRT] Mul_1913 [Mul] outputs: [2467 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1914 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2467
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.patch_embed4.norm.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1914 [Add] inputs: [2467 -> (-1, 1024, 512)[FLOAT]], [backbone.patch_embed4.norm.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.patch_embed4.norm.bias for ONNX node: backbone.patch_embed4.norm.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1914 for ONNX node: Add_1914
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2468 for ONNX tensor: 2468
[06/10/2022-19:21:32] [V] [TRT] Add_1914 [Add] outputs: [2468 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1915 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2468
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1915 [ReduceMean] inputs: [2468 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1915 for ONNX node: ReduceMean_1915
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2469 for ONNX tensor: 2469
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1915 [ReduceMean] outputs: [2469 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sub_1916 [Sub]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2468
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2469
[06/10/2022-19:21:32] [V] [TRT] Sub_1916 [Sub] inputs: [2468 -> (-1, 1024, 512)[FLOAT]], [2469 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sub_1916 for ONNX node: Sub_1916
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2470 for ONNX tensor: 2470
[06/10/2022-19:21:32] [V] [TRT] Sub_1916 [Sub] outputs: [2470 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Pow_1918 [Pow]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2470
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2471
[06/10/2022-19:21:32] [V] [TRT] Pow_1918 [Pow] inputs: [2470 -> (-1, 1024, 512)[FLOAT]], [2471 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2471 for ONNX node: 2471
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Pow_1918 for ONNX node: Pow_1918
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2472 for ONNX tensor: 2472
[06/10/2022-19:21:32] [V] [TRT] Pow_1918 [Pow] outputs: [2472 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1919 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2472
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1919 [ReduceMean] inputs: [2472 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1919 for ONNX node: ReduceMean_1919
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2473 for ONNX tensor: 2473
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1919 [ReduceMean] outputs: [2473 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1921 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2473
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2474
[06/10/2022-19:21:32] [V] [TRT] Add_1921 [Add] inputs: [2473 -> (-1, 1024, 1)[FLOAT]], [2474 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2474 for ONNX node: 2474
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1921 for ONNX node: Add_1921
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2475 for ONNX tensor: 2475
[06/10/2022-19:21:32] [V] [TRT] Add_1921 [Add] outputs: [2475 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sqrt_1922 [Sqrt]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2475
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1922 [Sqrt] inputs: [2475 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sqrt_1922 for ONNX node: Sqrt_1922
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2476 for ONNX tensor: 2476
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1922 [Sqrt] outputs: [2476 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1923 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2470
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2476
[06/10/2022-19:21:32] [V] [TRT] Div_1923 [Div] inputs: [2470 -> (-1, 1024, 512)[FLOAT]], [2476 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1923 for ONNX node: Div_1923
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2477 for ONNX tensor: 2477
[06/10/2022-19:21:32] [V] [TRT] Div_1923 [Div] outputs: [2477 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1924 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2477
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.0.norm1.weight
[06/10/2022-19:21:32] [V] [TRT] Mul_1924 [Mul] inputs: [2477 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.0.norm1.weight -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.0.norm1.weight for ONNX node: backbone.block4.0.norm1.weight
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1924 for ONNX node: Mul_1924
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2478 for ONNX tensor: 2478
[06/10/2022-19:21:32] [V] [TRT] Mul_1924 [Mul] outputs: [2478 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1925 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2478
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.0.norm1.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1925 [Add] inputs: [2478 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.0.norm1.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.0.norm1.bias for ONNX node: backbone.block4.0.norm1.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1925 for ONNX node: Add_1925
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2479 for ONNX tensor: 2479
[06/10/2022-19:21:32] [V] [TRT] Add_1925 [Add] outputs: [2479 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1926 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2479
[06/10/2022-19:21:32] [V] [TRT] Shape_1926 [Shape] inputs: [2479 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1926 for ONNX node: Shape_1926
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2480 for ONNX tensor: 2480
[06/10/2022-19:21:32] [V] [TRT] Shape_1926 [Shape] outputs: [2480 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1928 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2480
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2481
[06/10/2022-19:21:32] [V] [TRT] Gather_1928 [Gather] inputs: [2480 -> (3)[INT32]], [2481 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2481 for ONNX node: 2481
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1928 for ONNX node: Gather_1928
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2482 for ONNX tensor: 2482
[06/10/2022-19:21:32] [V] [TRT] Gather_1928 [Gather] outputs: [2482 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1929 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2479
[06/10/2022-19:21:32] [V] [TRT] Shape_1929 [Shape] inputs: [2479 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1929 for ONNX node: Shape_1929
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2483 for ONNX tensor: 2483
[06/10/2022-19:21:32] [V] [TRT] Shape_1929 [Shape] outputs: [2483 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1931 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2483
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2484
[06/10/2022-19:21:32] [V] [TRT] Gather_1931 [Gather] inputs: [2483 -> (3)[INT32]], [2484 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2484 for ONNX node: 2484
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1931 for ONNX node: Gather_1931
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2485 for ONNX tensor: 2485
[06/10/2022-19:21:32] [V] [TRT] Gather_1931 [Gather] outputs: [2485 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1932 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2479
[06/10/2022-19:21:32] [V] [TRT] Shape_1932 [Shape] inputs: [2479 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1932 for ONNX node: Shape_1932
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2486 for ONNX tensor: 2486
[06/10/2022-19:21:32] [V] [TRT] Shape_1932 [Shape] outputs: [2486 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1934 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2486
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2487
[06/10/2022-19:21:32] [V] [TRT] Gather_1934 [Gather] inputs: [2486 -> (3)[INT32]], [2487 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2487 for ONNX node: 2487
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1934 for ONNX node: Gather_1934
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2488 for ONNX tensor: 2488
[06/10/2022-19:21:32] [V] [TRT] Gather_1934 [Gather] outputs: [2488 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1935 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2479
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3192
[06/10/2022-19:21:32] [V] [TRT] MatMul_1935 [MatMul] inputs: [2479 -> (-1, 1024, 512)[FLOAT]], [3192 -> (512, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3192 for ONNX node: 3192
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1935 for ONNX node: MatMul_1935
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2490 for ONNX tensor: 2490
[06/10/2022-19:21:32] [V] [TRT] MatMul_1935 [MatMul] outputs: [2490 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1936 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2490
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.0.attn.q.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1936 [Add] inputs: [2490 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.0.attn.q.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.0.attn.q.bias for ONNX node: backbone.block4.0.attn.q.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1936 for ONNX node: Add_1936
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2491 for ONNX tensor: 2491
[06/10/2022-19:21:32] [V] [TRT] Add_1936 [Add] outputs: [2491 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1938 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2488
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2492
[06/10/2022-19:21:32] [V] [TRT] Div_1938 [Div] inputs: [2488 -> ()[INT32]], [2492 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2492 for ONNX node: 2492
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1938 for ONNX node: Div_1938
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2493 for ONNX tensor: 2493
[06/10/2022-19:21:32] [V] [TRT] Div_1938 [Div] outputs: [2493 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_1939 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2493
[06/10/2022-19:21:32] [V] [TRT] Cast_1939 [Cast] inputs: [2493 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_1939 for ONNX node: Cast_1939
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2494 for ONNX tensor: 2494
[06/10/2022-19:21:32] [V] [TRT] Cast_1939 [Cast] outputs: [2494 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_1940 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2494
[06/10/2022-19:21:32] [V] [TRT] Cast_1940 [Cast] inputs: [2494 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_1940 for ONNX node: Cast_1940
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2495 for ONNX tensor: 2495
[06/10/2022-19:21:32] [V] [TRT] Cast_1940 [Cast] outputs: [2495 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1941 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2482
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1941 [Unsqueeze] inputs: [2482 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1941 for ONNX node: Unsqueeze_1941
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2497 for ONNX tensor: 2497
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1941 [Unsqueeze] outputs: [2497 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1942 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2485
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1942 [Unsqueeze] inputs: [2485 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1942 for ONNX node: Unsqueeze_1942
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2498 for ONNX tensor: 2498
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1942 [Unsqueeze] outputs: [2498 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1943 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2495
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1943 [Unsqueeze] inputs: [2495 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1943 for ONNX node: Unsqueeze_1943
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2500 for ONNX tensor: 2500
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1943 [Unsqueeze] outputs: [2500 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1944 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2497
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2498
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3193
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2500
[06/10/2022-19:21:32] [V] [TRT] Concat_1944 [Concat] inputs: [2497 -> (1)[INT32]], [2498 -> (1)[INT32]], [3193 -> (1)[INT32]], [2500 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3193 for ONNX node: 3193
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1944 for ONNX node: Concat_1944
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2501 for ONNX tensor: 2501
[06/10/2022-19:21:32] [V] [TRT] Concat_1944 [Concat] outputs: [2501 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1945 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2491
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2501
[06/10/2022-19:21:32] [V] [TRT] Reshape_1945 [Reshape] inputs: [2491 -> (-1, 1024, 512)[FLOAT]], [2501 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1945 for ONNX node: Reshape_1945
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2502 for ONNX tensor: 2502
[06/10/2022-19:21:32] [V] [TRT] Reshape_1945 [Reshape] outputs: [2502 -> (-1, 1024, 8, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1946 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2502
[06/10/2022-19:21:32] [V] [TRT] Transpose_1946 [Transpose] inputs: [2502 -> (-1, 1024, 8, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1946 for ONNX node: Transpose_1946
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2503 for ONNX tensor: 2503
[06/10/2022-19:21:32] [V] [TRT] Transpose_1946 [Transpose] outputs: [2503 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1947 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2479
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3194
[06/10/2022-19:21:32] [V] [TRT] MatMul_1947 [MatMul] inputs: [2479 -> (-1, 1024, 512)[FLOAT]], [3194 -> (512, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3194 for ONNX node: 3194
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1947 for ONNX node: MatMul_1947
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2505 for ONNX tensor: 2505
[06/10/2022-19:21:32] [V] [TRT] MatMul_1947 [MatMul] outputs: [2505 -> (-1, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1948 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2505
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.0.attn.kv.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1948 [Add] inputs: [2505 -> (-1, 1024, 1024)[FLOAT]], [backbone.block4.0.attn.kv.bias -> (1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.0.attn.kv.bias for ONNX node: backbone.block4.0.attn.kv.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1948 for ONNX node: Add_1948
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2506 for ONNX tensor: 2506
[06/10/2022-19:21:32] [V] [TRT] Add_1948 [Add] outputs: [2506 -> (-1, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1950 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2488
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2507
[06/10/2022-19:21:32] [V] [TRT] Div_1950 [Div] inputs: [2488 -> ()[INT32]], [2507 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2507 for ONNX node: 2507
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1950 for ONNX node: Div_1950
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2508 for ONNX tensor: 2508
[06/10/2022-19:21:32] [V] [TRT] Div_1950 [Div] outputs: [2508 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_1951 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2508
[06/10/2022-19:21:32] [V] [TRT] Cast_1951 [Cast] inputs: [2508 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_1951 for ONNX node: Cast_1951
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2509 for ONNX tensor: 2509
[06/10/2022-19:21:32] [V] [TRT] Cast_1951 [Cast] outputs: [2509 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_1952 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2509
[06/10/2022-19:21:32] [V] [TRT] Cast_1952 [Cast] inputs: [2509 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_1952 for ONNX node: Cast_1952
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2510 for ONNX tensor: 2510
[06/10/2022-19:21:32] [V] [TRT] Cast_1952 [Cast] outputs: [2510 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1953 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2482
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1953 [Unsqueeze] inputs: [2482 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1953 for ONNX node: Unsqueeze_1953
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2514 for ONNX tensor: 2514
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1953 [Unsqueeze] outputs: [2514 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1954 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2510
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1954 [Unsqueeze] inputs: [2510 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1954 for ONNX node: Unsqueeze_1954
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2518 for ONNX tensor: 2518
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1954 [Unsqueeze] outputs: [2518 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1955 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2514
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3195
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3196
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3197
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2518
[06/10/2022-19:21:32] [V] [TRT] Concat_1955 [Concat] inputs: [2514 -> (1)[INT32]], [3195 -> (1)[INT32]], [3196 -> (1)[INT32]], [3197 -> (1)[INT32]], [2518 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3195 for ONNX node: 3195
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3196 for ONNX node: 3196
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3197 for ONNX node: 3197
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1955 for ONNX node: Concat_1955
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2519 for ONNX tensor: 2519
[06/10/2022-19:21:32] [V] [TRT] Concat_1955 [Concat] outputs: [2519 -> (5)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1956 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2506
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2519
[06/10/2022-19:21:32] [V] [TRT] Reshape_1956 [Reshape] inputs: [2506 -> (-1, 1024, 1024)[FLOAT]], [2519 -> (5)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1956 for ONNX node: Reshape_1956
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2520 for ONNX tensor: 2520
[06/10/2022-19:21:32] [V] [TRT] Reshape_1956 [Reshape] outputs: [2520 -> (-1, 1024, 2, 8, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1957 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2520
[06/10/2022-19:21:32] [V] [TRT] Transpose_1957 [Transpose] inputs: [2520 -> (-1, 1024, 2, 8, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1957 for ONNX node: Transpose_1957
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2521 for ONNX tensor: 2521
[06/10/2022-19:21:32] [V] [TRT] Transpose_1957 [Transpose] outputs: [2521 -> (2, -1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1959 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2521
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2522
[06/10/2022-19:21:32] [V] [TRT] Gather_1959 [Gather] inputs: [2521 -> (2, -1, 8, 1024, 64)[FLOAT]], [2522 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2522 for ONNX node: 2522
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1959 for ONNX node: Gather_1959
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2523 for ONNX tensor: 2523
[06/10/2022-19:21:32] [V] [TRT] Gather_1959 [Gather] outputs: [2523 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1961 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2521
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2524
[06/10/2022-19:21:32] [V] [TRT] Gather_1961 [Gather] inputs: [2521 -> (2, -1, 8, 1024, 64)[FLOAT]], [2524 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2524 for ONNX node: 2524
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1961 for ONNX node: Gather_1961
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2525 for ONNX tensor: 2525
[06/10/2022-19:21:32] [V] [TRT] Gather_1961 [Gather] outputs: [2525 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1962 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2523
[06/10/2022-19:21:32] [V] [TRT] Transpose_1962 [Transpose] inputs: [2523 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1962 for ONNX node: Transpose_1962
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2526 for ONNX tensor: 2526
[06/10/2022-19:21:32] [V] [TRT] Transpose_1962 [Transpose] outputs: [2526 -> (-1, 8, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1963 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2503
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2526
[06/10/2022-19:21:32] [V] [TRT] MatMul_1963 [MatMul] inputs: [2503 -> (-1, 8, 1024, 64)[FLOAT]], [2526 -> (-1, 8, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1963 for ONNX node: MatMul_1963
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2527 for ONNX tensor: 2527
[06/10/2022-19:21:32] [V] [TRT] MatMul_1963 [MatMul] outputs: [2527 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1965 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2527
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2528
[06/10/2022-19:21:32] [V] [TRT] Mul_1965 [Mul] inputs: [2527 -> (-1, 8, 1024, 1024)[FLOAT]], [2528 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2528 for ONNX node: 2528
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1965 for ONNX node: Mul_1965
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2529 for ONNX tensor: 2529
[06/10/2022-19:21:32] [V] [TRT] Mul_1965 [Mul] outputs: [2529 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Softmax_1966 [Softmax]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2529
[06/10/2022-19:21:32] [V] [TRT] Softmax_1966 [Softmax] inputs: [2529 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Softmax_1966 for ONNX node: Softmax_1966
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2530 for ONNX tensor: 2530
[06/10/2022-19:21:32] [V] [TRT] Softmax_1966 [Softmax] outputs: [2530 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1967 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2530
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2525
[06/10/2022-19:21:32] [V] [TRT] MatMul_1967 [MatMul] inputs: [2530 -> (-1, 8, 1024, 1024)[FLOAT]], [2525 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1967 for ONNX node: MatMul_1967
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2531 for ONNX tensor: 2531
[06/10/2022-19:21:32] [V] [TRT] MatMul_1967 [MatMul] outputs: [2531 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1968 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2531
[06/10/2022-19:21:32] [V] [TRT] Transpose_1968 [Transpose] inputs: [2531 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1968 for ONNX node: Transpose_1968
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2532 for ONNX tensor: 2532
[06/10/2022-19:21:32] [V] [TRT] Transpose_1968 [Transpose] outputs: [2532 -> (-1, 1024, 8, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1969 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2482
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1969 [Unsqueeze] inputs: [2482 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1969 for ONNX node: Unsqueeze_1969
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2533 for ONNX tensor: 2533
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1969 [Unsqueeze] outputs: [2533 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1970 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2485
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1970 [Unsqueeze] inputs: [2485 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1970 for ONNX node: Unsqueeze_1970
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2534 for ONNX tensor: 2534
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1970 [Unsqueeze] outputs: [2534 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1971 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2488
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1971 [Unsqueeze] inputs: [2488 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1971 for ONNX node: Unsqueeze_1971
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2535 for ONNX tensor: 2535
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1971 [Unsqueeze] outputs: [2535 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_1972 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2533
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2534
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2535
[06/10/2022-19:21:32] [V] [TRT] Concat_1972 [Concat] inputs: [2533 -> (1)[INT32]], [2534 -> (1)[INT32]], [2535 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_1972 for ONNX node: Concat_1972
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2536 for ONNX tensor: 2536
[06/10/2022-19:21:32] [V] [TRT] Concat_1972 [Concat] outputs: [2536 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_1973 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2532
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2536
[06/10/2022-19:21:32] [V] [TRT] Reshape_1973 [Reshape] inputs: [2532 -> (-1, 1024, 8, 64)[FLOAT]], [2536 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_1973 for ONNX node: Reshape_1973
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2537 for ONNX tensor: 2537
[06/10/2022-19:21:32] [V] [TRT] Reshape_1973 [Reshape] outputs: [2537 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1974 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2537
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3198
[06/10/2022-19:21:32] [V] [TRT] MatMul_1974 [MatMul] inputs: [2537 -> (-1, 1024, 512)[FLOAT]], [3198 -> (512, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3198 for ONNX node: 3198
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1974 for ONNX node: MatMul_1974
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2539 for ONNX tensor: 2539
[06/10/2022-19:21:32] [V] [TRT] MatMul_1974 [MatMul] outputs: [2539 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1975 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2539
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.0.attn.proj.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1975 [Add] inputs: [2539 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.0.attn.proj.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.0.attn.proj.bias for ONNX node: backbone.block4.0.attn.proj.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1975 for ONNX node: Add_1975
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2540 for ONNX tensor: 2540
[06/10/2022-19:21:32] [V] [TRT] Add_1975 [Add] outputs: [2540 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1976 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2468
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2540
[06/10/2022-19:21:32] [V] [TRT] Add_1976 [Add] inputs: [2468 -> (-1, 1024, 512)[FLOAT]], [2540 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1976 for ONNX node: Add_1976
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2541 for ONNX tensor: 2541
[06/10/2022-19:21:32] [V] [TRT] Add_1976 [Add] outputs: [2541 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1977 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2541
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1977 [ReduceMean] inputs: [2541 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1977 for ONNX node: ReduceMean_1977
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2542 for ONNX tensor: 2542
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1977 [ReduceMean] outputs: [2542 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sub_1978 [Sub]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2541
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2542
[06/10/2022-19:21:32] [V] [TRT] Sub_1978 [Sub] inputs: [2541 -> (-1, 1024, 512)[FLOAT]], [2542 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sub_1978 for ONNX node: Sub_1978
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2543 for ONNX tensor: 2543
[06/10/2022-19:21:32] [V] [TRT] Sub_1978 [Sub] outputs: [2543 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Pow_1980 [Pow]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2543
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2544
[06/10/2022-19:21:32] [V] [TRT] Pow_1980 [Pow] inputs: [2543 -> (-1, 1024, 512)[FLOAT]], [2544 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2544 for ONNX node: 2544
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Pow_1980 for ONNX node: Pow_1980
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2545 for ONNX tensor: 2545
[06/10/2022-19:21:32] [V] [TRT] Pow_1980 [Pow] outputs: [2545 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_1981 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2545
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1981 [ReduceMean] inputs: [2545 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_1981 for ONNX node: ReduceMean_1981
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2546 for ONNX tensor: 2546
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_1981 [ReduceMean] outputs: [2546 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1983 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2546
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2547
[06/10/2022-19:21:32] [V] [TRT] Add_1983 [Add] inputs: [2546 -> (-1, 1024, 1)[FLOAT]], [2547 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2547 for ONNX node: 2547
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1983 for ONNX node: Add_1983
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2548 for ONNX tensor: 2548
[06/10/2022-19:21:32] [V] [TRT] Add_1983 [Add] outputs: [2548 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sqrt_1984 [Sqrt]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2548
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1984 [Sqrt] inputs: [2548 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sqrt_1984 for ONNX node: Sqrt_1984
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2549 for ONNX tensor: 2549
[06/10/2022-19:21:32] [V] [TRT] Sqrt_1984 [Sqrt] outputs: [2549 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_1985 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2543
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2549
[06/10/2022-19:21:32] [V] [TRT] Div_1985 [Div] inputs: [2543 -> (-1, 1024, 512)[FLOAT]], [2549 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_1985 for ONNX node: Div_1985
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2550 for ONNX tensor: 2550
[06/10/2022-19:21:32] [V] [TRT] Div_1985 [Div] outputs: [2550 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_1986 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2550
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.0.norm2.weight
[06/10/2022-19:21:32] [V] [TRT] Mul_1986 [Mul] inputs: [2550 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.0.norm2.weight -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.0.norm2.weight for ONNX node: backbone.block4.0.norm2.weight
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_1986 for ONNX node: Mul_1986
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2551 for ONNX tensor: 2551
[06/10/2022-19:21:32] [V] [TRT] Mul_1986 [Mul] outputs: [2551 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1987 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2551
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.0.norm2.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1987 [Add] inputs: [2551 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.0.norm2.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.0.norm2.bias for ONNX node: backbone.block4.0.norm2.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1987 for ONNX node: Add_1987
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2552 for ONNX tensor: 2552
[06/10/2022-19:21:32] [V] [TRT] Add_1987 [Add] outputs: [2552 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_1988 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2552
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3199
[06/10/2022-19:21:32] [V] [TRT] MatMul_1988 [MatMul] inputs: [2552 -> (-1, 1024, 512)[FLOAT]], [3199 -> (512, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3199 for ONNX node: 3199
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_1988 for ONNX node: MatMul_1988
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2554 for ONNX tensor: 2554
[06/10/2022-19:21:32] [V] [TRT] MatMul_1988 [MatMul] outputs: [2554 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_1989 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2554
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.0.mlp.fc1.bias
[06/10/2022-19:21:32] [V] [TRT] Add_1989 [Add] inputs: [2554 -> (-1, 1024, 2048)[FLOAT]], [backbone.block4.0.mlp.fc1.bias -> (2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.0.mlp.fc1.bias for ONNX node: backbone.block4.0.mlp.fc1.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_1989 for ONNX node: Add_1989
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2555 for ONNX tensor: 2555
[06/10/2022-19:21:32] [V] [TRT] Add_1989 [Add] outputs: [2555 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1990 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2555
[06/10/2022-19:21:32] [V] [TRT] Shape_1990 [Shape] inputs: [2555 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1990 for ONNX node: Shape_1990
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2556 for ONNX tensor: 2556
[06/10/2022-19:21:32] [V] [TRT] Shape_1990 [Shape] outputs: [2556 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1992 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2556
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2557
[06/10/2022-19:21:32] [V] [TRT] Gather_1992 [Gather] inputs: [2556 -> (3)[INT32]], [2557 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2557 for ONNX node: 2557
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1992 for ONNX node: Gather_1992
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2558 for ONNX tensor: 2558
[06/10/2022-19:21:32] [V] [TRT] Gather_1992 [Gather] outputs: [2558 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_1993 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2555
[06/10/2022-19:21:32] [V] [TRT] Shape_1993 [Shape] inputs: [2555 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_1993 for ONNX node: Shape_1993
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2559 for ONNX tensor: 2559
[06/10/2022-19:21:32] [V] [TRT] Shape_1993 [Shape] outputs: [2559 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_1995 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2559
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2560
[06/10/2022-19:21:32] [V] [TRT] Gather_1995 [Gather] inputs: [2559 -> (3)[INT32]], [2560 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2560 for ONNX node: 2560
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_1995 for ONNX node: Gather_1995
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2561 for ONNX tensor: 2561
[06/10/2022-19:21:32] [V] [TRT] Gather_1995 [Gather] outputs: [2561 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_1996 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2555
[06/10/2022-19:21:32] [V] [TRT] Transpose_1996 [Transpose] inputs: [2555 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_1996 for ONNX node: Transpose_1996
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2562 for ONNX tensor: 2562
[06/10/2022-19:21:32] [V] [TRT] Transpose_1996 [Transpose] outputs: [2562 -> (-1, 2048, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1997 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2558
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1997 [Unsqueeze] inputs: [2558 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1997 for ONNX node: Unsqueeze_1997
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2563 for ONNX tensor: 2563
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1997 [Unsqueeze] outputs: [2563 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1998 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2561
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1998 [Unsqueeze] inputs: [2561 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1998 for ONNX node: Unsqueeze_1998
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2564 for ONNX tensor: 2564
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1998 [Unsqueeze] outputs: [2564 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_1999 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2445
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1999 [Unsqueeze] inputs: [2445 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_1999 for ONNX node: Unsqueeze_1999
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2565 for ONNX tensor: 2565
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_1999 [Unsqueeze] outputs: [2565 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_2000 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2448
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2000 [Unsqueeze] inputs: [2448 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_2000 for ONNX node: Unsqueeze_2000
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2566 for ONNX tensor: 2566
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2000 [Unsqueeze] outputs: [2566 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_2001 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2563
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2564
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2565
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2566
[06/10/2022-19:21:32] [V] [TRT] Concat_2001 [Concat] inputs: [2563 -> (1)[INT32]], [2564 -> (1)[INT32]], [2565 -> (1)[INT32]], [2566 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_2001 for ONNX node: Concat_2001
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2567 for ONNX tensor: 2567
[06/10/2022-19:21:32] [V] [TRT] Concat_2001 [Concat] outputs: [2567 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_2002 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2562
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2567
[06/10/2022-19:21:32] [V] [TRT] Reshape_2002 [Reshape] inputs: [2562 -> (-1, 2048, 1024)[FLOAT]], [2567 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_2002 for ONNX node: Reshape_2002
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2568 for ONNX tensor: 2568
[06/10/2022-19:21:32] [V] [TRT] Reshape_2002 [Reshape] outputs: [2568 -> (-1, 2048, 32, 32)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Conv_2003 [Conv]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2568
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.0.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.0.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:32] [V] [TRT] Conv_2003 [Conv] inputs: [2568 -> (-1, 2048, 32, 32)[FLOAT]], [backbone.block4.0.mlp.dwconv.dwconv.weight -> (2048, 1, 3, 3)[FLOAT]], [backbone.block4.0.mlp.dwconv.dwconv.bias -> (2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Convolution input dimensions: (-1, 2048, 32, 32)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Conv_2003 for ONNX node: Conv_2003
[06/10/2022-19:21:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2048
[06/10/2022-19:21:32] [V] [TRT] Convolution output dimensions: (-1, 2048, 32, 32)
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2569 for ONNX tensor: 2569
[06/10/2022-19:21:32] [V] [TRT] Conv_2003 [Conv] outputs: [2569 -> (-1, 2048, 32, 32)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_2004 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2569
[06/10/2022-19:21:32] [V] [TRT] Shape_2004 [Shape] inputs: [2569 -> (-1, 2048, 32, 32)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_2004 for ONNX node: Shape_2004
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2570 for ONNX tensor: 2570
[06/10/2022-19:21:32] [V] [TRT] Shape_2004 [Shape] outputs: [2570 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Slice_2008 [Slice]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2570
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2572
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2573
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2571
[06/10/2022-19:21:32] [V] [TRT] Slice_2008 [Slice] inputs: [2570 -> (4)[INT32]], [2572 -> (1)[INT32]], [2573 -> (1)[INT32]], [2571 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Slice_2008 for ONNX node: Slice_2008
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2574 for ONNX tensor: 2574
[06/10/2022-19:21:32] [V] [TRT] Slice_2008 [Slice] outputs: [2574 -> (2)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_2010 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2574
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2575
[06/10/2022-19:21:32] [V] [TRT] Concat_2010 [Concat] inputs: [2574 -> (2)[INT32]], [2575 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2575 for ONNX node: 2575
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_2010 for ONNX node: Concat_2010
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2576 for ONNX tensor: 2576
[06/10/2022-19:21:32] [V] [TRT] Concat_2010 [Concat] outputs: [2576 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_2011 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2569
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2576
[06/10/2022-19:21:32] [V] [TRT] Reshape_2011 [Reshape] inputs: [2569 -> (-1, 2048, 32, 32)[FLOAT]], [2576 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_2011 for ONNX node: Reshape_2011
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2577 for ONNX tensor: 2577
[06/10/2022-19:21:32] [V] [TRT] Reshape_2011 [Reshape] outputs: [2577 -> (-1, 2048, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_2012 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2577
[06/10/2022-19:21:32] [V] [TRT] Transpose_2012 [Transpose] inputs: [2577 -> (-1, 2048, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_2012 for ONNX node: Transpose_2012
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2578 for ONNX tensor: 2578
[06/10/2022-19:21:32] [V] [TRT] Transpose_2012 [Transpose] outputs: [2578 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_2014 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2578
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2579
[06/10/2022-19:21:32] [V] [TRT] Div_2014 [Div] inputs: [2578 -> (-1, 1024, 2048)[FLOAT]], [2579 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2579 for ONNX node: 2579
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_2014 for ONNX node: Div_2014
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2580 for ONNX tensor: 2580
[06/10/2022-19:21:32] [V] [TRT] Div_2014 [Div] outputs: [2580 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Erf_2015 [Erf]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2580
[06/10/2022-19:21:32] [V] [TRT] Erf_2015 [Erf] inputs: [2580 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Erf_2015 for ONNX node: Erf_2015
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2581 for ONNX tensor: 2581
[06/10/2022-19:21:32] [V] [TRT] Erf_2015 [Erf] outputs: [2581 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_2017 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2581
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2582
[06/10/2022-19:21:32] [V] [TRT] Add_2017 [Add] inputs: [2581 -> (-1, 1024, 2048)[FLOAT]], [2582 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2582 for ONNX node: 2582
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_2017 for ONNX node: Add_2017
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2583 for ONNX tensor: 2583
[06/10/2022-19:21:32] [V] [TRT] Add_2017 [Add] outputs: [2583 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_2018 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2578
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2583
[06/10/2022-19:21:32] [V] [TRT] Mul_2018 [Mul] inputs: [2578 -> (-1, 1024, 2048)[FLOAT]], [2583 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_2018 for ONNX node: Mul_2018
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2584 for ONNX tensor: 2584
[06/10/2022-19:21:32] [V] [TRT] Mul_2018 [Mul] outputs: [2584 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_2020 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2584
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2585
[06/10/2022-19:21:32] [V] [TRT] Mul_2020 [Mul] inputs: [2584 -> (-1, 1024, 2048)[FLOAT]], [2585 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2585 for ONNX node: 2585
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_2020 for ONNX node: Mul_2020
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2586 for ONNX tensor: 2586
[06/10/2022-19:21:32] [V] [TRT] Mul_2020 [Mul] outputs: [2586 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_2021 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2586
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3200
[06/10/2022-19:21:32] [V] [TRT] MatMul_2021 [MatMul] inputs: [2586 -> (-1, 1024, 2048)[FLOAT]], [3200 -> (2048, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3200 for ONNX node: 3200
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_2021 for ONNX node: MatMul_2021
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2588 for ONNX tensor: 2588
[06/10/2022-19:21:32] [V] [TRT] MatMul_2021 [MatMul] outputs: [2588 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_2022 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2588
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.0.mlp.fc2.bias
[06/10/2022-19:21:32] [V] [TRT] Add_2022 [Add] inputs: [2588 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.0.mlp.fc2.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.0.mlp.fc2.bias for ONNX node: backbone.block4.0.mlp.fc2.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_2022 for ONNX node: Add_2022
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2589 for ONNX tensor: 2589
[06/10/2022-19:21:32] [V] [TRT] Add_2022 [Add] outputs: [2589 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_2023 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2541
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2589
[06/10/2022-19:21:32] [V] [TRT] Add_2023 [Add] inputs: [2541 -> (-1, 1024, 512)[FLOAT]], [2589 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_2023 for ONNX node: Add_2023
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2590 for ONNX tensor: 2590
[06/10/2022-19:21:32] [V] [TRT] Add_2023 [Add] outputs: [2590 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_2024 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2590
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_2024 [ReduceMean] inputs: [2590 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_2024 for ONNX node: ReduceMean_2024
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2591 for ONNX tensor: 2591
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_2024 [ReduceMean] outputs: [2591 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sub_2025 [Sub]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2590
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2591
[06/10/2022-19:21:32] [V] [TRT] Sub_2025 [Sub] inputs: [2590 -> (-1, 1024, 512)[FLOAT]], [2591 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sub_2025 for ONNX node: Sub_2025
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2592 for ONNX tensor: 2592
[06/10/2022-19:21:32] [V] [TRT] Sub_2025 [Sub] outputs: [2592 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Pow_2027 [Pow]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2592
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2593
[06/10/2022-19:21:32] [V] [TRT] Pow_2027 [Pow] inputs: [2592 -> (-1, 1024, 512)[FLOAT]], [2593 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2593 for ONNX node: 2593
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Pow_2027 for ONNX node: Pow_2027
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2594 for ONNX tensor: 2594
[06/10/2022-19:21:32] [V] [TRT] Pow_2027 [Pow] outputs: [2594 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: ReduceMean_2028 [ReduceMean]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2594
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_2028 [ReduceMean] inputs: [2594 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: ReduceMean_2028 for ONNX node: ReduceMean_2028
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2595 for ONNX tensor: 2595
[06/10/2022-19:21:32] [V] [TRT] ReduceMean_2028 [ReduceMean] outputs: [2595 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_2030 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2595
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2596
[06/10/2022-19:21:32] [V] [TRT] Add_2030 [Add] inputs: [2595 -> (-1, 1024, 1)[FLOAT]], [2596 -> ()[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2596 for ONNX node: 2596
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_2030 for ONNX node: Add_2030
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2597 for ONNX tensor: 2597
[06/10/2022-19:21:32] [V] [TRT] Add_2030 [Add] outputs: [2597 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Sqrt_2031 [Sqrt]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2597
[06/10/2022-19:21:32] [V] [TRT] Sqrt_2031 [Sqrt] inputs: [2597 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Sqrt_2031 for ONNX node: Sqrt_2031
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2598 for ONNX tensor: 2598
[06/10/2022-19:21:32] [V] [TRT] Sqrt_2031 [Sqrt] outputs: [2598 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_2032 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2592
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2598
[06/10/2022-19:21:32] [V] [TRT] Div_2032 [Div] inputs: [2592 -> (-1, 1024, 512)[FLOAT]], [2598 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_2032 for ONNX node: Div_2032
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2599 for ONNX tensor: 2599
[06/10/2022-19:21:32] [V] [TRT] Div_2032 [Div] outputs: [2599 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Mul_2033 [Mul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2599
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.1.norm1.weight
[06/10/2022-19:21:32] [V] [TRT] Mul_2033 [Mul] inputs: [2599 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.1.norm1.weight -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.1.norm1.weight for ONNX node: backbone.block4.1.norm1.weight
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Mul_2033 for ONNX node: Mul_2033
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2600 for ONNX tensor: 2600
[06/10/2022-19:21:32] [V] [TRT] Mul_2033 [Mul] outputs: [2600 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_2034 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2600
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.1.norm1.bias
[06/10/2022-19:21:32] [V] [TRT] Add_2034 [Add] inputs: [2600 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.1.norm1.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.1.norm1.bias for ONNX node: backbone.block4.1.norm1.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_2034 for ONNX node: Add_2034
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2601 for ONNX tensor: 2601
[06/10/2022-19:21:32] [V] [TRT] Add_2034 [Add] outputs: [2601 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_2035 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2601
[06/10/2022-19:21:32] [V] [TRT] Shape_2035 [Shape] inputs: [2601 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_2035 for ONNX node: Shape_2035
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2602 for ONNX tensor: 2602
[06/10/2022-19:21:32] [V] [TRT] Shape_2035 [Shape] outputs: [2602 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_2037 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2602
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2603
[06/10/2022-19:21:32] [V] [TRT] Gather_2037 [Gather] inputs: [2602 -> (3)[INT32]], [2603 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2603 for ONNX node: 2603
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_2037 for ONNX node: Gather_2037
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2604 for ONNX tensor: 2604
[06/10/2022-19:21:32] [V] [TRT] Gather_2037 [Gather] outputs: [2604 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_2038 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2601
[06/10/2022-19:21:32] [V] [TRT] Shape_2038 [Shape] inputs: [2601 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_2038 for ONNX node: Shape_2038
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2605 for ONNX tensor: 2605
[06/10/2022-19:21:32] [V] [TRT] Shape_2038 [Shape] outputs: [2605 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_2040 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2605
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2606
[06/10/2022-19:21:32] [V] [TRT] Gather_2040 [Gather] inputs: [2605 -> (3)[INT32]], [2606 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2606 for ONNX node: 2606
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_2040 for ONNX node: Gather_2040
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2607 for ONNX tensor: 2607
[06/10/2022-19:21:32] [V] [TRT] Gather_2040 [Gather] outputs: [2607 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Shape_2041 [Shape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2601
[06/10/2022-19:21:32] [V] [TRT] Shape_2041 [Shape] inputs: [2601 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Shape_2041 for ONNX node: Shape_2041
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2608 for ONNX tensor: 2608
[06/10/2022-19:21:32] [V] [TRT] Shape_2041 [Shape] outputs: [2608 -> (3)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Gather_2043 [Gather]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2608
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2609
[06/10/2022-19:21:32] [V] [TRT] Gather_2043 [Gather] inputs: [2608 -> (3)[INT32]], [2609 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2609 for ONNX node: 2609
[06/10/2022-19:21:32] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Gather_2043 for ONNX node: Gather_2043
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2610 for ONNX tensor: 2610
[06/10/2022-19:21:32] [V] [TRT] Gather_2043 [Gather] outputs: [2610 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_2044 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2601
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3201
[06/10/2022-19:21:32] [V] [TRT] MatMul_2044 [MatMul] inputs: [2601 -> (-1, 1024, 512)[FLOAT]], [3201 -> (512, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3201 for ONNX node: 3201
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_2044 for ONNX node: MatMul_2044
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2612 for ONNX tensor: 2612
[06/10/2022-19:21:32] [V] [TRT] MatMul_2044 [MatMul] outputs: [2612 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_2045 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2612
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.1.attn.q.bias
[06/10/2022-19:21:32] [V] [TRT] Add_2045 [Add] inputs: [2612 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.1.attn.q.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.1.attn.q.bias for ONNX node: backbone.block4.1.attn.q.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_2045 for ONNX node: Add_2045
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2613 for ONNX tensor: 2613
[06/10/2022-19:21:32] [V] [TRT] Add_2045 [Add] outputs: [2613 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_2047 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2610
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2614
[06/10/2022-19:21:32] [V] [TRT] Div_2047 [Div] inputs: [2610 -> ()[INT32]], [2614 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2614 for ONNX node: 2614
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_2047 for ONNX node: Div_2047
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2615 for ONNX tensor: 2615
[06/10/2022-19:21:32] [V] [TRT] Div_2047 [Div] outputs: [2615 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_2048 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2615
[06/10/2022-19:21:32] [V] [TRT] Cast_2048 [Cast] inputs: [2615 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_2048 for ONNX node: Cast_2048
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2616 for ONNX tensor: 2616
[06/10/2022-19:21:32] [V] [TRT] Cast_2048 [Cast] outputs: [2616 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_2049 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2616
[06/10/2022-19:21:32] [V] [TRT] Cast_2049 [Cast] inputs: [2616 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_2049 for ONNX node: Cast_2049
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2617 for ONNX tensor: 2617
[06/10/2022-19:21:32] [V] [TRT] Cast_2049 [Cast] outputs: [2617 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_2050 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2604
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2050 [Unsqueeze] inputs: [2604 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_2050 for ONNX node: Unsqueeze_2050
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2619 for ONNX tensor: 2619
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2050 [Unsqueeze] outputs: [2619 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_2051 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2607
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2051 [Unsqueeze] inputs: [2607 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_2051 for ONNX node: Unsqueeze_2051
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2620 for ONNX tensor: 2620
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2051 [Unsqueeze] outputs: [2620 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_2052 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2617
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2052 [Unsqueeze] inputs: [2617 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_2052 for ONNX node: Unsqueeze_2052
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2622 for ONNX tensor: 2622
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2052 [Unsqueeze] outputs: [2622 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_2053 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2619
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2620
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3202
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2622
[06/10/2022-19:21:32] [V] [TRT] Concat_2053 [Concat] inputs: [2619 -> (1)[INT32]], [2620 -> (1)[INT32]], [3202 -> (1)[INT32]], [2622 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3202 for ONNX node: 3202
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_2053 for ONNX node: Concat_2053
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2623 for ONNX tensor: 2623
[06/10/2022-19:21:32] [V] [TRT] Concat_2053 [Concat] outputs: [2623 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_2054 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2613
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2623
[06/10/2022-19:21:32] [V] [TRT] Reshape_2054 [Reshape] inputs: [2613 -> (-1, 1024, 512)[FLOAT]], [2623 -> (4)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_2054 for ONNX node: Reshape_2054
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2624 for ONNX tensor: 2624
[06/10/2022-19:21:32] [V] [TRT] Reshape_2054 [Reshape] outputs: [2624 -> (-1, 1024, 8, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_2055 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2624
[06/10/2022-19:21:32] [V] [TRT] Transpose_2055 [Transpose] inputs: [2624 -> (-1, 1024, 8, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Transpose_2055 for ONNX node: Transpose_2055
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2625 for ONNX tensor: 2625
[06/10/2022-19:21:32] [V] [TRT] Transpose_2055 [Transpose] outputs: [2625 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: MatMul_2056 [MatMul]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2601
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3203
[06/10/2022-19:21:32] [V] [TRT] MatMul_2056 [MatMul] inputs: [2601 -> (-1, 1024, 512)[FLOAT]], [3203 -> (512, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3203 for ONNX node: 3203
[06/10/2022-19:21:32] [V] [TRT] Registering layer: MatMul_2056 for ONNX node: MatMul_2056
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2627 for ONNX tensor: 2627
[06/10/2022-19:21:32] [V] [TRT] MatMul_2056 [MatMul] outputs: [2627 -> (-1, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Add_2057 [Add]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2627
[06/10/2022-19:21:32] [V] [TRT] Searching for input: backbone.block4.1.attn.kv.bias
[06/10/2022-19:21:32] [V] [TRT] Add_2057 [Add] inputs: [2627 -> (-1, 1024, 1024)[FLOAT]], [backbone.block4.1.attn.kv.bias -> (1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: backbone.block4.1.attn.kv.bias for ONNX node: backbone.block4.1.attn.kv.bias
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Add_2057 for ONNX node: Add_2057
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2628 for ONNX tensor: 2628
[06/10/2022-19:21:32] [V] [TRT] Add_2057 [Add] outputs: [2628 -> (-1, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Div_2059 [Div]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2610
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2629
[06/10/2022-19:21:32] [V] [TRT] Div_2059 [Div] inputs: [2610 -> ()[INT32]], [2629 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 2629 for ONNX node: 2629
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Div_2059 for ONNX node: Div_2059
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2630 for ONNX tensor: 2630
[06/10/2022-19:21:32] [V] [TRT] Div_2059 [Div] outputs: [2630 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_2060 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2630
[06/10/2022-19:21:32] [V] [TRT] Cast_2060 [Cast] inputs: [2630 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_2060 for ONNX node: Cast_2060
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2631 for ONNX tensor: 2631
[06/10/2022-19:21:32] [V] [TRT] Cast_2060 [Cast] outputs: [2631 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Cast_2061 [Cast]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2631
[06/10/2022-19:21:32] [V] [TRT] Cast_2061 [Cast] inputs: [2631 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Cast_2061 for ONNX node: Cast_2061
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2632 for ONNX tensor: 2632
[06/10/2022-19:21:32] [V] [TRT] Cast_2061 [Cast] outputs: [2632 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_2062 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2604
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2062 [Unsqueeze] inputs: [2604 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_2062 for ONNX node: Unsqueeze_2062
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2636 for ONNX tensor: 2636
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2062 [Unsqueeze] outputs: [2636 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Unsqueeze_2063 [Unsqueeze]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2632
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2063 [Unsqueeze] inputs: [2632 -> ()[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Unsqueeze_2063 for ONNX node: Unsqueeze_2063
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2640 for ONNX tensor: 2640
[06/10/2022-19:21:32] [V] [TRT] Unsqueeze_2063 [Unsqueeze] outputs: [2640 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Concat_2064 [Concat]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2636
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3204
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3205
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 3206
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2640
[06/10/2022-19:21:32] [V] [TRT] Concat_2064 [Concat] inputs: [2636 -> (1)[INT32]], [3204 -> (1)[INT32]], [3205 -> (1)[INT32]], [3206 -> (1)[INT32]], [2640 -> (1)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3204 for ONNX node: 3204
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3205 for ONNX node: 3205
[06/10/2022-19:21:32] [V] [TRT] Registering layer: 3206 for ONNX node: 3206
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Concat_2064 for ONNX node: Concat_2064
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2641 for ONNX tensor: 2641
[06/10/2022-19:21:32] [V] [TRT] Concat_2064 [Concat] outputs: [2641 -> (5)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Reshape_2065 [Reshape]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2628
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2641
[06/10/2022-19:21:32] [V] [TRT] Reshape_2065 [Reshape] inputs: [2628 -> (-1, 1024, 1024)[FLOAT]], [2641 -> (5)[INT32]], 
[06/10/2022-19:21:32] [V] [TRT] Registering layer: Reshape_2065 for ONNX node: Reshape_2065
[06/10/2022-19:21:32] [V] [TRT] Registering tensor: 2642 for ONNX tensor: 2642
[06/10/2022-19:21:32] [V] [TRT] Reshape_2065 [Reshape] outputs: [2642 -> (-1, 1024, 2, 8, 64)[FLOAT]], 
[06/10/2022-19:21:32] [V] [TRT] Parsing node: Transpose_2066 [Transpose]
[06/10/2022-19:21:32] [V] [TRT] Searching for input: 2642
[06/10/2022-19:21:32] [V] [TRT] Transpose_2066 [Transpose] inputs: [2642 -> (-1, 1024, 2, 8, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2066 for ONNX node: Transpose_2066
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2643 for ONNX tensor: 2643
[06/10/2022-19:21:33] [V] [TRT] Transpose_2066 [Transpose] outputs: [2643 -> (2, -1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2068 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2643
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2644
[06/10/2022-19:21:33] [V] [TRT] Gather_2068 [Gather] inputs: [2643 -> (2, -1, 8, 1024, 64)[FLOAT]], [2644 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2644 for ONNX node: 2644
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2068 for ONNX node: Gather_2068
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2645 for ONNX tensor: 2645
[06/10/2022-19:21:33] [V] [TRT] Gather_2068 [Gather] outputs: [2645 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2070 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2643
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2646
[06/10/2022-19:21:33] [V] [TRT] Gather_2070 [Gather] inputs: [2643 -> (2, -1, 8, 1024, 64)[FLOAT]], [2646 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2646 for ONNX node: 2646
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2070 for ONNX node: Gather_2070
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2647 for ONNX tensor: 2647
[06/10/2022-19:21:33] [V] [TRT] Gather_2070 [Gather] outputs: [2647 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2071 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2645
[06/10/2022-19:21:33] [V] [TRT] Transpose_2071 [Transpose] inputs: [2645 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2071 for ONNX node: Transpose_2071
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2648 for ONNX tensor: 2648
[06/10/2022-19:21:33] [V] [TRT] Transpose_2071 [Transpose] outputs: [2648 -> (-1, 8, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2072 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2625
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2648
[06/10/2022-19:21:33] [V] [TRT] MatMul_2072 [MatMul] inputs: [2625 -> (-1, 8, 1024, 64)[FLOAT]], [2648 -> (-1, 8, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2072 for ONNX node: MatMul_2072
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2649 for ONNX tensor: 2649
[06/10/2022-19:21:33] [V] [TRT] MatMul_2072 [MatMul] outputs: [2649 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Mul_2074 [Mul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2649
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2650
[06/10/2022-19:21:33] [V] [TRT] Mul_2074 [Mul] inputs: [2649 -> (-1, 8, 1024, 1024)[FLOAT]], [2650 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2650 for ONNX node: 2650
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Mul_2074 for ONNX node: Mul_2074
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2651 for ONNX tensor: 2651
[06/10/2022-19:21:33] [V] [TRT] Mul_2074 [Mul] outputs: [2651 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Softmax_2075 [Softmax]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2651
[06/10/2022-19:21:33] [V] [TRT] Softmax_2075 [Softmax] inputs: [2651 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Softmax_2075 for ONNX node: Softmax_2075
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2652 for ONNX tensor: 2652
[06/10/2022-19:21:33] [V] [TRT] Softmax_2075 [Softmax] outputs: [2652 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2076 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2652
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2647
[06/10/2022-19:21:33] [V] [TRT] MatMul_2076 [MatMul] inputs: [2652 -> (-1, 8, 1024, 1024)[FLOAT]], [2647 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2076 for ONNX node: MatMul_2076
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2653 for ONNX tensor: 2653
[06/10/2022-19:21:33] [V] [TRT] MatMul_2076 [MatMul] outputs: [2653 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2077 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2653
[06/10/2022-19:21:33] [V] [TRT] Transpose_2077 [Transpose] inputs: [2653 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2077 for ONNX node: Transpose_2077
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2654 for ONNX tensor: 2654
[06/10/2022-19:21:33] [V] [TRT] Transpose_2077 [Transpose] outputs: [2654 -> (-1, 1024, 8, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2078 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2604
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2078 [Unsqueeze] inputs: [2604 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2078 for ONNX node: Unsqueeze_2078
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2655 for ONNX tensor: 2655
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2078 [Unsqueeze] outputs: [2655 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2079 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2607
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2079 [Unsqueeze] inputs: [2607 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2079 for ONNX node: Unsqueeze_2079
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2656 for ONNX tensor: 2656
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2079 [Unsqueeze] outputs: [2656 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2080 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2610
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2080 [Unsqueeze] inputs: [2610 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2080 for ONNX node: Unsqueeze_2080
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2657 for ONNX tensor: 2657
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2080 [Unsqueeze] outputs: [2657 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2081 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2655
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2656
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2657
[06/10/2022-19:21:33] [V] [TRT] Concat_2081 [Concat] inputs: [2655 -> (1)[INT32]], [2656 -> (1)[INT32]], [2657 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2081 for ONNX node: Concat_2081
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2658 for ONNX tensor: 2658
[06/10/2022-19:21:33] [V] [TRT] Concat_2081 [Concat] outputs: [2658 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2082 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2654
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2658
[06/10/2022-19:21:33] [V] [TRT] Reshape_2082 [Reshape] inputs: [2654 -> (-1, 1024, 8, 64)[FLOAT]], [2658 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2082 for ONNX node: Reshape_2082
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2659 for ONNX tensor: 2659
[06/10/2022-19:21:33] [V] [TRT] Reshape_2082 [Reshape] outputs: [2659 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2083 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2659
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3207
[06/10/2022-19:21:33] [V] [TRT] MatMul_2083 [MatMul] inputs: [2659 -> (-1, 1024, 512)[FLOAT]], [3207 -> (512, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3207 for ONNX node: 3207
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2083 for ONNX node: MatMul_2083
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2661 for ONNX tensor: 2661
[06/10/2022-19:21:33] [V] [TRT] MatMul_2083 [MatMul] outputs: [2661 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2084 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2661
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.1.attn.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2084 [Add] inputs: [2661 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.1.attn.proj.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.1.attn.proj.bias for ONNX node: backbone.block4.1.attn.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2084 for ONNX node: Add_2084
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2662 for ONNX tensor: 2662
[06/10/2022-19:21:33] [V] [TRT] Add_2084 [Add] outputs: [2662 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2085 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2590
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2662
[06/10/2022-19:21:33] [V] [TRT] Add_2085 [Add] inputs: [2590 -> (-1, 1024, 512)[FLOAT]], [2662 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2085 for ONNX node: Add_2085
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2663 for ONNX tensor: 2663
[06/10/2022-19:21:33] [V] [TRT] Add_2085 [Add] outputs: [2663 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: ReduceMean_2086 [ReduceMean]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2663
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2086 [ReduceMean] inputs: [2663 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: ReduceMean_2086 for ONNX node: ReduceMean_2086
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2664 for ONNX tensor: 2664
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2086 [ReduceMean] outputs: [2664 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Sub_2087 [Sub]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2663
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2664
[06/10/2022-19:21:33] [V] [TRT] Sub_2087 [Sub] inputs: [2663 -> (-1, 1024, 512)[FLOAT]], [2664 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Sub_2087 for ONNX node: Sub_2087
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2665 for ONNX tensor: 2665
[06/10/2022-19:21:33] [V] [TRT] Sub_2087 [Sub] outputs: [2665 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Pow_2089 [Pow]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2665
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2666
[06/10/2022-19:21:33] [V] [TRT] Pow_2089 [Pow] inputs: [2665 -> (-1, 1024, 512)[FLOAT]], [2666 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2666 for ONNX node: 2666
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Pow_2089 for ONNX node: Pow_2089
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2667 for ONNX tensor: 2667
[06/10/2022-19:21:33] [V] [TRT] Pow_2089 [Pow] outputs: [2667 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: ReduceMean_2090 [ReduceMean]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2667
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2090 [ReduceMean] inputs: [2667 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: ReduceMean_2090 for ONNX node: ReduceMean_2090
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2668 for ONNX tensor: 2668
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2090 [ReduceMean] outputs: [2668 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2092 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2668
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2669
[06/10/2022-19:21:33] [V] [TRT] Add_2092 [Add] inputs: [2668 -> (-1, 1024, 1)[FLOAT]], [2669 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2669 for ONNX node: 2669
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2092 for ONNX node: Add_2092
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2670 for ONNX tensor: 2670
[06/10/2022-19:21:33] [V] [TRT] Add_2092 [Add] outputs: [2670 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Sqrt_2093 [Sqrt]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2670
[06/10/2022-19:21:33] [V] [TRT] Sqrt_2093 [Sqrt] inputs: [2670 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Sqrt_2093 for ONNX node: Sqrt_2093
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2671 for ONNX tensor: 2671
[06/10/2022-19:21:33] [V] [TRT] Sqrt_2093 [Sqrt] outputs: [2671 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Div_2094 [Div]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2665
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2671
[06/10/2022-19:21:33] [V] [TRT] Div_2094 [Div] inputs: [2665 -> (-1, 1024, 512)[FLOAT]], [2671 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Div_2094 for ONNX node: Div_2094
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2672 for ONNX tensor: 2672
[06/10/2022-19:21:33] [V] [TRT] Div_2094 [Div] outputs: [2672 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Mul_2095 [Mul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2672
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.1.norm2.weight
[06/10/2022-19:21:33] [V] [TRT] Mul_2095 [Mul] inputs: [2672 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.1.norm2.weight -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.1.norm2.weight for ONNX node: backbone.block4.1.norm2.weight
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Mul_2095 for ONNX node: Mul_2095
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2673 for ONNX tensor: 2673
[06/10/2022-19:21:33] [V] [TRT] Mul_2095 [Mul] outputs: [2673 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2096 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2673
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.1.norm2.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2096 [Add] inputs: [2673 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.1.norm2.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.1.norm2.bias for ONNX node: backbone.block4.1.norm2.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2096 for ONNX node: Add_2096
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2674 for ONNX tensor: 2674
[06/10/2022-19:21:33] [V] [TRT] Add_2096 [Add] outputs: [2674 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2097 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2674
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3208
[06/10/2022-19:21:33] [V] [TRT] MatMul_2097 [MatMul] inputs: [2674 -> (-1, 1024, 512)[FLOAT]], [3208 -> (512, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3208 for ONNX node: 3208
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2097 for ONNX node: MatMul_2097
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2676 for ONNX tensor: 2676
[06/10/2022-19:21:33] [V] [TRT] MatMul_2097 [MatMul] outputs: [2676 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2098 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2676
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.1.mlp.fc1.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2098 [Add] inputs: [2676 -> (-1, 1024, 2048)[FLOAT]], [backbone.block4.1.mlp.fc1.bias -> (2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.1.mlp.fc1.bias for ONNX node: backbone.block4.1.mlp.fc1.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2098 for ONNX node: Add_2098
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2677 for ONNX tensor: 2677
[06/10/2022-19:21:33] [V] [TRT] Add_2098 [Add] outputs: [2677 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2099 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2677
[06/10/2022-19:21:33] [V] [TRT] Shape_2099 [Shape] inputs: [2677 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2099 for ONNX node: Shape_2099
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2678 for ONNX tensor: 2678
[06/10/2022-19:21:33] [V] [TRT] Shape_2099 [Shape] outputs: [2678 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2101 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2678
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2679
[06/10/2022-19:21:33] [V] [TRT] Gather_2101 [Gather] inputs: [2678 -> (3)[INT32]], [2679 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2679 for ONNX node: 2679
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2101 for ONNX node: Gather_2101
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2680 for ONNX tensor: 2680
[06/10/2022-19:21:33] [V] [TRT] Gather_2101 [Gather] outputs: [2680 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2102 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2677
[06/10/2022-19:21:33] [V] [TRT] Shape_2102 [Shape] inputs: [2677 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2102 for ONNX node: Shape_2102
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2681 for ONNX tensor: 2681
[06/10/2022-19:21:33] [V] [TRT] Shape_2102 [Shape] outputs: [2681 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2104 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2681
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2682
[06/10/2022-19:21:33] [V] [TRT] Gather_2104 [Gather] inputs: [2681 -> (3)[INT32]], [2682 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2682 for ONNX node: 2682
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2104 for ONNX node: Gather_2104
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2683 for ONNX tensor: 2683
[06/10/2022-19:21:33] [V] [TRT] Gather_2104 [Gather] outputs: [2683 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2105 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2677
[06/10/2022-19:21:33] [V] [TRT] Transpose_2105 [Transpose] inputs: [2677 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2105 for ONNX node: Transpose_2105
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2684 for ONNX tensor: 2684
[06/10/2022-19:21:33] [V] [TRT] Transpose_2105 [Transpose] outputs: [2684 -> (-1, 2048, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2106 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2680
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2106 [Unsqueeze] inputs: [2680 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2106 for ONNX node: Unsqueeze_2106
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2685 for ONNX tensor: 2685
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2106 [Unsqueeze] outputs: [2685 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2107 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2683
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2107 [Unsqueeze] inputs: [2683 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2107 for ONNX node: Unsqueeze_2107
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2686 for ONNX tensor: 2686
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2107 [Unsqueeze] outputs: [2686 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2108 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2445
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2108 [Unsqueeze] inputs: [2445 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2108 for ONNX node: Unsqueeze_2108
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2687 for ONNX tensor: 2687
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2108 [Unsqueeze] outputs: [2687 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2109 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2448
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2109 [Unsqueeze] inputs: [2448 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2109 for ONNX node: Unsqueeze_2109
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2688 for ONNX tensor: 2688
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2109 [Unsqueeze] outputs: [2688 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2110 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2685
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2686
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2687
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2688
[06/10/2022-19:21:33] [V] [TRT] Concat_2110 [Concat] inputs: [2685 -> (1)[INT32]], [2686 -> (1)[INT32]], [2687 -> (1)[INT32]], [2688 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2110 for ONNX node: Concat_2110
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2689 for ONNX tensor: 2689
[06/10/2022-19:21:33] [V] [TRT] Concat_2110 [Concat] outputs: [2689 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2111 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2684
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2689
[06/10/2022-19:21:33] [V] [TRT] Reshape_2111 [Reshape] inputs: [2684 -> (-1, 2048, 1024)[FLOAT]], [2689 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2111 for ONNX node: Reshape_2111
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2690 for ONNX tensor: 2690
[06/10/2022-19:21:33] [V] [TRT] Reshape_2111 [Reshape] outputs: [2690 -> (-1, 2048, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Conv_2112 [Conv]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2690
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.1.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.1.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:33] [V] [TRT] Conv_2112 [Conv] inputs: [2690 -> (-1, 2048, 32, 32)[FLOAT]], [backbone.block4.1.mlp.dwconv.dwconv.weight -> (2048, 1, 3, 3)[FLOAT]], [backbone.block4.1.mlp.dwconv.dwconv.bias -> (2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Convolution input dimensions: (-1, 2048, 32, 32)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Conv_2112 for ONNX node: Conv_2112
[06/10/2022-19:21:33] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2048
[06/10/2022-19:21:33] [V] [TRT] Convolution output dimensions: (-1, 2048, 32, 32)
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2691 for ONNX tensor: 2691
[06/10/2022-19:21:33] [V] [TRT] Conv_2112 [Conv] outputs: [2691 -> (-1, 2048, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2113 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2691
[06/10/2022-19:21:33] [V] [TRT] Shape_2113 [Shape] inputs: [2691 -> (-1, 2048, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2113 for ONNX node: Shape_2113
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2692 for ONNX tensor: 2692
[06/10/2022-19:21:33] [V] [TRT] Shape_2113 [Shape] outputs: [2692 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Slice_2117 [Slice]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2692
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2694
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2695
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2693
[06/10/2022-19:21:33] [V] [TRT] Slice_2117 [Slice] inputs: [2692 -> (4)[INT32]], [2694 -> (1)[INT32]], [2695 -> (1)[INT32]], [2693 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Slice_2117 for ONNX node: Slice_2117
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2696 for ONNX tensor: 2696
[06/10/2022-19:21:33] [V] [TRT] Slice_2117 [Slice] outputs: [2696 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2119 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2696
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2697
[06/10/2022-19:21:33] [V] [TRT] Concat_2119 [Concat] inputs: [2696 -> (2)[INT32]], [2697 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2697 for ONNX node: 2697
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2119 for ONNX node: Concat_2119
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2698 for ONNX tensor: 2698
[06/10/2022-19:21:33] [V] [TRT] Concat_2119 [Concat] outputs: [2698 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2120 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2691
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2698
[06/10/2022-19:21:33] [V] [TRT] Reshape_2120 [Reshape] inputs: [2691 -> (-1, 2048, 32, 32)[FLOAT]], [2698 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2120 for ONNX node: Reshape_2120
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2699 for ONNX tensor: 2699
[06/10/2022-19:21:33] [V] [TRT] Reshape_2120 [Reshape] outputs: [2699 -> (-1, 2048, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2121 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2699
[06/10/2022-19:21:33] [V] [TRT] Transpose_2121 [Transpose] inputs: [2699 -> (-1, 2048, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2121 for ONNX node: Transpose_2121
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2700 for ONNX tensor: 2700
[06/10/2022-19:21:33] [V] [TRT] Transpose_2121 [Transpose] outputs: [2700 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Div_2123 [Div]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2700
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2701
[06/10/2022-19:21:33] [V] [TRT] Div_2123 [Div] inputs: [2700 -> (-1, 1024, 2048)[FLOAT]], [2701 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2701 for ONNX node: 2701
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Div_2123 for ONNX node: Div_2123
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2702 for ONNX tensor: 2702
[06/10/2022-19:21:33] [V] [TRT] Div_2123 [Div] outputs: [2702 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Erf_2124 [Erf]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2702
[06/10/2022-19:21:33] [V] [TRT] Erf_2124 [Erf] inputs: [2702 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Erf_2124 for ONNX node: Erf_2124
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2703 for ONNX tensor: 2703
[06/10/2022-19:21:33] [V] [TRT] Erf_2124 [Erf] outputs: [2703 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2126 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2703
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2704
[06/10/2022-19:21:33] [V] [TRT] Add_2126 [Add] inputs: [2703 -> (-1, 1024, 2048)[FLOAT]], [2704 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2704 for ONNX node: 2704
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2126 for ONNX node: Add_2126
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2705 for ONNX tensor: 2705
[06/10/2022-19:21:33] [V] [TRT] Add_2126 [Add] outputs: [2705 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Mul_2127 [Mul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2700
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2705
[06/10/2022-19:21:33] [V] [TRT] Mul_2127 [Mul] inputs: [2700 -> (-1, 1024, 2048)[FLOAT]], [2705 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Mul_2127 for ONNX node: Mul_2127
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2706 for ONNX tensor: 2706
[06/10/2022-19:21:33] [V] [TRT] Mul_2127 [Mul] outputs: [2706 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Mul_2129 [Mul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2706
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2707
[06/10/2022-19:21:33] [V] [TRT] Mul_2129 [Mul] inputs: [2706 -> (-1, 1024, 2048)[FLOAT]], [2707 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2707 for ONNX node: 2707
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Mul_2129 for ONNX node: Mul_2129
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2708 for ONNX tensor: 2708
[06/10/2022-19:21:33] [V] [TRT] Mul_2129 [Mul] outputs: [2708 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2130 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2708
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3209
[06/10/2022-19:21:33] [V] [TRT] MatMul_2130 [MatMul] inputs: [2708 -> (-1, 1024, 2048)[FLOAT]], [3209 -> (2048, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3209 for ONNX node: 3209
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2130 for ONNX node: MatMul_2130
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2710 for ONNX tensor: 2710
[06/10/2022-19:21:33] [V] [TRT] MatMul_2130 [MatMul] outputs: [2710 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2131 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2710
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.1.mlp.fc2.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2131 [Add] inputs: [2710 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.1.mlp.fc2.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.1.mlp.fc2.bias for ONNX node: backbone.block4.1.mlp.fc2.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2131 for ONNX node: Add_2131
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2711 for ONNX tensor: 2711
[06/10/2022-19:21:33] [V] [TRT] Add_2131 [Add] outputs: [2711 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2132 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2663
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2711
[06/10/2022-19:21:33] [V] [TRT] Add_2132 [Add] inputs: [2663 -> (-1, 1024, 512)[FLOAT]], [2711 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2132 for ONNX node: Add_2132
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2712 for ONNX tensor: 2712
[06/10/2022-19:21:33] [V] [TRT] Add_2132 [Add] outputs: [2712 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: ReduceMean_2133 [ReduceMean]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2712
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2133 [ReduceMean] inputs: [2712 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: ReduceMean_2133 for ONNX node: ReduceMean_2133
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2713 for ONNX tensor: 2713
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2133 [ReduceMean] outputs: [2713 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Sub_2134 [Sub]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2712
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2713
[06/10/2022-19:21:33] [V] [TRT] Sub_2134 [Sub] inputs: [2712 -> (-1, 1024, 512)[FLOAT]], [2713 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Sub_2134 for ONNX node: Sub_2134
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2714 for ONNX tensor: 2714
[06/10/2022-19:21:33] [V] [TRT] Sub_2134 [Sub] outputs: [2714 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Pow_2136 [Pow]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2714
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2715
[06/10/2022-19:21:33] [V] [TRT] Pow_2136 [Pow] inputs: [2714 -> (-1, 1024, 512)[FLOAT]], [2715 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2715 for ONNX node: 2715
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Pow_2136 for ONNX node: Pow_2136
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2716 for ONNX tensor: 2716
[06/10/2022-19:21:33] [V] [TRT] Pow_2136 [Pow] outputs: [2716 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: ReduceMean_2137 [ReduceMean]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2716
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2137 [ReduceMean] inputs: [2716 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: ReduceMean_2137 for ONNX node: ReduceMean_2137
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2717 for ONNX tensor: 2717
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2137 [ReduceMean] outputs: [2717 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2139 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2717
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2718
[06/10/2022-19:21:33] [V] [TRT] Add_2139 [Add] inputs: [2717 -> (-1, 1024, 1)[FLOAT]], [2718 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2718 for ONNX node: 2718
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2139 for ONNX node: Add_2139
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2719 for ONNX tensor: 2719
[06/10/2022-19:21:33] [V] [TRT] Add_2139 [Add] outputs: [2719 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Sqrt_2140 [Sqrt]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2719
[06/10/2022-19:21:33] [V] [TRT] Sqrt_2140 [Sqrt] inputs: [2719 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Sqrt_2140 for ONNX node: Sqrt_2140
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2720 for ONNX tensor: 2720
[06/10/2022-19:21:33] [V] [TRT] Sqrt_2140 [Sqrt] outputs: [2720 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Div_2141 [Div]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2714
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2720
[06/10/2022-19:21:33] [V] [TRT] Div_2141 [Div] inputs: [2714 -> (-1, 1024, 512)[FLOAT]], [2720 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Div_2141 for ONNX node: Div_2141
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2721 for ONNX tensor: 2721
[06/10/2022-19:21:33] [V] [TRT] Div_2141 [Div] outputs: [2721 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Mul_2142 [Mul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2721
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.2.norm1.weight
[06/10/2022-19:21:33] [V] [TRT] Mul_2142 [Mul] inputs: [2721 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.2.norm1.weight -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.2.norm1.weight for ONNX node: backbone.block4.2.norm1.weight
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Mul_2142 for ONNX node: Mul_2142
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2722 for ONNX tensor: 2722
[06/10/2022-19:21:33] [V] [TRT] Mul_2142 [Mul] outputs: [2722 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2143 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2722
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.2.norm1.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2143 [Add] inputs: [2722 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.2.norm1.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.2.norm1.bias for ONNX node: backbone.block4.2.norm1.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2143 for ONNX node: Add_2143
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2723 for ONNX tensor: 2723
[06/10/2022-19:21:33] [V] [TRT] Add_2143 [Add] outputs: [2723 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2144 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2723
[06/10/2022-19:21:33] [V] [TRT] Shape_2144 [Shape] inputs: [2723 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2144 for ONNX node: Shape_2144
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2724 for ONNX tensor: 2724
[06/10/2022-19:21:33] [V] [TRT] Shape_2144 [Shape] outputs: [2724 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2146 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2724
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2725
[06/10/2022-19:21:33] [V] [TRT] Gather_2146 [Gather] inputs: [2724 -> (3)[INT32]], [2725 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2725 for ONNX node: 2725
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2146 for ONNX node: Gather_2146
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2726 for ONNX tensor: 2726
[06/10/2022-19:21:33] [V] [TRT] Gather_2146 [Gather] outputs: [2726 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2147 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2723
[06/10/2022-19:21:33] [V] [TRT] Shape_2147 [Shape] inputs: [2723 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2147 for ONNX node: Shape_2147
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2727 for ONNX tensor: 2727
[06/10/2022-19:21:33] [V] [TRT] Shape_2147 [Shape] outputs: [2727 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2149 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2727
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2728
[06/10/2022-19:21:33] [V] [TRT] Gather_2149 [Gather] inputs: [2727 -> (3)[INT32]], [2728 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2728 for ONNX node: 2728
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2149 for ONNX node: Gather_2149
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2729 for ONNX tensor: 2729
[06/10/2022-19:21:33] [V] [TRT] Gather_2149 [Gather] outputs: [2729 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2150 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2723
[06/10/2022-19:21:33] [V] [TRT] Shape_2150 [Shape] inputs: [2723 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2150 for ONNX node: Shape_2150
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2730 for ONNX tensor: 2730
[06/10/2022-19:21:33] [V] [TRT] Shape_2150 [Shape] outputs: [2730 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2152 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2730
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2731
[06/10/2022-19:21:33] [V] [TRT] Gather_2152 [Gather] inputs: [2730 -> (3)[INT32]], [2731 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2731 for ONNX node: 2731
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2152 for ONNX node: Gather_2152
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2732 for ONNX tensor: 2732
[06/10/2022-19:21:33] [V] [TRT] Gather_2152 [Gather] outputs: [2732 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2153 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2723
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3210
[06/10/2022-19:21:33] [V] [TRT] MatMul_2153 [MatMul] inputs: [2723 -> (-1, 1024, 512)[FLOAT]], [3210 -> (512, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3210 for ONNX node: 3210
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2153 for ONNX node: MatMul_2153
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2734 for ONNX tensor: 2734
[06/10/2022-19:21:33] [V] [TRT] MatMul_2153 [MatMul] outputs: [2734 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2154 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2734
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.2.attn.q.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2154 [Add] inputs: [2734 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.2.attn.q.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.2.attn.q.bias for ONNX node: backbone.block4.2.attn.q.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2154 for ONNX node: Add_2154
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2735 for ONNX tensor: 2735
[06/10/2022-19:21:33] [V] [TRT] Add_2154 [Add] outputs: [2735 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Div_2156 [Div]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2732
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2736
[06/10/2022-19:21:33] [V] [TRT] Div_2156 [Div] inputs: [2732 -> ()[INT32]], [2736 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2736 for ONNX node: 2736
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Div_2156 for ONNX node: Div_2156
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2737 for ONNX tensor: 2737
[06/10/2022-19:21:33] [V] [TRT] Div_2156 [Div] outputs: [2737 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Cast_2157 [Cast]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2737
[06/10/2022-19:21:33] [V] [TRT] Cast_2157 [Cast] inputs: [2737 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Cast_2157 for ONNX node: Cast_2157
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2738 for ONNX tensor: 2738
[06/10/2022-19:21:33] [V] [TRT] Cast_2157 [Cast] outputs: [2738 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Cast_2158 [Cast]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2738
[06/10/2022-19:21:33] [V] [TRT] Cast_2158 [Cast] inputs: [2738 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Cast_2158 for ONNX node: Cast_2158
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2739 for ONNX tensor: 2739
[06/10/2022-19:21:33] [V] [TRT] Cast_2158 [Cast] outputs: [2739 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2159 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2726
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2159 [Unsqueeze] inputs: [2726 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2159 for ONNX node: Unsqueeze_2159
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2741 for ONNX tensor: 2741
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2159 [Unsqueeze] outputs: [2741 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2160 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2729
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2160 [Unsqueeze] inputs: [2729 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2160 for ONNX node: Unsqueeze_2160
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2742 for ONNX tensor: 2742
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2160 [Unsqueeze] outputs: [2742 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2161 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2739
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2161 [Unsqueeze] inputs: [2739 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2161 for ONNX node: Unsqueeze_2161
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2744 for ONNX tensor: 2744
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2161 [Unsqueeze] outputs: [2744 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2162 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2741
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2742
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3211
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2744
[06/10/2022-19:21:33] [V] [TRT] Concat_2162 [Concat] inputs: [2741 -> (1)[INT32]], [2742 -> (1)[INT32]], [3211 -> (1)[INT32]], [2744 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3211 for ONNX node: 3211
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2162 for ONNX node: Concat_2162
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2745 for ONNX tensor: 2745
[06/10/2022-19:21:33] [V] [TRT] Concat_2162 [Concat] outputs: [2745 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2163 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2735
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2745
[06/10/2022-19:21:33] [V] [TRT] Reshape_2163 [Reshape] inputs: [2735 -> (-1, 1024, 512)[FLOAT]], [2745 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2163 for ONNX node: Reshape_2163
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2746 for ONNX tensor: 2746
[06/10/2022-19:21:33] [V] [TRT] Reshape_2163 [Reshape] outputs: [2746 -> (-1, 1024, 8, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2164 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2746
[06/10/2022-19:21:33] [V] [TRT] Transpose_2164 [Transpose] inputs: [2746 -> (-1, 1024, 8, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2164 for ONNX node: Transpose_2164
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2747 for ONNX tensor: 2747
[06/10/2022-19:21:33] [V] [TRT] Transpose_2164 [Transpose] outputs: [2747 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2165 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2723
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3212
[06/10/2022-19:21:33] [V] [TRT] MatMul_2165 [MatMul] inputs: [2723 -> (-1, 1024, 512)[FLOAT]], [3212 -> (512, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3212 for ONNX node: 3212
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2165 for ONNX node: MatMul_2165
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2749 for ONNX tensor: 2749
[06/10/2022-19:21:33] [V] [TRT] MatMul_2165 [MatMul] outputs: [2749 -> (-1, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2166 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2749
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.2.attn.kv.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2166 [Add] inputs: [2749 -> (-1, 1024, 1024)[FLOAT]], [backbone.block4.2.attn.kv.bias -> (1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.2.attn.kv.bias for ONNX node: backbone.block4.2.attn.kv.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2166 for ONNX node: Add_2166
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2750 for ONNX tensor: 2750
[06/10/2022-19:21:33] [V] [TRT] Add_2166 [Add] outputs: [2750 -> (-1, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Div_2168 [Div]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2732
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2751
[06/10/2022-19:21:33] [V] [TRT] Div_2168 [Div] inputs: [2732 -> ()[INT32]], [2751 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2751 for ONNX node: 2751
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Div_2168 for ONNX node: Div_2168
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2752 for ONNX tensor: 2752
[06/10/2022-19:21:33] [V] [TRT] Div_2168 [Div] outputs: [2752 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Cast_2169 [Cast]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2752
[06/10/2022-19:21:33] [V] [TRT] Cast_2169 [Cast] inputs: [2752 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Cast_2169 for ONNX node: Cast_2169
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2753 for ONNX tensor: 2753
[06/10/2022-19:21:33] [V] [TRT] Cast_2169 [Cast] outputs: [2753 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Cast_2170 [Cast]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2753
[06/10/2022-19:21:33] [V] [TRT] Cast_2170 [Cast] inputs: [2753 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Casting to type: int32
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Cast_2170 for ONNX node: Cast_2170
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2754 for ONNX tensor: 2754
[06/10/2022-19:21:33] [V] [TRT] Cast_2170 [Cast] outputs: [2754 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2171 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2726
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2171 [Unsqueeze] inputs: [2726 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2171 for ONNX node: Unsqueeze_2171
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2758 for ONNX tensor: 2758
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2171 [Unsqueeze] outputs: [2758 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2172 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2754
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2172 [Unsqueeze] inputs: [2754 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2172 for ONNX node: Unsqueeze_2172
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2762 for ONNX tensor: 2762
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2172 [Unsqueeze] outputs: [2762 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2173 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2758
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3213
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3214
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3215
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2762
[06/10/2022-19:21:33] [V] [TRT] Concat_2173 [Concat] inputs: [2758 -> (1)[INT32]], [3213 -> (1)[INT32]], [3214 -> (1)[INT32]], [3215 -> (1)[INT32]], [2762 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3213 for ONNX node: 3213
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3214 for ONNX node: 3214
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3215 for ONNX node: 3215
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2173 for ONNX node: Concat_2173
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2763 for ONNX tensor: 2763
[06/10/2022-19:21:33] [V] [TRT] Concat_2173 [Concat] outputs: [2763 -> (5)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2174 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2750
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2763
[06/10/2022-19:21:33] [V] [TRT] Reshape_2174 [Reshape] inputs: [2750 -> (-1, 1024, 1024)[FLOAT]], [2763 -> (5)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2174 for ONNX node: Reshape_2174
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2764 for ONNX tensor: 2764
[06/10/2022-19:21:33] [V] [TRT] Reshape_2174 [Reshape] outputs: [2764 -> (-1, 1024, 2, 8, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2175 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2764
[06/10/2022-19:21:33] [V] [TRT] Transpose_2175 [Transpose] inputs: [2764 -> (-1, 1024, 2, 8, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2175 for ONNX node: Transpose_2175
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2765 for ONNX tensor: 2765
[06/10/2022-19:21:33] [V] [TRT] Transpose_2175 [Transpose] outputs: [2765 -> (2, -1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2177 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2765
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2766
[06/10/2022-19:21:33] [V] [TRT] Gather_2177 [Gather] inputs: [2765 -> (2, -1, 8, 1024, 64)[FLOAT]], [2766 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2766 for ONNX node: 2766
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2177 for ONNX node: Gather_2177
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2767 for ONNX tensor: 2767
[06/10/2022-19:21:33] [V] [TRT] Gather_2177 [Gather] outputs: [2767 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2179 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2765
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2768
[06/10/2022-19:21:33] [V] [TRT] Gather_2179 [Gather] inputs: [2765 -> (2, -1, 8, 1024, 64)[FLOAT]], [2768 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2768 for ONNX node: 2768
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2179 for ONNX node: Gather_2179
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2769 for ONNX tensor: 2769
[06/10/2022-19:21:33] [V] [TRT] Gather_2179 [Gather] outputs: [2769 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2180 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2767
[06/10/2022-19:21:33] [V] [TRT] Transpose_2180 [Transpose] inputs: [2767 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2180 for ONNX node: Transpose_2180
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2770 for ONNX tensor: 2770
[06/10/2022-19:21:33] [V] [TRT] Transpose_2180 [Transpose] outputs: [2770 -> (-1, 8, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2181 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2747
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2770
[06/10/2022-19:21:33] [V] [TRT] MatMul_2181 [MatMul] inputs: [2747 -> (-1, 8, 1024, 64)[FLOAT]], [2770 -> (-1, 8, 64, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2181 for ONNX node: MatMul_2181
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2771 for ONNX tensor: 2771
[06/10/2022-19:21:33] [V] [TRT] MatMul_2181 [MatMul] outputs: [2771 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Mul_2183 [Mul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2771
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2772
[06/10/2022-19:21:33] [V] [TRT] Mul_2183 [Mul] inputs: [2771 -> (-1, 8, 1024, 1024)[FLOAT]], [2772 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2772 for ONNX node: 2772
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Mul_2183 for ONNX node: Mul_2183
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2773 for ONNX tensor: 2773
[06/10/2022-19:21:33] [V] [TRT] Mul_2183 [Mul] outputs: [2773 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Softmax_2184 [Softmax]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2773
[06/10/2022-19:21:33] [V] [TRT] Softmax_2184 [Softmax] inputs: [2773 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Softmax_2184 for ONNX node: Softmax_2184
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2774 for ONNX tensor: 2774
[06/10/2022-19:21:33] [V] [TRT] Softmax_2184 [Softmax] outputs: [2774 -> (-1, 8, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2185 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2774
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2769
[06/10/2022-19:21:33] [V] [TRT] MatMul_2185 [MatMul] inputs: [2774 -> (-1, 8, 1024, 1024)[FLOAT]], [2769 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2185 for ONNX node: MatMul_2185
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2775 for ONNX tensor: 2775
[06/10/2022-19:21:33] [V] [TRT] MatMul_2185 [MatMul] outputs: [2775 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2186 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2775
[06/10/2022-19:21:33] [V] [TRT] Transpose_2186 [Transpose] inputs: [2775 -> (-1, 8, 1024, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2186 for ONNX node: Transpose_2186
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2776 for ONNX tensor: 2776
[06/10/2022-19:21:33] [V] [TRT] Transpose_2186 [Transpose] outputs: [2776 -> (-1, 1024, 8, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2187 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2726
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2187 [Unsqueeze] inputs: [2726 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2187 for ONNX node: Unsqueeze_2187
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2777 for ONNX tensor: 2777
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2187 [Unsqueeze] outputs: [2777 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2188 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2729
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2188 [Unsqueeze] inputs: [2729 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2188 for ONNX node: Unsqueeze_2188
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2778 for ONNX tensor: 2778
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2188 [Unsqueeze] outputs: [2778 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2189 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2732
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2189 [Unsqueeze] inputs: [2732 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2189 for ONNX node: Unsqueeze_2189
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2779 for ONNX tensor: 2779
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2189 [Unsqueeze] outputs: [2779 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2190 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2777
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2778
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2779
[06/10/2022-19:21:33] [V] [TRT] Concat_2190 [Concat] inputs: [2777 -> (1)[INT32]], [2778 -> (1)[INT32]], [2779 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2190 for ONNX node: Concat_2190
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2780 for ONNX tensor: 2780
[06/10/2022-19:21:33] [V] [TRT] Concat_2190 [Concat] outputs: [2780 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2191 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2776
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2780
[06/10/2022-19:21:33] [V] [TRT] Reshape_2191 [Reshape] inputs: [2776 -> (-1, 1024, 8, 64)[FLOAT]], [2780 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2191 for ONNX node: Reshape_2191
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2781 for ONNX tensor: 2781
[06/10/2022-19:21:33] [V] [TRT] Reshape_2191 [Reshape] outputs: [2781 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2192 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2781
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3216
[06/10/2022-19:21:33] [V] [TRT] MatMul_2192 [MatMul] inputs: [2781 -> (-1, 1024, 512)[FLOAT]], [3216 -> (512, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3216 for ONNX node: 3216
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2192 for ONNX node: MatMul_2192
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2783 for ONNX tensor: 2783
[06/10/2022-19:21:33] [V] [TRT] MatMul_2192 [MatMul] outputs: [2783 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2193 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2783
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.2.attn.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2193 [Add] inputs: [2783 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.2.attn.proj.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.2.attn.proj.bias for ONNX node: backbone.block4.2.attn.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2193 for ONNX node: Add_2193
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2784 for ONNX tensor: 2784
[06/10/2022-19:21:33] [V] [TRT] Add_2193 [Add] outputs: [2784 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2194 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2712
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2784
[06/10/2022-19:21:33] [V] [TRT] Add_2194 [Add] inputs: [2712 -> (-1, 1024, 512)[FLOAT]], [2784 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2194 for ONNX node: Add_2194
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2785 for ONNX tensor: 2785
[06/10/2022-19:21:33] [V] [TRT] Add_2194 [Add] outputs: [2785 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: ReduceMean_2195 [ReduceMean]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2785
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2195 [ReduceMean] inputs: [2785 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: ReduceMean_2195 for ONNX node: ReduceMean_2195
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2786 for ONNX tensor: 2786
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2195 [ReduceMean] outputs: [2786 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Sub_2196 [Sub]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2785
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2786
[06/10/2022-19:21:33] [V] [TRT] Sub_2196 [Sub] inputs: [2785 -> (-1, 1024, 512)[FLOAT]], [2786 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Sub_2196 for ONNX node: Sub_2196
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2787 for ONNX tensor: 2787
[06/10/2022-19:21:33] [V] [TRT] Sub_2196 [Sub] outputs: [2787 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Pow_2198 [Pow]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2787
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2788
[06/10/2022-19:21:33] [V] [TRT] Pow_2198 [Pow] inputs: [2787 -> (-1, 1024, 512)[FLOAT]], [2788 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2788 for ONNX node: 2788
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Pow_2198 for ONNX node: Pow_2198
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2789 for ONNX tensor: 2789
[06/10/2022-19:21:33] [V] [TRT] Pow_2198 [Pow] outputs: [2789 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: ReduceMean_2199 [ReduceMean]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2789
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2199 [ReduceMean] inputs: [2789 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: ReduceMean_2199 for ONNX node: ReduceMean_2199
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2790 for ONNX tensor: 2790
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2199 [ReduceMean] outputs: [2790 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2201 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2790
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2791
[06/10/2022-19:21:33] [V] [TRT] Add_2201 [Add] inputs: [2790 -> (-1, 1024, 1)[FLOAT]], [2791 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2791 for ONNX node: 2791
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2201 for ONNX node: Add_2201
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2792 for ONNX tensor: 2792
[06/10/2022-19:21:33] [V] [TRT] Add_2201 [Add] outputs: [2792 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Sqrt_2202 [Sqrt]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2792
[06/10/2022-19:21:33] [V] [TRT] Sqrt_2202 [Sqrt] inputs: [2792 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Sqrt_2202 for ONNX node: Sqrt_2202
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2793 for ONNX tensor: 2793
[06/10/2022-19:21:33] [V] [TRT] Sqrt_2202 [Sqrt] outputs: [2793 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Div_2203 [Div]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2787
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2793
[06/10/2022-19:21:33] [V] [TRT] Div_2203 [Div] inputs: [2787 -> (-1, 1024, 512)[FLOAT]], [2793 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Div_2203 for ONNX node: Div_2203
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2794 for ONNX tensor: 2794
[06/10/2022-19:21:33] [V] [TRT] Div_2203 [Div] outputs: [2794 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Mul_2204 [Mul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2794
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.2.norm2.weight
[06/10/2022-19:21:33] [V] [TRT] Mul_2204 [Mul] inputs: [2794 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.2.norm2.weight -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.2.norm2.weight for ONNX node: backbone.block4.2.norm2.weight
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Mul_2204 for ONNX node: Mul_2204
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2795 for ONNX tensor: 2795
[06/10/2022-19:21:33] [V] [TRT] Mul_2204 [Mul] outputs: [2795 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2205 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2795
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.2.norm2.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2205 [Add] inputs: [2795 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.2.norm2.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.2.norm2.bias for ONNX node: backbone.block4.2.norm2.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2205 for ONNX node: Add_2205
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2796 for ONNX tensor: 2796
[06/10/2022-19:21:33] [V] [TRT] Add_2205 [Add] outputs: [2796 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2206 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2796
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3217
[06/10/2022-19:21:33] [V] [TRT] MatMul_2206 [MatMul] inputs: [2796 -> (-1, 1024, 512)[FLOAT]], [3217 -> (512, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3217 for ONNX node: 3217
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2206 for ONNX node: MatMul_2206
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2798 for ONNX tensor: 2798
[06/10/2022-19:21:33] [V] [TRT] MatMul_2206 [MatMul] outputs: [2798 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2207 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2798
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.2.mlp.fc1.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2207 [Add] inputs: [2798 -> (-1, 1024, 2048)[FLOAT]], [backbone.block4.2.mlp.fc1.bias -> (2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.2.mlp.fc1.bias for ONNX node: backbone.block4.2.mlp.fc1.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2207 for ONNX node: Add_2207
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2799 for ONNX tensor: 2799
[06/10/2022-19:21:33] [V] [TRT] Add_2207 [Add] outputs: [2799 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2208 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2799
[06/10/2022-19:21:33] [V] [TRT] Shape_2208 [Shape] inputs: [2799 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2208 for ONNX node: Shape_2208
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2800 for ONNX tensor: 2800
[06/10/2022-19:21:33] [V] [TRT] Shape_2208 [Shape] outputs: [2800 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2210 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2800
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2801
[06/10/2022-19:21:33] [V] [TRT] Gather_2210 [Gather] inputs: [2800 -> (3)[INT32]], [2801 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2801 for ONNX node: 2801
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2210 for ONNX node: Gather_2210
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2802 for ONNX tensor: 2802
[06/10/2022-19:21:33] [V] [TRT] Gather_2210 [Gather] outputs: [2802 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2211 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2799
[06/10/2022-19:21:33] [V] [TRT] Shape_2211 [Shape] inputs: [2799 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2211 for ONNX node: Shape_2211
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2803 for ONNX tensor: 2803
[06/10/2022-19:21:33] [V] [TRT] Shape_2211 [Shape] outputs: [2803 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2213 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2803
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2804
[06/10/2022-19:21:33] [V] [TRT] Gather_2213 [Gather] inputs: [2803 -> (3)[INT32]], [2804 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2804 for ONNX node: 2804
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2213 for ONNX node: Gather_2213
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2805 for ONNX tensor: 2805
[06/10/2022-19:21:33] [V] [TRT] Gather_2213 [Gather] outputs: [2805 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2214 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2799
[06/10/2022-19:21:33] [V] [TRT] Transpose_2214 [Transpose] inputs: [2799 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2214 for ONNX node: Transpose_2214
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2806 for ONNX tensor: 2806
[06/10/2022-19:21:33] [V] [TRT] Transpose_2214 [Transpose] outputs: [2806 -> (-1, 2048, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2215 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2802
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2215 [Unsqueeze] inputs: [2802 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2215 for ONNX node: Unsqueeze_2215
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2807 for ONNX tensor: 2807
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2215 [Unsqueeze] outputs: [2807 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2216 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2805
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2216 [Unsqueeze] inputs: [2805 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2216 for ONNX node: Unsqueeze_2216
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2808 for ONNX tensor: 2808
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2216 [Unsqueeze] outputs: [2808 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2217 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2445
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2217 [Unsqueeze] inputs: [2445 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2217 for ONNX node: Unsqueeze_2217
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2809 for ONNX tensor: 2809
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2217 [Unsqueeze] outputs: [2809 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2218 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2448
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2218 [Unsqueeze] inputs: [2448 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2218 for ONNX node: Unsqueeze_2218
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2810 for ONNX tensor: 2810
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2218 [Unsqueeze] outputs: [2810 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2219 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2807
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2808
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2809
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2810
[06/10/2022-19:21:33] [V] [TRT] Concat_2219 [Concat] inputs: [2807 -> (1)[INT32]], [2808 -> (1)[INT32]], [2809 -> (1)[INT32]], [2810 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2219 for ONNX node: Concat_2219
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2811 for ONNX tensor: 2811
[06/10/2022-19:21:33] [V] [TRT] Concat_2219 [Concat] outputs: [2811 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2220 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2806
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2811
[06/10/2022-19:21:33] [V] [TRT] Reshape_2220 [Reshape] inputs: [2806 -> (-1, 2048, 1024)[FLOAT]], [2811 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2220 for ONNX node: Reshape_2220
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2812 for ONNX tensor: 2812
[06/10/2022-19:21:33] [V] [TRT] Reshape_2220 [Reshape] outputs: [2812 -> (-1, 2048, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Conv_2221 [Conv]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2812
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.2.mlp.dwconv.dwconv.weight
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.2.mlp.dwconv.dwconv.bias
[06/10/2022-19:21:33] [V] [TRT] Conv_2221 [Conv] inputs: [2812 -> (-1, 2048, 32, 32)[FLOAT]], [backbone.block4.2.mlp.dwconv.dwconv.weight -> (2048, 1, 3, 3)[FLOAT]], [backbone.block4.2.mlp.dwconv.dwconv.bias -> (2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Convolution input dimensions: (-1, 2048, 32, 32)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Conv_2221 for ONNX node: Conv_2221
[06/10/2022-19:21:33] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2048
[06/10/2022-19:21:33] [V] [TRT] Convolution output dimensions: (-1, 2048, 32, 32)
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2813 for ONNX tensor: 2813
[06/10/2022-19:21:33] [V] [TRT] Conv_2221 [Conv] outputs: [2813 -> (-1, 2048, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2222 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2813
[06/10/2022-19:21:33] [V] [TRT] Shape_2222 [Shape] inputs: [2813 -> (-1, 2048, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2222 for ONNX node: Shape_2222
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2814 for ONNX tensor: 2814
[06/10/2022-19:21:33] [V] [TRT] Shape_2222 [Shape] outputs: [2814 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Slice_2226 [Slice]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2814
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2816
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2817
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2815
[06/10/2022-19:21:33] [V] [TRT] Slice_2226 [Slice] inputs: [2814 -> (4)[INT32]], [2816 -> (1)[INT32]], [2817 -> (1)[INT32]], [2815 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Slice_2226 for ONNX node: Slice_2226
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2818 for ONNX tensor: 2818
[06/10/2022-19:21:33] [V] [TRT] Slice_2226 [Slice] outputs: [2818 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2228 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2818
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2819
[06/10/2022-19:21:33] [V] [TRT] Concat_2228 [Concat] inputs: [2818 -> (2)[INT32]], [2819 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2819 for ONNX node: 2819
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2228 for ONNX node: Concat_2228
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2820 for ONNX tensor: 2820
[06/10/2022-19:21:33] [V] [TRT] Concat_2228 [Concat] outputs: [2820 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2229 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2813
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2820
[06/10/2022-19:21:33] [V] [TRT] Reshape_2229 [Reshape] inputs: [2813 -> (-1, 2048, 32, 32)[FLOAT]], [2820 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2229 for ONNX node: Reshape_2229
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2821 for ONNX tensor: 2821
[06/10/2022-19:21:33] [V] [TRT] Reshape_2229 [Reshape] outputs: [2821 -> (-1, 2048, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2230 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2821
[06/10/2022-19:21:33] [V] [TRT] Transpose_2230 [Transpose] inputs: [2821 -> (-1, 2048, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2230 for ONNX node: Transpose_2230
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2822 for ONNX tensor: 2822
[06/10/2022-19:21:33] [V] [TRT] Transpose_2230 [Transpose] outputs: [2822 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Div_2232 [Div]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2822
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2823
[06/10/2022-19:21:33] [V] [TRT] Div_2232 [Div] inputs: [2822 -> (-1, 1024, 2048)[FLOAT]], [2823 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2823 for ONNX node: 2823
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Div_2232 for ONNX node: Div_2232
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2824 for ONNX tensor: 2824
[06/10/2022-19:21:33] [V] [TRT] Div_2232 [Div] outputs: [2824 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Erf_2233 [Erf]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2824
[06/10/2022-19:21:33] [V] [TRT] Erf_2233 [Erf] inputs: [2824 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Erf_2233 for ONNX node: Erf_2233
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2825 for ONNX tensor: 2825
[06/10/2022-19:21:33] [V] [TRT] Erf_2233 [Erf] outputs: [2825 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2235 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2825
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2826
[06/10/2022-19:21:33] [V] [TRT] Add_2235 [Add] inputs: [2825 -> (-1, 1024, 2048)[FLOAT]], [2826 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2826 for ONNX node: 2826
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2235 for ONNX node: Add_2235
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2827 for ONNX tensor: 2827
[06/10/2022-19:21:33] [V] [TRT] Add_2235 [Add] outputs: [2827 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Mul_2236 [Mul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2822
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2827
[06/10/2022-19:21:33] [V] [TRT] Mul_2236 [Mul] inputs: [2822 -> (-1, 1024, 2048)[FLOAT]], [2827 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Mul_2236 for ONNX node: Mul_2236
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2828 for ONNX tensor: 2828
[06/10/2022-19:21:33] [V] [TRT] Mul_2236 [Mul] outputs: [2828 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Mul_2238 [Mul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2828
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2829
[06/10/2022-19:21:33] [V] [TRT] Mul_2238 [Mul] inputs: [2828 -> (-1, 1024, 2048)[FLOAT]], [2829 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2829 for ONNX node: 2829
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Mul_2238 for ONNX node: Mul_2238
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2830 for ONNX tensor: 2830
[06/10/2022-19:21:33] [V] [TRT] Mul_2238 [Mul] outputs: [2830 -> (-1, 1024, 2048)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2239 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2830
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3218
[06/10/2022-19:21:33] [V] [TRT] MatMul_2239 [MatMul] inputs: [2830 -> (-1, 1024, 2048)[FLOAT]], [3218 -> (2048, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3218 for ONNX node: 3218
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2239 for ONNX node: MatMul_2239
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2832 for ONNX tensor: 2832
[06/10/2022-19:21:33] [V] [TRT] MatMul_2239 [MatMul] outputs: [2832 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2240 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2832
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.block4.2.mlp.fc2.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2240 [Add] inputs: [2832 -> (-1, 1024, 512)[FLOAT]], [backbone.block4.2.mlp.fc2.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.block4.2.mlp.fc2.bias for ONNX node: backbone.block4.2.mlp.fc2.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2240 for ONNX node: Add_2240
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2833 for ONNX tensor: 2833
[06/10/2022-19:21:33] [V] [TRT] Add_2240 [Add] outputs: [2833 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2241 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2785
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2833
[06/10/2022-19:21:33] [V] [TRT] Add_2241 [Add] inputs: [2785 -> (-1, 1024, 512)[FLOAT]], [2833 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2241 for ONNX node: Add_2241
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2834 for ONNX tensor: 2834
[06/10/2022-19:21:33] [V] [TRT] Add_2241 [Add] outputs: [2834 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: ReduceMean_2242 [ReduceMean]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2834
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2242 [ReduceMean] inputs: [2834 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: ReduceMean_2242 for ONNX node: ReduceMean_2242
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2835 for ONNX tensor: 2835
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2242 [ReduceMean] outputs: [2835 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Sub_2243 [Sub]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2834
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2835
[06/10/2022-19:21:33] [V] [TRT] Sub_2243 [Sub] inputs: [2834 -> (-1, 1024, 512)[FLOAT]], [2835 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Sub_2243 for ONNX node: Sub_2243
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2836 for ONNX tensor: 2836
[06/10/2022-19:21:33] [V] [TRT] Sub_2243 [Sub] outputs: [2836 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Pow_2245 [Pow]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2836
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2837
[06/10/2022-19:21:33] [V] [TRT] Pow_2245 [Pow] inputs: [2836 -> (-1, 1024, 512)[FLOAT]], [2837 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2837 for ONNX node: 2837
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Pow_2245 for ONNX node: Pow_2245
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2838 for ONNX tensor: 2838
[06/10/2022-19:21:33] [V] [TRT] Pow_2245 [Pow] outputs: [2838 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: ReduceMean_2246 [ReduceMean]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2838
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2246 [ReduceMean] inputs: [2838 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: ReduceMean_2246 for ONNX node: ReduceMean_2246
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2839 for ONNX tensor: 2839
[06/10/2022-19:21:33] [V] [TRT] ReduceMean_2246 [ReduceMean] outputs: [2839 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2248 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2839
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2840
[06/10/2022-19:21:33] [V] [TRT] Add_2248 [Add] inputs: [2839 -> (-1, 1024, 1)[FLOAT]], [2840 -> ()[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2840 for ONNX node: 2840
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2248 for ONNX node: Add_2248
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2841 for ONNX tensor: 2841
[06/10/2022-19:21:33] [V] [TRT] Add_2248 [Add] outputs: [2841 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Sqrt_2249 [Sqrt]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2841
[06/10/2022-19:21:33] [V] [TRT] Sqrt_2249 [Sqrt] inputs: [2841 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Sqrt_2249 for ONNX node: Sqrt_2249
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2842 for ONNX tensor: 2842
[06/10/2022-19:21:33] [V] [TRT] Sqrt_2249 [Sqrt] outputs: [2842 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Div_2250 [Div]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2836
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2842
[06/10/2022-19:21:33] [V] [TRT] Div_2250 [Div] inputs: [2836 -> (-1, 1024, 512)[FLOAT]], [2842 -> (-1, 1024, 1)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Div_2250 for ONNX node: Div_2250
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2843 for ONNX tensor: 2843
[06/10/2022-19:21:33] [V] [TRT] Div_2250 [Div] outputs: [2843 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Mul_2251 [Mul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2843
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.norm4.weight
[06/10/2022-19:21:33] [V] [TRT] Mul_2251 [Mul] inputs: [2843 -> (-1, 1024, 512)[FLOAT]], [backbone.norm4.weight -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.norm4.weight for ONNX node: backbone.norm4.weight
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Mul_2251 for ONNX node: Mul_2251
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2844 for ONNX tensor: 2844
[06/10/2022-19:21:33] [V] [TRT] Mul_2251 [Mul] outputs: [2844 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2252 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2844
[06/10/2022-19:21:33] [V] [TRT] Searching for input: backbone.norm4.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2252 [Add] inputs: [2844 -> (-1, 1024, 512)[FLOAT]], [backbone.norm4.bias -> (512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: backbone.norm4.bias for ONNX node: backbone.norm4.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2252 for ONNX node: Add_2252
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2845 for ONNX tensor: 2845
[06/10/2022-19:21:33] [V] [TRT] Add_2252 [Add] outputs: [2845 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2253 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 379
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2253 [Unsqueeze] inputs: [379 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2253 for ONNX node: Unsqueeze_2253
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2847 for ONNX tensor: 2847
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2253 [Unsqueeze] outputs: [2847 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2254 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2445
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2254 [Unsqueeze] inputs: [2445 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2254 for ONNX node: Unsqueeze_2254
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2848 for ONNX tensor: 2848
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2254 [Unsqueeze] outputs: [2848 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2255 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2448
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2255 [Unsqueeze] inputs: [2448 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2255 for ONNX node: Unsqueeze_2255
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2849 for ONNX tensor: 2849
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2255 [Unsqueeze] outputs: [2849 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2256 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2847
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2848
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2849
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3219
[06/10/2022-19:21:33] [V] [TRT] Concat_2256 [Concat] inputs: [2847 -> (1)[INT32]], [2848 -> (1)[INT32]], [2849 -> (1)[INT32]], [3219 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3219 for ONNX node: 3219
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2256 for ONNX node: Concat_2256
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2851 for ONNX tensor: 2851
[06/10/2022-19:21:33] [V] [TRT] Concat_2256 [Concat] outputs: [2851 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2257 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2845
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2851
[06/10/2022-19:21:33] [V] [TRT] Reshape_2257 [Reshape] inputs: [2845 -> (-1, 1024, 512)[FLOAT]], [2851 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2257 for ONNX node: Reshape_2257
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2852 for ONNX tensor: 2852
[06/10/2022-19:21:33] [V] [TRT] Reshape_2257 [Reshape] outputs: [2852 -> (-1, 32, 32, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2258 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2852
[06/10/2022-19:21:33] [V] [TRT] Transpose_2258 [Transpose] inputs: [2852 -> (-1, 32, 32, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2258 for ONNX node: Transpose_2258
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2853 for ONNX tensor: 2853
[06/10/2022-19:21:33] [V] [TRT] Transpose_2258 [Transpose] outputs: [2853 -> (-1, 512, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2259 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2853
[06/10/2022-19:21:33] [V] [TRT] Shape_2259 [Shape] inputs: [2853 -> (-1, 512, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2259 for ONNX node: Shape_2259
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2854 for ONNX tensor: 2854
[06/10/2022-19:21:33] [V] [TRT] Shape_2259 [Shape] outputs: [2854 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2261 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2854
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2855
[06/10/2022-19:21:33] [V] [TRT] Gather_2261 [Gather] inputs: [2854 -> (4)[INT32]], [2855 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2855 for ONNX node: 2855
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2261 for ONNX node: Gather_2261
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2856 for ONNX tensor: 2856
[06/10/2022-19:21:33] [V] [TRT] Gather_2261 [Gather] outputs: [2856 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2262 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2853
[06/10/2022-19:21:33] [V] [TRT] Shape_2262 [Shape] inputs: [2853 -> (-1, 512, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2262 for ONNX node: Shape_2262
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2857 for ONNX tensor: 2857
[06/10/2022-19:21:33] [V] [TRT] Shape_2262 [Shape] outputs: [2857 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Slice_2266 [Slice]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2857
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2859
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2860
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2858
[06/10/2022-19:21:33] [V] [TRT] Slice_2266 [Slice] inputs: [2857 -> (4)[INT32]], [2859 -> (1)[INT32]], [2860 -> (1)[INT32]], [2858 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Slice_2266 for ONNX node: Slice_2266
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2861 for ONNX tensor: 2861
[06/10/2022-19:21:33] [V] [TRT] Slice_2266 [Slice] outputs: [2861 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2268 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2861
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2862
[06/10/2022-19:21:33] [V] [TRT] Concat_2268 [Concat] inputs: [2861 -> (2)[INT32]], [2862 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2862 for ONNX node: 2862
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2268 for ONNX node: Concat_2268
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2863 for ONNX tensor: 2863
[06/10/2022-19:21:33] [V] [TRT] Concat_2268 [Concat] outputs: [2863 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2269 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2853
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2863
[06/10/2022-19:21:33] [V] [TRT] Reshape_2269 [Reshape] inputs: [2853 -> (-1, 512, 32, 32)[FLOAT]], [2863 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2269 for ONNX node: Reshape_2269
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2864 for ONNX tensor: 2864
[06/10/2022-19:21:33] [V] [TRT] Reshape_2269 [Reshape] outputs: [2864 -> (-1, 512, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2270 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2864
[06/10/2022-19:21:33] [V] [TRT] Transpose_2270 [Transpose] inputs: [2864 -> (-1, 512, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2270 for ONNX node: Transpose_2270
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2865 for ONNX tensor: 2865
[06/10/2022-19:21:33] [V] [TRT] Transpose_2270 [Transpose] outputs: [2865 -> (-1, 1024, 512)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2271 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2865
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3220
[06/10/2022-19:21:33] [V] [TRT] MatMul_2271 [MatMul] inputs: [2865 -> (-1, 1024, 512)[FLOAT]], [3220 -> (512, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3220 for ONNX node: 3220
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2271 for ONNX node: MatMul_2271
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2867 for ONNX tensor: 2867
[06/10/2022-19:21:33] [V] [TRT] MatMul_2271 [MatMul] outputs: [2867 -> (-1, 1024, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2272 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2867
[06/10/2022-19:21:33] [V] [TRT] Searching for input: decode_head.linear_c4.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2272 [Add] inputs: [2867 -> (-1, 1024, 768)[FLOAT]], [decode_head.linear_c4.proj.bias -> (768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: decode_head.linear_c4.proj.bias for ONNX node: decode_head.linear_c4.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2272 for ONNX node: Add_2272
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2868 for ONNX tensor: 2868
[06/10/2022-19:21:33] [V] [TRT] Add_2272 [Add] outputs: [2868 -> (-1, 1024, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2273 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2868
[06/10/2022-19:21:33] [V] [TRT] Transpose_2273 [Transpose] inputs: [2868 -> (-1, 1024, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2273 for ONNX node: Transpose_2273
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2869 for ONNX tensor: 2869
[06/10/2022-19:21:33] [V] [TRT] Transpose_2273 [Transpose] outputs: [2869 -> (-1, 768, 1024)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2274 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2853
[06/10/2022-19:21:33] [V] [TRT] Shape_2274 [Shape] inputs: [2853 -> (-1, 512, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2274 for ONNX node: Shape_2274
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2870 for ONNX tensor: 2870
[06/10/2022-19:21:33] [V] [TRT] Shape_2274 [Shape] outputs: [2870 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2276 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2870
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2871
[06/10/2022-19:21:33] [V] [TRT] Gather_2276 [Gather] inputs: [2870 -> (4)[INT32]], [2871 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2871 for ONNX node: 2871
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2276 for ONNX node: Gather_2276
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2872 for ONNX tensor: 2872
[06/10/2022-19:21:33] [V] [TRT] Gather_2276 [Gather] outputs: [2872 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2277 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2853
[06/10/2022-19:21:33] [V] [TRT] Shape_2277 [Shape] inputs: [2853 -> (-1, 512, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2277 for ONNX node: Shape_2277
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2873 for ONNX tensor: 2873
[06/10/2022-19:21:33] [V] [TRT] Shape_2277 [Shape] outputs: [2873 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2279 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2873
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2874
[06/10/2022-19:21:33] [V] [TRT] Gather_2279 [Gather] inputs: [2873 -> (4)[INT32]], [2874 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2874 for ONNX node: 2874
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2279 for ONNX node: Gather_2279
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2875 for ONNX tensor: 2875
[06/10/2022-19:21:33] [V] [TRT] Gather_2279 [Gather] outputs: [2875 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2280 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2856
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2280 [Unsqueeze] inputs: [2856 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2280 for ONNX node: Unsqueeze_2280
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2877 for ONNX tensor: 2877
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2280 [Unsqueeze] outputs: [2877 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2281 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2872
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2281 [Unsqueeze] inputs: [2872 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2281 for ONNX node: Unsqueeze_2281
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2879 for ONNX tensor: 2879
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2281 [Unsqueeze] outputs: [2879 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2282 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2875
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2282 [Unsqueeze] inputs: [2875 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2282 for ONNX node: Unsqueeze_2282
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2880 for ONNX tensor: 2880
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2282 [Unsqueeze] outputs: [2880 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2283 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2877
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3221
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2879
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2880
[06/10/2022-19:21:33] [V] [TRT] Concat_2283 [Concat] inputs: [2877 -> (1)[INT32]], [3221 -> (1)[INT32]], [2879 -> (1)[INT32]], [2880 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3221 for ONNX node: 3221
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2283 for ONNX node: Concat_2283
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2881 for ONNX tensor: 2881
[06/10/2022-19:21:33] [V] [TRT] Concat_2283 [Concat] outputs: [2881 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2284 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2869
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2881
[06/10/2022-19:21:33] [V] [TRT] Reshape_2284 [Reshape] inputs: [2869 -> (-1, 768, 1024)[FLOAT]], [2881 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2284 for ONNX node: Reshape_2284
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2882 for ONNX tensor: 2882
[06/10/2022-19:21:33] [V] [TRT] Reshape_2284 [Reshape] outputs: [2882 -> (-1, 768, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2286 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2882
[06/10/2022-19:21:33] [V] [TRT] Shape_2286 [Shape] inputs: [2882 -> (-1, 768, 32, 32)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2286 for ONNX node: Shape_2286
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2885 for ONNX tensor: 2885
[06/10/2022-19:21:33] [V] [TRT] Shape_2286 [Shape] outputs: [2885 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Slice_2290 [Slice]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2885
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2887
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2888
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2886
[06/10/2022-19:21:33] [V] [TRT] Slice_2290 [Slice] inputs: [2885 -> (4)[INT32]], [2887 -> (1)[INT32]], [2888 -> (1)[INT32]], [2886 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Slice_2290 for ONNX node: Slice_2290
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2889 for ONNX tensor: 2889
[06/10/2022-19:21:33] [V] [TRT] Slice_2290 [Slice] outputs: [2889 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2291 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2889
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3222
[06/10/2022-19:21:33] [V] [TRT] Concat_2291 [Concat] inputs: [2889 -> (2)[INT32]], [3222 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3222 for ONNX node: 3222
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2291 for ONNX node: Concat_2291
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2891 for ONNX tensor: 2891
[06/10/2022-19:21:33] [V] [TRT] Concat_2291 [Concat] outputs: [2891 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Resize_2293 [Resize]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2882
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2884
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2892
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2891
[06/10/2022-19:21:33] [V] [TRT] Resize_2293 [Resize] inputs: [2882 -> (-1, 768, 32, 32)[FLOAT]], [2884 -> (0)[FLOAT]], [2892 -> (0)[FLOAT]], [2891 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Resize_2293 for ONNX node: Resize_2293
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2893 for ONNX tensor: 2893
[06/10/2022-19:21:33] [V] [TRT] Resize_2293 [Resize] outputs: [2893 -> (-1, 768, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2294 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2441
[06/10/2022-19:21:33] [V] [TRT] Shape_2294 [Shape] inputs: [2441 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2294 for ONNX node: Shape_2294
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2894 for ONNX tensor: 2894
[06/10/2022-19:21:33] [V] [TRT] Shape_2294 [Shape] outputs: [2894 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Slice_2298 [Slice]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2894
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2896
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2897
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2895
[06/10/2022-19:21:33] [V] [TRT] Slice_2298 [Slice] inputs: [2894 -> (4)[INT32]], [2896 -> (1)[INT32]], [2897 -> (1)[INT32]], [2895 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Slice_2298 for ONNX node: Slice_2298
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2898 for ONNX tensor: 2898
[06/10/2022-19:21:33] [V] [TRT] Slice_2298 [Slice] outputs: [2898 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2300 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2898
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2899
[06/10/2022-19:21:33] [V] [TRT] Concat_2300 [Concat] inputs: [2898 -> (2)[INT32]], [2899 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2899 for ONNX node: 2899
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2300 for ONNX node: Concat_2300
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2900 for ONNX tensor: 2900
[06/10/2022-19:21:33] [V] [TRT] Concat_2300 [Concat] outputs: [2900 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2301 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2441
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2900
[06/10/2022-19:21:33] [V] [TRT] Reshape_2301 [Reshape] inputs: [2441 -> (-1, 320, 64, 64)[FLOAT]], [2900 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2301 for ONNX node: Reshape_2301
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2901 for ONNX tensor: 2901
[06/10/2022-19:21:33] [V] [TRT] Reshape_2301 [Reshape] outputs: [2901 -> (-1, 320, 4096)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2302 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2901
[06/10/2022-19:21:33] [V] [TRT] Transpose_2302 [Transpose] inputs: [2901 -> (-1, 320, 4096)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2302 for ONNX node: Transpose_2302
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2902 for ONNX tensor: 2902
[06/10/2022-19:21:33] [V] [TRT] Transpose_2302 [Transpose] outputs: [2902 -> (-1, 4096, 320)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2303 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2902
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3223
[06/10/2022-19:21:33] [V] [TRT] MatMul_2303 [MatMul] inputs: [2902 -> (-1, 4096, 320)[FLOAT]], [3223 -> (320, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3223 for ONNX node: 3223
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2303 for ONNX node: MatMul_2303
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2904 for ONNX tensor: 2904
[06/10/2022-19:21:33] [V] [TRT] MatMul_2303 [MatMul] outputs: [2904 -> (-1, 4096, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2304 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2904
[06/10/2022-19:21:33] [V] [TRT] Searching for input: decode_head.linear_c3.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2304 [Add] inputs: [2904 -> (-1, 4096, 768)[FLOAT]], [decode_head.linear_c3.proj.bias -> (768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: decode_head.linear_c3.proj.bias for ONNX node: decode_head.linear_c3.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2304 for ONNX node: Add_2304
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2905 for ONNX tensor: 2905
[06/10/2022-19:21:33] [V] [TRT] Add_2304 [Add] outputs: [2905 -> (-1, 4096, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2305 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2905
[06/10/2022-19:21:33] [V] [TRT] Transpose_2305 [Transpose] inputs: [2905 -> (-1, 4096, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2305 for ONNX node: Transpose_2305
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2906 for ONNX tensor: 2906
[06/10/2022-19:21:33] [V] [TRT] Transpose_2305 [Transpose] outputs: [2906 -> (-1, 768, 4096)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2306 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2441
[06/10/2022-19:21:33] [V] [TRT] Shape_2306 [Shape] inputs: [2441 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2306 for ONNX node: Shape_2306
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2907 for ONNX tensor: 2907
[06/10/2022-19:21:33] [V] [TRT] Shape_2306 [Shape] outputs: [2907 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2308 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2907
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2908
[06/10/2022-19:21:33] [V] [TRT] Gather_2308 [Gather] inputs: [2907 -> (4)[INT32]], [2908 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2908 for ONNX node: 2908
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2308 for ONNX node: Gather_2308
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2909 for ONNX tensor: 2909
[06/10/2022-19:21:33] [V] [TRT] Gather_2308 [Gather] outputs: [2909 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2309 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2441
[06/10/2022-19:21:33] [V] [TRT] Shape_2309 [Shape] inputs: [2441 -> (-1, 320, 64, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2309 for ONNX node: Shape_2309
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2910 for ONNX tensor: 2910
[06/10/2022-19:21:33] [V] [TRT] Shape_2309 [Shape] outputs: [2910 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2311 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2910
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2911
[06/10/2022-19:21:33] [V] [TRT] Gather_2311 [Gather] inputs: [2910 -> (4)[INT32]], [2911 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2911 for ONNX node: 2911
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2311 for ONNX node: Gather_2311
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2912 for ONNX tensor: 2912
[06/10/2022-19:21:33] [V] [TRT] Gather_2311 [Gather] outputs: [2912 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2312 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2856
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2312 [Unsqueeze] inputs: [2856 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2312 for ONNX node: Unsqueeze_2312
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2914 for ONNX tensor: 2914
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2312 [Unsqueeze] outputs: [2914 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2313 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2909
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2313 [Unsqueeze] inputs: [2909 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2313 for ONNX node: Unsqueeze_2313
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2916 for ONNX tensor: 2916
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2313 [Unsqueeze] outputs: [2916 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2314 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2912
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2314 [Unsqueeze] inputs: [2912 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2314 for ONNX node: Unsqueeze_2314
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2917 for ONNX tensor: 2917
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2314 [Unsqueeze] outputs: [2917 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2315 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2914
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3224
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2916
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2917
[06/10/2022-19:21:33] [V] [TRT] Concat_2315 [Concat] inputs: [2914 -> (1)[INT32]], [3224 -> (1)[INT32]], [2916 -> (1)[INT32]], [2917 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3224 for ONNX node: 3224
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2315 for ONNX node: Concat_2315
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2918 for ONNX tensor: 2918
[06/10/2022-19:21:33] [V] [TRT] Concat_2315 [Concat] outputs: [2918 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2316 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2906
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2918
[06/10/2022-19:21:33] [V] [TRT] Reshape_2316 [Reshape] inputs: [2906 -> (-1, 768, 4096)[FLOAT]], [2918 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2316 for ONNX node: Reshape_2316
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2919 for ONNX tensor: 2919
[06/10/2022-19:21:33] [V] [TRT] Reshape_2316 [Reshape] outputs: [2919 -> (-1, 768, 64, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2318 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2919
[06/10/2022-19:21:33] [V] [TRT] Shape_2318 [Shape] inputs: [2919 -> (-1, 768, 64, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2318 for ONNX node: Shape_2318
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2922 for ONNX tensor: 2922
[06/10/2022-19:21:33] [V] [TRT] Shape_2318 [Shape] outputs: [2922 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Slice_2322 [Slice]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2922
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2924
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2925
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2923
[06/10/2022-19:21:33] [V] [TRT] Slice_2322 [Slice] inputs: [2922 -> (4)[INT32]], [2924 -> (1)[INT32]], [2925 -> (1)[INT32]], [2923 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Slice_2322 for ONNX node: Slice_2322
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2926 for ONNX tensor: 2926
[06/10/2022-19:21:33] [V] [TRT] Slice_2322 [Slice] outputs: [2926 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2323 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2926
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3225
[06/10/2022-19:21:33] [V] [TRT] Concat_2323 [Concat] inputs: [2926 -> (2)[INT32]], [3225 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3225 for ONNX node: 3225
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2323 for ONNX node: Concat_2323
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2928 for ONNX tensor: 2928
[06/10/2022-19:21:33] [V] [TRT] Concat_2323 [Concat] outputs: [2928 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Resize_2325 [Resize]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2919
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2921
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2929
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2928
[06/10/2022-19:21:33] [V] [TRT] Resize_2325 [Resize] inputs: [2919 -> (-1, 768, 64, 64)[FLOAT]], [2921 -> (0)[FLOAT]], [2929 -> (0)[FLOAT]], [2928 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Resize_2325 for ONNX node: Resize_2325
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2930 for ONNX tensor: 2930
[06/10/2022-19:21:33] [V] [TRT] Resize_2325 [Resize] outputs: [2930 -> (-1, 768, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2326 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 1507
[06/10/2022-19:21:33] [V] [TRT] Shape_2326 [Shape] inputs: [1507 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2326 for ONNX node: Shape_2326
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2931 for ONNX tensor: 2931
[06/10/2022-19:21:33] [V] [TRT] Shape_2326 [Shape] outputs: [2931 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Slice_2330 [Slice]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2931
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2933
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2934
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2932
[06/10/2022-19:21:33] [V] [TRT] Slice_2330 [Slice] inputs: [2931 -> (4)[INT32]], [2933 -> (1)[INT32]], [2934 -> (1)[INT32]], [2932 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Slice_2330 for ONNX node: Slice_2330
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2935 for ONNX tensor: 2935
[06/10/2022-19:21:33] [V] [TRT] Slice_2330 [Slice] outputs: [2935 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2332 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2935
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2936
[06/10/2022-19:21:33] [V] [TRT] Concat_2332 [Concat] inputs: [2935 -> (2)[INT32]], [2936 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2936 for ONNX node: 2936
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2332 for ONNX node: Concat_2332
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2937 for ONNX tensor: 2937
[06/10/2022-19:21:33] [V] [TRT] Concat_2332 [Concat] outputs: [2937 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2333 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 1507
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2937
[06/10/2022-19:21:33] [V] [TRT] Reshape_2333 [Reshape] inputs: [1507 -> (-1, 128, 128, 128)[FLOAT]], [2937 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2333 for ONNX node: Reshape_2333
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2938 for ONNX tensor: 2938
[06/10/2022-19:21:33] [V] [TRT] Reshape_2333 [Reshape] outputs: [2938 -> (-1, 128, 16384)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2334 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2938
[06/10/2022-19:21:33] [V] [TRT] Transpose_2334 [Transpose] inputs: [2938 -> (-1, 128, 16384)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2334 for ONNX node: Transpose_2334
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2939 for ONNX tensor: 2939
[06/10/2022-19:21:33] [V] [TRT] Transpose_2334 [Transpose] outputs: [2939 -> (-1, 16384, 128)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2335 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2939
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3226
[06/10/2022-19:21:33] [V] [TRT] MatMul_2335 [MatMul] inputs: [2939 -> (-1, 16384, 128)[FLOAT]], [3226 -> (128, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3226 for ONNX node: 3226
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2335 for ONNX node: MatMul_2335
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2941 for ONNX tensor: 2941
[06/10/2022-19:21:33] [V] [TRT] MatMul_2335 [MatMul] outputs: [2941 -> (-1, 16384, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2336 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2941
[06/10/2022-19:21:33] [V] [TRT] Searching for input: decode_head.linear_c2.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2336 [Add] inputs: [2941 -> (-1, 16384, 768)[FLOAT]], [decode_head.linear_c2.proj.bias -> (768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: decode_head.linear_c2.proj.bias for ONNX node: decode_head.linear_c2.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2336 for ONNX node: Add_2336
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2942 for ONNX tensor: 2942
[06/10/2022-19:21:33] [V] [TRT] Add_2336 [Add] outputs: [2942 -> (-1, 16384, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2337 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2942
[06/10/2022-19:21:33] [V] [TRT] Transpose_2337 [Transpose] inputs: [2942 -> (-1, 16384, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2337 for ONNX node: Transpose_2337
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2943 for ONNX tensor: 2943
[06/10/2022-19:21:33] [V] [TRT] Transpose_2337 [Transpose] outputs: [2943 -> (-1, 768, 16384)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2338 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 1507
[06/10/2022-19:21:33] [V] [TRT] Shape_2338 [Shape] inputs: [1507 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2338 for ONNX node: Shape_2338
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2944 for ONNX tensor: 2944
[06/10/2022-19:21:33] [V] [TRT] Shape_2338 [Shape] outputs: [2944 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2340 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2944
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2945
[06/10/2022-19:21:33] [V] [TRT] Gather_2340 [Gather] inputs: [2944 -> (4)[INT32]], [2945 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2945 for ONNX node: 2945
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2340 for ONNX node: Gather_2340
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2946 for ONNX tensor: 2946
[06/10/2022-19:21:33] [V] [TRT] Gather_2340 [Gather] outputs: [2946 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2341 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 1507
[06/10/2022-19:21:33] [V] [TRT] Shape_2341 [Shape] inputs: [1507 -> (-1, 128, 128, 128)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2341 for ONNX node: Shape_2341
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2947 for ONNX tensor: 2947
[06/10/2022-19:21:33] [V] [TRT] Shape_2341 [Shape] outputs: [2947 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2343 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2947
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2948
[06/10/2022-19:21:33] [V] [TRT] Gather_2343 [Gather] inputs: [2947 -> (4)[INT32]], [2948 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2948 for ONNX node: 2948
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2343 for ONNX node: Gather_2343
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2949 for ONNX tensor: 2949
[06/10/2022-19:21:33] [V] [TRT] Gather_2343 [Gather] outputs: [2949 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2344 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2856
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2344 [Unsqueeze] inputs: [2856 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2344 for ONNX node: Unsqueeze_2344
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2951 for ONNX tensor: 2951
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2344 [Unsqueeze] outputs: [2951 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2345 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2946
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2345 [Unsqueeze] inputs: [2946 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2345 for ONNX node: Unsqueeze_2345
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2953 for ONNX tensor: 2953
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2345 [Unsqueeze] outputs: [2953 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2346 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2949
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2346 [Unsqueeze] inputs: [2949 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2346 for ONNX node: Unsqueeze_2346
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2954 for ONNX tensor: 2954
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2346 [Unsqueeze] outputs: [2954 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2347 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2951
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3227
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2953
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2954
[06/10/2022-19:21:33] [V] [TRT] Concat_2347 [Concat] inputs: [2951 -> (1)[INT32]], [3227 -> (1)[INT32]], [2953 -> (1)[INT32]], [2954 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3227 for ONNX node: 3227
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2347 for ONNX node: Concat_2347
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2955 for ONNX tensor: 2955
[06/10/2022-19:21:33] [V] [TRT] Concat_2347 [Concat] outputs: [2955 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2348 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2943
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2955
[06/10/2022-19:21:33] [V] [TRT] Reshape_2348 [Reshape] inputs: [2943 -> (-1, 768, 16384)[FLOAT]], [2955 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2348 for ONNX node: Reshape_2348
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2956 for ONNX tensor: 2956
[06/10/2022-19:21:33] [V] [TRT] Reshape_2348 [Reshape] outputs: [2956 -> (-1, 768, 128, 128)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2350 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2956
[06/10/2022-19:21:33] [V] [TRT] Shape_2350 [Shape] inputs: [2956 -> (-1, 768, 128, 128)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2350 for ONNX node: Shape_2350
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2959 for ONNX tensor: 2959
[06/10/2022-19:21:33] [V] [TRT] Shape_2350 [Shape] outputs: [2959 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Slice_2354 [Slice]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2959
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2961
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2962
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2960
[06/10/2022-19:21:33] [V] [TRT] Slice_2354 [Slice] inputs: [2959 -> (4)[INT32]], [2961 -> (1)[INT32]], [2962 -> (1)[INT32]], [2960 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Slice_2354 for ONNX node: Slice_2354
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2963 for ONNX tensor: 2963
[06/10/2022-19:21:33] [V] [TRT] Slice_2354 [Slice] outputs: [2963 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2355 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2963
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3228
[06/10/2022-19:21:33] [V] [TRT] Concat_2355 [Concat] inputs: [2963 -> (2)[INT32]], [3228 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3228 for ONNX node: 3228
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2355 for ONNX node: Concat_2355
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2965 for ONNX tensor: 2965
[06/10/2022-19:21:33] [V] [TRT] Concat_2355 [Concat] outputs: [2965 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Resize_2357 [Resize]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2956
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2958
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2966
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2965
[06/10/2022-19:21:33] [V] [TRT] Resize_2357 [Resize] inputs: [2956 -> (-1, 768, 128, 128)[FLOAT]], [2958 -> (0)[FLOAT]], [2966 -> (0)[FLOAT]], [2965 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Resize_2357 for ONNX node: Resize_2357
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2967 for ONNX tensor: 2967
[06/10/2022-19:21:33] [V] [TRT] Resize_2357 [Resize] outputs: [2967 -> (-1, 768, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2358 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 869
[06/10/2022-19:21:33] [V] [TRT] Shape_2358 [Shape] inputs: [869 -> (-1, 64, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2358 for ONNX node: Shape_2358
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2968 for ONNX tensor: 2968
[06/10/2022-19:21:33] [V] [TRT] Shape_2358 [Shape] outputs: [2968 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Slice_2362 [Slice]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2968
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2970
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2971
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2969
[06/10/2022-19:21:33] [V] [TRT] Slice_2362 [Slice] inputs: [2968 -> (4)[INT32]], [2970 -> (1)[INT32]], [2971 -> (1)[INT32]], [2969 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Slice_2362 for ONNX node: Slice_2362
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2972 for ONNX tensor: 2972
[06/10/2022-19:21:33] [V] [TRT] Slice_2362 [Slice] outputs: [2972 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2364 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2972
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2973
[06/10/2022-19:21:33] [V] [TRT] Concat_2364 [Concat] inputs: [2972 -> (2)[INT32]], [2973 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2973 for ONNX node: 2973
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2364 for ONNX node: Concat_2364
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2974 for ONNX tensor: 2974
[06/10/2022-19:21:33] [V] [TRT] Concat_2364 [Concat] outputs: [2974 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2365 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 869
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2974
[06/10/2022-19:21:33] [V] [TRT] Reshape_2365 [Reshape] inputs: [869 -> (-1, 64, 256, 256)[FLOAT]], [2974 -> (3)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2365 for ONNX node: Reshape_2365
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2975 for ONNX tensor: 2975
[06/10/2022-19:21:33] [V] [TRT] Reshape_2365 [Reshape] outputs: [2975 -> (-1, 64, 65536)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2366 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2975
[06/10/2022-19:21:33] [V] [TRT] Transpose_2366 [Transpose] inputs: [2975 -> (-1, 64, 65536)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2366 for ONNX node: Transpose_2366
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2976 for ONNX tensor: 2976
[06/10/2022-19:21:33] [V] [TRT] Transpose_2366 [Transpose] outputs: [2976 -> (-1, 65536, 64)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: MatMul_2367 [MatMul]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2976
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3229
[06/10/2022-19:21:33] [V] [TRT] MatMul_2367 [MatMul] inputs: [2976 -> (-1, 65536, 64)[FLOAT]], [3229 -> (64, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3229 for ONNX node: 3229
[06/10/2022-19:21:33] [V] [TRT] Registering layer: MatMul_2367 for ONNX node: MatMul_2367
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2978 for ONNX tensor: 2978
[06/10/2022-19:21:33] [V] [TRT] MatMul_2367 [MatMul] outputs: [2978 -> (-1, 65536, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Add_2368 [Add]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2978
[06/10/2022-19:21:33] [V] [TRT] Searching for input: decode_head.linear_c1.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Add_2368 [Add] inputs: [2978 -> (-1, 65536, 768)[FLOAT]], [decode_head.linear_c1.proj.bias -> (768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: decode_head.linear_c1.proj.bias for ONNX node: decode_head.linear_c1.proj.bias
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Add_2368 for ONNX node: Add_2368
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2979 for ONNX tensor: 2979
[06/10/2022-19:21:33] [V] [TRT] Add_2368 [Add] outputs: [2979 -> (-1, 65536, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Transpose_2369 [Transpose]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2979
[06/10/2022-19:21:33] [V] [TRT] Transpose_2369 [Transpose] inputs: [2979 -> (-1, 65536, 768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Transpose_2369 for ONNX node: Transpose_2369
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2980 for ONNX tensor: 2980
[06/10/2022-19:21:33] [V] [TRT] Transpose_2369 [Transpose] outputs: [2980 -> (-1, 768, 65536)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2370 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 869
[06/10/2022-19:21:33] [V] [TRT] Shape_2370 [Shape] inputs: [869 -> (-1, 64, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2370 for ONNX node: Shape_2370
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2981 for ONNX tensor: 2981
[06/10/2022-19:21:33] [V] [TRT] Shape_2370 [Shape] outputs: [2981 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2372 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2981
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2982
[06/10/2022-19:21:33] [V] [TRT] Gather_2372 [Gather] inputs: [2981 -> (4)[INT32]], [2982 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2982 for ONNX node: 2982
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2372 for ONNX node: Gather_2372
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2983 for ONNX tensor: 2983
[06/10/2022-19:21:33] [V] [TRT] Gather_2372 [Gather] outputs: [2983 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2373 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 869
[06/10/2022-19:21:33] [V] [TRT] Shape_2373 [Shape] inputs: [869 -> (-1, 64, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2373 for ONNX node: Shape_2373
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2984 for ONNX tensor: 2984
[06/10/2022-19:21:33] [V] [TRT] Shape_2373 [Shape] outputs: [2984 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Gather_2375 [Gather]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2984
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2985
[06/10/2022-19:21:33] [V] [TRT] Gather_2375 [Gather] inputs: [2984 -> (4)[INT32]], [2985 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 2985 for ONNX node: 2985
[06/10/2022-19:21:33] [V] [TRT] Using Gather axis: 0
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Gather_2375 for ONNX node: Gather_2375
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2986 for ONNX tensor: 2986
[06/10/2022-19:21:33] [V] [TRT] Gather_2375 [Gather] outputs: [2986 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2376 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2856
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2376 [Unsqueeze] inputs: [2856 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2376 for ONNX node: Unsqueeze_2376
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2988 for ONNX tensor: 2988
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2376 [Unsqueeze] outputs: [2988 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2377 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2983
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2377 [Unsqueeze] inputs: [2983 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2377 for ONNX node: Unsqueeze_2377
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2990 for ONNX tensor: 2990
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2377 [Unsqueeze] outputs: [2990 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Unsqueeze_2378 [Unsqueeze]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2986
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2378 [Unsqueeze] inputs: [2986 -> ()[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Unsqueeze_2378 for ONNX node: Unsqueeze_2378
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2991 for ONNX tensor: 2991
[06/10/2022-19:21:33] [V] [TRT] Unsqueeze_2378 [Unsqueeze] outputs: [2991 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2379 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2988
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3230
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2990
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2991
[06/10/2022-19:21:33] [V] [TRT] Concat_2379 [Concat] inputs: [2988 -> (1)[INT32]], [3230 -> (1)[INT32]], [2990 -> (1)[INT32]], [2991 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3230 for ONNX node: 3230
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2379 for ONNX node: Concat_2379
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2992 for ONNX tensor: 2992
[06/10/2022-19:21:33] [V] [TRT] Concat_2379 [Concat] outputs: [2992 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Reshape_2380 [Reshape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2980
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2992
[06/10/2022-19:21:33] [V] [TRT] Reshape_2380 [Reshape] inputs: [2980 -> (-1, 768, 65536)[FLOAT]], [2992 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Reshape_2380 for ONNX node: Reshape_2380
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2993 for ONNX tensor: 2993
[06/10/2022-19:21:33] [V] [TRT] Reshape_2380 [Reshape] outputs: [2993 -> (-1, 768, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2381 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2893
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2930
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2967
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2993
[06/10/2022-19:21:33] [V] [TRT] Concat_2381 [Concat] inputs: [2893 -> (-1, 768, 256, 256)[FLOAT]], [2930 -> (-1, 768, 256, 256)[FLOAT]], [2967 -> (-1, 768, 256, 256)[FLOAT]], [2993 -> (-1, 768, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2381 for ONNX node: Concat_2381
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2994 for ONNX tensor: 2994
[06/10/2022-19:21:33] [V] [TRT] Concat_2381 [Concat] outputs: [2994 -> (-1, 3072, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Conv_2382 [Conv]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2994
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3056
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3057
[06/10/2022-19:21:33] [V] [TRT] Conv_2382 [Conv] inputs: [2994 -> (-1, 3072, 256, 256)[FLOAT]], [3056 -> (768, 3072, 1, 1)[FLOAT]], [3057 -> (768)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Convolution input dimensions: (-1, 3072, 256, 256)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Conv_2382 for ONNX node: Conv_2382
[06/10/2022-19:21:33] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 768
[06/10/2022-19:21:33] [V] [TRT] Convolution output dimensions: (-1, 768, 256, 256)
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 3055 for ONNX tensor: 3055
[06/10/2022-19:21:33] [V] [TRT] Conv_2382 [Conv] outputs: [3055 -> (-1, 768, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Relu_2383 [Relu]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3055
[06/10/2022-19:21:33] [V] [TRT] Relu_2383 [Relu] inputs: [3055 -> (-1, 768, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Relu_2383 for ONNX node: Relu_2383
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2997 for ONNX tensor: 2997
[06/10/2022-19:21:33] [V] [TRT] Relu_2383 [Relu] outputs: [2997 -> (-1, 768, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Conv_2384 [Conv]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2997
[06/10/2022-19:21:33] [V] [TRT] Searching for input: decode_head.linear_pred.weight
[06/10/2022-19:21:33] [V] [TRT] Searching for input: decode_head.linear_pred.bias
[06/10/2022-19:21:33] [V] [TRT] Conv_2384 [Conv] inputs: [2997 -> (-1, 768, 256, 256)[FLOAT]], [decode_head.linear_pred.weight -> (19, 768, 1, 1)[FLOAT]], [decode_head.linear_pred.bias -> (19)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Convolution input dimensions: (-1, 768, 256, 256)
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Conv_2384 for ONNX node: Conv_2384
[06/10/2022-19:21:33] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 19
[06/10/2022-19:21:33] [V] [TRT] Convolution output dimensions: (-1, 19, 256, 256)
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 2998 for ONNX tensor: 2998
[06/10/2022-19:21:33] [V] [TRT] Conv_2384 [Conv] outputs: [2998 -> (-1, 19, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Shape_2386 [Shape]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2998
[06/10/2022-19:21:33] [V] [TRT] Shape_2386 [Shape] inputs: [2998 -> (-1, 19, 256, 256)[FLOAT]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Shape_2386 for ONNX node: Shape_2386
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 3001 for ONNX tensor: 3001
[06/10/2022-19:21:33] [V] [TRT] Shape_2386 [Shape] outputs: [3001 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Slice_2390 [Slice]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3001
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3003
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3004
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3002
[06/10/2022-19:21:33] [V] [TRT] Slice_2390 [Slice] inputs: [3001 -> (4)[INT32]], [3003 -> (1)[INT32]], [3004 -> (1)[INT32]], [3002 -> (1)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Slice_2390 for ONNX node: Slice_2390
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 3005 for ONNX tensor: 3005
[06/10/2022-19:21:33] [V] [TRT] Slice_2390 [Slice] outputs: [3005 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Concat_2391 [Concat]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3005
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3231
[06/10/2022-19:21:33] [V] [TRT] Concat_2391 [Concat] inputs: [3005 -> (2)[INT32]], [3231 -> (2)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: 3231 for ONNX node: 3231
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Concat_2391 for ONNX node: Concat_2391
[06/10/2022-19:21:33] [V] [TRT] Registering tensor: 3007 for ONNX tensor: 3007
[06/10/2022-19:21:33] [V] [TRT] Concat_2391 [Concat] outputs: [3007 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Parsing node: Resize_2393 [Resize]
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 2998
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3000
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3008
[06/10/2022-19:21:33] [V] [TRT] Searching for input: 3007
[06/10/2022-19:21:33] [V] [TRT] Resize_2393 [Resize] inputs: [2998 -> (-1, 19, 256, 256)[FLOAT]], [3000 -> (0)[FLOAT]], [3008 -> (0)[FLOAT]], [3007 -> (4)[INT32]], 
[06/10/2022-19:21:33] [V] [TRT] Registering layer: Resize_2393 for ONNX node: Resize_2393
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3009 for ONNX tensor: 3009
[06/10/2022-19:21:34] [V] [TRT] Resize_2393 [Resize] outputs: [3009 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: Pad_2408 [Pad]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3009
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3031
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3032
[06/10/2022-19:21:34] [V] [TRT] Pad_2408 [Pad] inputs: [3009 -> (-1, 19, 1024, 1024)[FLOAT]], [3031 -> (8)[INT32]], [3032 -> ()[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Found no-op pad in node: Pad_2408
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3033 for ONNX tensor: 3033
[06/10/2022-19:21:34] [V] [TRT] Pad_2408 [Pad] outputs: [3033 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: Add_2409 [Add]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 366
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3033
[06/10/2022-19:21:34] [V] [TRT] Add_2409 [Add] inputs: [366 -> (-1, 19, 1024, 1024)[FLOAT]], [3033 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: Add_2409 for ONNX node: Add_2409
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3034 for ONNX tensor: 3034
[06/10/2022-19:21:34] [V] [TRT] Add_2409 [Add] outputs: [3034 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: Div_2411 [Div]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3034
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3035
[06/10/2022-19:21:34] [V] [TRT] Div_2411 [Div] inputs: [3034 -> (-1, 19, 1024, 1024)[FLOAT]], [3035 -> (1, 1, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: 3035 for ONNX node: 3035
[06/10/2022-19:21:34] [V] [TRT] Registering layer: Div_2411 for ONNX node: Div_2411
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3036 for ONNX tensor: 3036
[06/10/2022-19:21:34] [V] [TRT] Div_2411 [Div] outputs: [3036 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: Shape_2413 [Shape]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3036
[06/10/2022-19:21:34] [V] [TRT] Shape_2413 [Shape] inputs: [3036 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: Shape_2413 for ONNX node: Shape_2413
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3039 for ONNX tensor: 3039
[06/10/2022-19:21:34] [V] [TRT] Shape_2413 [Shape] outputs: [3039 -> (4)[INT32]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: Slice_2417 [Slice]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3039
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3041
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3042
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3040
[06/10/2022-19:21:34] [V] [TRT] Slice_2417 [Slice] inputs: [3039 -> (4)[INT32]], [3041 -> (1)[INT32]], [3042 -> (1)[INT32]], [3040 -> (1)[INT32]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: Slice_2417 for ONNX node: Slice_2417
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3043 for ONNX tensor: 3043
[06/10/2022-19:21:34] [V] [TRT] Slice_2417 [Slice] outputs: [3043 -> (2)[INT32]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: Concat_2418 [Concat]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3043
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3237
[06/10/2022-19:21:34] [V] [TRT] Concat_2418 [Concat] inputs: [3043 -> (2)[INT32]], [3237 -> (2)[INT32]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: 3237 for ONNX node: 3237
[06/10/2022-19:21:34] [V] [TRT] Registering layer: Concat_2418 for ONNX node: Concat_2418
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3045 for ONNX tensor: 3045
[06/10/2022-19:21:34] [V] [TRT] Concat_2418 [Concat] outputs: [3045 -> (4)[INT32]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: Resize_2420 [Resize]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3036
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3038
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3046
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3045
[06/10/2022-19:21:34] [V] [TRT] Resize_2420 [Resize] inputs: [3036 -> (-1, 19, 1024, 1024)[FLOAT]], [3038 -> (0)[FLOAT]], [3046 -> (0)[FLOAT]], [3045 -> (4)[INT32]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: Resize_2420 for ONNX node: Resize_2420
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3047 for ONNX tensor: 3047
[06/10/2022-19:21:34] [V] [TRT] Resize_2420 [Resize] outputs: [3047 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: ReduceMax_2421 [ReduceMax]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3047
[06/10/2022-19:21:34] [V] [TRT] ReduceMax_2421 [ReduceMax] inputs: [3047 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: ReduceMax_2421 for ONNX node: ReduceMax_2421
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3048 for ONNX tensor: 3048
[06/10/2022-19:21:34] [V] [TRT] ReduceMax_2421 [ReduceMax] outputs: [3048 -> (-1, 1, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: Sub_2422 [Sub]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3047
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3048
[06/10/2022-19:21:34] [V] [TRT] Sub_2422 [Sub] inputs: [3047 -> (-1, 19, 1024, 1024)[FLOAT]], [3048 -> (-1, 1, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: Sub_2422 for ONNX node: Sub_2422
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3049 for ONNX tensor: 3049
[06/10/2022-19:21:34] [V] [TRT] Sub_2422 [Sub] outputs: [3049 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: Exp_2423 [Exp]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3049
[06/10/2022-19:21:34] [V] [TRT] Exp_2423 [Exp] inputs: [3049 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: Exp_2423 for ONNX node: Exp_2423
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3050 for ONNX tensor: 3050
[06/10/2022-19:21:34] [V] [TRT] Exp_2423 [Exp] outputs: [3050 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: ReduceSum_2424 [ReduceSum]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3050
[06/10/2022-19:21:34] [V] [TRT] ReduceSum_2424 [ReduceSum] inputs: [3050 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: ReduceSum_2424 for ONNX node: ReduceSum_2424
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3051 for ONNX tensor: 3051
[06/10/2022-19:21:34] [V] [TRT] ReduceSum_2424 [ReduceSum] outputs: [3051 -> (-1, 1, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: Div_2425 [Div]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3050
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3051
[06/10/2022-19:21:34] [V] [TRT] Div_2425 [Div] inputs: [3050 -> (-1, 19, 1024, 1024)[FLOAT]], [3051 -> (-1, 1, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: Div_2425 for ONNX node: Div_2425
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3052 for ONNX tensor: 3052
[06/10/2022-19:21:34] [V] [TRT] Div_2425 [Div] outputs: [3052 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: ArgMax_2426 [ArgMax]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3052
[06/10/2022-19:21:34] [V] [TRT] ArgMax_2426 [ArgMax] inputs: [3052 -> (-1, 19, 1024, 1024)[FLOAT]], 
[06/10/2022-19:21:34] [V] [TRT] Registering layer: ArgMax_2426 for ONNX node: ArgMax_2426
[06/10/2022-19:21:34] [V] [TRT] Original shape: (_, 1, 1024, 1024), squeezing to: (_, _, _)
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: 3053 for ONNX tensor: 3053
[06/10/2022-19:21:34] [V] [TRT] ArgMax_2426 [ArgMax] outputs: [3053 -> (-1, 1024, 1024)[INT32]], 
[06/10/2022-19:21:34] [V] [TRT] Parsing node: Unsqueeze_2427 [Unsqueeze]
[06/10/2022-19:21:34] [V] [TRT] Searching for input: 3053
[06/10/2022-19:21:34] [V] [TRT] Unsqueeze_2427 [Unsqueeze] inputs: [3053 -> (-1, 1024, 1024)[INT32]], 
[06/10/2022-19:21:34] [V] [TRT] Original shape: (_, 1024, 1024), unsqueezing to: (_, _, _, _)
[06/10/2022-19:21:34] [V] [TRT] Registering layer: Unsqueeze_2427 for ONNX node: Unsqueeze_2427
[06/10/2022-19:21:34] [V] [TRT] Registering tensor: output_471 for ONNX tensor: output
[06/10/2022-19:21:34] [V] [TRT] Unsqueeze_2427 [Unsqueeze] outputs: [output -> (1, -1, 1024, 1024)[INT32]], 
[06/10/2022-19:21:34] [V] [TRT] Marking output_471 as output: output
[06/10/2022-19:21:34] [I] Finish parsing network model
[06/10/2022-19:21:34] [V] [TRT] Applying generic optimizations to the graph for inference.
[06/10/2022-19:21:34] [V] [TRT] Original: 2124 layers
[06/10/2022-19:21:34] [V] [TRT] After dead-layer removal: 2124 layers
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on (Unnamed Layer* 8) [Constant]
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing (Unnamed Layer* 8) [Constant] with (Unnamed Layer* 9) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 398
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 398 with (Unnamed Layer* 75) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 401
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 401 with (Unnamed Layer* 79) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.patch_embed1.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.patch_embed1.norm.weight with (Unnamed Layer* 84) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.patch_embed1.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.patch_embed1.norm.bias with (Unnamed Layer* 87) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 409
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 409 with (Unnamed Layer* 92) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 412
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 412 with (Unnamed Layer* 96) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.0.norm1.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.0.norm1.weight with (Unnamed Layer* 101) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.0.norm1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.0.norm1.bias with (Unnamed Layer* 104) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3059
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3059 with (Unnamed Layer* 116) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.0.attn.q.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.0.attn.q.bias with (Unnamed Layer* 119) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 459
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 459 with (Unnamed Layer* 149) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 462
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 462 with (Unnamed Layer* 153) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.0.attn.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.0.attn.norm.weight with (Unnamed Layer* 158) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.0.attn.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.0.attn.norm.bias with (Unnamed Layer* 161) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3062
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3062 with (Unnamed Layer* 164) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.0.attn.kv.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.0.attn.kv.bias with (Unnamed Layer* 167) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 492
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 492 with (Unnamed Layer* 188) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3066
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3066 with (Unnamed Layer* 209) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.0.attn.proj.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.0.attn.proj.bias with (Unnamed Layer* 212) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 508
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 508 with (Unnamed Layer* 218) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 511
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 511 with (Unnamed Layer* 222) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.0.norm2.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.0.norm2.weight with (Unnamed Layer* 227) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.0.norm2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.0.norm2.bias with (Unnamed Layer* 230) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3067
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3067 with (Unnamed Layer* 233) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.0.mlp.fc1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.0.mlp.fc1.bias with (Unnamed Layer* 236) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 543
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 543 with (Unnamed Layer* 259) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 546
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 546 with (Unnamed Layer* 263) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 549
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 549 with (Unnamed Layer* 267) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3068
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3068 with (Unnamed Layer* 270) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.0.mlp.fc2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.0.mlp.fc2.bias with (Unnamed Layer* 273) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 557
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 557 with (Unnamed Layer* 279) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 560
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 560 with (Unnamed Layer* 283) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.1.norm1.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.1.norm1.weight with (Unnamed Layer* 288) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.1.norm1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.1.norm1.bias with (Unnamed Layer* 291) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3069
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3069 with (Unnamed Layer* 303) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.1.attn.q.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.1.attn.q.bias with (Unnamed Layer* 306) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 607
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 607 with (Unnamed Layer* 336) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 610
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 610 with (Unnamed Layer* 340) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.1.attn.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.1.attn.norm.weight with (Unnamed Layer* 345) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.1.attn.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.1.attn.norm.bias with (Unnamed Layer* 348) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3072
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3072 with (Unnamed Layer* 351) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.1.attn.kv.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.1.attn.kv.bias with (Unnamed Layer* 354) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 640
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 640 with (Unnamed Layer* 375) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3076
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3076 with (Unnamed Layer* 396) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.1.attn.proj.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.1.attn.proj.bias with (Unnamed Layer* 399) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 656
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 656 with (Unnamed Layer* 405) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 659
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 659 with (Unnamed Layer* 409) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.1.norm2.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.1.norm2.weight with (Unnamed Layer* 414) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.1.norm2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.1.norm2.bias with (Unnamed Layer* 417) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3077
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3077 with (Unnamed Layer* 420) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.1.mlp.fc1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.1.mlp.fc1.bias with (Unnamed Layer* 423) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 691
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 691 with (Unnamed Layer* 446) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 694
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 694 with (Unnamed Layer* 450) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 697
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 697 with (Unnamed Layer* 454) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3078
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3078 with (Unnamed Layer* 457) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.1.mlp.fc2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.1.mlp.fc2.bias with (Unnamed Layer* 460) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 705
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 705 with (Unnamed Layer* 466) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 708
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 708 with (Unnamed Layer* 470) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.2.norm1.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.2.norm1.weight with (Unnamed Layer* 475) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.2.norm1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.2.norm1.bias with (Unnamed Layer* 478) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3079
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3079 with (Unnamed Layer* 490) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.2.attn.q.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.2.attn.q.bias with (Unnamed Layer* 493) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 755
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 755 with (Unnamed Layer* 523) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 758
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 758 with (Unnamed Layer* 527) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.2.attn.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.2.attn.norm.weight with (Unnamed Layer* 532) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.2.attn.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.2.attn.norm.bias with (Unnamed Layer* 535) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3082
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3082 with (Unnamed Layer* 538) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.2.attn.kv.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.2.attn.kv.bias with (Unnamed Layer* 541) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 788
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 788 with (Unnamed Layer* 562) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3086
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3086 with (Unnamed Layer* 583) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.2.attn.proj.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.2.attn.proj.bias with (Unnamed Layer* 586) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 804
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 804 with (Unnamed Layer* 592) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 807
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 807 with (Unnamed Layer* 596) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.2.norm2.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.2.norm2.weight with (Unnamed Layer* 601) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.2.norm2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.2.norm2.bias with (Unnamed Layer* 604) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3087
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3087 with (Unnamed Layer* 607) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.2.mlp.fc1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.2.mlp.fc1.bias with (Unnamed Layer* 610) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 839
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 839 with (Unnamed Layer* 633) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 842
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 842 with (Unnamed Layer* 637) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 845
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 845 with (Unnamed Layer* 641) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3088
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3088 with (Unnamed Layer* 644) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block1.2.mlp.fc2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block1.2.mlp.fc2.bias with (Unnamed Layer* 647) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 853
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 853 with (Unnamed Layer* 653) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 856
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 856 with (Unnamed Layer* 657) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.norm1.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.norm1.weight with (Unnamed Layer* 662) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.norm1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.norm1.bias with (Unnamed Layer* 665) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 888
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 888 with (Unnamed Layer* 690) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 891
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 891 with (Unnamed Layer* 694) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.patch_embed2.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.patch_embed2.norm.weight with (Unnamed Layer* 699) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.patch_embed2.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.patch_embed2.norm.bias with (Unnamed Layer* 702) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 899
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 899 with (Unnamed Layer* 707) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 902
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 902 with (Unnamed Layer* 711) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.0.norm1.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.0.norm1.weight with (Unnamed Layer* 716) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.0.norm1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.0.norm1.bias with (Unnamed Layer* 719) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3090
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3090 with (Unnamed Layer* 731) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.0.attn.q.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.0.attn.q.bias with (Unnamed Layer* 734) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 949
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 949 with (Unnamed Layer* 764) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 952
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 952 with (Unnamed Layer* 768) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.0.attn.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.0.attn.norm.weight with (Unnamed Layer* 773) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.0.attn.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.0.attn.norm.bias with (Unnamed Layer* 776) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3093
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3093 with (Unnamed Layer* 779) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.0.attn.kv.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.0.attn.kv.bias with (Unnamed Layer* 782) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 982
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 982 with (Unnamed Layer* 803) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3097
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3097 with (Unnamed Layer* 826) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.0.attn.proj.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.0.attn.proj.bias with (Unnamed Layer* 829) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 998
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 998 with (Unnamed Layer* 835) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1001
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1001 with (Unnamed Layer* 839) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.0.norm2.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.0.norm2.weight with (Unnamed Layer* 844) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.0.norm2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.0.norm2.bias with (Unnamed Layer* 847) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3098
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3098 with (Unnamed Layer* 850) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.0.mlp.fc1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.0.mlp.fc1.bias with (Unnamed Layer* 853) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1033
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1033 with (Unnamed Layer* 876) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1036
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1036 with (Unnamed Layer* 880) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1039
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1039 with (Unnamed Layer* 884) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3099
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3099 with (Unnamed Layer* 887) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.0.mlp.fc2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.0.mlp.fc2.bias with (Unnamed Layer* 890) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1047
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1047 with (Unnamed Layer* 896) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1050
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1050 with (Unnamed Layer* 900) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.1.norm1.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.1.norm1.weight with (Unnamed Layer* 905) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.1.norm1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.1.norm1.bias with (Unnamed Layer* 908) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3100
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3100 with (Unnamed Layer* 920) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.1.attn.q.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.1.attn.q.bias with (Unnamed Layer* 923) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1097
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1097 with (Unnamed Layer* 953) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1100
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1100 with (Unnamed Layer* 957) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.1.attn.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.1.attn.norm.weight with (Unnamed Layer* 962) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.1.attn.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.1.attn.norm.bias with (Unnamed Layer* 965) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3103
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3103 with (Unnamed Layer* 968) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.1.attn.kv.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.1.attn.kv.bias with (Unnamed Layer* 971) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1130
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1130 with (Unnamed Layer* 992) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3107
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3107 with (Unnamed Layer* 1015) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.1.attn.proj.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.1.attn.proj.bias with (Unnamed Layer* 1018) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1146
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1146 with (Unnamed Layer* 1024) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1149
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1149 with (Unnamed Layer* 1028) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.1.norm2.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.1.norm2.weight with (Unnamed Layer* 1033) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.1.norm2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.1.norm2.bias with (Unnamed Layer* 1036) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3108
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3108 with (Unnamed Layer* 1039) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.1.mlp.fc1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.1.mlp.fc1.bias with (Unnamed Layer* 1042) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1181
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1181 with (Unnamed Layer* 1065) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1184
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1184 with (Unnamed Layer* 1069) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1187
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1187 with (Unnamed Layer* 1073) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3109
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3109 with (Unnamed Layer* 1076) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.1.mlp.fc2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.1.mlp.fc2.bias with (Unnamed Layer* 1079) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1195
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1195 with (Unnamed Layer* 1085) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1198
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1198 with (Unnamed Layer* 1089) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.2.norm1.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.2.norm1.weight with (Unnamed Layer* 1094) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.2.norm1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.2.norm1.bias with (Unnamed Layer* 1097) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3110
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3110 with (Unnamed Layer* 1109) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.2.attn.q.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.2.attn.q.bias with (Unnamed Layer* 1112) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1245
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1245 with (Unnamed Layer* 1142) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1248
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1248 with (Unnamed Layer* 1146) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.2.attn.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.2.attn.norm.weight with (Unnamed Layer* 1151) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.2.attn.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.2.attn.norm.bias with (Unnamed Layer* 1154) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3113
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3113 with (Unnamed Layer* 1157) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.2.attn.kv.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.2.attn.kv.bias with (Unnamed Layer* 1160) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1278
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1278 with (Unnamed Layer* 1181) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3117
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3117 with (Unnamed Layer* 1204) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.2.attn.proj.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.2.attn.proj.bias with (Unnamed Layer* 1207) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1294
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1294 with (Unnamed Layer* 1213) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1297
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1297 with (Unnamed Layer* 1217) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.2.norm2.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.2.norm2.weight with (Unnamed Layer* 1222) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.2.norm2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.2.norm2.bias with (Unnamed Layer* 1225) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3118
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3118 with (Unnamed Layer* 1228) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.2.mlp.fc1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.2.mlp.fc1.bias with (Unnamed Layer* 1231) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1329
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1329 with (Unnamed Layer* 1254) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1332
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1332 with (Unnamed Layer* 1258) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1335
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1335 with (Unnamed Layer* 1262) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3119
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3119 with (Unnamed Layer* 1265) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.2.mlp.fc2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.2.mlp.fc2.bias with (Unnamed Layer* 1268) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1343
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1343 with (Unnamed Layer* 1274) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1346
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1346 with (Unnamed Layer* 1278) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.3.norm1.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.3.norm1.weight with (Unnamed Layer* 1283) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.3.norm1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.3.norm1.bias with (Unnamed Layer* 1286) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3120
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3120 with (Unnamed Layer* 1298) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.3.attn.q.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.3.attn.q.bias with (Unnamed Layer* 1301) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1393
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1393 with (Unnamed Layer* 1331) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1396
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1396 with (Unnamed Layer* 1335) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.3.attn.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.3.attn.norm.weight with (Unnamed Layer* 1340) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.3.attn.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.3.attn.norm.bias with (Unnamed Layer* 1343) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3123
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3123 with (Unnamed Layer* 1346) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.3.attn.kv.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.3.attn.kv.bias with (Unnamed Layer* 1349) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1426
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1426 with (Unnamed Layer* 1370) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3127
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3127 with (Unnamed Layer* 1393) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.3.attn.proj.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.3.attn.proj.bias with (Unnamed Layer* 1396) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1442
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1442 with (Unnamed Layer* 1402) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1445
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1445 with (Unnamed Layer* 1406) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.3.norm2.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.3.norm2.weight with (Unnamed Layer* 1411) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.3.norm2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.3.norm2.bias with (Unnamed Layer* 1414) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3128
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3128 with (Unnamed Layer* 1417) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.3.mlp.fc1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.3.mlp.fc1.bias with (Unnamed Layer* 1420) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1477
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1477 with (Unnamed Layer* 1443) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1480
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1480 with (Unnamed Layer* 1447) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1483
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1483 with (Unnamed Layer* 1451) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3129
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3129 with (Unnamed Layer* 1454) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block2.3.mlp.fc2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block2.3.mlp.fc2.bias with (Unnamed Layer* 1457) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1491
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1491 with (Unnamed Layer* 1463) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1494
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1494 with (Unnamed Layer* 1467) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.norm2.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.norm2.weight with (Unnamed Layer* 1472) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.norm2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.norm2.bias with (Unnamed Layer* 1475) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1526
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1526 with (Unnamed Layer* 1500) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1529
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1529 with (Unnamed Layer* 1504) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.patch_embed3.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.patch_embed3.norm.weight with (Unnamed Layer* 1509) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.patch_embed3.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.patch_embed3.norm.bias with (Unnamed Layer* 1512) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1537
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1537 with (Unnamed Layer* 1517) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1540
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1540 with (Unnamed Layer* 1521) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.0.norm1.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.0.norm1.weight with (Unnamed Layer* 1526) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.0.norm1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.0.norm1.bias with (Unnamed Layer* 1529) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3131
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3131 with (Unnamed Layer* 1541) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.0.attn.q.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.0.attn.q.bias with (Unnamed Layer* 1544) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1587
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1587 with (Unnamed Layer* 1574) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1590
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1590 with (Unnamed Layer* 1578) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.0.attn.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.0.attn.norm.weight with (Unnamed Layer* 1583) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.0.attn.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.0.attn.norm.bias with (Unnamed Layer* 1586) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3134
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3134 with (Unnamed Layer* 1589) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.0.attn.kv.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.0.attn.kv.bias with (Unnamed Layer* 1592) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1620
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1620 with (Unnamed Layer* 1613) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3138
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3138 with (Unnamed Layer* 1636) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.0.attn.proj.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.0.attn.proj.bias with (Unnamed Layer* 1639) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1636
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1636 with (Unnamed Layer* 1645) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1639
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1639 with (Unnamed Layer* 1649) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.0.norm2.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.0.norm2.weight with (Unnamed Layer* 1654) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.0.norm2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.0.norm2.bias with (Unnamed Layer* 1657) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3139
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3139 with (Unnamed Layer* 1660) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.0.mlp.fc1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.0.mlp.fc1.bias with (Unnamed Layer* 1663) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1671
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1671 with (Unnamed Layer* 1686) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1674
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1674 with (Unnamed Layer* 1690) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1677
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1677 with (Unnamed Layer* 1694) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3140
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3140 with (Unnamed Layer* 1697) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.0.mlp.fc2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.0.mlp.fc2.bias with (Unnamed Layer* 1700) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1685
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1685 with (Unnamed Layer* 1706) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1688
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1688 with (Unnamed Layer* 1710) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.1.norm1.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.1.norm1.weight with (Unnamed Layer* 1715) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.1.norm1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.1.norm1.bias with (Unnamed Layer* 1718) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3141
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3141 with (Unnamed Layer* 1730) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.1.attn.q.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.1.attn.q.bias with (Unnamed Layer* 1733) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1735
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1735 with (Unnamed Layer* 1763) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1738
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1738 with (Unnamed Layer* 1767) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.1.attn.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.1.attn.norm.weight with (Unnamed Layer* 1772) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.1.attn.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.1.attn.norm.bias with (Unnamed Layer* 1775) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3144
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3144 with (Unnamed Layer* 1778) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.1.attn.kv.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.1.attn.kv.bias with (Unnamed Layer* 1781) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1768
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1768 with (Unnamed Layer* 1802) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3148
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3148 with (Unnamed Layer* 1825) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.1.attn.proj.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.1.attn.proj.bias with (Unnamed Layer* 1828) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1784
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1784 with (Unnamed Layer* 1834) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1787
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1787 with (Unnamed Layer* 1838) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.1.norm2.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.1.norm2.weight with (Unnamed Layer* 1843) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.1.norm2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.1.norm2.bias with (Unnamed Layer* 1846) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3149
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3149 with (Unnamed Layer* 1849) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.1.mlp.fc1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.1.mlp.fc1.bias with (Unnamed Layer* 1852) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1819
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1819 with (Unnamed Layer* 1875) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1822
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1822 with (Unnamed Layer* 1879) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1825
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1825 with (Unnamed Layer* 1883) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3150
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3150 with (Unnamed Layer* 1886) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.1.mlp.fc2.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.1.mlp.fc2.bias with (Unnamed Layer* 1889) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1833
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1833 with (Unnamed Layer* 1895) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1836
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1836 with (Unnamed Layer* 1899) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.2.norm1.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.2.norm1.weight with (Unnamed Layer* 1904) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.2.norm1.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.2.norm1.bias with (Unnamed Layer* 1907) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3151
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3151 with (Unnamed Layer* 1919) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.2.attn.q.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.2.attn.q.bias with (Unnamed Layer* 1922) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1883
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1883 with (Unnamed Layer* 1952) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 1886
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 1886 with (Unnamed Layer* 1956) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.2.attn.norm.weight
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.2.attn.norm.weight with (Unnamed Layer* 1961) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.2.attn.norm.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.2.attn.norm.bias with (Unnamed Layer* 1964) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on 3154
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing 3154 with (Unnamed Layer* 1967) [Shuffle]
[06/10/2022-19:21:34] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.2.attn.kv.bias
[06/10/2022-19:21:34] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.2.attn.kv.bias with (Unnamed Layer* 1970) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 1916
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 1916 with (Unnamed Layer* 1991) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3158
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3158 with (Unnamed Layer* 2014) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.2.attn.proj.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.2.attn.proj.bias with (Unnamed Layer* 2017) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 1932
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 1932 with (Unnamed Layer* 2023) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 1935
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 1935 with (Unnamed Layer* 2027) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.2.norm2.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.2.norm2.weight with (Unnamed Layer* 2032) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.2.norm2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.2.norm2.bias with (Unnamed Layer* 2035) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3159
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3159 with (Unnamed Layer* 2038) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.2.mlp.fc1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.2.mlp.fc1.bias with (Unnamed Layer* 2041) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 1967
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 1967 with (Unnamed Layer* 2064) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 1970
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 1970 with (Unnamed Layer* 2068) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 1973
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 1973 with (Unnamed Layer* 2072) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3160
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3160 with (Unnamed Layer* 2075) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.2.mlp.fc2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.2.mlp.fc2.bias with (Unnamed Layer* 2078) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 1981
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 1981 with (Unnamed Layer* 2084) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 1984
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 1984 with (Unnamed Layer* 2088) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.3.norm1.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.3.norm1.weight with (Unnamed Layer* 2093) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.3.norm1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.3.norm1.bias with (Unnamed Layer* 2096) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3161
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3161 with (Unnamed Layer* 2108) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.3.attn.q.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.3.attn.q.bias with (Unnamed Layer* 2111) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2031
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2031 with (Unnamed Layer* 2141) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2034
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2034 with (Unnamed Layer* 2145) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.3.attn.norm.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.3.attn.norm.weight with (Unnamed Layer* 2150) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.3.attn.norm.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.3.attn.norm.bias with (Unnamed Layer* 2153) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3164
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3164 with (Unnamed Layer* 2156) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.3.attn.kv.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.3.attn.kv.bias with (Unnamed Layer* 2159) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2064
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2064 with (Unnamed Layer* 2180) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3168
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3168 with (Unnamed Layer* 2203) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.3.attn.proj.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.3.attn.proj.bias with (Unnamed Layer* 2206) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2080
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2080 with (Unnamed Layer* 2212) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2083
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2083 with (Unnamed Layer* 2216) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.3.norm2.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.3.norm2.weight with (Unnamed Layer* 2221) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.3.norm2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.3.norm2.bias with (Unnamed Layer* 2224) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3169
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3169 with (Unnamed Layer* 2227) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.3.mlp.fc1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.3.mlp.fc1.bias with (Unnamed Layer* 2230) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2115
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2115 with (Unnamed Layer* 2253) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2118
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2118 with (Unnamed Layer* 2257) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2121
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2121 with (Unnamed Layer* 2261) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3170
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3170 with (Unnamed Layer* 2264) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.3.mlp.fc2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.3.mlp.fc2.bias with (Unnamed Layer* 2267) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2129
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2129 with (Unnamed Layer* 2273) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2132
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2132 with (Unnamed Layer* 2277) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.4.norm1.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.4.norm1.weight with (Unnamed Layer* 2282) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.4.norm1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.4.norm1.bias with (Unnamed Layer* 2285) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3171
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3171 with (Unnamed Layer* 2297) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.4.attn.q.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.4.attn.q.bias with (Unnamed Layer* 2300) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2179
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2179 with (Unnamed Layer* 2330) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2182
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2182 with (Unnamed Layer* 2334) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.4.attn.norm.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.4.attn.norm.weight with (Unnamed Layer* 2339) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.4.attn.norm.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.4.attn.norm.bias with (Unnamed Layer* 2342) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3174
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3174 with (Unnamed Layer* 2345) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.4.attn.kv.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.4.attn.kv.bias with (Unnamed Layer* 2348) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2212
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2212 with (Unnamed Layer* 2369) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3178
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3178 with (Unnamed Layer* 2392) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.4.attn.proj.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.4.attn.proj.bias with (Unnamed Layer* 2395) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2228
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2228 with (Unnamed Layer* 2401) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2231
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2231 with (Unnamed Layer* 2405) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.4.norm2.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.4.norm2.weight with (Unnamed Layer* 2410) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.4.norm2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.4.norm2.bias with (Unnamed Layer* 2413) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3179
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3179 with (Unnamed Layer* 2416) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.4.mlp.fc1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.4.mlp.fc1.bias with (Unnamed Layer* 2419) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2263
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2263 with (Unnamed Layer* 2442) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2266
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2266 with (Unnamed Layer* 2446) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2269
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2269 with (Unnamed Layer* 2450) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3180
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3180 with (Unnamed Layer* 2453) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.4.mlp.fc2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.4.mlp.fc2.bias with (Unnamed Layer* 2456) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2277
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2277 with (Unnamed Layer* 2462) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2280
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2280 with (Unnamed Layer* 2466) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.5.norm1.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.5.norm1.weight with (Unnamed Layer* 2471) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.5.norm1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.5.norm1.bias with (Unnamed Layer* 2474) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3181
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3181 with (Unnamed Layer* 2486) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.5.attn.q.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.5.attn.q.bias with (Unnamed Layer* 2489) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2327
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2327 with (Unnamed Layer* 2519) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2330
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2330 with (Unnamed Layer* 2523) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.5.attn.norm.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.5.attn.norm.weight with (Unnamed Layer* 2528) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.5.attn.norm.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.5.attn.norm.bias with (Unnamed Layer* 2531) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3184
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3184 with (Unnamed Layer* 2534) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.5.attn.kv.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.5.attn.kv.bias with (Unnamed Layer* 2537) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2360
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2360 with (Unnamed Layer* 2558) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3188
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3188 with (Unnamed Layer* 2581) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.5.attn.proj.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.5.attn.proj.bias with (Unnamed Layer* 2584) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2376
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2376 with (Unnamed Layer* 2590) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2379
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2379 with (Unnamed Layer* 2594) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.5.norm2.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.5.norm2.weight with (Unnamed Layer* 2599) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.5.norm2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.5.norm2.bias with (Unnamed Layer* 2602) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3189
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3189 with (Unnamed Layer* 2605) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.5.mlp.fc1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.5.mlp.fc1.bias with (Unnamed Layer* 2608) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2411
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2411 with (Unnamed Layer* 2631) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2414
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2414 with (Unnamed Layer* 2635) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2417
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2417 with (Unnamed Layer* 2639) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3190
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3190 with (Unnamed Layer* 2642) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block3.5.mlp.fc2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block3.5.mlp.fc2.bias with (Unnamed Layer* 2645) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2425
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2425 with (Unnamed Layer* 2651) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2428
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2428 with (Unnamed Layer* 2655) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.norm3.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.norm3.weight with (Unnamed Layer* 2660) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.norm3.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.norm3.bias with (Unnamed Layer* 2663) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2460
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2460 with (Unnamed Layer* 2688) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2463
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2463 with (Unnamed Layer* 2692) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.patch_embed4.norm.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.patch_embed4.norm.weight with (Unnamed Layer* 2697) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.patch_embed4.norm.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.patch_embed4.norm.bias with (Unnamed Layer* 2700) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2471
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2471 with (Unnamed Layer* 2705) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2474
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2474 with (Unnamed Layer* 2709) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.0.norm1.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.0.norm1.weight with (Unnamed Layer* 2714) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.0.norm1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.0.norm1.bias with (Unnamed Layer* 2717) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3192
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3192 with (Unnamed Layer* 2729) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.0.attn.q.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.0.attn.q.bias with (Unnamed Layer* 2732) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3194
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3194 with (Unnamed Layer* 2746) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.0.attn.kv.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.0.attn.kv.bias with (Unnamed Layer* 2749) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2528
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2528 with (Unnamed Layer* 2770) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3198
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3198 with (Unnamed Layer* 2793) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.0.attn.proj.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.0.attn.proj.bias with (Unnamed Layer* 2796) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2544
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2544 with (Unnamed Layer* 2802) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2547
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2547 with (Unnamed Layer* 2806) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.0.norm2.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.0.norm2.weight with (Unnamed Layer* 2811) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.0.norm2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.0.norm2.bias with (Unnamed Layer* 2814) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3199
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3199 with (Unnamed Layer* 2817) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.0.mlp.fc1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.0.mlp.fc1.bias with (Unnamed Layer* 2820) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2579
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2579 with (Unnamed Layer* 2843) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2582
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2582 with (Unnamed Layer* 2847) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2585
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2585 with (Unnamed Layer* 2851) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3200
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3200 with (Unnamed Layer* 2854) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.0.mlp.fc2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.0.mlp.fc2.bias with (Unnamed Layer* 2857) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2593
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2593 with (Unnamed Layer* 2863) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2596
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2596 with (Unnamed Layer* 2867) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.1.norm1.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.1.norm1.weight with (Unnamed Layer* 2872) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.1.norm1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.1.norm1.bias with (Unnamed Layer* 2875) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3201
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3201 with (Unnamed Layer* 2887) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.1.attn.q.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.1.attn.q.bias with (Unnamed Layer* 2890) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3203
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3203 with (Unnamed Layer* 2904) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.1.attn.kv.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.1.attn.kv.bias with (Unnamed Layer* 2907) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2650
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2650 with (Unnamed Layer* 2928) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3207
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3207 with (Unnamed Layer* 2951) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.1.attn.proj.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.1.attn.proj.bias with (Unnamed Layer* 2954) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2666
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2666 with (Unnamed Layer* 2960) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2669
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2669 with (Unnamed Layer* 2964) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.1.norm2.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.1.norm2.weight with (Unnamed Layer* 2969) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.1.norm2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.1.norm2.bias with (Unnamed Layer* 2972) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3208
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3208 with (Unnamed Layer* 2975) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.1.mlp.fc1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.1.mlp.fc1.bias with (Unnamed Layer* 2978) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2701
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2701 with (Unnamed Layer* 3001) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2704
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2704 with (Unnamed Layer* 3005) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2707
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2707 with (Unnamed Layer* 3009) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3209
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3209 with (Unnamed Layer* 3012) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.1.mlp.fc2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.1.mlp.fc2.bias with (Unnamed Layer* 3015) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2715
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2715 with (Unnamed Layer* 3021) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2718
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2718 with (Unnamed Layer* 3025) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.2.norm1.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.2.norm1.weight with (Unnamed Layer* 3030) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.2.norm1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.2.norm1.bias with (Unnamed Layer* 3033) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3210
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3210 with (Unnamed Layer* 3045) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.2.attn.q.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.2.attn.q.bias with (Unnamed Layer* 3048) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3212
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3212 with (Unnamed Layer* 3062) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.2.attn.kv.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.2.attn.kv.bias with (Unnamed Layer* 3065) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2772
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2772 with (Unnamed Layer* 3086) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3216
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3216 with (Unnamed Layer* 3109) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.2.attn.proj.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.2.attn.proj.bias with (Unnamed Layer* 3112) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2788
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2788 with (Unnamed Layer* 3118) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2791
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2791 with (Unnamed Layer* 3122) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.2.norm2.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.2.norm2.weight with (Unnamed Layer* 3127) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.2.norm2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.2.norm2.bias with (Unnamed Layer* 3130) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3217
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3217 with (Unnamed Layer* 3133) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.2.mlp.fc1.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.2.mlp.fc1.bias with (Unnamed Layer* 3136) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2823
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2823 with (Unnamed Layer* 3159) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2826
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2826 with (Unnamed Layer* 3163) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2829
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2829 with (Unnamed Layer* 3167) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3218
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3218 with (Unnamed Layer* 3170) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.block4.2.mlp.fc2.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.block4.2.mlp.fc2.bias with (Unnamed Layer* 3173) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2837
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2837 with (Unnamed Layer* 3179) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 2840
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 2840 with (Unnamed Layer* 3183) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.norm4.weight
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.norm4.weight with (Unnamed Layer* 3188) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on backbone.norm4.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing backbone.norm4.bias with (Unnamed Layer* 3191) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3220
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3220 with (Unnamed Layer* 3210) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on decode_head.linear_c4.proj.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing decode_head.linear_c4.proj.bias with (Unnamed Layer* 3213) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3223
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3223 with (Unnamed Layer* 3240) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on decode_head.linear_c3.proj.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing decode_head.linear_c3.proj.bias with (Unnamed Layer* 3243) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3226
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3226 with (Unnamed Layer* 3270) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on decode_head.linear_c2.proj.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing decode_head.linear_c2.proj.bias with (Unnamed Layer* 3273) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on 3229
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing 3229 with (Unnamed Layer* 3300) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ConstShuffleFusion on decode_head.linear_c1.proj.bias
[06/10/2022-19:21:35] [V] [TRT] ConstShuffleFusion: Fusing decode_head.linear_c1.proj.bias with (Unnamed Layer* 3303) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_41
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_41 with Transpose_42
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_86
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_86 with Reshape_92
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_97
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_97 with Transpose_98
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_84
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_84 with Transpose_85
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_119
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_119 with Transpose_120
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_131
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_131 with Reshape_136
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_159
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_159 with Reshape_165
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_174
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_174 with Transpose_175
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_219
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_219 with Reshape_225
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_230
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_230 with Transpose_231
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_217
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_217 with Transpose_218
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_252
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_252 with Transpose_253
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_264
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_264 with Reshape_269
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_292
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_292 with Reshape_298
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_307
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_307 with Transpose_308
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_352
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_352 with Reshape_358
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_363
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_363 with Transpose_364
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_350
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_350 with Transpose_351
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_385
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_385 with Transpose_386
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_397
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_397 with Reshape_402
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_425
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_425 with Reshape_431
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_440
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_440 with Transpose_441
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_468
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_468 with Transpose_469
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2365
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2365 with Transpose_2366
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_484
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_484 with Transpose_485
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_2369
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_2369 with Reshape_2380
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_529
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_529 with Reshape_535
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_540
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_540 with Transpose_541
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_527
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_527 with Transpose_528
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_562
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_562 with Transpose_563
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_574
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_574 with Reshape_579
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_602
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_602 with Reshape_608
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_617
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_617 with Transpose_618
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_662
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_662 with Reshape_668
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_673
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_673 with Transpose_674
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_660
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_660 with Transpose_661
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_695
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_695 with Transpose_696
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_707
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_707 with Reshape_712
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_735
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_735 with Reshape_741
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_750
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_750 with Transpose_751
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_795
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_795 with Reshape_801
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_806
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_806 with Transpose_807
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_793
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_793 with Transpose_794
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_828
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_828 with Transpose_829
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_840
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_840 with Reshape_845
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_868
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_868 with Reshape_874
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_883
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_883 with Transpose_884
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_928
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_928 with Reshape_934
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_939
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_939 with Transpose_940
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_926
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_926 with Transpose_927
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_961
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_961 with Transpose_962
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_973
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_973 with Reshape_978
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1001
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1001 with Reshape_1007
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1016
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1016 with Transpose_1017
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1044
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1044 with Transpose_1045
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2333
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2333 with Transpose_2334
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1060
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1060 with Transpose_1061
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_2337
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_2337 with Reshape_2348
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1105
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1105 with Reshape_1111
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1116
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1116 with Transpose_1117
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1103
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1103 with Transpose_1104
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1138
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1138 with Transpose_1139
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1150
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1150 with Reshape_1155
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1178
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1178 with Reshape_1184
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1193
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1193 with Transpose_1194
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1238
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1238 with Reshape_1244
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1249
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1249 with Transpose_1250
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1236
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1236 with Transpose_1237
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1271
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1271 with Transpose_1272
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1283
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1283 with Reshape_1288
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1311
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1311 with Reshape_1317
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1326
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1326 with Transpose_1327
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1371
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1371 with Reshape_1377
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1382
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1382 with Transpose_1383
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1369
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1369 with Transpose_1370
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1404
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1404 with Transpose_1405
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1416
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1416 with Reshape_1421
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1444
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1444 with Reshape_1450
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1459
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1459 with Transpose_1460
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1504
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1504 with Reshape_1510
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1515
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1515 with Transpose_1516
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1502
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1502 with Transpose_1503
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1537
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1537 with Transpose_1538
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1549
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1549 with Reshape_1554
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1577
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1577 with Reshape_1583
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1592
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1592 with Transpose_1593
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1637
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1637 with Reshape_1643
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1648
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1648 with Transpose_1649
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1635
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1635 with Transpose_1636
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1670
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1670 with Transpose_1671
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1682
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1682 with Reshape_1687
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1710
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1710 with Reshape_1716
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1725
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1725 with Transpose_1726
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1770
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1770 with Reshape_1776
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1781
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1781 with Transpose_1782
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1768
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1768 with Transpose_1769
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1803
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1803 with Transpose_1804
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1815
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1815 with Reshape_1820
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1843
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1843 with Reshape_1849
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1858
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1858 with Transpose_1859
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1886
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1886 with Transpose_1887
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2301
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2301 with Transpose_2302
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1902
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1902 with Transpose_1903
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_2305
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_2305 with Reshape_2316
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1945
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1945 with Transpose_1946
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_1956
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_1956 with Transpose_1957
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1968
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1968 with Reshape_1973
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_1996
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_1996 with Reshape_2002
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2011
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2011 with Transpose_2012
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2054
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2054 with Transpose_2055
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2065
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2065 with Transpose_2066
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_2077
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_2077 with Reshape_2082
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_2105
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_2105 with Reshape_2111
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2120
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2120 with Transpose_2121
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2163
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2163 with Transpose_2164
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2174
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2174 with Transpose_2175
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_2186
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_2186 with Reshape_2191
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_2214
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_2214 with Reshape_2220
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2229
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2229 with Transpose_2230
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2257
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2257 with Transpose_2258
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Reshape_2269
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Reshape_2269 with Transpose_2270
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on Transpose_2273
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose_2273 with Reshape_2284
[06/10/2022-19:21:35] [V] [TRT] Running: ShuffleShuffleFusion on (Unnamed Layer* 3345) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] ShuffleShuffleFusion: Fusing (Unnamed Layer* 3345) [Shuffle] with Unsqueeze_2427
[06/10/2022-19:21:35] [V] [TRT] After Myelin optimization: 573 layers
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_184
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_184 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_317
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_317 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_450
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_450 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_627
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_627 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_760
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_760 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_893
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_893 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_1026
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_1026 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_1203
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_1203 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_1336
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_1336 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_1469
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_1469 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_1602
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_1602 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_1735
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_1735 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_1868
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_1868 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_2335
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_2335 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_2303
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_2303 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_2239
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_2239 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_2271
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_2271 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: MatMulToConvTransform on MatMul_2367
[06/10/2022-19:21:35] [V] [TRT] Convert layer type of MatMul_2367 from MATRIX_MULTIPLY to CONVOLUTION
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_184
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_317
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_450
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_627
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_760
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_893
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_1026
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_1203
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_1336
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_1469
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_1602
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_1735
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_1868
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_2335
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_2303
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_2239
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_2271
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReshapeBiasAddFusion on MatMul_2367
[06/10/2022-19:21:35] [V] [TRT] Applying ScaleNodes fusions.
[06/10/2022-19:21:35] [V] [TRT] After scale fusion: 555 layers
[06/10/2022-19:21:35] [V] [TRT] Running: SliceErasure on Slice_18
[06/10/2022-19:21:35] [V] [TRT] Removing Slice_18
[06/10/2022-19:21:35] [V] [TRT] Running: SliceErasure on Slice_23
[06/10/2022-19:21:35] [V] [TRT] Removing Slice_23
[06/10/2022-19:21:35] [V] [TRT] Running: ConvReluFusion on Conv_2382
[06/10/2022-19:21:35] [V] [TRT] ConvReluFusion: Fusing Conv_2382 with Relu_2383
[06/10/2022-19:21:35] [V] [TRT] After dupe layer removal: 552 layers
[06/10/2022-19:21:35] [V] [TRT] After final dead-layer removal: 552 layers
[06/10/2022-19:21:35] [V] [TRT] After tensor merging: 552 layers
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 401 + (Unnamed Layer* 79) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 401 + (Unnamed Layer* 79) [Shuffle] with Add_49
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 398 + (Unnamed Layer* 75) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 398 + (Unnamed Layer* 75) [Shuffle] with Pow_46
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49) with Sqrt_50
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50) with Div_51
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51) with Mul_52
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52) with Add_53
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 412 + (Unnamed Layer* 96) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 412 + (Unnamed Layer* 96) [Shuffle] with Add_60
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 409 + (Unnamed Layer* 92) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 409 + (Unnamed Layer* 92) [Shuffle] with Pow_57
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60) with Sqrt_61
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61) with Div_62
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62) with Mul_63
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63) with Add_64
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 549 + (Unnamed Layer* 267) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 549 + (Unnamed Layer* 267) [Shuffle] with Mul_183
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 546 + (Unnamed Layer* 263) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 546 + (Unnamed Layer* 263) [Shuffle] with Add_180
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 543 + (Unnamed Layer* 259) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 543 + (Unnamed Layer* 259) [Shuffle] with Div_177
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177) with Erf_178
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178) with PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180))
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)) with Mul_181
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181) with PWN(549 + (Unnamed Layer* 267) [Shuffle], Mul_183)
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 560 + (Unnamed Layer* 283) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 560 + (Unnamed Layer* 283) [Shuffle] with Add_193
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 557 + (Unnamed Layer* 279) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 557 + (Unnamed Layer* 279) [Shuffle] with Pow_190
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193) with Sqrt_194
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193), Sqrt_194)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193), Sqrt_194) with Div_195
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193), Sqrt_194), Div_195)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193), Sqrt_194), Div_195) with Mul_196
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193), Sqrt_194), Div_195), Mul_196)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193), Sqrt_194), Div_195), Mul_196) with Add_197
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 697 + (Unnamed Layer* 454) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 697 + (Unnamed Layer* 454) [Shuffle] with Mul_316
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 694 + (Unnamed Layer* 450) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 694 + (Unnamed Layer* 450) [Shuffle] with Add_313
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 691 + (Unnamed Layer* 446) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 691 + (Unnamed Layer* 446) [Shuffle] with Div_310
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310) with Erf_311
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310), Erf_311)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310), Erf_311) with PWN(694 + (Unnamed Layer* 450) [Shuffle], Add_313)
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310), Erf_311), PWN(694 + (Unnamed Layer* 450) [Shuffle], Add_313))
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310), Erf_311), PWN(694 + (Unnamed Layer* 450) [Shuffle], Add_313)) with Mul_314
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310), Erf_311), PWN(694 + (Unnamed Layer* 450) [Shuffle], Add_313)), Mul_314)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310), Erf_311), PWN(694 + (Unnamed Layer* 450) [Shuffle], Add_313)), Mul_314) with PWN(697 + (Unnamed Layer* 454) [Shuffle], Mul_316)
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 708 + (Unnamed Layer* 470) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 708 + (Unnamed Layer* 470) [Shuffle] with Add_326
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 705 + (Unnamed Layer* 466) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 705 + (Unnamed Layer* 466) [Shuffle] with Pow_323
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326) with Sqrt_327
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326), Sqrt_327)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326), Sqrt_327) with Div_328
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326), Sqrt_327), Div_328)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326), Sqrt_327), Div_328) with Mul_329
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326), Sqrt_327), Div_328), Mul_329)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326), Sqrt_327), Div_328), Mul_329) with Add_330
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 845 + (Unnamed Layer* 641) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 845 + (Unnamed Layer* 641) [Shuffle] with Mul_449
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 842 + (Unnamed Layer* 637) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 842 + (Unnamed Layer* 637) [Shuffle] with Add_446
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 839 + (Unnamed Layer* 633) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 839 + (Unnamed Layer* 633) [Shuffle] with Div_443
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443) with Erf_444
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443), Erf_444)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443), Erf_444) with PWN(842 + (Unnamed Layer* 637) [Shuffle], Add_446)
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443), Erf_444), PWN(842 + (Unnamed Layer* 637) [Shuffle], Add_446))
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443), Erf_444), PWN(842 + (Unnamed Layer* 637) [Shuffle], Add_446)) with Mul_447
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443), Erf_444), PWN(842 + (Unnamed Layer* 637) [Shuffle], Add_446)), Mul_447)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443), Erf_444), PWN(842 + (Unnamed Layer* 637) [Shuffle], Add_446)), Mul_447) with PWN(845 + (Unnamed Layer* 641) [Shuffle], Mul_449)
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 856 + (Unnamed Layer* 657) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 856 + (Unnamed Layer* 657) [Shuffle] with Add_459
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 853 + (Unnamed Layer* 653) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 853 + (Unnamed Layer* 653) [Shuffle] with Pow_456
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459) with Sqrt_460
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459), Sqrt_460)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459), Sqrt_460) with Div_461
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459), Sqrt_460), Div_461)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459), Sqrt_460), Div_461) with Mul_462
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459), Sqrt_460), Div_461), Mul_462)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459), Sqrt_460), Div_461), Mul_462) with Add_463
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 891 + (Unnamed Layer* 694) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 891 + (Unnamed Layer* 694) [Shuffle] with Add_492
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on 888 + (Unnamed Layer* 690) [Shuffle]
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing 888 + (Unnamed Layer* 690) [Shuffle] with Pow_489
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492) with Sqrt_493
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493) with Div_494
[06/10/2022-19:21:35] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494)
[06/10/2022-19:21:35] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494) with Mul_495
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495) with Add_496
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 902 + (Unnamed Layer* 711) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 902 + (Unnamed Layer* 711) [Shuffle] with Add_503
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 899 + (Unnamed Layer* 707) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 899 + (Unnamed Layer* 707) [Shuffle] with Pow_500
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503) with Sqrt_504
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504) with Div_505
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505) with Mul_506
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506) with Add_507
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1039 + (Unnamed Layer* 884) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1039 + (Unnamed Layer* 884) [Shuffle] with Mul_626
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1036 + (Unnamed Layer* 880) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1036 + (Unnamed Layer* 880) [Shuffle] with Add_623
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1033 + (Unnamed Layer* 876) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1033 + (Unnamed Layer* 876) [Shuffle] with Div_620
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620) with Erf_621
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621) with PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623))
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)) with Mul_624
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624) with PWN(1039 + (Unnamed Layer* 884) [Shuffle], Mul_626)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1050 + (Unnamed Layer* 900) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1050 + (Unnamed Layer* 900) [Shuffle] with Add_636
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1047 + (Unnamed Layer* 896) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1047 + (Unnamed Layer* 896) [Shuffle] with Pow_633
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636) with Sqrt_637
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636), Sqrt_637)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636), Sqrt_637) with Div_638
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636), Sqrt_637), Div_638)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636), Sqrt_637), Div_638) with Mul_639
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636), Sqrt_637), Div_638), Mul_639)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636), Sqrt_637), Div_638), Mul_639) with Add_640
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1187 + (Unnamed Layer* 1073) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1187 + (Unnamed Layer* 1073) [Shuffle] with Mul_759
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1184 + (Unnamed Layer* 1069) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1184 + (Unnamed Layer* 1069) [Shuffle] with Add_756
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1181 + (Unnamed Layer* 1065) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1181 + (Unnamed Layer* 1065) [Shuffle] with Div_753
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753) with Erf_754
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753), Erf_754)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753), Erf_754) with PWN(1184 + (Unnamed Layer* 1069) [Shuffle], Add_756)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753), Erf_754), PWN(1184 + (Unnamed Layer* 1069) [Shuffle], Add_756))
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753), Erf_754), PWN(1184 + (Unnamed Layer* 1069) [Shuffle], Add_756)) with Mul_757
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753), Erf_754), PWN(1184 + (Unnamed Layer* 1069) [Shuffle], Add_756)), Mul_757)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753), Erf_754), PWN(1184 + (Unnamed Layer* 1069) [Shuffle], Add_756)), Mul_757) with PWN(1187 + (Unnamed Layer* 1073) [Shuffle], Mul_759)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1198 + (Unnamed Layer* 1089) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1198 + (Unnamed Layer* 1089) [Shuffle] with Add_769
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1195 + (Unnamed Layer* 1085) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1195 + (Unnamed Layer* 1085) [Shuffle] with Pow_766
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769) with Sqrt_770
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769), Sqrt_770)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769), Sqrt_770) with Div_771
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769), Sqrt_770), Div_771)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769), Sqrt_770), Div_771) with Mul_772
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769), Sqrt_770), Div_771), Mul_772)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769), Sqrt_770), Div_771), Mul_772) with Add_773
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1335 + (Unnamed Layer* 1262) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1335 + (Unnamed Layer* 1262) [Shuffle] with Mul_892
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1332 + (Unnamed Layer* 1258) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1332 + (Unnamed Layer* 1258) [Shuffle] with Add_889
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1329 + (Unnamed Layer* 1254) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1329 + (Unnamed Layer* 1254) [Shuffle] with Div_886
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886) with Erf_887
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886), Erf_887)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886), Erf_887) with PWN(1332 + (Unnamed Layer* 1258) [Shuffle], Add_889)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886), Erf_887), PWN(1332 + (Unnamed Layer* 1258) [Shuffle], Add_889))
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886), Erf_887), PWN(1332 + (Unnamed Layer* 1258) [Shuffle], Add_889)) with Mul_890
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886), Erf_887), PWN(1332 + (Unnamed Layer* 1258) [Shuffle], Add_889)), Mul_890)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886), Erf_887), PWN(1332 + (Unnamed Layer* 1258) [Shuffle], Add_889)), Mul_890) with PWN(1335 + (Unnamed Layer* 1262) [Shuffle], Mul_892)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1346 + (Unnamed Layer* 1278) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1346 + (Unnamed Layer* 1278) [Shuffle] with Add_902
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1343 + (Unnamed Layer* 1274) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1343 + (Unnamed Layer* 1274) [Shuffle] with Pow_899
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902) with Sqrt_903
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902), Sqrt_903)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902), Sqrt_903) with Div_904
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902), Sqrt_903), Div_904)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902), Sqrt_903), Div_904) with Mul_905
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902), Sqrt_903), Div_904), Mul_905)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902), Sqrt_903), Div_904), Mul_905) with Add_906
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1483 + (Unnamed Layer* 1451) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1483 + (Unnamed Layer* 1451) [Shuffle] with Mul_1025
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1480 + (Unnamed Layer* 1447) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1480 + (Unnamed Layer* 1447) [Shuffle] with Add_1022
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1477 + (Unnamed Layer* 1443) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1477 + (Unnamed Layer* 1443) [Shuffle] with Div_1019
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019) with Erf_1020
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019), Erf_1020)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019), Erf_1020) with PWN(1480 + (Unnamed Layer* 1447) [Shuffle], Add_1022)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019), Erf_1020), PWN(1480 + (Unnamed Layer* 1447) [Shuffle], Add_1022))
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019), Erf_1020), PWN(1480 + (Unnamed Layer* 1447) [Shuffle], Add_1022)) with Mul_1023
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019), Erf_1020), PWN(1480 + (Unnamed Layer* 1447) [Shuffle], Add_1022)), Mul_1023)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019), Erf_1020), PWN(1480 + (Unnamed Layer* 1447) [Shuffle], Add_1022)), Mul_1023) with PWN(1483 + (Unnamed Layer* 1451) [Shuffle], Mul_1025)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1494 + (Unnamed Layer* 1467) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1494 + (Unnamed Layer* 1467) [Shuffle] with Add_1035
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1491 + (Unnamed Layer* 1463) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1491 + (Unnamed Layer* 1463) [Shuffle] with Pow_1032
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035) with Sqrt_1036
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035), Sqrt_1036)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035), Sqrt_1036) with Div_1037
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035), Sqrt_1036), Div_1037)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035), Sqrt_1036), Div_1037) with Mul_1038
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035), Sqrt_1036), Div_1037), Mul_1038)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035), Sqrt_1036), Div_1037), Mul_1038) with Add_1039
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1529 + (Unnamed Layer* 1504) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1529 + (Unnamed Layer* 1504) [Shuffle] with Add_1068
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1526 + (Unnamed Layer* 1500) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1526 + (Unnamed Layer* 1500) [Shuffle] with Pow_1065
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068) with Sqrt_1069
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069) with Div_1070
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070) with Mul_1071
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071) with Add_1072
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1540 + (Unnamed Layer* 1521) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1540 + (Unnamed Layer* 1521) [Shuffle] with Add_1079
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1537 + (Unnamed Layer* 1517) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1537 + (Unnamed Layer* 1517) [Shuffle] with Pow_1076
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079) with Sqrt_1080
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080) with Div_1081
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081) with Mul_1082
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082) with Add_1083
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1677 + (Unnamed Layer* 1694) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1677 + (Unnamed Layer* 1694) [Shuffle] with Mul_1202
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1674 + (Unnamed Layer* 1690) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1674 + (Unnamed Layer* 1690) [Shuffle] with Add_1199
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1671 + (Unnamed Layer* 1686) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1671 + (Unnamed Layer* 1686) [Shuffle] with Div_1196
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196) with Erf_1197
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197) with PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199))
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)) with Mul_1200
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200) with PWN(1677 + (Unnamed Layer* 1694) [Shuffle], Mul_1202)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1688 + (Unnamed Layer* 1710) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1688 + (Unnamed Layer* 1710) [Shuffle] with Add_1212
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1685 + (Unnamed Layer* 1706) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1685 + (Unnamed Layer* 1706) [Shuffle] with Pow_1209
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212) with Sqrt_1213
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212), Sqrt_1213)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212), Sqrt_1213) with Div_1214
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212), Sqrt_1213), Div_1214)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212), Sqrt_1213), Div_1214) with Mul_1215
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212), Sqrt_1213), Div_1214), Mul_1215)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212), Sqrt_1213), Div_1214), Mul_1215) with Add_1216
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1825 + (Unnamed Layer* 1883) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1825 + (Unnamed Layer* 1883) [Shuffle] with Mul_1335
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1822 + (Unnamed Layer* 1879) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1822 + (Unnamed Layer* 1879) [Shuffle] with Add_1332
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1819 + (Unnamed Layer* 1875) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1819 + (Unnamed Layer* 1875) [Shuffle] with Div_1329
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329) with Erf_1330
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329), Erf_1330)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329), Erf_1330) with PWN(1822 + (Unnamed Layer* 1879) [Shuffle], Add_1332)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329), Erf_1330), PWN(1822 + (Unnamed Layer* 1879) [Shuffle], Add_1332))
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329), Erf_1330), PWN(1822 + (Unnamed Layer* 1879) [Shuffle], Add_1332)) with Mul_1333
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329), Erf_1330), PWN(1822 + (Unnamed Layer* 1879) [Shuffle], Add_1332)), Mul_1333)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329), Erf_1330), PWN(1822 + (Unnamed Layer* 1879) [Shuffle], Add_1332)), Mul_1333) with PWN(1825 + (Unnamed Layer* 1883) [Shuffle], Mul_1335)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1836 + (Unnamed Layer* 1899) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1836 + (Unnamed Layer* 1899) [Shuffle] with Add_1345
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1833 + (Unnamed Layer* 1895) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1833 + (Unnamed Layer* 1895) [Shuffle] with Pow_1342
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345) with Sqrt_1346
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345), Sqrt_1346)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345), Sqrt_1346) with Div_1347
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345), Sqrt_1346), Div_1347)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345), Sqrt_1346), Div_1347) with Mul_1348
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345), Sqrt_1346), Div_1347), Mul_1348)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345), Sqrt_1346), Div_1347), Mul_1348) with Add_1349
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1973 + (Unnamed Layer* 2072) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1973 + (Unnamed Layer* 2072) [Shuffle] with Mul_1468
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1970 + (Unnamed Layer* 2068) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1970 + (Unnamed Layer* 2068) [Shuffle] with Add_1465
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1967 + (Unnamed Layer* 2064) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1967 + (Unnamed Layer* 2064) [Shuffle] with Div_1462
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462) with Erf_1463
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462), Erf_1463)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462), Erf_1463) with PWN(1970 + (Unnamed Layer* 2068) [Shuffle], Add_1465)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462), Erf_1463), PWN(1970 + (Unnamed Layer* 2068) [Shuffle], Add_1465))
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462), Erf_1463), PWN(1970 + (Unnamed Layer* 2068) [Shuffle], Add_1465)) with Mul_1466
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462), Erf_1463), PWN(1970 + (Unnamed Layer* 2068) [Shuffle], Add_1465)), Mul_1466)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462), Erf_1463), PWN(1970 + (Unnamed Layer* 2068) [Shuffle], Add_1465)), Mul_1466) with PWN(1973 + (Unnamed Layer* 2072) [Shuffle], Mul_1468)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1984 + (Unnamed Layer* 2088) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1984 + (Unnamed Layer* 2088) [Shuffle] with Add_1478
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 1981 + (Unnamed Layer* 2084) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 1981 + (Unnamed Layer* 2084) [Shuffle] with Pow_1475
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478) with Sqrt_1479
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478), Sqrt_1479)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478), Sqrt_1479) with Div_1480
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478), Sqrt_1479), Div_1480)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478), Sqrt_1479), Div_1480) with Mul_1481
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478), Sqrt_1479), Div_1480), Mul_1481)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478), Sqrt_1479), Div_1480), Mul_1481) with Add_1482
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2121 + (Unnamed Layer* 2261) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2121 + (Unnamed Layer* 2261) [Shuffle] with Mul_1601
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2118 + (Unnamed Layer* 2257) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2118 + (Unnamed Layer* 2257) [Shuffle] with Add_1598
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2115 + (Unnamed Layer* 2253) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2115 + (Unnamed Layer* 2253) [Shuffle] with Div_1595
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595) with Erf_1596
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595), Erf_1596)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595), Erf_1596) with PWN(2118 + (Unnamed Layer* 2257) [Shuffle], Add_1598)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595), Erf_1596), PWN(2118 + (Unnamed Layer* 2257) [Shuffle], Add_1598))
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595), Erf_1596), PWN(2118 + (Unnamed Layer* 2257) [Shuffle], Add_1598)) with Mul_1599
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595), Erf_1596), PWN(2118 + (Unnamed Layer* 2257) [Shuffle], Add_1598)), Mul_1599)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595), Erf_1596), PWN(2118 + (Unnamed Layer* 2257) [Shuffle], Add_1598)), Mul_1599) with PWN(2121 + (Unnamed Layer* 2261) [Shuffle], Mul_1601)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2132 + (Unnamed Layer* 2277) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2132 + (Unnamed Layer* 2277) [Shuffle] with Add_1611
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2129 + (Unnamed Layer* 2273) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2129 + (Unnamed Layer* 2273) [Shuffle] with Pow_1608
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611) with Sqrt_1612
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611), Sqrt_1612)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611), Sqrt_1612) with Div_1613
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611), Sqrt_1612), Div_1613)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611), Sqrt_1612), Div_1613) with Mul_1614
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611), Sqrt_1612), Div_1613), Mul_1614)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611), Sqrt_1612), Div_1613), Mul_1614) with Add_1615
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2269 + (Unnamed Layer* 2450) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2269 + (Unnamed Layer* 2450) [Shuffle] with Mul_1734
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2266 + (Unnamed Layer* 2446) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2266 + (Unnamed Layer* 2446) [Shuffle] with Add_1731
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2263 + (Unnamed Layer* 2442) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2263 + (Unnamed Layer* 2442) [Shuffle] with Div_1728
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728) with Erf_1729
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728), Erf_1729)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728), Erf_1729) with PWN(2266 + (Unnamed Layer* 2446) [Shuffle], Add_1731)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728), Erf_1729), PWN(2266 + (Unnamed Layer* 2446) [Shuffle], Add_1731))
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728), Erf_1729), PWN(2266 + (Unnamed Layer* 2446) [Shuffle], Add_1731)) with Mul_1732
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728), Erf_1729), PWN(2266 + (Unnamed Layer* 2446) [Shuffle], Add_1731)), Mul_1732)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728), Erf_1729), PWN(2266 + (Unnamed Layer* 2446) [Shuffle], Add_1731)), Mul_1732) with PWN(2269 + (Unnamed Layer* 2450) [Shuffle], Mul_1734)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2280 + (Unnamed Layer* 2466) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2280 + (Unnamed Layer* 2466) [Shuffle] with Add_1744
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2277 + (Unnamed Layer* 2462) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2277 + (Unnamed Layer* 2462) [Shuffle] with Pow_1741
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744) with Sqrt_1745
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744), Sqrt_1745)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744), Sqrt_1745) with Div_1746
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744), Sqrt_1745), Div_1746)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744), Sqrt_1745), Div_1746) with Mul_1747
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744), Sqrt_1745), Div_1746), Mul_1747)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744), Sqrt_1745), Div_1746), Mul_1747) with Add_1748
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2417 + (Unnamed Layer* 2639) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2417 + (Unnamed Layer* 2639) [Shuffle] with Mul_1867
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2414 + (Unnamed Layer* 2635) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2414 + (Unnamed Layer* 2635) [Shuffle] with Add_1864
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2411 + (Unnamed Layer* 2631) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2411 + (Unnamed Layer* 2631) [Shuffle] with Div_1861
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861) with Erf_1862
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861), Erf_1862)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861), Erf_1862) with PWN(2414 + (Unnamed Layer* 2635) [Shuffle], Add_1864)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861), Erf_1862), PWN(2414 + (Unnamed Layer* 2635) [Shuffle], Add_1864))
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861), Erf_1862), PWN(2414 + (Unnamed Layer* 2635) [Shuffle], Add_1864)) with Mul_1865
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861), Erf_1862), PWN(2414 + (Unnamed Layer* 2635) [Shuffle], Add_1864)), Mul_1865)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861), Erf_1862), PWN(2414 + (Unnamed Layer* 2635) [Shuffle], Add_1864)), Mul_1865) with PWN(2417 + (Unnamed Layer* 2639) [Shuffle], Mul_1867)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2428 + (Unnamed Layer* 2655) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2428 + (Unnamed Layer* 2655) [Shuffle] with Add_1877
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2425 + (Unnamed Layer* 2651) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2425 + (Unnamed Layer* 2651) [Shuffle] with Pow_1874
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877) with Sqrt_1878
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877), Sqrt_1878)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877), Sqrt_1878) with Div_1879
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877), Sqrt_1878), Div_1879)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877), Sqrt_1878), Div_1879) with Mul_1880
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877), Sqrt_1878), Div_1879), Mul_1880)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877), Sqrt_1878), Div_1879), Mul_1880) with Add_1881
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2829 + (Unnamed Layer* 3167) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2829 + (Unnamed Layer* 3167) [Shuffle] with Mul_2238
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2826 + (Unnamed Layer* 3163) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2826 + (Unnamed Layer* 3163) [Shuffle] with Add_2235
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2823 + (Unnamed Layer* 3159) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2823 + (Unnamed Layer* 3159) [Shuffle] with Div_2232
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232) with Erf_2233
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233) with PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235))
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)) with Mul_2236
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236) with PWN(2829 + (Unnamed Layer* 3167) [Shuffle], Mul_2238)
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2840 + (Unnamed Layer* 3183) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2840 + (Unnamed Layer* 3183) [Shuffle] with Add_2248
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on 2837 + (Unnamed Layer* 3179) [Shuffle]
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing 2837 + (Unnamed Layer* 3179) [Shuffle] with Pow_2245
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248) with Sqrt_2249
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249) with Div_2250
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250) with Mul_2251
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251)
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251) with Add_2252
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on Add_2409
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing Add_2409 with Div_2411
[06/10/2022-19:21:36] [V] [TRT] Running: PointWiseFusion on Sub_2422
[06/10/2022-19:21:36] [V] [TRT] PointWiseFusion: Fusing Sub_2422 with Exp_2423
[06/10/2022-19:21:36] [V] [TRT] After vertical fusions: 332 layers
[06/10/2022-19:21:36] [V] [TRT] After dupe layer removal: 332 layers
[06/10/2022-19:21:36] [V] [TRT] After final dead-layer removal: 332 layers
[06/10/2022-19:21:36] [V] [TRT] After tensor merging: 332 layers
[06/10/2022-19:21:36] [V] [TRT] After slice removal: 332 layers
[06/10/2022-19:21:36] [V] [TRT] Eliminating concatenation Concat_2381
[06/10/2022-19:21:36] [V] [TRT] Generating copy for 2893 to 2994 because input does not support striding.
[06/10/2022-19:21:36] [V] [TRT] Generating copy for 2930 to 2994 because input does not support striding.
[06/10/2022-19:21:36] [V] [TRT] Generating copy for 2967 to 2994 because input does not support striding.
[06/10/2022-19:21:36] [V] [TRT] Retargeting 2993 to 2994
[06/10/2022-19:21:36] [V] [TRT] After concat removal: 334 layers
[06/10/2022-19:21:36] [V] [TRT] Trying to split Reshape and strided tensor
[06/10/2022-19:21:36] [V] [TRT] Graph construction and optimization completed in 2.47757 seconds.
[06/10/2022-19:21:37] [V] [TRT] Using cublasLt as a tactic source
[06/10/2022-19:21:37] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +756, GPU +324, now: CPU 1575, GPU 831 (MiB)
[06/10/2022-19:21:37] [V] [TRT] Using cuDNN as a tactic source
[06/10/2022-19:21:37] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +588, GPU +342, now: CPU 2163, GPU 1173 (MiB)
[06/10/2022-19:21:37] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[06/10/2022-19:21:37] [V] [TRT] Constructing optimization profile number 0 [1/1].
[06/10/2022-19:21:37] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[06/10/2022-19:21:37] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:37] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(3145728,1048576,1024,1) -> Float(3145728,1,3072,3) ***************
[06/10/2022-19:21:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.203776
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.202459
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.20363
[06/10/2022-19:21:37] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.202459
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(3145728,1048576,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:21:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.683154
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.244151
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.683301
[06/10/2022-19:21:37] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.244151
[06/10/2022-19:21:37] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 104) [Shuffle]_output) (Reformat)
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00300781
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00663044
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0030139
[06/10/2022-19:21:37] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00300781
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 104) [Shuffle]_output) (Reformat)
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00304019
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00623861
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00305498
[06/10/2022-19:21:37] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00304019
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 104) [Shuffle]_output) (Reformat)
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00310748
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00701475
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00312636
[06/10/2022-19:21:37] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00310748
[06/10/2022-19:21:37] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:37] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.292133
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.282331
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.291986
[06/10/2022-19:21:37] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.282331
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.293595
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.28277
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.293595
[06/10/2022-19:21:37] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.28277
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:21:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.38914
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.282478
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.39631
[06/10/2022-19:21:37] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.282478
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.41005
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.289207
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.40551
[06/10/2022-19:21:37] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.289207
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.272969
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.279552
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.274139
[06/10/2022-19:21:37] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.272969
[06/10/2022-19:21:37] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:21:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 4.65423
[06/10/2022-19:21:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.280722
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.65452
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.280722
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.38225
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.290377
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.38459
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.290377
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.275163
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.279113
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.275895
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.275163
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 4.65306
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.28043
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.65218
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.28043
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.18111
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.28976
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.18084
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.28976
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.274139
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.280137
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.275163
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.274139
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(380 -> <out>) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.268288
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.28043
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.268288
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.268288
[06/10/2022-19:21:38] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.27253
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.279406
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.272384
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.272384
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.27531
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.279113
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.275749
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.27531
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 29.0506
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.79785
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 28.9814
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.79785
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.642341
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.81043
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.642487
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.642341
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.269019
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.87611
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.264923
[06/10/2022-19:21:38] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.264923
[06/10/2022-19:21:38] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 29.185
[06/10/2022-19:21:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.90508
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 29.1319
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.90508
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.643511
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.7961
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.641609
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.641609
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.265216
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.04727
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.265509
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.265216
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 29.1626
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.79317
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 29.1543
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.79317
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.47866
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.81453
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.47748
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.47748
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.477486
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.96564
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.477769
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.477486
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 395) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.479817
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.07199
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.47733
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.47733
[06/10/2022-19:21:39] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(395 -> <out>) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.644096
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.01172
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.641609
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.641609
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(395 -> <out>) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.641024
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.06994
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.643072
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.641024
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(395 -> <out>) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.48041
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.99151
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.47895
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.47895
[06/10/2022-19:21:39] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 396) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00600419
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00683951
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00602076
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00600419
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 396) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.361618
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0377051
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.355767
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0377051
[06/10/2022-19:21:39] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(395 -> <out>) (Reformat)
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.278235
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.278967
[06/10/2022-19:21:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.278089
[06/10/2022-19:21:39] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.278089
[06/10/2022-19:21:39] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(395 -> <out>) (Reformat)
[06/10/2022-19:21:40] [V] [TRT] Tactic: 0x00000000000003e8 Time: 28.9985
[06/10/2022-19:21:40] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.84832
[06/10/2022-19:21:40] [V] [TRT] Tactic: 0x0000000000000000 Time: 28.9656
[06/10/2022-19:21:40] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.84832
[06/10/2022-19:21:40] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:40] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(395 -> <out>) (Reformat)
[06/10/2022-19:21:40] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.274871
[06/10/2022-19:21:40] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.78937
[06/10/2022-19:21:40] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.270889
[06/10/2022-19:21:40] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.270889
[06/10/2022-19:21:40] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(395 -> <out>) (Reformat)
[06/10/2022-19:21:40] [V] [TRT] Tactic: 0x00000000000003e8 Time: 29.1392
[06/10/2022-19:21:40] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.79215
[06/10/2022-19:21:40] [V] [TRT] Tactic: 0x0000000000000000 Time: 29.13
[06/10/2022-19:21:40] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.79215
[06/10/2022-19:21:40] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:40] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(395 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 29.2124
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.84057
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 29.1417
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.84057
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(395 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.47733
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.81292
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.477623
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.47733
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(396 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00525992
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00655626
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00557204
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00525992
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(396 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.364398
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0385097
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.365422
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0385097
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(396 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00588782
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0378777
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00587008
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00587008
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(396 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.363081
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0385829
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.351963
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0385829
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(65536,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(396 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0221316
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0360594
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0222524
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0221316
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(396 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00988739
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.03584
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00992579
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00988739
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(397 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.273737
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.279552
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.273847
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.273737
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(397 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.267995
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.82082
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.27019
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.267995
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(397 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.478793
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.06611
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.47877
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.47877
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 400) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00576896
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00700713
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00573257
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00573257
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(400 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00574555
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00699385
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0055476
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0055476
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(65536,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(400 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00551894
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0372697
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0055302
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00551894
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(400 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00570567
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.03712
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00571446
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00570567
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(400 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.354743
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0378514
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.354743
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0378514
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(400 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00554374
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0350245
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00543594
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00543594
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(65536,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(400 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0098691
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0357303
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00990842
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0098691
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00285742
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00705894
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00290468
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00285742
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00290002
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00588197
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00309525
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00290002
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00326203
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00726743
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00324378
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00324378
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00291872
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0068406
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00296975
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00291872
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00289188
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00703935
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00293411
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00289188
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00331127
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00694117
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00322296
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00322296
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00288009
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00693094
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00292665
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00288009
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00288302
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00691723
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00289161
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00288302
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00348103
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00697992
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00345948
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00345948
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00286711
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00689633
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00293056
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00286711
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00288795
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00690721
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00290222
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00288795
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 84) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00303828
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00686977
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0030299
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0030299
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(65536,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(65536,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(65536,1,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,2048,64) -> Float(65536,1024,32,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(449 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00676156
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0074736
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0067707
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00676156
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(16384,1:4,512,16) -> Float(65536,1024,32,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(449 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00668779
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00744594
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00672083
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00668779
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 532) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.31483
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.12026
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.3438
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.12026
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 532) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.35638
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.11996
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.38856
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.11996
[06/10/2022-19:21:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(532 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.40041
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.12274
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.40056
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.12274
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(532 -> <out>) (Reformat)
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.38651
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.12055
[06/10/2022-19:21:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.389
[06/10/2022-19:21:41] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.12055
[06/10/2022-19:21:41] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(532 -> <out>) (Reformat)
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003e8 Time: 7.49392
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.15259
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.50958
[06/10/2022-19:21:42] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.15259
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(532 -> <out>) (Reformat)
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.08003
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.11938
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.07798
[06/10/2022-19:21:42] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.07798
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(532 -> <out>) (Reformat)
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003e8 Time: 7.48486
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.15449
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.48325
[06/10/2022-19:21:42] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.15449
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(532 -> <out>) (Reformat)
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.07227
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.11909
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.06628
[06/10/2022-19:21:42] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.06628
[06/10/2022-19:21:42] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:42] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:42] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(524288,65536:32,256,1) ***************
[06/10/2022-19:21:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(533 -> <out>) (Reformat)
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003e8 Time: 9.59327
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.11718
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 9.58669
[06/10/2022-19:21:42] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.11718
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(524288,65536:32,256,1) ***************
[06/10/2022-19:21:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(533 -> <out>) (Reformat)
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003e8 Time: 22.8371
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.11734
[06/10/2022-19:21:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 22.8409
[06/10/2022-19:21:42] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.11734
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:42] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(524288,65536:32,256,1) ***************
[06/10/2022-19:21:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(533 -> <out>) (Reformat)
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003e8 Time: 22.8302
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.11675
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x0000000000000000 Time: 22.8267
[06/10/2022-19:21:43] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.11675
[06/10/2022-19:21:43] [V] [TRT] *************** Autotuning Reformat: Float(524288,65536:32,256,1) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(533 -> <out>) (Reformat)
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003e8 Time: 4.72181
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.13986
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.71771
[06/10/2022-19:21:43] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.13986
[06/10/2022-19:21:43] [V] [TRT] *************** Autotuning Reformat: Float(524288,65536:32,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(533 -> <out>) (Reformat)
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.09509
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.10958
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.09904
[06/10/2022-19:21:43] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.09509
[06/10/2022-19:21:43] [V] [TRT] *************** Autotuning Reformat: Float(524288,65536:32,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(533 -> <out>) (Reformat)
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.08368
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.10972
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.08646
[06/10/2022-19:21:43] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.08368
[06/10/2022-19:21:43] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:43] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.08412
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.1027
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.08485
[06/10/2022-19:21:43] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.08412
[06/10/2022-19:21:43] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.09802
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.09861
[06/10/2022-19:21:43] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.10197
[06/10/2022-19:21:43] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.09802
[06/10/2022-19:21:43] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:44] [V] [TRT] Tactic: 0x00000000000003e8 Time: 115.932
[06/10/2022-19:21:44] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.49834
[06/10/2022-19:21:45] [V] [TRT] Tactic: 0x0000000000000000 Time: 115.974
[06/10/2022-19:21:45] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 8.49834
[06/10/2022-19:21:45] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:45] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.60315
[06/10/2022-19:21:45] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.36345
[06/10/2022-19:21:45] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.60462
[06/10/2022-19:21:45] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 2.60315
[06/10/2022-19:21:45] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:45] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.05223
[06/10/2022-19:21:45] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.4224
[06/10/2022-19:21:45] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.05589
[06/10/2022-19:21:45] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.05223
[06/10/2022-19:21:45] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:46] [V] [TRT] Tactic: 0x00000000000003e8 Time: 116.654
[06/10/2022-19:21:46] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.74408
[06/10/2022-19:21:47] [V] [TRT] Tactic: 0x0000000000000000 Time: 116.674
[06/10/2022-19:21:47] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 8.74408
[06/10/2022-19:21:47] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:47] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.60432
[06/10/2022-19:21:47] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.57702
[06/10/2022-19:21:47] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.60228
[06/10/2022-19:21:47] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 2.60228
[06/10/2022-19:21:47] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:47] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.05209
[06/10/2022-19:21:47] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.44595
[06/10/2022-19:21:47] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.05544
[06/10/2022-19:21:47] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.05209
[06/10/2022-19:21:47] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 116.602
[06/10/2022-19:21:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.73882
[06/10/2022-19:21:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 116.568
[06/10/2022-19:21:49] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 8.73882
[06/10/2022-19:21:49] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 5.88156
[06/10/2022-19:21:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.82629
[06/10/2022-19:21:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.88039
[06/10/2022-19:21:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 5.88039
[06/10/2022-19:21:49] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.88387
[06/10/2022-19:21:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.32863
[06/10/2022-19:21:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.88401
[06/10/2022-19:21:49] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.88387
[06/10/2022-19:21:49] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(542 -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.88372
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.42196
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.87363
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.87363
[06/10/2022-19:21:50] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:50] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.06364
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.09744
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.07813
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.06364
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(64,1:4,64,64) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.06233
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.11806
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.06364
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.06233
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.08734
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.09641
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.08661
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.08661
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(64,1:4,64,64) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.06335
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.11777
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.06364
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.06335
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(64,1:4,64,64) -> Float(256,1,1,1) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.07505
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 27.7751
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.06101
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.06101
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(64,1:4,64,64) -> Float(256,1,256,256) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.05691
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.11762
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.05691
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.05691
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.07286
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 27.5484
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.06408
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.06408
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.06174
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.11733
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.0616
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.0616
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(64,1:4,64,64) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.05326
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.11923
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.05179
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.05179
[06/10/2022-19:21:50] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(64,1,64,64) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.274578
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.280283
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.274432
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.274432
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.265216
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.280722
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.265362
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.265216
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(2,1:32,1,1) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.267849
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.82289
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.26507
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.26507
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(64,1,1,1) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.271214
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.85071
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.273701
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.271214
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.265509
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.279991
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.266683
[06/10/2022-19:21:50] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.265509
[06/10/2022-19:21:50] [V] [TRT] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(2,1:32,1,1) ***************
[06/10/2022-19:21:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.264923
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.84632
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.265362
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.264923
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(64,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.266231
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.89357
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.26507
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.26507
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(64,1,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.265947
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.279259
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.266386
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.265947
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(2,1:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.265216
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.8706
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.265193
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.265193
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(64,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.266094
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.87294
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.265509
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.265509
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(64,1,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.26507
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.278967
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.266386
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.26507
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_184_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.266825
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.279552
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.266386
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.266386
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,2048,64) -> Float(65536,1024,32,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16384,1:4,512,16) -> Float(65536,1024,32,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(524288,65536:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(524288,65536:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(524288,65536:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(524288,65536:32,256,1) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(524288,65536:32,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(524288,65536:32,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(64,1:4,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(64,1:4,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1:4,64,64) -> Float(256,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1:4,64,64) -> Float(256,1,256,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(64,1:4,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(64,1,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(2,1:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(64,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(2,1:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(64,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(64,1,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(2,1:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(64,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(64,1,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,2048,64) -> Float(65536,1024,32,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16384,1:4,512,16) -> Float(65536,1024,32,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,65536,256,1) -> Float(524288,65536:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,1,65536,256) -> Float(524288,65536:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1:4,16384,64) -> Float(524288,65536:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(524288,65536:32,256,1) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(524288,65536:32,256,1) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(524288,65536:32,256,1) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16777216:32,256,1) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(256,1,256,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(256,1,1,1) -> Float(64,1:4,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(256,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(256,1,256,256) -> Float(64,1:4,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1:4,64,64) -> Float(256,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1:4,64,64) -> Float(256,1,256,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(256,1,256,256) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(8,1:32,1,1) -> Float(64,1:4,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(64,1,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(2,1:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(64,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(2,1:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(64,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(64,1,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(2,1:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(64,1,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(64,1,64,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,1,1) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(65536:32,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(65536,1,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,64,1) -> Float(64:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(64,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(64:32,64,1) -> Float(1:4,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.295351
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.282917
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.29509
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.282917
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.296667
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.283941
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.295611
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.283941
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.40596
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.283209
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.40304
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.283209
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.3956
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.289938
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.40902
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.289938
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.273239
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.278967
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.272091
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.272091
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 4.6554
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.280603
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.65379
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.280603
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.38928
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.289646
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.39952
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.289646
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.273408
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.27957
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.273115
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.273115
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 4.65452
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.280283
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.65686
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.280283
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.18082
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.290231
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.18331
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.290231
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.272494
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.281746
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.270482
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.270482
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 869) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.269458
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.28043
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.268434
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.268434
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 719) [Shuffle]_output) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00285768
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0068615
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00290834
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00285768
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 719) [Shuffle]_output) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00292282
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0059445
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00294652
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00292282
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 719) [Shuffle]_output) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00374318
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00737851
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00372337
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00372337
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.163401
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144238
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.163547
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.144238
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.163547
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143506
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.16384
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.143506
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.367022
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.14395
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.365275
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.14395
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.198217
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.147749
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.19851
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.147749
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.136635
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143035
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135954
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.135954
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.465335
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143067
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.465481
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.143067
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.202752
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.147749
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.203337
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.147749
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.135314
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143003
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134802
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.134802
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.475584
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.14336
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.475575
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.14336
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.180224
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.147895
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.181687
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.147895
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.137143
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143785
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.136997
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.136997
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(870 -> <out>) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.138667
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143506
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.138759
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.138667
[06/10/2022-19:21:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.140153
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142336
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.140434
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.140153
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.142043
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142482
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.142043
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.142043
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 14.4385
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.92789
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.4245
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.92789
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.320782
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.922345
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.320805
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.320782
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.136265
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.915602
[06/10/2022-19:21:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.136411
[06/10/2022-19:21:51] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.136265
[06/10/2022-19:21:51] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 14.5253
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.915163
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.5538
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.915163
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.320658
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.918967
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.320658
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.320658
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.136649
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.970313
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135168
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.135168
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 14.519
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.923355
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.5093
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.923355
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.740901
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.943397
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.741522
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.740901
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.242103
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.951881
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.241664
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.241664
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 885) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.242103
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.966949
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.242103
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.242103
[06/10/2022-19:21:52] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(885 -> <out>) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.321115
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.05179
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.321097
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.321097
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(885 -> <out>) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.321243
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.04331
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.321097
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.321097
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(885 -> <out>) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.741522
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.02927
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.740937
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.740937
[06/10/2022-19:21:52] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 886) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00365257
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00588709
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00369418
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00365257
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 886) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0866743
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0126419
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0817737
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0126419
[06/10/2022-19:21:52] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(885 -> <out>) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.141385
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142482
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.141458
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.141385
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(885 -> <out>) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 14.484
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.92043
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.4039
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.92043
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(885 -> <out>) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.135591
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.922624
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135079
[06/10/2022-19:21:52] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.135079
[06/10/2022-19:21:52] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(885 -> <out>) (Reformat)
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 14.5344
[06/10/2022-19:21:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.916773
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.5467
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.916773
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(885 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 14.5727
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.915017
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.5227
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.915017
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(885 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.242542
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.930816
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.242103
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.242103
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(886 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00347429
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00596242
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00345437
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00345437
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(886 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0819269
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0125406
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0815543
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0125406
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(886 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0036861
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0124735
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00368903
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0036861
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(886 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.078848
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120057
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0789211
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0120057
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(886 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00410762
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120076
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00409143
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00409143
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(886 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00347048
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119966
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00350707
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00347048
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(887 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.139483
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142423
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.139191
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.139191
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(887 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.136923
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.905216
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.136485
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.136485
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(887 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.242249
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.930816
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.241518
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.241518
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 890) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00334756
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00652218
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00333555
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00333555
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(890 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00340408
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00589861
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00342248
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00340408
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(890 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00362411
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0124979
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00361977
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00361977
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(890 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00345154
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0124568
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00349168
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00345154
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(890 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.078848
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120926
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0789211
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0120926
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(890 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0033331
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011997
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00333544
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0033331
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(890 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00333938
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120312
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00334692
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00333938
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00286939
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00690656
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00287305
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00286939
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00287561
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00598667
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00296042
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00287561
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00365451
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00718103
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00364526
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00364526
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00293168
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00679917
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00311175
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00293168
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00288283
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00695401
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00294876
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00288283
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00359086
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00693812
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00361497
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00359086
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00289929
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00701889
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00292702
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00289929
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0029399
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00690329
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00292907
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00292907
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00365257
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00693812
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00365829
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00365257
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00290825
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00693116
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00294381
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00290825
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00281681
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00691004
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00289042
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00281681
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 699) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00295286
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00687543
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00304759
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00295286
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(131072,1,4096,128) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(939 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0104803
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00845903
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0105146
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.00845903
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(32768,1:4,1024,32) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(939 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0105228
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00847946
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0105113
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.00847946
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1022) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.687104
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.563493
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.686811
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.563493
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1022) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.689591
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.563054
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.689865
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.563054
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1022 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.70539
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.564517
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.705829
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.564517
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1022 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.723803
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.564663
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.724992
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.564663
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1022 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.924233
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.579438
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.923794
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.579438
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1022 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.526921
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.560567
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.527506
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.526921
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1022 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.923502
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.579145
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.923648
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.579145
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1022 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.531749
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.559835
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.530286
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.530286
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1023 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.57199
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.563639
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.55984
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.563639
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1023 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.03483
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.560421
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.01728
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.560421
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1023 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.02752
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.561298
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.02971
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.561298
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1023 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.718117
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.570807
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.730405
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.570807
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1023 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.541403
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.559689
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.541842
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.541403
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1023 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.548718
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.559543
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.548133
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.548133
[06/10/2022-19:21:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.54784
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.553838
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.547547
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.547547
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.554423
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.553545
[06/10/2022-19:21:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.554569
[06/10/2022-19:21:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.553545
[06/10/2022-19:21:53] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 57.9289
[06/10/2022-19:21:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 4.11838
[06/10/2022-19:21:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 57.8822
[06/10/2022-19:21:54] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 4.11838
[06/10/2022-19:21:54] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.29141
[06/10/2022-19:21:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.89749
[06/10/2022-19:21:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.29638
[06/10/2022-19:21:54] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.29141
[06/10/2022-19:21:54] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.528823
[06/10/2022-19:21:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 4.28003
[06/10/2022-19:21:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.530578
[06/10/2022-19:21:54] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.528823
[06/10/2022-19:21:54] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 58.2208
[06/10/2022-19:21:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.99155
[06/10/2022-19:21:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 58.2483
[06/10/2022-19:21:55] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.99155
[06/10/2022-19:21:55] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.29273
[06/10/2022-19:21:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.94957
[06/10/2022-19:21:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.29461
[06/10/2022-19:21:55] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.29273
[06/10/2022-19:21:55] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.530432
[06/10/2022-19:21:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 4.30651
[06/10/2022-19:21:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.529701
[06/10/2022-19:21:56] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.529701
[06/10/2022-19:21:56] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 58.2034
[06/10/2022-19:21:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.95264
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 58.1381
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.95264
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.9481
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 4.02417
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.94678
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 2.94678
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.944567
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 4.14676
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.951136
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.944567
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1032 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.946176
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 4.23907
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.953198
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.946176
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.526482
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.550181
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.529701
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.526482
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.527067
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.559689
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.529993
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.527067
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.537015
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.55179
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.544183
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.537015
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.528091
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.55925
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.529408
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.528091
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.531749
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 13.8436
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.532919
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.531749
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.526775
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.55925
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.528238
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.526775
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.531602
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 13.839
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.526482
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.526482
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.530871
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.559259
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.530139
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.530139
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.529262
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.558665
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.52853
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.52853
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.137874
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142921
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.13685
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.13685
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134656
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143067
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134656
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134656
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134949
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.41489
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135232
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134949
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.138021
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.44049
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.138256
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.138021
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134656
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142702
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135303
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134656
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.135534
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.43859
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135973
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.135534
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134583
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.44722
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134882
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134583
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134656
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.14285
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134583
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.134583
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134729
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.41855
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134583
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.134583
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134802
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.41943
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134949
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134802
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134875
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143067
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135168
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134875
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_627_out_tensor -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.135168
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142921
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135168
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.135168
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(131072,1,4096,128) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32768,1:4,1024,32) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(131072,1,4096,128) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32768,1:4,1024,32) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(131072,1,4096,128) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32768,1:4,1024,32) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,16384,128,1) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,1,65536,512) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1:4,16384,128) -> Float(262144,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(262144,16384:32,128,1) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(8388608:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384,1,1) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(16384:32,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(16384,1,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(16384:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,128,1) -> Float(128:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(128,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(128:32,128,1) -> Float(1:4,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.165595
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144091
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.164571
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.144091
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.166619
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144823
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.166619
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.144823
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.378555
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144384
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.378149
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.144384
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.201582
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.148041
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.201289
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.148041
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.135168
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143799
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135022
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.135022
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.472795
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143653
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.47221
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.143653
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.204654
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.147895
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.205531
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.147895
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.135314
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142775
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135095
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.135095
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.479232
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143506
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.483035
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.143506
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.182565
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.147602
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.182711
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.147602
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.137216
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.14336
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.137289
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.137216
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1507) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.138825
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143227
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.138898
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.138825
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 1529) [Shuffle]_output) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00308484
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00589239
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0029979
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0029979
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 1529) [Shuffle]_output) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00298086
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00593445
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00299514
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00298086
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 1529) [Shuffle]_output) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00516669
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00798883
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00519053
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00516669
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.112064
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.09216
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.110373
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.09216
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.110885
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0925989
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.110958
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0925989
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.212846
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0922331
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.213138
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0922331
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.136942
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.096256
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.136777
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.096256
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0856503
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0920869
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0856503
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0856503
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.280137
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0915931
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.280146
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0915931
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.137582
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0959634
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.13824
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0959634
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0854309
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.09216
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.085504
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0854309
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.290962
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.091648
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.290816
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.091648
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107666
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0939886
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.107655
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0939886
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0879909
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0918674
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0879909
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0879909
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1508 -> <out>) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0888686
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0918674
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0889257
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0888686
[06/10/2022-19:21:57] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0883566
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.091136
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0885029
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0883566
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0896754
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0909166
[06/10/2022-19:21:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0896731
[06/10/2022-19:21:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0896731
[06/10/2022-19:21:57] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 9.00242
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.592457
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 9.01486
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.592457
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.202021
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.581047
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.201856
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.201856
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0857234
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.594944
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0857234
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0857234
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 9.06284
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.58485
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 9.0921
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.58485
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.20219
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.586021
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.201879
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.201879
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0856503
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.583534
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0857874
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0856503
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 9.06269
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.590117
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 9.07878
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.590117
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.463872
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.591579
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.464018
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.463872
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.152576
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.612352
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.152576
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.152576
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1523) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.152393
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.612352
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.152869
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.152393
[06/10/2022-19:21:58] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1523 -> <out>) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.202167
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.644681
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.202459
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.202167
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1523 -> <out>) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.202606
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.646144
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.202313
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.202313
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1523 -> <out>) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.464165
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.650825
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.464018
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.464018
[06/10/2022-19:21:58] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1524) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00324389
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00591433
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00325153
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00324389
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1524) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0251368
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00816762
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0233032
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.00816762
[06/10/2022-19:21:58] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1523 -> <out>) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0892457
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0906971
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0892343
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0892343
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1523 -> <out>) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 9.03753
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.576219
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 9.03314
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.576219
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1523 -> <out>) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0856503
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.58368
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0857234
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0856503
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1523 -> <out>) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 9.07586
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.590263
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 9.08741
[06/10/2022-19:21:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.590263
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1523 -> <out>) (Reformat)
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 9.09093
[06/10/2022-19:21:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.584704
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 9.0839
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.584704
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1523 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.152283
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.594944
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.152576
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.152283
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1524 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00300971
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00588069
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00308892
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00300971
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1524 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0234475
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00768265
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0235716
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.00768265
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1524 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00311543
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00775916
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00310668
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00310668
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1524 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0234893
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00768385
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0229042
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.00768385
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1524 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00320335
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00743748
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00319268
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00319268
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1524 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00298838
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00730423
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00302657
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00298838
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1525 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0876983
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0907703
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0877714
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0876983
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1525 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0861623
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.568027
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0858812
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0858812
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1525 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.15243
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.568027
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.152722
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.15243
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1528) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0028608
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0059275
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00292702
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0028608
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1528 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.003006
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00594414
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0030199
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.003006
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1528 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00304564
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00767904
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00304846
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00304564
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1528 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00301771
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00758376
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00303314
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00301771
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1528 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0227951
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00755406
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0225698
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.00755406
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1528 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00370309
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0075354
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00376421
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00370309
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1528 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00370098
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00752228
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00402717
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00370098
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00370391
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00763573
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00373568
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00370391
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00374388
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00776036
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00376818
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00374388
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00471255
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00742148
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00474013
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00471255
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0036684
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00752193
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00371306
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0036684
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00367859
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0074416
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00379934
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00367859
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00469014
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00743977
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00463867
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00463867
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00367965
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00756042
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00372114
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00367965
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00387188
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00757486
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00369805
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00369805
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00452086
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00743703
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00450286
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00450286
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00367637
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0075354
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00376325
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00367637
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00368692
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00697121
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00287845
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00287845
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 1509) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00294316
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00687478
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0029621
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00294316
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(327680,1,10240,320) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1577 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0320951
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0248686
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0320951
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0248686
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(81920,1:4,2560,80) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1577 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0323026
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0248442
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0322734
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0248442
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1660) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.453193
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.354597
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.453006
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.354597
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1660) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.456119
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.354597
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.456265
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.354597
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1660 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.458898
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.355767
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.462409
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.355767
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1660 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.468238
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.355035
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.484091
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.355035
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1660 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.607525
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.363959
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.607817
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.363959
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1660 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.331191
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.353719
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.331191
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.331191
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1660 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.610743
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.363374
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.609719
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.363374
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1660 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.330898
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.354743
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.330752
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.330752
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1661 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.928622
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.356206
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.913847
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.356206
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1661 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.23056
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.354158
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.21651
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.354158
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1661 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.21622
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.354304
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.21285
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.354304
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1661 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.423351
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.358546
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.423205
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.358546
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1661 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.338798
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.352256
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.339822
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.338798
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1661 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.344649
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.351378
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.344795
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.344649
[06/10/2022-19:21:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.343479
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.348014
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.342747
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.342747
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.347575
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.347429
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.347721
[06/10/2022-19:21:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.347429
[06/10/2022-19:21:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:21:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 36.144
[06/10/2022-19:21:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.38622
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 36.0966
[06/10/2022-19:22:00] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.38622
[06/10/2022-19:22:00] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.804425
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.46053
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.806181
[06/10/2022-19:22:00] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.804425
[06/10/2022-19:22:00] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.332946
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.75427
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.335141
[06/10/2022-19:22:00] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.332946
[06/10/2022-19:22:00] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 36.3538
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.34174
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 36.297
[06/10/2022-19:22:00] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.34174
[06/10/2022-19:22:00] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.806327
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.30458
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.805888
[06/10/2022-19:22:00] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.805888
[06/10/2022-19:22:00] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.33163
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.66547
[06/10/2022-19:22:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.331776
[06/10/2022-19:22:00] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.33163
[06/10/2022-19:22:00] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 36.3245
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.45175
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 36.3249
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.45175
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.84466
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.34803
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.84583
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.84466
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.595968
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.66708
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.597431
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.595968
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1670 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.596553
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.70365
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.596846
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.596553
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.330459
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.346697
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.330752
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.330459
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.3328
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.354011
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.331191
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.331191
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.331045
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.346258
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.333678
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.331045
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.331191
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.354158
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.330752
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.330752
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.330606
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.71834
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.331483
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.330606
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.330606
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.353719
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.33163
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.330606
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.3328
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 8.62091
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.330459
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.330459
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.331191
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.353719
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.331191
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.331191
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.332654
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.353573
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.332654
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.332654
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0863086
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0877714
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0861623
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0861623
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0855771
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0920869
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0857234
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0855771
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.085504
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.15698
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0855771
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.085504
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0868937
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0863086
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0866743
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0863086
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0857234
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0917943
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0857234
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0857234
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0855771
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.14499
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0857234
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0855771
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0857966
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.1387
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0857966
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0857966
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0857257
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0917211
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0857234
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0857234
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0857234
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.13797
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0856503
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0856503
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0856503
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.13914
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0857966
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0856503
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0856503
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0919406
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0856503
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0856503
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_1203_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0861623
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0918674
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0862354
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0861623
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1,10240,320) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(81920,1:4,2560,80) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1,10240,320) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(81920,1:4,2560,80) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1,10240,320) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(81920,1:4,2560,80) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1,10240,320) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(81920,1:4,2560,80) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1,10240,320) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(81920,1:4,2560,80) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,4096,64,1) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1,81920,1280) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1:4,20480,320) -> Float(163840,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(163840,4096:32,64,1) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(5242880:32,1280,1) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1280,1,1280,1280) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1:4,320,320) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40,1:32,1,1) -> Float(320,1:4,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096,1,1) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4096:32,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(4096,1,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(4096:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,320,1) -> Float(320:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(320,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(320:32,320,1) -> Float(1:4,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.110299
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0923817
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.110153
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0923817
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.110592
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.09216
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.110592
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.09216
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.210944
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0919954
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.210798
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0919954
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.13685
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0961829
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.13707
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0961829
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0856503
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0917943
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0856503
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0856503
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.28277
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0918674
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.28277
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0918674
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.137947
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0960366
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.139264
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0960366
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0856411
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0919406
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0855771
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0855771
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.290816
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0917943
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.290816
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0917943
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.10752
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.094208
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.107593
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.094208
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0879177
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.091648
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0879909
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0879177
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2441) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0888686
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0920137
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0887954
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0887954
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(524288,1,16384,512) -> Float(524288,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2442 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0458926
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0408034
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0457143
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0408034
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(131072,1:4,4096,128) -> Float(524288,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2442 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0461531
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.040704
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0461897
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.040704
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2568) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.191488
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.145554
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.191488
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.145554
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2568) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.195438
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144969
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.195584
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.144969
[06/10/2022-19:22:01] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2568 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.191195
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.145408
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.191342
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.145408
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2568 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.195291
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.145554
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.199095
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.145554
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,65536,2048) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2568 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.186661
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.148773
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.186953
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.148773
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,65536,2048) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2568 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134793
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144969
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134802
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134793
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,16384,512) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2568 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.188562
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.149211
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.188709
[06/10/2022-19:22:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.149211
[06/10/2022-19:22:01] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,16384,512) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2568 -> <out>) (Reformat)
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.135022
[06/10/2022-19:22:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.14453
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135022
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.135022
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,65536,2048) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,16384,512) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,65536,2048) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,65536,2048) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,16384,512) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,16384,512) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,65536,2048) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,16384,512) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2785) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0385097
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0390949
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0386194
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0385097
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2785) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.58561
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.258633
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.59526
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.258633
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,16384,128,1) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,16384,128) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,4096,32) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(65536,16384:32,128,1) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,128,1) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(128,1,128,128) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(128,1,1,1) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(128,1,1,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(128,1,128,128) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,1,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(32,1:4,32,32) -> Float(128,1,128,128) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,1,1) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(128,1,128,128) ***************
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(4,1:32,1,1) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:22:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.818176
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.823003
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.815397
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.815397
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.792869
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.841874
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.790382
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.790382
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.789358
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 20.8665
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.792869
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.789358
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.813495
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.823881
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.815397
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.813495
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.793893
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.839826
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.787602
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.787602
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.79755
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 20.9995
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.793746
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.793746
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.788626
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 20.8799
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.788187
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.788187
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.791991
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.840558
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.792283
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.791991
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.789504
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 20.9725
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.788334
[06/10/2022-19:22:02] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.788334
[06/10/2022-19:22:02] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.790089
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x00000000000003ea Time: 20.9913
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.795209
[06/10/2022-19:22:03] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.790089
[06/10/2022-19:22:03] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.789797
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.840411
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.791259
[06/10/2022-19:22:03] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.789797
[06/10/2022-19:22:03] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2335_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.79243
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.84085
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.797234
[06/10/2022-19:22:03] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.79243
[06/10/2022-19:22:03] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:03] [V] [TRT] *************** Autotuning Reformat: Float(12582912,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.821541
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.828279
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.821248
[06/10/2022-19:22:03] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.821248
[06/10/2022-19:22:03] [V] [TRT] *************** Autotuning Reformat: Float(12582912,768,1) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.83339
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.828855
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.834267
[06/10/2022-19:22:03] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.828855
[06/10/2022-19:22:03] [V] [TRT] *************** Autotuning Reformat: Float(12582912,768,1) -> Float(12582912:32,768,1) ***************
[06/10/2022-19:22:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x00000000000003e8 Time: 86.7066
[06/10/2022-19:22:03] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.36445
[06/10/2022-19:22:04] [V] [TRT] Tactic: 0x0000000000000000 Time: 86.7128
[06/10/2022-19:22:04] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 6.36445
[06/10/2022-19:22:04] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12582912,768,1) ***************
[06/10/2022-19:22:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:04] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.94692
[06/10/2022-19:22:04] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.16359
[06/10/2022-19:22:04] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.94399
[06/10/2022-19:22:04] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.94399
[06/10/2022-19:22:04] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:04] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.794039
[06/10/2022-19:22:04] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.38932
[06/10/2022-19:22:04] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.791845
[06/10/2022-19:22:04] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.791845
[06/10/2022-19:22:04] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12582912:32,768,1) ***************
[06/10/2022-19:22:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:05] [V] [TRT] Tactic: 0x00000000000003e8 Time: 87.1939
[06/10/2022-19:22:05] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.33081
[06/10/2022-19:22:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 87.1839
[06/10/2022-19:22:06] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 6.33081
[06/10/2022-19:22:06] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(12582912,768,1) ***************
[06/10/2022-19:22:06] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.94224
[06/10/2022-19:22:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.28253
[06/10/2022-19:22:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.94736
[06/10/2022-19:22:06] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.94224
[06/10/2022-19:22:06] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:06] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:06] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.795355
[06/10/2022-19:22:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.37835
[06/10/2022-19:22:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.792137
[06/10/2022-19:22:06] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.792137
[06/10/2022-19:22:06] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(12582912:32,768,1) ***************
[06/10/2022-19:22:06] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 87.1671
[06/10/2022-19:22:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.41785
[06/10/2022-19:22:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 87.1532
[06/10/2022-19:22:07] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 6.41785
[06/10/2022-19:22:07] [V] [TRT] *************** Autotuning Reformat: Float(12582912:32,768,1) -> Float(12582912,768,1) ***************
[06/10/2022-19:22:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:07] [V] [TRT] Tactic: 0x00000000000003e8 Time: 4.41373
[06/10/2022-19:22:07] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.35582
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.41446
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 4.41373
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(12582912:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.42499
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.23218
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.40859
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.40859
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(12582912:32,768,1) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2942 -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.41019
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 6.53078
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.42438
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.41019
[06/10/2022-19:22:08] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(12582912,1,98304,768) -> Float(12582912,16384,128,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2956 -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.64133
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.866011
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.63621
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.866011
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(3145728,1:4,24576,192) -> Float(12582912,16384,128,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2956 -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.63738
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.86645
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.63811
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.86645
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384:32,128,1) -> Float(12582912,16384,128,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2956 -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.12304
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.852699
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.12391
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.852699
[06/10/2022-19:22:08] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:08] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720,4096,64,1) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720,1,20480,320) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,5120,80) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(40960,4096:32,64,1) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:22:08] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1310720:32,320,1) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:08] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(320,1,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(320,1,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(80,1:4,80,80) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(320,1,320,320) ***************
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(10,1:32,1,1) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:22:08] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.199973
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.210213
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.199973
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.199973
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.200997
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.214309
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.200997
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.200997
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.200119
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 5.47196
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.199826
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.199826
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.204946
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.209637
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.204654
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.204654
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.200119
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.21387
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.199973
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.199973
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.20085
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 5.19768
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.200704
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.200704
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.20085
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 5.1848
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.19968
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.19968
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.200119
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.214455
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.200119
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.200119
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.200119
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 5.2107
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.199973
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.199973
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.199973
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 5.17588
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.199826
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.199826
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.199826
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.214162
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.199973
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.199826
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2303_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.201289
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.21387
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.201289
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.201289
[06/10/2022-19:22:08] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(3145728,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.209042
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.210651
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.209042
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.209042
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(3145728,768,1) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.211529
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.210944
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.211529
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.210944
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(3145728,768,1) -> Float(3145728:32,768,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 21.6427
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.41268
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 21.652
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.41268
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(3145728,768,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.481865
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.39717
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.480695
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.480695
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.200119
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.58471
[06/10/2022-19:22:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.200558
[06/10/2022-19:22:08] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.200119
[06/10/2022-19:22:08] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(3145728:32,768,1) ***************
[06/10/2022-19:22:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 21.7543
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.41663
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 21.7113
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.41663
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(3145728,768,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.479817
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.43755
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.481573
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.479817
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.200535
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.60168
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.200997
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.200535
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(3145728:32,768,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 21.7626
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.40668
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 21.7945
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.40668
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(3145728:32,768,1) -> Float(3145728,768,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.10958
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.42175
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.11045
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.10958
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(3145728:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.359424
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.45905
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.359707
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.359424
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(3145728:32,768,1) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2905 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.360741
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.54536
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.360155
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.360155
[06/10/2022-19:22:09] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(3145728,1,49152,768) -> Float(3145728,4096,64,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2919 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.318757
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.221038
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.319634
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.221038
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(786432,1:4,12288,192) -> Float(3145728,4096,64,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2919 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.32373
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.220599
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.323584
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.220599
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(98304,4096:32,64,1) -> Float(3145728,4096,64,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2919 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.260242
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.218112
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.260681
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.218112
[06/10/2022-19:22:09] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:09] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,65536,2048) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,65536,2048) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,16384,512) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,16384,512) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:09] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(1,512,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 3191) [Shuffle]_output) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0031833
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.007424
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00382881
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0031833
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(1:4,512,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 3191) [Shuffle]_output) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00384192
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.007424
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00381185
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00381185
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(512:32,512,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 3191) [Shuffle]_output) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00687521
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00862225
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00686999
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00686999
[06/10/2022-19:22:09] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(1,512,1) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(1:4,512,1) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(512:32,512,1) ***************
[06/10/2022-19:22:09] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1024,32,1) -> Float(65536,1024:32,32,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2813 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.387511
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.145115
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.350062
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.145115
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,65536,2048) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,65536,2048) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,65536,2048) -> Float(65536,1024:32,32,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2813 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.47499
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.14453
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.475136
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.14453
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,16384,512) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,16384,512) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(524288,1:4,16384,512) -> Float(65536,1024:32,32,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2813 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.475136
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.14453
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.466213
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.14453
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(65536,1024:32,32,1) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2813 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.157257
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.146263
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.157111
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.146263
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(65536,1024:32,32,1) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2813 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.137801
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144384
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.137728
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.137728
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(65536,1024:32,32,1) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2813 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.138533
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143799
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.138832
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.138533
[06/10/2022-19:22:09] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,2048,1) -> Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.140288
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142336
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.140434
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.140288
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,2048,1) -> Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.142117
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142409
[06/10/2022-19:22:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.14197
[06/10/2022-19:22:09] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.14197
[06/10/2022-19:22:09] [V] [TRT] *************** Autotuning Reformat: Float(2097152,2048,1) -> Float(2097152:32,2048,1) ***************
[06/10/2022-19:22:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 14.4232
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.944859
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.4305
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.944859
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,2048,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.320805
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.942811
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.320805
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.320805
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134802
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.964462
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134802
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134802
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,2048,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 14.4848
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.940763
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.4754
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.940763
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,2048,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.320805
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.951589
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.321097
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.320805
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134729
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.985966
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134745
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134729
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,2048,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 14.4846
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.949979
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.5139
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.949979
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,2048,1) -> Float(2097152,2048,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.74123
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.942683
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.74123
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.74123
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,2048,1) -> Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.241637
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.00571
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.24181
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.241637
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,2048,1) -> Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2822 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.241371
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.01712
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.241664
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.241371
[06/10/2022-19:22:10] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2097152,2048,1) -> Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2097152,2048,1) -> Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2097152,2048,1) -> Float(2097152:32,2048,1) ***************
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,2048,1) ***************
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152:32,2048,1) ***************
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152,2048,1) ***************
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(2097152:32,2048,1) ***************
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,2048,1) -> Float(2097152,2048,1) ***************
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,2048,1) -> Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2097152:32,2048,1) -> Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:10] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2048,1,1,1) -> Float(2048,1,2048,2048) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.135095
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142043
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2048,1,1,1) -> Float(512,1:4,512,512) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144677
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2048,1,2048,2048) -> Float(2048,1,1,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.141897
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135241
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(2048,1,2048,2048) -> Float(512,1:4,512,512) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144384
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(512,1:4,512,512) -> Float(2048,1,1,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.5505
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135019
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(512,1:4,512,512) -> Float(2048,1,2048,2048) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134953
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.143799
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134802
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.134802
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(64,1:32,1,1) -> Float(2048,1,1,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134875
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.52256
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134729
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.134729
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(64,1:32,1,1) -> Float(2048,1,2048,2048) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134793
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144091
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134729
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.134729
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(64,1:32,1,1) -> Float(512,1:4,512,512) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(reshape_before_MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.135826
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144238
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.135899
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.135826
[06/10/2022-19:22:10] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0364983
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0395634
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.036352
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.036352
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0367909
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0388389
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0367177
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0367177
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(16,1:32,1,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0365749
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.884297
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0366446
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0365749
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0360594
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0393509
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0365349
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0360594
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0367109
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0387257
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0366446
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0366446
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(16,1:32,1,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0365714
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.876251
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0364617
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0364617
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0366137
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.859575
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0364617
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0364617
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0366446
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0387269
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0366137
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0366137
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(16,1:32,1,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0366834
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.857527
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0366446
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0366446
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0365326
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.85109
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0364617
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0364617
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0365349
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0387291
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0365337
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0365337
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2239_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0368274
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0385097
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0368274
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0368274
[06/10/2022-19:22:10] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2785 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0380411
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0391314
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0379977
[06/10/2022-19:22:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0379977
[06/10/2022-19:22:10] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2785 -> <out>) (Reformat)
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.59175
[06/10/2022-19:22:10] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.24459
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.61062
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.24459
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2785 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0831634
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.23947
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0830903
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0830903
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2785 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.6431
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.23947
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.63213
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.23947
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2785 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.187099
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.239762
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.187387
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.187099
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2785 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.063293
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.23947
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0630979
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0630979
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2833 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0832343
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.242249
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0831634
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0831634
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2833 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0364251
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.241079
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0364983
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0364251
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2833 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.62672
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.244005
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.63096
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.244005
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2834) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0833097
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.244297
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0831634
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0831634
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2834) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.63068
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.239447
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.63067
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.239447
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2834) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.187099
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.242103
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.187392
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.187099
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2834) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0632411
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.241225
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0630491
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0630491
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2835) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00292198
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00597219
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00292077
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00292077
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1024:32,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2835) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00802946
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00745417
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0077529
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.00745417
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2835 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00286482
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00599581
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00291109
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00286482
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1024:32,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2835 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00777383
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00718857
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00779164
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.00718857
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1024,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2835 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00287909
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00731863
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00287634
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00287634
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1024:32,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2835 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00772211
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00707026
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00763549
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.00707026
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024:32,1,1) -> Float(1024,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2835 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00286473
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.007168
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00287662
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00286473
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2835 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00292599
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00707527
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00291928
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00291928
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2836) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0372297
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.038656
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0371566
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0371566
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2836) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0361771
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.22645
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0361326
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0361326
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2836) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0630004
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.226304
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0629516
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0629516
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2836 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0371566
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0386606
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0371931
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0371566
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2836 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0366811
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.226304
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0362423
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0362423
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2836 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0630339
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.22645
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0630979
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0630339
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2839) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00369348
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00769179
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00364903
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00364903
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1024:32,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2839 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00363863
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00780656
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00401409
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00363863
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1024:32,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1024,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2839 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00362469
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00766364
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00369442
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00362469
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2839 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00363691
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00760253
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00368891
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00363691
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) -> Float(1024:32,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2839 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00756042
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00740937
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00753203
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.00740937
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1024,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2839 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00364114
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0076978
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00372466
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00364114
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1024:32,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024:32,1,1) -> Float(1024,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024:32,1,1) -> Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2839 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00365714
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00762225
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00372501
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00365714
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1024:32,1,1) -> Float(1:4,E0,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(1,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00363783
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00777383
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00376072
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00363783
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(1:4,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00366758
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00780463
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00375525
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00366758
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(512:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00568985
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00777624
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00569952
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00568985
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,512,1) -> Float(512,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00364629
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00775988
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00373181
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00364629
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,512,1) -> Float(1:4,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00364251
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00759579
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00374728
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00364251
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,512,1) -> Float(512:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00568879
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00748983
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00568791
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00568791
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,512,1) -> Float(512,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00286647
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00690155
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0028971
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00286647
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,512,1) -> Float(1,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00283007
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00690112
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00288923
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00283007
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,512,1) -> Float(512:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00526024
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00693007
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00525077
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00525077
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512:32,512,1) -> Float(512,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00283716
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00689459
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00288283
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00283716
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512:32,512,1) -> Float(1,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00287963
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00692071
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00289655
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00287963
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512:32,512,1) -> Float(1:4,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3188) [Shuffle]_output -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00294213
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00691723
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00301352
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00294213
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(1,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(1:4,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512,512,1) -> Float(512:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,512,1) -> Float(512,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,512,1) -> Float(1:4,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,512,1) -> Float(512:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,512,1) -> Float(512,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,512,1) -> Float(1,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,512,1) -> Float(512:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512:32,512,1) -> Float(512,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512:32,512,1) -> Float(1,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512:32,512,1) -> Float(1:4,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,1024,32,1) -> Float(524288,1,16384,512) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2853 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0442183
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.038912
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0444709
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.038912
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,1024,32,1) -> Float(131072,1:4,4096,128) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2853 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0449097
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0388834
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0449463
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0388834
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,1024,32,1) -> Float(16384,1024:32,32,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2853 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.083168
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0391314
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0832366
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0391314
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,1,16384,512) -> Float(524288,1024,32,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,1,16384,512) -> Float(131072,1:4,4096,128) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2853 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.036352
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0388389
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0361326
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0361326
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,1,16384,512) -> Float(16384,1024:32,32,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2853 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107081
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0387291
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.107154
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0387291
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(131072,1:4,4096,128) -> Float(524288,1024,32,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(131072,1:4,4096,128) -> Float(524288,1,16384,512) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2853 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0361646
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0388286
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0362057
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0361646
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(131072,1:4,4096,128) -> Float(16384,1024:32,32,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2853 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107154
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0387017
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.109129
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0387017
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(16384,1024:32,32,1) -> Float(524288,1024,32,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2853 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0418
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0399669
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0418377
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0399669
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(16384,1024:32,32,1) -> Float(524288,1,16384,512) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2853 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.037224
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0391326
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0372629
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.037224
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(16384,1024:32,32,1) -> Float(131072,1:4,4096,128) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2853 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0374183
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0392777
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0373737
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0373737
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(524288:32,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(524288:32,512,1) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(512,1,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0536869
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0563688
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0537905
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0536869
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0528579
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.05792
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0530042
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0528579
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0533943
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.23582
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0533455
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0533455
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0538423
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.056515
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0532968
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0532968
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0529524
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0581806
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0529067
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0529067
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0529554
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.27283
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0528091
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0528091
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0528091
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.27312
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0530575
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0528091
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0529128
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0579779
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0529981
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0529128
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0531017
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.2977
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0531505
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0531017
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0529554
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.29814
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.053053
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0529554
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.053056
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0582705
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0530042
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0530042
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2271_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0535893
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0583192
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0535817
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0535817
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(786432,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0543695
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.056899
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0544183
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0543695
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(786432,768,1) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0551497
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0568564
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0551497
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0551497
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(786432,768,1) -> Float(786432:32,768,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 5.40292
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.361033
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.41316
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.361033
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(786432,768,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.122807
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.360741
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.122734
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.122734
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0528091
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.359278
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0528091
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0528091
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(786432:32,768,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 5.43568
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.363374
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.45295
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.363374
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(786432,768,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.122807
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.357079
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.123026
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.122807
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.052992
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.355767
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0529189
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0529189
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(786432:32,768,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 5.4408
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.365861
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.44987
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.365861
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(786432:32,768,1) -> Float(786432,768,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.279259
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.357083
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.279406
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.279259
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(786432:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0931109
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.355767
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0932571
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0931109
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(786432:32,768,1) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2868 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0928914
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.36235
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0929646
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0928914
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(786432,1,24576,768) -> Float(786432,1024,32,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2882 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0705585
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.060032
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0705097
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.060032
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(196608,1:4,6144,192) -> Float(786432,1024,32,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2882 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0712411
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0602209
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0714606
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0602209
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(24576,1024:32,32,1) -> Float(786432,1024,32,1) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2882 -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0611474
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0592945
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0621227
[06/10/2022-19:22:11] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0592945
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304,65536,256,1) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304,1,16384,64) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,4096,16) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(131072,65536:32,256,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,64,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304,64,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(4194304:32,64,1) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(64,1,64,64) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(64,1,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(64,1,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(64,1,64,64) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(64,1,1,1) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(64,1,64,64) ***************
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:22:11] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:11] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.2474
[06/10/2022-19:22:11] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.27226
[06/10/2022-19:22:12] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.25427
[06/10/2022-19:22:12] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 3.2474
[06/10/2022-19:22:12] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:12] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:12] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.21829
[06/10/2022-19:22:12] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.33824
[06/10/2022-19:22:12] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.212
[06/10/2022-19:22:12] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.212
[06/10/2022-19:22:12] [V] [TRT] *************** Autotuning Reformat: Float(768,1,1,1) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:12] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:12] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.19912
[06/10/2022-19:22:12] [V] [TRT] Tactic: 0x00000000000003ea Time: 84.5545
[06/10/2022-19:22:12] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.21902
[06/10/2022-19:22:12] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 3.19912
[06/10/2022-19:22:12] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:12] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:12] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.25252
[06/10/2022-19:22:12] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.27578
[06/10/2022-19:22:12] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.25208
[06/10/2022-19:22:12] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.25208
[06/10/2022-19:22:12] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:12] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:12] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.22267
[06/10/2022-19:22:13] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.34143
[06/10/2022-19:22:13] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.21799
[06/10/2022-19:22:13] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.21799
[06/10/2022-19:22:13] [V] [TRT] *************** Autotuning Reformat: Float(768,1,768,768) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:13] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:13] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.23174
[06/10/2022-19:22:13] [V] [TRT] Tactic: 0x00000000000003ea Time: 83.5252
[06/10/2022-19:22:13] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.22516
[06/10/2022-19:22:13] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.22516
[06/10/2022-19:22:13] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:13] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:13] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.23174
[06/10/2022-19:22:14] [V] [TRT] Tactic: 0x00000000000003ea Time: 83.5572
[06/10/2022-19:22:14] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.22662
[06/10/2022-19:22:14] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.22662
[06/10/2022-19:22:14] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:14] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.21726
[06/10/2022-19:22:14] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.34043
[06/10/2022-19:22:14] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.22209
[06/10/2022-19:22:14] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 3.21726
[06/10/2022-19:22:14] [V] [TRT] *************** Autotuning Reformat: Float(192,1:4,192,192) -> Float(24,1:32,1,1) ***************
[06/10/2022-19:22:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:14] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.14558
[06/10/2022-19:22:15] [V] [TRT] Tactic: 0x00000000000003ea Time: 83.5253
[06/10/2022-19:22:15] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.16357
[06/10/2022-19:22:15] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 3.14558
[06/10/2022-19:22:15] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,1,1) ***************
[06/10/2022-19:22:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:15] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.19693
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x00000000000003ea Time: 83.5574
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.22355
[06/10/2022-19:22:16] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 3.19693
[06/10/2022-19:22:16] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(768,1,768,768) ***************
[06/10/2022-19:22:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.21009
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.34014
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.23013
[06/10/2022-19:22:16] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 3.21009
[06/10/2022-19:22:16] [V] [TRT] *************** Autotuning Reformat: Float(24,1:32,1,1) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:22:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(MatMul_2367_out_tensor -> <out>) (Reformat)
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.17074
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.3397
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.15875
[06/10/2022-19:22:16] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.15875
[06/10/2022-19:22:16] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:16] [V] [TRT] *************** Autotuning Reformat: Float(50331648,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.27241
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.27914
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.27212
[06/10/2022-19:22:16] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.27212
[06/10/2022-19:22:16] [V] [TRT] *************** Autotuning Reformat: Float(50331648,768,1) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.31571
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.27812
[06/10/2022-19:22:16] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.32083
[06/10/2022-19:22:16] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.27812
[06/10/2022-19:22:16] [V] [TRT] *************** Autotuning Reformat: Float(50331648,768,1) -> Float(50331648:32,768,1) ***************
[06/10/2022-19:22:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:19] [V] [TRT] Tactic: 0x00000000000003e8 Time: 346.473
[06/10/2022-19:22:19] [V] [TRT] Tactic: 0x00000000000003ea Time: 27.1866
[06/10/2022-19:22:22] [V] [TRT] Tactic: 0x0000000000000000 Time: 346.507
[06/10/2022-19:22:22] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 27.1866
[06/10/2022-19:22:22] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50331648,768,1) ***************
[06/10/2022-19:22:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:22] [V] [TRT] Tactic: 0x00000000000003e8 Time: 7.87079
[06/10/2022-19:22:22] [V] [TRT] Tactic: 0x00000000000003ea Time: 27.2368
[06/10/2022-19:22:22] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.86417
[06/10/2022-19:22:22] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 7.86417
[06/10/2022-19:22:22] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:22] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.24462
[06/10/2022-19:22:22] [V] [TRT] Tactic: 0x00000000000003ea Time: 26.3964
[06/10/2022-19:22:22] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.16518
[06/10/2022-19:22:22] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.16518
[06/10/2022-19:22:22] [V] [TRT] *************** Autotuning Reformat: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(50331648:32,768,1) ***************
[06/10/2022-19:22:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:25] [V] [TRT] Tactic: 0x00000000000003e8 Time: 348.55
[06/10/2022-19:22:26] [V] [TRT] Tactic: 0x00000000000003ea Time: 28.0484
[06/10/2022-19:22:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 348.413
[06/10/2022-19:22:28] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 28.0484
[06/10/2022-19:22:28] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(50331648,768,1) ***************
[06/10/2022-19:22:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:28] [V] [TRT] Tactic: 0x00000000000003e8 Time: 7.86783
[06/10/2022-19:22:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 27.4634
[06/10/2022-19:22:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.86973
[06/10/2022-19:22:29] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 7.86783
[06/10/2022-19:22:29] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:29] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.22575
[06/10/2022-19:22:29] [V] [TRT] Tactic: 0x00000000000003ea Time: 26.5595
[06/10/2022-19:22:29] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.15553
[06/10/2022-19:22:29] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.15553
[06/10/2022-19:22:29] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(50331648:32,768,1) ***************
[06/10/2022-19:22:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:32] [V] [TRT] Tactic: 0x00000000000003e8 Time: 348.238
[06/10/2022-19:22:32] [V] [TRT] Tactic: 0x00000000000003ea Time: 28.3859
[06/10/2022-19:22:35] [V] [TRT] Tactic: 0x0000000000000000 Time: 348.046
[06/10/2022-19:22:35] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 28.3859
[06/10/2022-19:22:35] [V] [TRT] *************** Autotuning Reformat: Float(50331648:32,768,1) -> Float(50331648,768,1) ***************
[06/10/2022-19:22:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:35] [V] [TRT] Tactic: 0x00000000000003e8 Time: 17.6228
[06/10/2022-19:22:35] [V] [TRT] Tactic: 0x00000000000003ea Time: 28.2001
[06/10/2022-19:22:35] [V] [TRT] Tactic: 0x0000000000000000 Time: 17.6236
[06/10/2022-19:22:35] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 17.6228
[06/10/2022-19:22:35] [V] [TRT] *************** Autotuning Reformat: Float(50331648:32,768,1) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:22:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:35] [V] [TRT] Tactic: 0x00000000000003e8 Time: 5.6282
[06/10/2022-19:22:36] [V] [TRT] Tactic: 0x00000000000003ea Time: 26.9893
[06/10/2022-19:22:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.63712
[06/10/2022-19:22:36] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 5.6282
[06/10/2022-19:22:36] [V] [TRT] *************** Autotuning Reformat: Float(50331648:32,768,1) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2979 -> <out>) (Reformat)
[06/10/2022-19:22:36] [V] [TRT] Tactic: 0x00000000000003e8 Time: 5.61942
[06/10/2022-19:22:36] [V] [TRT] Tactic: 0x00000000000003ea Time: 27.0345
[06/10/2022-19:22:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.60976
[06/10/2022-19:22:36] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 5.60976
[06/10/2022-19:22:36] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:36] [V] [TRT] *************** Autotuning Reformat: Float(201326592,65536,256,1) -> Float(201326592,1,786432,3072) ***************
[06/10/2022-19:22:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:36] [V] [TRT] Tactic: 0x00000000000003e8 Time: 11.9511
[06/10/2022-19:22:36] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.44517
[06/10/2022-19:22:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.6704
[06/10/2022-19:22:36] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.44517
[06/10/2022-19:22:36] [V] [TRT] *************** Autotuning Reformat: Float(201326592,65536,256,1) -> Float(50331648,1:4,196608,768) ***************
[06/10/2022-19:22:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:36] [V] [TRT] Tactic: 0x00000000000003e8 Time: 11.6498
[06/10/2022-19:22:36] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.44605
[06/10/2022-19:22:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.8095
[06/10/2022-19:22:37] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.44605
[06/10/2022-19:22:37] [V] [TRT] *************** Autotuning Reformat: Float(201326592,65536,256,1) -> Float(6291456,65536:32,256,1) ***************
[06/10/2022-19:22:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 28.7585
[06/10/2022-19:22:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.35299
[06/10/2022-19:22:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 28.7841
[06/10/2022-19:22:37] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.35299
[06/10/2022-19:22:37] [V] [TRT] *************** Autotuning Reformat: Float(201326592,1,786432,3072) -> Float(201326592,65536,256,1) ***************
[06/10/2022-19:22:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:37] [V] [TRT] Tactic: 0x00000000000003e8 Time: 25.6424
[06/10/2022-19:22:37] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.4598
[06/10/2022-19:22:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 25.6309
[06/10/2022-19:22:38] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.4598
[06/10/2022-19:22:38] [V] [TRT] *************** Autotuning Reformat: Float(201326592,1,786432,3072) -> Float(50331648,1:4,196608,768) ***************
[06/10/2022-19:22:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.32771
[06/10/2022-19:22:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.43157
[06/10/2022-19:22:38] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.32624
[06/10/2022-19:22:38] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.32624
[06/10/2022-19:22:38] [V] [TRT] *************** Autotuning Reformat: Float(201326592,1,786432,3072) -> Float(6291456,65536:32,256,1) ***************
[06/10/2022-19:22:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:38] [V] [TRT] Tactic: 0x00000000000003e8 Time: 68.4459
[06/10/2022-19:22:38] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.34367
[06/10/2022-19:22:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 68.4478
[06/10/2022-19:22:39] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.34367
[06/10/2022-19:22:39] [V] [TRT] *************** Autotuning Reformat: Float(50331648,1:4,196608,768) -> Float(201326592,65536,256,1) ***************
[06/10/2022-19:22:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 25.5685
[06/10/2022-19:22:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.46317
[06/10/2022-19:22:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 25.5801
[06/10/2022-19:22:39] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.46317
[06/10/2022-19:22:39] [V] [TRT] *************** Autotuning Reformat: Float(50331648,1:4,196608,768) -> Float(201326592,1,786432,3072) ***************
[06/10/2022-19:22:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:39] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.32741
[06/10/2022-19:22:39] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.43069
[06/10/2022-19:22:40] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.32069
[06/10/2022-19:22:40] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.32069
[06/10/2022-19:22:40] [V] [TRT] *************** Autotuning Reformat: Float(50331648,1:4,196608,768) -> Float(6291456,65536:32,256,1) ***************
[06/10/2022-19:22:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:40] [V] [TRT] Tactic: 0x00000000000003e8 Time: 68.4693
[06/10/2022-19:22:40] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.34482
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 68.4611
[06/10/2022-19:22:41] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.34482
[06/10/2022-19:22:41] [V] [TRT] *************** Autotuning Reformat: Float(6291456,65536:32,256,1) -> Float(201326592,65536,256,1) ***************
[06/10/2022-19:22:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 14.1384
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.40246
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.1401
[06/10/2022-19:22:41] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.40246
[06/10/2022-19:22:41] [V] [TRT] *************** Autotuning Reformat: Float(6291456,65536:32,256,1) -> Float(201326592,1,786432,3072) ***************
[06/10/2022-19:22:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.40656
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.41153
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.4073
[06/10/2022-19:22:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 3.40656
[06/10/2022-19:22:41] [V] [TRT] *************** Autotuning Reformat: Float(6291456,65536:32,256,1) -> Float(50331648,1:4,196608,768) ***************
[06/10/2022-19:22:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 2993) (Reformat)
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.37291
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.41065
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.38593
[06/10/2022-19:22:41] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 3.37291
[06/10/2022-19:22:41] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:41] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(201326592,65536,256,1) ***************
[06/10/2022-19:22:41] [V] [TRT] --------------- Timing Runner: 2893 copy (Reformat)
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.27168
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.27051
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.2723
[06/10/2022-19:22:41] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.27051
[06/10/2022-19:22:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:22:41] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(201326592,1,786432,3072) ***************
[06/10/2022-19:22:41] [V] [TRT] --------------- Timing Runner: 2893 copy (Reformat)
[06/10/2022-19:22:41] [V] [TRT] Tactic: 0x00000000000003e8 Time: 11.5795
[06/10/2022-19:22:42] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.44298
[06/10/2022-19:22:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.746
[06/10/2022-19:22:42] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.44298
[06/10/2022-19:22:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:22:42] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(50331648,1:4,196608,768) ***************
[06/10/2022-19:22:42] [V] [TRT] --------------- Timing Runner: 2893 copy (Reformat)
[06/10/2022-19:22:42] [V] [TRT] Tactic: 0x00000000000003e8 Time: 11.8407
[06/10/2022-19:22:42] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.44298
[06/10/2022-19:22:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.7795
[06/10/2022-19:22:42] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.44298
[06/10/2022-19:22:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:22:42] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(6291456,65536:32,256,1) ***************
[06/10/2022-19:22:42] [V] [TRT] --------------- Timing Runner: 2893 copy (Reformat)
[06/10/2022-19:22:42] [V] [TRT] Tactic: 0x00000000000003e8 Time: 28.7672
[06/10/2022-19:22:42] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.35345
[06/10/2022-19:22:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 28.8101
[06/10/2022-19:22:42] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.35345
[06/10/2022-19:22:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:22:42] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:42] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(201326592,65536,256,1) ***************
[06/10/2022-19:22:42] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(201326592,1,786432,3072) ***************
[06/10/2022-19:22:42] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(50331648,1:4,196608,768) ***************
[06/10/2022-19:22:42] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(6291456,65536:32,256,1) ***************
[06/10/2022-19:22:42] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:42] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(201326592,65536,256,1) ***************
[06/10/2022-19:22:42] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(201326592,1,786432,3072) ***************
[06/10/2022-19:22:42] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(50331648,1:4,196608,768) ***************
[06/10/2022-19:22:42] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(6291456,65536:32,256,1) ***************
[06/10/2022-19:22:42] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:42] [V] [TRT] *************** Autotuning Reformat: Float(201326592,65536,256,1) -> Float(201326592,1,786432,3072) ***************
[06/10/2022-19:22:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2994 -> <out>) (Reformat)
[06/10/2022-19:22:43] [V] [TRT] Tactic: 0x00000000000003e8 Time: 48.627
[06/10/2022-19:22:43] [V] [TRT] Tactic: 0x00000000000003ea Time: 13.4437
[06/10/2022-19:22:43] [V] [TRT] Tactic: 0x0000000000000000 Time: 48.6366
[06/10/2022-19:22:43] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 13.4437
[06/10/2022-19:22:43] [V] [TRT] *************** Autotuning Reformat: Float(201326592,65536,256,1) -> Float(50331648,1:4,196608,768) ***************
[06/10/2022-19:22:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2994 -> <out>) (Reformat)
[06/10/2022-19:22:44] [V] [TRT] Tactic: 0x00000000000003e8 Time: 49.2294
[06/10/2022-19:22:44] [V] [TRT] Tactic: 0x00000000000003ea Time: 13.445
[06/10/2022-19:22:44] [V] [TRT] Tactic: 0x0000000000000000 Time: 49.0572
[06/10/2022-19:22:44] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 13.445
[06/10/2022-19:22:44] [V] [TRT] *************** Autotuning Reformat: Float(201326592,1,786432,3072) -> Float(201326592,65536,256,1) ***************
[06/10/2022-19:22:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2994 -> <out>) (Reformat)
[06/10/2022-19:22:45] [V] [TRT] Tactic: 0x00000000000003e8 Time: 116.845
[06/10/2022-19:22:45] [V] [TRT] Tactic: 0x00000000000003ea Time: 13.9987
[06/10/2022-19:22:46] [V] [TRT] Tactic: 0x0000000000000000 Time: 116.828
[06/10/2022-19:22:46] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 13.9987
[06/10/2022-19:22:46] [V] [TRT] *************** Autotuning Reformat: Float(201326592,1,786432,3072) -> Float(50331648,1:4,196608,768) ***************
[06/10/2022-19:22:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2994 -> <out>) (Reformat)
[06/10/2022-19:22:47] [V] [TRT] Tactic: 0x00000000000003e8 Time: 12.7655
[06/10/2022-19:22:47] [V] [TRT] Tactic: 0x00000000000003ea Time: 13.3493
[06/10/2022-19:22:47] [V] [TRT] Tactic: 0x0000000000000000 Time: 12.8168
[06/10/2022-19:22:47] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 12.7655
[06/10/2022-19:22:47] [V] [TRT] *************** Autotuning Reformat: Float(50331648,1:4,196608,768) -> Float(201326592,65536,256,1) ***************
[06/10/2022-19:22:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2994 -> <out>) (Reformat)
[06/10/2022-19:22:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 116.563
[06/10/2022-19:22:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 13.9976
[06/10/2022-19:22:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 116.573
[06/10/2022-19:22:49] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 13.9976
[06/10/2022-19:22:49] [V] [TRT] *************** Autotuning Reformat: Float(50331648,1:4,196608,768) -> Float(201326592,1,786432,3072) ***************
[06/10/2022-19:22:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2994 -> <out>) (Reformat)
[06/10/2022-19:22:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 12.7798
[06/10/2022-19:22:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 13.3427
[06/10/2022-19:22:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 12.7358
[06/10/2022-19:22:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 12.7358
[06/10/2022-19:22:49] [V] [TRT] *************** Autotuning Reformat: Float(6291456,65536:32,256,1) -> Float(201326592,65536,256,1) ***************
[06/10/2022-19:22:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2994 -> <out>) (Reformat)
[06/10/2022-19:22:50] [V] [TRT] Tactic: 0x00000000000003e8 Time: 56.546
[06/10/2022-19:22:50] [V] [TRT] Tactic: 0x00000000000003ea Time: 13.5752
[06/10/2022-19:22:50] [V] [TRT] Tactic: 0x0000000000000000 Time: 56.5134
[06/10/2022-19:22:50] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 13.5752
[06/10/2022-19:22:50] [V] [TRT] *************** Autotuning Reformat: Float(6291456,65536:32,256,1) -> Float(201326592,1,786432,3072) ***************
[06/10/2022-19:22:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2994 -> <out>) (Reformat)
[06/10/2022-19:22:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 13.0058
[06/10/2022-19:22:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 13.2511
[06/10/2022-19:22:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 13.0459
[06/10/2022-19:22:51] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 13.0058
[06/10/2022-19:22:51] [V] [TRT] *************** Autotuning Reformat: Float(6291456,65536:32,256,1) -> Float(50331648,1:4,196608,768) ***************
[06/10/2022-19:22:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2994 -> <out>) (Reformat)
[06/10/2022-19:22:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 13.6347
[06/10/2022-19:22:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 13.2523
[06/10/2022-19:22:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 13.4782
[06/10/2022-19:22:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 13.2523
[06/10/2022-19:22:51] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:51] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(50331648,1,196608,768) ***************
[06/10/2022-19:22:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2997 -> <out>) (Reformat)
[06/10/2022-19:22:51] [V] [TRT] Tactic: 0x00000000000003e8 Time: 12.5348
[06/10/2022-19:22:51] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.35945
[06/10/2022-19:22:51] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.82
[06/10/2022-19:22:51] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.35945
[06/10/2022-19:22:51] [V] [TRT] *************** Autotuning Reformat: Float(50331648,65536,256,1) -> Float(12582912,1:4,49152,192) ***************
[06/10/2022-19:22:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2997 -> <out>) (Reformat)
[06/10/2022-19:22:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 11.8252
[06/10/2022-19:22:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.36004
[06/10/2022-19:22:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 12.0242
[06/10/2022-19:22:52] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.36004
[06/10/2022-19:22:52] [V] [TRT] *************** Autotuning Reformat: Float(50331648,1,196608,768) -> Float(50331648,65536,256,1) ***************
[06/10/2022-19:22:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2997 -> <out>) (Reformat)
[06/10/2022-19:22:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 25.6437
[06/10/2022-19:22:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.46214
[06/10/2022-19:22:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 25.6146
[06/10/2022-19:22:52] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.46214
[06/10/2022-19:22:52] [V] [TRT] *************** Autotuning Reformat: Float(50331648,1,196608,768) -> Float(12582912,1:4,49152,192) ***************
[06/10/2022-19:22:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2997 -> <out>) (Reformat)
[06/10/2022-19:22:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.19971
[06/10/2022-19:22:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.34055
[06/10/2022-19:22:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.16123
[06/10/2022-19:22:52] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.16123
[06/10/2022-19:22:52] [V] [TRT] *************** Autotuning Reformat: Float(12582912,1:4,49152,192) -> Float(50331648,65536,256,1) ***************
[06/10/2022-19:22:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2997 -> <out>) (Reformat)
[06/10/2022-19:22:52] [V] [TRT] Tactic: 0x00000000000003e8 Time: 25.5661
[06/10/2022-19:22:52] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.46463
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 25.5959
[06/10/2022-19:22:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.46463
[06/10/2022-19:22:53] [V] [TRT] *************** Autotuning Reformat: Float(12582912,1:4,49152,192) -> Float(50331648,1,196608,768) ***************
[06/10/2022-19:22:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2997 -> <out>) (Reformat)
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.23174
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.33839
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.16211
[06/10/2022-19:22:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.16211
[06/10/2022-19:22:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:53] [V] [TRT] *************** Autotuning Reformat: Float(1245184,1,4864,19) -> Float(1245184,65536,256,1) ***************
[06/10/2022-19:22:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2998 -> <out>) (Reformat)
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.17013
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.139557
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.171008
[06/10/2022-19:22:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.139557
[06/10/2022-19:22:53] [V] [TRT] *************** Autotuning Reformat: Float(327680,1:4,1280,5) -> Float(1245184,65536,256,1) ***************
[06/10/2022-19:22:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(2998 -> <out>) (Reformat)
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.164571
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142482
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.162395
[06/10/2022-19:22:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.142482
[06/10/2022-19:22:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:53] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3009) (Reformat)
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.37232
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.29742
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.39514
[06/10/2022-19:22:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.37232
[06/10/2022-19:22:53] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3009) (Reformat)
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.47575
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.36193
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.44853
[06/10/2022-19:22:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.36193
[06/10/2022-19:22:53] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3009) (Reformat)
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 30.5636
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.88869
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 30.5794
[06/10/2022-19:22:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.88869
[06/10/2022-19:22:53] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3009) (Reformat)
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.29726
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.30794
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.31774
[06/10/2022-19:22:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.29726
[06/10/2022-19:22:53] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:53] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1,1024,1) ***************
[06/10/2022-19:22:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 3329) [Constant]_output) (Reformat)
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0202971
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.019072
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0202789
[06/10/2022-19:22:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.019072
[06/10/2022-19:22:53] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:22:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 3329) [Constant]_output) (Reformat)
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.159744
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0553935
[06/10/2022-19:22:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.15989
[06/10/2022-19:22:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0553935
[06/10/2022-19:22:53] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 3329) [Constant]_output) (Reformat)
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 7.09851
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.506002
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.10905
[06/10/2022-19:22:54] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.506002
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1:4,1048576,1024,1) ***************
[06/10/2022-19:22:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> (Unnamed Layer* 3329) [Constant]_output) (Reformat)
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.159598
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0527116
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.159159
[06/10/2022-19:22:54] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0527116
[06/10/2022-19:22:54] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:54] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:54] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:54] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.3527
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.11266
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.37743
[06/10/2022-19:22:54] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.3527
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.44326
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.22896
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.43127
[06/10/2022-19:22:54] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.22896
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 30.5486
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.86909
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 30.5573
[06/10/2022-19:22:54] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.86909
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.29726
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.30706
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.31789
[06/10/2022-19:22:54] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.29726
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 6.34529
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.91824
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.34792
[06/10/2022-19:22:54] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.91824
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.48993
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.93185
[06/10/2022-19:22:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.49445
[06/10/2022-19:22:54] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.93185
[06/10/2022-19:22:54] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 32.7674
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.84627
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 32.761
[06/10/2022-19:22:55] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.84627
[06/10/2022-19:22:55] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 10.8598
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.14295
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 10.8626
[06/10/2022-19:22:55] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.14295
[06/10/2022-19:22:55] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 6.39927
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.97003
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.39634
[06/10/2022-19:22:55] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.97003
[06/10/2022-19:22:55] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.29638
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.06629
[06/10/2022-19:22:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.28556
[06/10/2022-19:22:55] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.28556
[06/10/2022-19:22:55] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 32.6691
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.93375
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 32.6695
[06/10/2022-19:22:56] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.93375
[06/10/2022-19:22:56] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 10.8867
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.43669
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 10.888
[06/10/2022-19:22:56] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.43669
[06/10/2022-19:22:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 6.98134
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.97764
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.98324
[06/10/2022-19:22:56] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.97764
[06/10/2022-19:22:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.48626
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.10534
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.47076
[06/10/2022-19:22:56] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.47076
[06/10/2022-19:22:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.69078
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.377
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.69005
[06/10/2022-19:22:56] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.377
[06/10/2022-19:22:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 11.4878
[06/10/2022-19:22:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.41533
[06/10/2022-19:22:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.484
[06/10/2022-19:22:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.41533
[06/10/2022-19:22:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.09511
[06/10/2022-19:22:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 10.3157
[06/10/2022-19:22:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.09585
[06/10/2022-19:22:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 3.09511
[06/10/2022-19:22:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.24886
[06/10/2022-19:22:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 32.9185
[06/10/2022-19:22:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.24871
[06/10/2022-19:22:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.24871
[06/10/2022-19:22:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 4.41008
[06/10/2022-19:22:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 33.0314
[06/10/2022-19:22:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.40554
[06/10/2022-19:22:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 4.40554
[06/10/2022-19:22:57] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3009 -> <out>) (Reformat)
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 31.3549
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 33.0875
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 31.4328
[06/10/2022-19:22:58] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 31.3549
[06/10/2022-19:22:58] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0191469
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0171845
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0191794
[06/10/2022-19:22:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0171845
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.158427
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0489143
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.15872
[06/10/2022-19:22:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0489143
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 7.13172
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.497957
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.08637
[06/10/2022-19:22:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.497957
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1:4,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.158574
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0548084
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.159451
[06/10/2022-19:22:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0548084
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,1024,1) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0195474
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0188891
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0195657
[06/10/2022-19:22:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0188891
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.159598
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.505271
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.158135
[06/10/2022-19:22:58] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.158135
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 7.08403
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.495762
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.09
[06/10/2022-19:22:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.495762
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,1024,1) -> Float(1:4,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.302519
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0532968
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.301202
[06/10/2022-19:22:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0532968
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,1024,1) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0438491
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.491813
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0438857
[06/10/2022-19:22:58] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0438491
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,1024,1) -> Float(1048576,1,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0437314
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.482011
[06/10/2022-19:22:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0437829
[06/10/2022-19:22:58] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0437314
[06/10/2022-19:22:58] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 7.11373
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.482011
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.11651
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.482011
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,1024,1) -> Float(1:4,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.324023
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.28733
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.325778
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.324023
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.095744
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.490935
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.095744
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.095744
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1048576,1,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0956709
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.491813
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.095744
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0956709
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.225134
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.489733
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.225719
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.225134
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1:4,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.370395
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.37247
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.371273
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.370395
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1048576,1024,1) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0438411
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.499566
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0438194
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0438194
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1048576,1024,1) -> Float(1048576,1,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0438126
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.501906
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0439223
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0438126
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1048576,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.181093
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.39427
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.180224
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.180224
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 3329) [Constant]_output -> <out>) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 7.11973
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 31.1431
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.12148
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 7.11973
[06/10/2022-19:22:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:22:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3048) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0699733
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0737989
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.069632
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.069632
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3048) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.635922
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.195145
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.627127
[06/10/2022-19:22:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.195145
[06/10/2022-19:22:59] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:22:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3048) (Reformat)
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 28.4685
[06/10/2022-19:22:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.02503
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 28.421
[06/10/2022-19:23:00] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.02503
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3048) (Reformat)
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.072832
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0738766
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.072704
[06/10/2022-19:23:00] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.072704
[06/10/2022-19:23:00] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.069827
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.073664
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0701196
[06/10/2022-19:23:00] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.069827
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.632393
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.193243
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.632686
[06/10/2022-19:23:00] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.193243
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 28.4438
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.01406
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 28.4676
[06/10/2022-19:23:00] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.01406
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.072992
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0740937
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0728503
[06/10/2022-19:23:00] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0728503
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,1024,1) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0712411
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.073728
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0709973
[06/10/2022-19:23:00] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0709973
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.634002
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.88507
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.635173
[06/10/2022-19:23:00] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.634002
[06/10/2022-19:23:00] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 28.4186
[06/10/2022-19:23:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.97456
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 28.4178
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.97456
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.339822
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0740937
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.342894
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0740937
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,1024,1) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.162523
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.90405
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.162523
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.162523
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,1024,1) -> Float(1048576,1,1024,1) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.162523
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.01918
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.162816
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.162523
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 28.4919
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.93038
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 28.4991
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.93038
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.427154
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.32405
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.426862
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.426862
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.371712
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.99358
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.371712
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.371712
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1048576,1,1024,1) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.371712
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.07258
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.37184
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.371712
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.900535
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.06482
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.900389
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.900389
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.607671
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.54538
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.607817
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.607671
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.162816
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.560567
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.162962
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.162816
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1048576,1,1024,1) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.162816
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.558958
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.162816
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.162816
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.723822
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.65583
[06/10/2022-19:23:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.721335
[06/10/2022-19:23:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.721335
[06/10/2022-19:23:01] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(3048 -> <out>) (Reformat)
[06/10/2022-19:23:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 28.4957
[06/10/2022-19:23:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 31.3277
[06/10/2022-19:23:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 28.4554
[06/10/2022-19:23:02] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 28.4554
[06/10/2022-19:23:02] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:02] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:23:02] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:02] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:02] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:02] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 6.34661
[06/10/2022-19:23:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.86529
[06/10/2022-19:23:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.34617
[06/10/2022-19:23:02] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.86529
[06/10/2022-19:23:02] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:02] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.49183
[06/10/2022-19:23:02] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.01231
[06/10/2022-19:23:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.50251
[06/10/2022-19:23:02] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.01231
[06/10/2022-19:23:02] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x00000000000003e8 Time: 32.7518
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.89455
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x0000000000000000 Time: 32.7591
[06/10/2022-19:23:03] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.89455
[06/10/2022-19:23:03] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x00000000000003e8 Time: 10.863
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.24798
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x0000000000000000 Time: 10.861
[06/10/2022-19:23:03] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.24798
[06/10/2022-19:23:03] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x00000000000003e8 Time: 6.39634
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.94911
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.39883
[06/10/2022-19:23:03] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.94911
[06/10/2022-19:23:03] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:23:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.29843
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.16225
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.30677
[06/10/2022-19:23:03] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.29843
[06/10/2022-19:23:03] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x00000000000003e8 Time: 32.6478
[06/10/2022-19:23:03] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.90391
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x0000000000000000 Time: 32.6707
[06/10/2022-19:23:04] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.90391
[06/10/2022-19:23:04] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x00000000000003e8 Time: 10.8873
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.33371
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x0000000000000000 Time: 10.8875
[06/10/2022-19:23:04] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.33371
[06/10/2022-19:23:04] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x00000000000003e8 Time: 6.9809
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.05268
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.98192
[06/10/2022-19:23:04] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.05268
[06/10/2022-19:23:04] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:23:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.48656
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.08881
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.47719
[06/10/2022-19:23:04] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.47719
[06/10/2022-19:23:04] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.69663
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.43405
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.68886
[06/10/2022-19:23:04] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.43405
[06/10/2022-19:23:04] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x00000000000003e8 Time: 11.4872
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.42513
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.482
[06/10/2022-19:23:04] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.42513
[06/10/2022-19:23:04] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:04] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.09965
[06/10/2022-19:23:05] [V] [TRT] Tactic: 0x00000000000003ea Time: 10.4689
[06/10/2022-19:23:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.09263
[06/10/2022-19:23:05] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.09263
[06/10/2022-19:23:05] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:23:05] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:05] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.24652
[06/10/2022-19:23:05] [V] [TRT] Tactic: 0x00000000000003ea Time: 32.9756
[06/10/2022-19:23:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.24769
[06/10/2022-19:23:05] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 3.24652
[06/10/2022-19:23:05] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:05] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:05] [V] [TRT] Tactic: 0x00000000000003e8 Time: 4.40686
[06/10/2022-19:23:05] [V] [TRT] Tactic: 0x00000000000003ea Time: 33.2073
[06/10/2022-19:23:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.40525
[06/10/2022-19:23:05] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 4.40525
[06/10/2022-19:23:05] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:05] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 3050) (Reformat)
[06/10/2022-19:23:05] [V] [TRT] Tactic: 0x00000000000003e8 Time: 31.4059
[06/10/2022-19:23:06] [V] [TRT] Tactic: 0x00000000000003ea Time: 33.3922
[06/10/2022-19:23:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 31.4068
[06/10/2022-19:23:06] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 31.4059
[06/10/2022-19:23:06] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(19922944,1,19456,19) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,1024,1) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1:4,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(1048576,1:4,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(5242880,1:4,5120,5) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1048576:32,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:23:06] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:06] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:06] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:06] [V] [TRT] =============== Computing reformatting costs
[06/10/2022-19:23:06] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning format combination:  -> Int32() ***************
[06/10/2022-19:23:06] [V] [TRT] --------------- Timing Runner: [HostToDeviceCopy] (ShapeHostToDevice)
[06/10/2022-19:23:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00300695
[06/10/2022-19:23:06] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00300695
[06/10/2022-19:23:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ShapeHostToDevice Tactic: 0x0000000000000000
[06/10/2022-19:23:06] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:06] [V] [TRT] *************** Autotuning format combination: Float(3145728,1048576,1024,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:23:06] [V] [TRT] --------------- Timing Runner: Conv_27 (CudaDepthwiseConvolution)
[06/10/2022-19:23:06] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:23:06] [V] [TRT] --------------- Timing Runner: Conv_27 (FusedConvActConvolution)
[06/10/2022-19:23:06] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:23:06] [V] [TRT] --------------- Timing Runner: Conv_27 (CudnnConvolution)
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.842898
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.693687
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000002 Time: 1.48495
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000038 Time: 0.86528
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.714459
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x000000000000003a Time: 1.56336
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000070 Time: 0.898779
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000071 Time: 0.746057
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000072 Time: 1.62085
[06/10/2022-19:23:07] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.693687
[06/10/2022-19:23:07] [V] [TRT] --------------- Timing Runner: Conv_27 (CaskConvolution)
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 0x5403ad713f811a18
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x5403ad713f811a18 Time: 0.926281
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x5deb29b7a8e275f7 Time: 0.461093
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 0.701586
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 0.741815
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 0.41867
[06/10/2022-19:23:07] [V] [TRT] Fastest Tactic: 0xf64396b97c889179 Time: 0.41867
[06/10/2022-19:23:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xf64396b97c889179
[06/10/2022-19:23:07] [V] [TRT] *************** Autotuning format combination: Float(3145728,1,3072,3) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:23:07] [V] [TRT] --------------- Timing Runner: Conv_27 (CaskConvolution)
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 1.05545
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: 0xca7eeb8d9143d738
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0xca7eeb8d9143d738 Time: 1.79083
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 1.76933
[06/10/2022-19:23:07] [V] [TRT] Fastest Tactic: 0x19b688348f983aa0 Time: 1.05545
[06/10/2022-19:23:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x19b688348f983aa0
[06/10/2022-19:23:07] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,1024,1) -> Float(1048576,1:4,4096,16) ***************
[06/10/2022-19:23:07] [V] [TRT] --------------- Timing Runner: Conv_27 (CaskConvolution)
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 1.11294
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 4.21742
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 2.08399
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0x634e99502974e4da
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x634e99502974e4da Time: 1.81248
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 1.45861
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 1.78205
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0xbdfdef6b84f7ccc9 Time: 1.98978
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: 0xca7eeb8d9143d738
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0xca7eeb8d9143d738 Time: 1.89864
[06/10/2022-19:23:07] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 1.8925
[06/10/2022-19:23:07] [V] [TRT] Fastest Tactic: 0x19b688348f983aa0 Time: 1.11294
[06/10/2022-19:23:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x19b688348f983aa0
[06/10/2022-19:23:07] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:07] [V] [TRT] *************** Autotuning format combination:  -> Float(64,64,1) ***************
[06/10/2022-19:23:07] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:07] [V] [TRT] *************** Autotuning format combination:  -> Float(64,64,1) ***************
[06/10/2022-19:23:07] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:07] [V] [TRT] *************** Autotuning format combination:  -> Float(64,64,1) ***************
[06/10/2022-19:23:07] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:07] [V] [TRT] *************** Autotuning format combination:  -> Float(64,64,1) ***************
[06/10/2022-19:23:07] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:07] [V] [TRT] *************** Autotuning format combination: Float(4194304,65536,256,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:23:07] [V] [TRT] --------------- Timing Runner: Reshape_41 + Transpose_42 (Shuffle)
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.305006
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.560713
[06/10/2022-19:23:07] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.305006
[06/10/2022-19:23:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:23:07] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,16384,64) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:23:07] [V] [TRT] --------------- Timing Runner: Reshape_41 + Transpose_42 (Shuffle)
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.4556
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.84481
[06/10/2022-19:23:07] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.84481
[06/10/2022-19:23:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:23:07] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,4096,16) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:07] [V] [TRT] --------------- Timing Runner: Reshape_41 + Transpose_42 (Shuffle)
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.44124
[06/10/2022-19:23:07] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.84232
[06/10/2022-19:23:07] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.84232
[06/10/2022-19:23:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:23:07] [V] [TRT] *************** Autotuning format combination: Float(131072,65536:32,256,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:23:07] [V] [TRT] --------------- Timing Runner: Reshape_41 + Transpose_42 (Shuffle)
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 63.1371
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.06903
[06/10/2022-19:23:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.06903
[06/10/2022-19:23:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:23:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:08] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(65536,1,1) ***************
[06/10/2022-19:23:08] [V] [TRT] --------------- Timing Runner: ReduceMean_43 (Reduce)
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.4604
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.253659
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.189001
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.188713
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.203776
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.203191
[06/10/2022-19:23:08] [V] [TRT] Fastest Tactic: 0x0000000000000004 Time: 0.188713
[06/10/2022-19:23:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000004
[06/10/2022-19:23:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:08] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1), Float(65536,1,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:23:08] [V] [TRT] --------------- Timing Runner: Sub_44 (ElementWise)
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.274139
[06/10/2022-19:23:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.274139
[06/10/2022-19:23:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:23:08] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:23:08] [V] [TRT] --------------- Timing Runner: Sub_44 (ElementWise)
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.270921
[06/10/2022-19:23:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.270921
[06/10/2022-19:23:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:23:08] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1), Float(65536:32,1,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:23:08] [V] [TRT] --------------- Timing Runner: Sub_44 (ElementWise)
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.1346
[06/10/2022-19:23:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.1346
[06/10/2022-19:23:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:23:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:08] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:23:08] [V] [TRT] --------------- Timing Runner: PWN(398 + (Unnamed Layer* 75) [Shuffle], Pow_46) (PointWiseV2)
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.275456
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.28277
[06/10/2022-19:23:08] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.276187
[06/10/2022-19:23:09] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.287305
[06/10/2022-19:23:09] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.278821
[06/10/2022-19:23:09] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.277797
[06/10/2022-19:23:09] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.297399
[06/10/2022-19:23:09] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.285842
[06/10/2022-19:23:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.285111
[06/10/2022-19:23:10] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.280869
[06/10/2022-19:23:10] [V] [TRT] Tactic: 0x000000000000001c Time: 0.275456
[06/10/2022-19:23:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.275456
[06/10/2022-19:23:10] [V] [TRT] --------------- Timing Runner: PWN(398 + (Unnamed Layer* 75) [Shuffle], Pow_46) (PointWise)
[06/10/2022-19:23:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000000
[06/10/2022-19:23:10] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 64 (# 0 (SHAPE input))) ***************
[06/10/2022-19:23:10] [V] [TRT] --------------- Timing Runner: PWN(398 + (Unnamed Layer* 75) [Shuffle], Pow_46) (PointWiseV2)
[06/10/2022-19:23:10] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:23:10] [V] [TRT] --------------- Timing Runner: PWN(398 + (Unnamed Layer* 75) [Shuffle], Pow_46) (PointWise)
[06/10/2022-19:23:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:10] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:23:10] [V] [TRT] --------------- Timing Runner: PWN(398 + (Unnamed Layer* 75) [Shuffle], Pow_46) (PointWiseV2)
[06/10/2022-19:23:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.30516
[06/10/2022-19:23:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.55282
[06/10/2022-19:23:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 1.50645
[06/10/2022-19:23:11] [V] [TRT] Tactic: 0x0000000000000003 Time: 2.0322
[06/10/2022-19:23:11] [V] [TRT] Tactic: 0x0000000000000004 Time: 2.02942
[06/10/2022-19:23:11] [V] [TRT] Tactic: 0x0000000000000005 Time: 1.50294
[06/10/2022-19:23:11] [V] [TRT] Tactic: 0x0000000000000006 Time: 3.0856
[06/10/2022-19:23:11] [V] [TRT] Tactic: 0x0000000000000007 Time: 2.64689
[06/10/2022-19:23:12] [V] [TRT] Tactic: 0x0000000000000008 Time: 2.33238
[06/10/2022-19:23:12] [V] [TRT] Tactic: 0x0000000000000009 Time: 2.36895
[06/10/2022-19:23:12] [V] [TRT] Tactic: 0x000000000000000a Time: 1.26011
[06/10/2022-19:23:12] [V] [TRT] Tactic: 0x000000000000000b Time: 1.46213
[06/10/2022-19:23:12] [V] [TRT] Tactic: 0x000000000000000c Time: 1.39864
[06/10/2022-19:23:13] [V] [TRT] Tactic: 0x000000000000000d Time: 1.82228
[06/10/2022-19:23:13] [V] [TRT] Tactic: 0x000000000000000e Time: 1.82769
[06/10/2022-19:23:13] [V] [TRT] Tactic: 0x000000000000000f Time: 1.40624
[06/10/2022-19:23:13] [V] [TRT] Tactic: 0x0000000000000010 Time: 2.62423
[06/10/2022-19:23:13] [V] [TRT] Tactic: 0x0000000000000011 Time: 2.42673
[06/10/2022-19:23:14] [V] [TRT] Tactic: 0x0000000000000012 Time: 2.03162
[06/10/2022-19:23:14] [V] [TRT] Tactic: 0x0000000000000013 Time: 1.70364
[06/10/2022-19:23:14] [V] [TRT] Tactic: 0x0000000000000014 Time: 1.16107
[06/10/2022-19:23:14] [V] [TRT] Tactic: 0x0000000000000015 Time: 1.47441
[06/10/2022-19:23:14] [V] [TRT] Tactic: 0x0000000000000016 Time: 1.89996
[06/10/2022-19:23:15] [V] [TRT] Tactic: 0x0000000000000017 Time: 2.78031
[06/10/2022-19:23:15] [V] [TRT] Tactic: 0x000000000000001c Time: 0.27648
[06/10/2022-19:23:15] [V] [TRT] Tactic: 0x000000000000001d Time: 0.274725
[06/10/2022-19:23:15] [V] [TRT] Tactic: 0x000000000000001e Time: 0.274139
[06/10/2022-19:23:15] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 0.274139
[06/10/2022-19:23:15] [V] [TRT] --------------- Timing Runner: PWN(398 + (Unnamed Layer* 75) [Shuffle], Pow_46) (PointWise)
[06/10/2022-19:23:15] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[06/10/2022-19:23:15] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:23:15] [V] [TRT] --------------- Timing Runner: PWN(398 + (Unnamed Layer* 75) [Shuffle], Pow_46) (PointWiseV2)
[06/10/2022-19:23:15] [V] [TRT] Tactic: 0x0000000000000018 Time: 2.19955
[06/10/2022-19:23:15] [V] [TRT] Tactic: 0x0000000000000019 Time: 2.25178
[06/10/2022-19:23:16] [V] [TRT] Tactic: 0x000000000000001a Time: 2.25322
[06/10/2022-19:23:16] [V] [TRT] Tactic: 0x000000000000001b Time: 2.25616
[06/10/2022-19:23:16] [V] [TRT] Tactic: 0x000000000000001f Time: 2.19882
[06/10/2022-19:23:16] [V] [TRT] Fastest Tactic: 0x000000000000001f Time: 2.19882
[06/10/2022-19:23:16] [V] [TRT] --------------- Timing Runner: PWN(398 + (Unnamed Layer* 75) [Shuffle], Pow_46) (PointWise)
[06/10/2022-19:23:16] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001f
[06/10/2022-19:23:16] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:16] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(65536,1,1) ***************
[06/10/2022-19:23:16] [V] [TRT] --------------- Timing Runner: ReduceMean_47 (Reduce)
[06/10/2022-19:23:16] [V] [TRT] Tactic: 0x0000000000000001 Time: 3.96127
[06/10/2022-19:23:16] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.230839
[06/10/2022-19:23:16] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.187685
[06/10/2022-19:23:16] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.187977
[06/10/2022-19:23:16] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.202752
[06/10/2022-19:23:16] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.203045
[06/10/2022-19:23:16] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 0.187685
[06/10/2022-19:23:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000003
[06/10/2022-19:23:16] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:16] [V] [TRT] *************** Autotuning format combination: Float(65536,1,1), Float(4194304,64,1), Float(64,64,1), Float(64,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:23:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52), Add_53) (PointWiseV2)
[06/10/2022-19:23:16] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.280869
[06/10/2022-19:23:16] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.282185
[06/10/2022-19:23:17] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.279113
[06/10/2022-19:23:17] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.279845
[06/10/2022-19:23:17] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.278235
[06/10/2022-19:23:17] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.278967
[06/10/2022-19:23:17] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.29301
[06/10/2022-19:23:18] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.298021
[06/10/2022-19:23:18] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.281746
[06/10/2022-19:23:18] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.269897
[06/10/2022-19:23:18] [V] [TRT] Tactic: 0x000000000000001c Time: 0.278821
[06/10/2022-19:23:18] [V] [TRT] Fastest Tactic: 0x0000000000000009 Time: 0.269897
[06/10/2022-19:23:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52), Add_53) (PointWise)
[06/10/2022-19:23:18] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000009
[06/10/2022-19:23:18] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,64,1), Float(1,64,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 64 (# 0 (SHAPE input))) ***************
[06/10/2022-19:23:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52), Add_53) (PointWiseV2)
[06/10/2022-19:23:18] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:23:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52), Add_53) (PointWise)
[06/10/2022-19:23:18] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:18] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,64,1), Float(1:4,64,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:23:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52), Add_53) (PointWiseV2)
[06/10/2022-19:23:18] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.18526
[06/10/2022-19:23:19] [V] [TRT] Tactic: 0x0000000000000001 Time: 8.14797
[06/10/2022-19:23:19] [V] [TRT] Tactic: 0x0000000000000002 Time: 10.5934
[06/10/2022-19:23:19] [V] [TRT] Tactic: 0x0000000000000003 Time: 9.08566
[06/10/2022-19:23:19] [V] [TRT] Tactic: 0x0000000000000004 Time: 8.37939
[06/10/2022-19:23:20] [V] [TRT] Tactic: 0x0000000000000005 Time: 7.20544
[06/10/2022-19:23:20] [V] [TRT] Tactic: 0x0000000000000006 Time: 10.7824
[06/10/2022-19:23:20] [V] [TRT] Tactic: 0x0000000000000007 Time: 9.40251
[06/10/2022-19:23:21] [V] [TRT] Tactic: 0x0000000000000008 Time: 9.66173
[06/10/2022-19:23:21] [V] [TRT] Tactic: 0x0000000000000009 Time: 12.0861
[06/10/2022-19:23:21] [V] [TRT] Tactic: 0x000000000000000a Time: 3.56264
[06/10/2022-19:23:21] [V] [TRT] Tactic: 0x000000000000000b Time: 4.33562
[06/10/2022-19:23:22] [V] [TRT] Tactic: 0x000000000000000c Time: 4.42734
[06/10/2022-19:23:22] [V] [TRT] Tactic: 0x000000000000000d Time: 5.10215
[06/10/2022-19:23:22] [V] [TRT] Tactic: 0x000000000000000e Time: 5.59792
[06/10/2022-19:23:22] [V] [TRT] Tactic: 0x000000000000000f Time: 3.70571
[06/10/2022-19:23:23] [V] [TRT] Tactic: 0x0000000000000010 Time: 6.65322
[06/10/2022-19:23:23] [V] [TRT] Tactic: 0x0000000000000011 Time: 6.60758
[06/10/2022-19:23:23] [V] [TRT] Tactic: 0x0000000000000012 Time: 5.53296
[06/10/2022-19:23:24] [V] [TRT] Tactic: 0x0000000000000013 Time: 5.15028
[06/10/2022-19:23:24] [V] [TRT] Tactic: 0x0000000000000014 Time: 2.24707
[06/10/2022-19:23:24] [V] [TRT] Tactic: 0x0000000000000015 Time: 2.81132
[06/10/2022-19:23:24] [V] [TRT] Tactic: 0x0000000000000016 Time: 3.33253
[06/10/2022-19:23:24] [V] [TRT] Tactic: 0x0000000000000017 Time: 4.3817
[06/10/2022-19:23:25] [V] [TRT] Tactic: 0x000000000000001c Time: 0.280722
[06/10/2022-19:23:25] [V] [TRT] Tactic: 0x000000000000001d Time: 0.276187
[06/10/2022-19:23:25] [V] [TRT] Tactic: 0x000000000000001e Time: 0.294327
[06/10/2022-19:23:25] [V] [TRT] Fastest Tactic: 0x000000000000001d Time: 0.276187
[06/10/2022-19:23:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52), Add_53) (PointWise)
[06/10/2022-19:23:25] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001d
[06/10/2022-19:23:25] [V] [TRT] *************** Autotuning format combination: Float(65536:32,1,1), Float(4194304:32,64,1), Float(64:32,64,1), Float(64:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:23:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52), Add_53) (PointWiseV2)
[06/10/2022-19:23:25] [V] [TRT] Tactic: 0x0000000000000018 Time: 2.1978
[06/10/2022-19:23:25] [V] [TRT] Tactic: 0x0000000000000019 Time: 2.23627
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x000000000000001a Time: 2.25777
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x000000000000001b Time: 2.27167
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x000000000000001f Time: 2.19867
[06/10/2022-19:23:26] [V] [TRT] Fastest Tactic: 0x0000000000000018 Time: 2.1978
[06/10/2022-19:23:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52), Add_53) (PointWise)
[06/10/2022-19:23:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000018
[06/10/2022-19:23:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:26] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(65536,1,1) ***************
[06/10/2022-19:23:26] [V] [TRT] --------------- Timing Runner: ReduceMean_54 (Reduce)
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.05767
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.234203
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.188123
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.187392
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.203337
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.202898
[06/10/2022-19:23:26] [V] [TRT] Fastest Tactic: 0x0000000000000004 Time: 0.187392
[06/10/2022-19:23:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000004
[06/10/2022-19:23:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:26] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1), Float(65536,1,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:23:26] [V] [TRT] --------------- Timing Runner: Sub_55 (ElementWise)
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.274725
[06/10/2022-19:23:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.274725
[06/10/2022-19:23:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:23:26] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:23:26] [V] [TRT] --------------- Timing Runner: Sub_55 (ElementWise)
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.269751
[06/10/2022-19:23:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.269751
[06/10/2022-19:23:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:23:26] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1), Float(65536:32,1,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:23:26] [V] [TRT] --------------- Timing Runner: Sub_55 (ElementWise)
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.12141
[06/10/2022-19:23:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.12141
[06/10/2022-19:23:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:23:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:26] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:23:26] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 64 (# 0 (SHAPE input))) ***************
[06/10/2022-19:23:26] [V] [TRT] --------------- Timing Runner: PWN(409 + (Unnamed Layer* 92) [Shuffle], Pow_57) (PointWiseV2)
[06/10/2022-19:23:26] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:23:26] [V] [TRT] --------------- Timing Runner: PWN(409 + (Unnamed Layer* 92) [Shuffle], Pow_57) (PointWise)
[06/10/2022-19:23:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:26] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:23:26] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:23:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:26] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(65536,1,1) ***************
[06/10/2022-19:23:26] [V] [TRT] --------------- Timing Runner: ReduceMean_58 (Reduce)
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.40174
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.247077
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.18827
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.188416
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.203191
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.203483
[06/10/2022-19:23:26] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 0.18827
[06/10/2022-19:23:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000003
[06/10/2022-19:23:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:26] [V] [TRT] *************** Autotuning format combination: Float(65536,1,1), Float(4194304,64,1), Float(64,64,1), Float(64,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:23:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63), Add_64) (PointWiseV2)
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.281307
[06/10/2022-19:23:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.281893
[06/10/2022-19:23:27] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.279552
[06/10/2022-19:23:27] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.279991
[06/10/2022-19:23:27] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.277065
[06/10/2022-19:23:27] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.279552
[06/10/2022-19:23:27] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.292864
[06/10/2022-19:23:27] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.296823
[06/10/2022-19:23:28] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.281161
[06/10/2022-19:23:28] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.270043
[06/10/2022-19:23:28] [V] [TRT] Tactic: 0x000000000000001c Time: 0.278528
[06/10/2022-19:23:28] [V] [TRT] Fastest Tactic: 0x0000000000000009 Time: 0.270043
[06/10/2022-19:23:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63), Add_64) (PointWise)
[06/10/2022-19:23:28] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000009
[06/10/2022-19:23:28] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,64,1), Float(1,64,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 64 (# 0 (SHAPE input))) ***************
[06/10/2022-19:23:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63), Add_64) (PointWiseV2)
[06/10/2022-19:23:28] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:23:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63), Add_64) (PointWise)
[06/10/2022-19:23:28] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:28] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,64,1), Float(1:4,64,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:23:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63), Add_64) (PointWiseV2)
[06/10/2022-19:23:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.21013
[06/10/2022-19:23:29] [V] [TRT] Tactic: 0x0000000000000001 Time: 8.16362
[06/10/2022-19:23:29] [V] [TRT] Tactic: 0x0000000000000002 Time: 10.6158
[06/10/2022-19:23:29] [V] [TRT] Tactic: 0x0000000000000003 Time: 9.04704
[06/10/2022-19:23:29] [V] [TRT] Tactic: 0x0000000000000004 Time: 8.4303
[06/10/2022-19:23:30] [V] [TRT] Tactic: 0x0000000000000005 Time: 7.23939
[06/10/2022-19:23:30] [V] [TRT] Tactic: 0x0000000000000006 Time: 10.7251
[06/10/2022-19:23:30] [V] [TRT] Tactic: 0x0000000000000007 Time: 9.44552
[06/10/2022-19:23:31] [V] [TRT] Tactic: 0x0000000000000008 Time: 9.65544
[06/10/2022-19:23:31] [V] [TRT] Tactic: 0x0000000000000009 Time: 12.0874
[06/10/2022-19:23:31] [V] [TRT] Tactic: 0x000000000000000a Time: 3.58195
[06/10/2022-19:23:31] [V] [TRT] Tactic: 0x000000000000000b Time: 4.37745
[06/10/2022-19:23:32] [V] [TRT] Tactic: 0x000000000000000c Time: 4.36429
[06/10/2022-19:23:32] [V] [TRT] Tactic: 0x000000000000000d Time: 5.08416
[06/10/2022-19:23:32] [V] [TRT] Tactic: 0x000000000000000e Time: 5.64063
[06/10/2022-19:23:32] [V] [TRT] Tactic: 0x000000000000000f Time: 3.7101
[06/10/2022-19:23:33] [V] [TRT] Tactic: 0x0000000000000010 Time: 6.70047
[06/10/2022-19:23:33] [V] [TRT] Tactic: 0x0000000000000011 Time: 6.64503
[06/10/2022-19:23:33] [V] [TRT] Tactic: 0x0000000000000012 Time: 5.56573
[06/10/2022-19:23:33] [V] [TRT] Tactic: 0x0000000000000013 Time: 5.11898
[06/10/2022-19:23:34] [V] [TRT] Tactic: 0x0000000000000014 Time: 2.24841
[06/10/2022-19:23:34] [V] [TRT] Tactic: 0x0000000000000015 Time: 2.84467
[06/10/2022-19:23:34] [V] [TRT] Tactic: 0x0000000000000016 Time: 3.33722
[06/10/2022-19:23:34] [V] [TRT] Tactic: 0x0000000000000017 Time: 4.38404
[06/10/2022-19:23:34] [V] [TRT] Tactic: 0x000000000000001c Time: 0.280869
[06/10/2022-19:23:35] [V] [TRT] Tactic: 0x000000000000001d Time: 0.276626
[06/10/2022-19:23:35] [V] [TRT] Tactic: 0x000000000000001e Time: 0.294181
[06/10/2022-19:23:35] [V] [TRT] Fastest Tactic: 0x000000000000001d Time: 0.276626
[06/10/2022-19:23:35] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63), Add_64) (PointWise)
[06/10/2022-19:23:35] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001d
[06/10/2022-19:23:35] [V] [TRT] *************** Autotuning format combination: Float(65536:32,1,1), Float(4194304:32,64,1), Float(64:32,64,1), Float(64:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:23:35] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63), Add_64) (PointWiseV2)
[06/10/2022-19:23:35] [V] [TRT] Tactic: 0x0000000000000018 Time: 2.19648
[06/10/2022-19:23:35] [V] [TRT] Tactic: 0x0000000000000019 Time: 2.23803
[06/10/2022-19:23:35] [V] [TRT] Tactic: 0x000000000000001a Time: 2.25792
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x000000000000001b Time: 2.26977
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x000000000000001f Time: 2.19589
[06/10/2022-19:23:36] [V] [TRT] Fastest Tactic: 0x000000000000001f Time: 2.19589
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63), Add_64) (PointWise)
[06/10/2022-19:23:36] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:23:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001f
[06/10/2022-19:23:36] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:36] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: Transpose_86 + Reshape_92 (Shuffle)
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.42321
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.55925
[06/10/2022-19:23:36] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.55925
[06/10/2022-19:23:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:23:36] [V] [TRT] *************** Autotuning format combination: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: Transpose_86 + Reshape_92 (Shuffle)
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.30458
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.12743
[06/10/2022-19:23:36] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.30458
[06/10/2022-19:23:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:23:36] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 64 E0),E0) -> Float(1048576,1:4,4096,16) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: Transpose_86 + Reshape_92 (Shuffle)
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.44282
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.42278
[06/10/2022-19:23:36] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.44282
[06/10/2022-19:23:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:23:36] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: Transpose_86 + Reshape_92 (Shuffle)
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.97401
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.22574
[06/10/2022-19:23:36] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.22574
[06/10/2022-19:23:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:23:36] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:36] [V] [TRT] *************** Autotuning format combination: Float(4194304,65536,256,1) -> Float(65536,1024,32,1) ***************
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: Conv_93 (CudaDepthwiseConvolution)
[06/10/2022-19:23:36] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: Conv_93 (FusedConvActConvolution)
[06/10/2022-19:23:36] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: Conv_93 (CudnnConvolution)
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.773705
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.605211
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.782921
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000038 Time: 0.757614
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.604306
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x000000000000003a Time: 0.772096
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000070 Time: 0.734647
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000071 Time: 0.454071
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x0000000000000072 Time: 0.775899
[06/10/2022-19:23:36] [V] [TRT] Fastest Tactic: 0x0000000000000071 Time: 0.454071
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: Conv_93 (CaskConvolution)
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 0x5403ad713f811a18
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x5403ad713f811a18 Time: 0.542281
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x5deb29b7a8e275f7 Time: 0.467822
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x9808072e706def96 Time: 0.57461
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 0.526336
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 0.44032
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 0.373769
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 0.533358
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 0.468887
[06/10/2022-19:23:36] [V] [TRT] Fastest Tactic: 0xd828f024626fa982 Time: 0.373769
[06/10/2022-19:23:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xd828f024626fa982
[06/10/2022-19:23:36] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,16384,64) -> Float(65536,1,2048,64) ***************
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: Conv_93 (CaskConvolution)
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 0.660187
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 0.598601
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 0.172178
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 0.320512
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0x634e99502974e4da
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x634e99502974e4da Time: 0.646875
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.303397
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 0.640439
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 0.320219
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0xbdfdef6b84f7ccc9 Time: 0.323291
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 0.168229
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: 0xca7eeb8d9143d738
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0xca7eeb8d9143d738 Time: 0.642487
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 0.630345
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 0.642341
[06/10/2022-19:23:36] [V] [TRT] Fastest Tactic: 0xc7feb33970feefa7 Time: 0.168229
[06/10/2022-19:23:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc7feb33970feefa7
[06/10/2022-19:23:36] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,4096,16) -> Float(16384,1:4,512,16) ***************
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: Conv_93 (CaskConvolution)
[06/10/2022-19:23:36] [V] [TRT] Conv_93 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:23:36] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.304274
[06/10/2022-19:23:36] [V] [TRT] Fastest Tactic: 0x65e41d81f093b482 Time: 0.304274
[06/10/2022-19:23:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x65e41d81f093b482
[06/10/2022-19:23:36] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:36] [V] [TRT] *************** Autotuning format combination: Float(65536,1024,32,1), Float(4194304,64,1), Float(4194304,64,1), Int32() -> Float(4194304,64,1), Float(16777216,65536,256,1) ***************
[06/10/2022-19:23:36] [V] [TRT] --------------- Timing Runner: {ForeignNode[488...Transpose_159 + Reshape_165]} (Myelin)
[06/10/2022-19:23:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 18.9913
[06/10/2022-19:23:52] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 18.9913
[06/10/2022-19:23:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:23:52] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:23:52] [V] [TRT] *************** Autotuning format combination: Float(16777216,65536,256,1) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:23:52] [V] [TRT] --------------- Timing Runner: Conv_166 (CudaDepthwiseConvolution)
[06/10/2022-19:23:52] [V] [TRT] Tactic: 0xffffffffffffffff Time: 1.25074
[06/10/2022-19:23:52] [V] [TRT] Fastest Tactic: 0xffffffffffffffff Time: 1.25074
[06/10/2022-19:23:52] [V] [TRT] --------------- Timing Runner: Conv_166 (CudnnConvolution)
[06/10/2022-19:23:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.27723
[06/10/2022-19:23:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.27751
[06/10/2022-19:23:53] [V] [TRT] Tactic: 0x0000000000000002 Time: 2.69283
[06/10/2022-19:23:54] [V] [TRT] Tactic: 0x0000000000000005 Time: 231.565
[06/10/2022-19:23:55] [V] [TRT] Tactic: 0x0000000000000006 Time: 109.769
[06/10/2022-19:23:55] [V] [TRT] Tactic: 0x0000000000000038 Time: 2.27152
[06/10/2022-19:23:55] [V] [TRT] Tactic: 0x0000000000000039 Time: 2.28659
[06/10/2022-19:23:55] [V] [TRT] Tactic: 0x000000000000003a Time: 2.7313
[06/10/2022-19:23:57] [V] [TRT] Tactic: 0x000000000000003d Time: 231.633
[06/10/2022-19:23:58] [V] [TRT] Tactic: 0x000000000000003e Time: 109.82
[06/10/2022-19:23:58] [V] [TRT] Tactic: 0x0000000000000070 Time: 2.27489
[06/10/2022-19:23:58] [V] [TRT] Tactic: 0x0000000000000071 Time: 2.28484
[06/10/2022-19:23:58] [V] [TRT] Tactic: 0x0000000000000072 Time: 2.71433
[06/10/2022-19:24:00] [V] [TRT] Tactic: 0x0000000000000075 Time: 231.6
[06/10/2022-19:24:01] [V] [TRT] Tactic: 0x0000000000000076 Time: 109.86
[06/10/2022-19:24:01] [V] [TRT] Fastest Tactic: 0x0000000000000038 Time: 2.27152
[06/10/2022-19:24:01] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskConvolution)
[06/10/2022-19:24:01] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006
[06/10/2022-19:24:02] [V] [TRT] Tactic: 0x01cf8ce2da913006 Time: 70.3778
[06/10/2022-19:24:02] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d
[06/10/2022-19:24:02] [V] [TRT] Tactic: 0x12dbf7d94ee3696d Time: 39.596
[06/10/2022-19:24:02] [V] [TRT] Conv_166 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:24:02] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 24.0639
[06/10/2022-19:24:02] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395
[06/10/2022-19:24:02] [V] [TRT] Tactic: 0x4727434768e46395 Time: 39.0077
[06/10/2022-19:24:02] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c
[06/10/2022-19:24:03] [V] [TRT] Tactic: 0x4efce38acc876f5c Time: 67.2439
[06/10/2022-19:24:03] [V] [TRT] Conv_166 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:24:03] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 48.6355
[06/10/2022-19:24:03] [V] [TRT] Conv_166 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 0x5403ad713f811a18
[06/10/2022-19:24:04] [V] [TRT] Tactic: 0x5403ad713f811a18 Time: 60.9922
[06/10/2022-19:24:04] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:24:04] [V] [TRT] Tactic: 0x5aa723e0481da855 Time: 72.5046
[06/10/2022-19:24:04] [V] [TRT] Conv_166 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7
[06/10/2022-19:24:05] [V] [TRT] Tactic: 0x5deb29b7a8e275f7 Time: 26.2305
[06/10/2022-19:24:05] [V] [TRT] Conv_166 Set Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a
[06/10/2022-19:24:05] [V] [TRT] Tactic: 0x94119b4c514b211a Time: 34.5158
[06/10/2022-19:24:05] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff
[06/10/2022-19:24:05] [V] [TRT] Tactic: 0xa31d27de74b895ff Time: 40.1287
[06/10/2022-19:24:05] [V] [TRT] Conv_166 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:24:05] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 11.6988
[06/10/2022-19:24:05] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30
[06/10/2022-19:24:06] [V] [TRT] Tactic: 0xbb8c3889c7eacd30 Time: 69.2964
[06/10/2022-19:24:06] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:24:06] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 45.064
[06/10/2022-19:24:06] [V] [TRT] Conv_166 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:24:07] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 48.774
[06/10/2022-19:24:07] [V] [TRT] Conv_166 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:24:07] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 24.4857
[06/10/2022-19:24:07] [V] [TRT] Fastest Tactic: 0xa8609adc4e0ceb90 Time: 11.6988
[06/10/2022-19:24:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: 0xffffffffffffffff
[06/10/2022-19:24:07] [V] [TRT] *************** Autotuning format combination: Float(16777216,1,65536,256) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:24:07] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskConvolution)
[06/10/2022-19:24:07] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:24:08] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 81.6151
[06/10/2022-19:24:08] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237
[06/10/2022-19:24:08] [V] [TRT] Tactic: 0x1da91d865428f237 Time: 80.8916
[06/10/2022-19:24:08] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98
[06/10/2022-19:24:13] [V] [TRT] Tactic: 0x3f0c846d6379bc98 Time: 550.772
[06/10/2022-19:24:13] [V] [TRT] Conv_166 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf2
[06/10/2022-19:24:14] [V] [TRT] Tactic: 0x5030121339a48bf2 Time: 105.412
[06/10/2022-19:24:14] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd
[06/10/2022-19:24:14] [V] [TRT] Tactic: 0x62835fce994f06dd Time: 76.5237
[06/10/2022-19:24:14] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49
[06/10/2022-19:24:15] [V] [TRT] Tactic: 0x8014228ec08b4d49 Time: 96.9571
[06/10/2022-19:24:15] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45
[06/10/2022-19:24:16] [V] [TRT] Tactic: 0x94a7db94ba744c45 Time: 78.0652
[06/10/2022-19:24:16] [V] [TRT] Conv_166 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: 0xca7eeb8d9143d739
[06/10/2022-19:24:16] [V] [TRT] Tactic: 0xca7eeb8d9143d739 Time: 106.378
[06/10/2022-19:24:16] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83
[06/10/2022-19:24:17] [V] [TRT] Tactic: 0xd15dd11d64344e83 Time: 126.607
[06/10/2022-19:24:17] [V] [TRT] Conv_166 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf50
[06/10/2022-19:24:18] [V] [TRT] Tactic: 0xd9031472c05adf50 Time: 106.078
[06/10/2022-19:24:18] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee
[06/10/2022-19:24:19] [V] [TRT] Tactic: 0xf48db81f02eca9ee Time: 79.1175
[06/10/2022-19:24:19] [V] [TRT] Fastest Tactic: 0x62835fce994f06dd Time: 76.5237
[06/10/2022-19:24:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x62835fce994f06dd
[06/10/2022-19:24:19] [V] [TRT] *************** Autotuning format combination: Float(4194304,1:4,16384,64) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:24:19] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskConvolution)
[06/10/2022-19:24:19] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:24:19] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:24:19] [V] [TRT] *************** Autotuning format combination:  -> Float(64,64,1) ***************
[06/10/2022-19:24:19] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:24:19] [V] [TRT] *************** Autotuning format combination:  -> Float(64,64,1) ***************
[06/10/2022-19:24:19] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:24:19] [V] [TRT] *************** Autotuning format combination: Float(16777216,65536,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:24:19] [V] [TRT] --------------- Timing Runner: Reshape_174 + Transpose_175 (Shuffle)
[06/10/2022-19:24:19] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.92997
[06/10/2022-19:24:19] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.21462
[06/10/2022-19:24:19] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.21462
[06/10/2022-19:24:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:24:19] [V] [TRT] *************** Autotuning format combination: Float(16777216,1,65536,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:24:19] [V] [TRT] --------------- Timing Runner: Reshape_174 + Transpose_175 (Shuffle)
[06/10/2022-19:24:19] [V] [TRT] Tactic: 0x0000000000000000 Time: 36.3896
[06/10/2022-19:24:19] [V] [TRT] Tactic: 0x0000000000000001 Time: 8.09384
[06/10/2022-19:24:19] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 8.09384
[06/10/2022-19:24:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:24:19] [V] [TRT] *************** Autotuning format combination: Float(4194304,1:4,16384,64) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:24:19] [V] [TRT] --------------- Timing Runner: Reshape_174 + Transpose_175 (Shuffle)
[06/10/2022-19:24:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 36.3796
[06/10/2022-19:24:20] [V] [TRT] Tactic: 0x0000000000000001 Time: 8.09662
[06/10/2022-19:24:20] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 8.09662
[06/10/2022-19:24:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:24:20] [V] [TRT] *************** Autotuning format combination: Float(524288,65536:32,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:24:20] [V] [TRT] --------------- Timing Runner: Reshape_174 + Transpose_175 (Shuffle)
[06/10/2022-19:24:22] [V] [TRT] Tactic: 0x0000000000000000 Time: 252.294
[06/10/2022-19:24:22] [V] [TRT] Tactic: 0x0000000000000001 Time: 10.4616
[06/10/2022-19:24:22] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 10.4616
[06/10/2022-19:24:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:24:22] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:24:22] [V] [TRT] *************** Autotuning format combination: Float(16777216,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:24:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181), PWN(549 + (Unnamed Layer* 267) [Shuffle], Mul_183)) (PointWiseV2)
[06/10/2022-19:24:22] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.04653
[06/10/2022-19:24:22] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.12069
[06/10/2022-19:24:22] [V] [TRT] Tactic: 0x0000000000000002 Time: 1.0888
[06/10/2022-19:24:23] [V] [TRT] Tactic: 0x0000000000000003 Time: 1.13737
[06/10/2022-19:24:23] [V] [TRT] Tactic: 0x0000000000000004 Time: 1.1027
[06/10/2022-19:24:23] [V] [TRT] Tactic: 0x0000000000000005 Time: 1.10182
[06/10/2022-19:24:23] [V] [TRT] Tactic: 0x0000000000000006 Time: 1.17628
[06/10/2022-19:24:23] [V] [TRT] Tactic: 0x0000000000000007 Time: 1.1264
[06/10/2022-19:24:23] [V] [TRT] Tactic: 0x0000000000000008 Time: 1.12991
[06/10/2022-19:24:24] [V] [TRT] Tactic: 0x0000000000000009 Time: 1.12552
[06/10/2022-19:24:24] [V] [TRT] Tactic: 0x000000000000001c Time: 1.04814
[06/10/2022-19:24:24] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.04653
[06/10/2022-19:24:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181), PWN(549 + (Unnamed Layer* 267) [Shuffle], Mul_183)) (PointWise)
[06/10/2022-19:24:24] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:24:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000000
[06/10/2022-19:24:24] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 256 (# 0 (SHAPE input))) ***************
[06/10/2022-19:24:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181), PWN(549 + (Unnamed Layer* 267) [Shuffle], Mul_183)) (PointWiseV2)
[06/10/2022-19:24:24] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:24:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181), PWN(549 + (Unnamed Layer* 267) [Shuffle], Mul_183)) (PointWise)
[06/10/2022-19:24:24] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:24:24] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 256 E0) ***************
[06/10/2022-19:24:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181), PWN(549 + (Unnamed Layer* 267) [Shuffle], Mul_183)) (PointWiseV2)
[06/10/2022-19:24:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 20.5134
[06/10/2022-19:24:25] [V] [TRT] Tactic: 0x0000000000000001 Time: 22.2939
[06/10/2022-19:24:25] [V] [TRT] Tactic: 0x0000000000000002 Time: 21.8427
[06/10/2022-19:24:25] [V] [TRT] Tactic: 0x0000000000000003 Time: 24.3172
[06/10/2022-19:24:26] [V] [TRT] Tactic: 0x0000000000000004 Time: 24.7842
[06/10/2022-19:24:26] [V] [TRT] Tactic: 0x0000000000000005 Time: 23.0221
[06/10/2022-19:24:27] [V] [TRT] Tactic: 0x0000000000000006 Time: 28.2871
[06/10/2022-19:24:27] [V] [TRT] Tactic: 0x0000000000000007 Time: 28.1726
[06/10/2022-19:24:28] [V] [TRT] Tactic: 0x0000000000000008 Time: 26.7949
[06/10/2022-19:24:28] [V] [TRT] Tactic: 0x0000000000000009 Time: 26.8954
[06/10/2022-19:24:28] [V] [TRT] Tactic: 0x000000000000000a Time: 12.8685
[06/10/2022-19:24:29] [V] [TRT] Tactic: 0x000000000000000b Time: 14.4972
[06/10/2022-19:24:29] [V] [TRT] Tactic: 0x000000000000000c Time: 13.5409
[06/10/2022-19:24:29] [V] [TRT] Tactic: 0x000000000000000d Time: 16.054
[06/10/2022-19:24:30] [V] [TRT] Tactic: 0x000000000000000e Time: 16.6132
[06/10/2022-19:24:30] [V] [TRT] Tactic: 0x000000000000000f Time: 14.3846
[06/10/2022-19:24:30] [V] [TRT] Tactic: 0x0000000000000010 Time: 19.135
[06/10/2022-19:24:31] [V] [TRT] Tactic: 0x0000000000000011 Time: 19.9341
[06/10/2022-19:24:31] [V] [TRT] Tactic: 0x0000000000000012 Time: 18.163
[06/10/2022-19:24:31] [V] [TRT] Tactic: 0x0000000000000013 Time: 16.0607
[06/10/2022-19:24:32] [V] [TRT] Tactic: 0x0000000000000014 Time: 7.70662
[06/10/2022-19:24:32] [V] [TRT] Tactic: 0x0000000000000015 Time: 8.80859
[06/10/2022-19:24:32] [V] [TRT] Tactic: 0x0000000000000016 Time: 10.2795
[06/10/2022-19:24:32] [V] [TRT] Tactic: 0x0000000000000017 Time: 13.2336
[06/10/2022-19:24:33] [V] [TRT] Tactic: 0x000000000000001c Time: 1.09846
[06/10/2022-19:24:33] [V] [TRT] Tactic: 0x000000000000001d Time: 1.08807
[06/10/2022-19:24:33] [V] [TRT] Tactic: 0x000000000000001e Time: 1.06555
[06/10/2022-19:24:33] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 1.06555
[06/10/2022-19:24:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181), PWN(549 + (Unnamed Layer* 267) [Shuffle], Mul_183)) (PointWise)
[06/10/2022-19:24:33] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:24:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[06/10/2022-19:24:33] [V] [TRT] *************** Autotuning format combination: Float(16777216:32,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:24:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181), PWN(549 + (Unnamed Layer* 267) [Shuffle], Mul_183)) (PointWiseV2)
[06/10/2022-19:24:33] [V] [TRT] Tactic: 0x0000000000000018 Time: 8.74642
[06/10/2022-19:24:34] [V] [TRT] Tactic: 0x0000000000000019 Time: 9.01604
[06/10/2022-19:24:34] [V] [TRT] Tactic: 0x000000000000001a Time: 8.98648
[06/10/2022-19:24:34] [V] [TRT] Tactic: 0x000000000000001b Time: 9.00813
[06/10/2022-19:24:34] [V] [TRT] Tactic: 0x000000000000001f Time: 8.74774
[06/10/2022-19:24:34] [V] [TRT] Fastest Tactic: 0x0000000000000018 Time: 8.74642
[06/10/2022-19:24:34] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181), PWN(549 + (Unnamed Layer* 267) [Shuffle], Mul_183)) (PointWise)
[06/10/2022-19:24:34] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:24:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000018
[06/10/2022-19:24:34] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:24:34] [V] [TRT] *************** Autotuning format combination: Float(16777216,256,1) -> Float(256,1,1,1) ***************
[06/10/2022-19:24:34] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_184 (Shuffle)
[06/10/2022-19:24:34] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.09729
[06/10/2022-19:24:34] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.19151
[06/10/2022-19:24:34] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.09729
[06/10/2022-19:24:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:24:34] [V] [TRT] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************
[06/10/2022-19:24:34] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_184 (Shuffle)
[06/10/2022-19:24:34] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.6049
[06/10/2022-19:24:35] [V] [TRT] Tactic: 0x0000000000000001 Time: 8.46321
[06/10/2022-19:24:35] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 2.6049
[06/10/2022-19:24:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:24:35] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 256 E0),E0) -> Float(64,1:4,64,64) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:24:35] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_184 (Shuffle)
[06/10/2022-19:24:35] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.5973
[06/10/2022-19:24:35] [V] [TRT] Tactic: 0x0000000000000001 Time: 9.83742
[06/10/2022-19:24:35] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 2.5973
[06/10/2022-19:24:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:24:35] [V] [TRT] *************** Autotuning format combination: Float(16777216:32,256,1) -> Float(8,1:32,1,1) ***************
[06/10/2022-19:24:35] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_184 (Shuffle)
[06/10/2022-19:24:35] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.88229
[06/10/2022-19:24:35] [V] [TRT] Tactic: 0x0000000000000001 Time: 37.0577
[06/10/2022-19:24:35] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 5.88229
[06/10/2022-19:24:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:24:35] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:24:35] [V] [TRT] *************** Autotuning format combination: Float(256,1,1,1) -> Float(64,1,1,1) ***************
[06/10/2022-19:24:35] [V] [TRT] --------------- Timing Runner: MatMul_184 (CudaDepthwiseConvolution)
[06/10/2022-19:24:35] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:24:35] [V] [TRT] --------------- Timing Runner: MatMul_184 (FusedConvActConvolution)
[06/10/2022-19:24:35] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:26:16] [V] [TRT] --------------- Timing Runner: MatMul_184 (CudnnConvolution)
[06/10/2022-19:26:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.95585
[06/10/2022-19:27:27] [V] [TRT] Tactic: 0x0000000000000001 Time: 5.8327
[06/10/2022-19:27:38] [V] [TRT] Tactic: 0x0000000000000002 Time: 11.5929
[06/10/2022-19:27:47] [V] [TRT] Tactic: 0x0000000000000038 Time: 2.94576
[06/10/2022-19:28:48] [V] [TRT] Tactic: 0x0000000000000039 Time: 5.84953
[06/10/2022-19:29:00] [V] [TRT] Tactic: 0x000000000000003a Time: 11.5863
[06/10/2022-19:29:09] [V] [TRT] Tactic: 0x0000000000000070 Time: 2.94268
[06/10/2022-19:29:24] [V] [TRT] Tactic: 0x0000000000000071 Time: 2.19736
[06/10/2022-19:29:35] [V] [TRT] Tactic: 0x0000000000000072 Time: 11.5915
[06/10/2022-19:29:35] [V] [TRT] Fastest Tactic: 0x0000000000000071 Time: 2.19736
[06/10/2022-19:29:35] [V] [TRT] --------------- Timing Runner: MatMul_184 (CublasConvolution)
[06/10/2022-19:29:35] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.31394
[06/10/2022-19:29:35] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.36514
[06/10/2022-19:29:35] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.967095
[06/10/2022-19:29:35] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.967973
[06/10/2022-19:29:35] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.967095
[06/10/2022-19:29:35] [V] [TRT] --------------- Timing Runner: MatMul_184 (CaskConvolution)
[06/10/2022-19:29:35] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a
[06/10/2022-19:29:35] [V] [TRT] Tactic: 0x1fc87d7eb370bb7a Time: 1.43916
[06/10/2022-19:29:35] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675
[06/10/2022-19:29:35] [V] [TRT] Tactic: 0x2ee10e11d6651675 Time: 3.54289
[06/10/2022-19:29:35] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:29:35] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 1.68375
[06/10/2022-19:29:35] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:29:35] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 2.11061
[06/10/2022-19:29:35] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x7f0145cb49517338 Time: 1.93112
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x865894c4635db7fd Time: 1.71681
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x8e3884f0eaec3ecd Time: 1.74519
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x9808072e706def96 Time: 2.42703
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x9cd5cdc35441c505 Time: 2.27313
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x9de226a0c44627c4 Time: 3.76525
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xa419b3b68f2da07b Time: 1.79332
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 2.39397
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 2.01684
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xc0b05b61d128e46e Time: 2.22764
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 1.74826
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xe5603263b7f00303 Time: 1.84013
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 2.15991
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 1.81072
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xfff46c7893896eb1 Time: 2.50602
[06/10/2022-19:29:36] [V] [TRT] Fastest Tactic: 0x1fc87d7eb370bb7a Time: 1.43916
[06/10/2022-19:29:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000002
[06/10/2022-19:29:36] [V] [TRT] *************** Autotuning format combination: Float(256,1,256,256) -> Float(64,1,64,64) ***************
[06/10/2022-19:29:36] [V] [TRT] --------------- Timing Runner: MatMul_184 (CublasConvolution)
[06/10/2022-19:29:36] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:29:36] [V] [TRT] --------------- Timing Runner: MatMul_184 (CaskConvolution)
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 1.09948
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.718263
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 1.19472
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.765074
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 0.855186
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 0.845239
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 0.823735
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 0.772974
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 1.3154
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 0.819639
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 1.26947
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 0.822711
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.728942
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 0.773998
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 0.99957
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 1.17965
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 0.814665
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 0.852114
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 1.31979
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 1.24869
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 1.25512
[06/10/2022-19:29:36] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 0.718263
[06/10/2022-19:29:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:29:36] [V] [TRT] *************** Autotuning format combination: Float(64,1:4,64,64) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:29:36] [V] [TRT] --------------- Timing Runner: MatMul_184 (CublasConvolution)
[06/10/2022-19:29:36] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:29:36] [V] [TRT] --------------- Timing Runner: MatMul_184 (CaskConvolution)
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.729088
[06/10/2022-19:29:36] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.727771
[06/10/2022-19:29:36] [V] [TRT] Fastest Tactic: 0x9dece0dc37e90462 Time: 0.727771
[06/10/2022-19:29:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9dece0dc37e90462
[06/10/2022-19:29:36] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:36] [V] [TRT] *************** Autotuning format combination: Float(64,1,1,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:29:36] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_184 (Shuffle)
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.278089
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x0000000000000001 Time: 7.65016
[06/10/2022-19:29:36] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.278089
[06/10/2022-19:29:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:29:36] [V] [TRT] *************** Autotuning format combination: Float(64,1,64,64) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:29:36] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_184 (Shuffle)
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.39504
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x0000000000000001 Time: 6.95442
[06/10/2022-19:29:36] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 6.95442
[06/10/2022-19:29:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:29:36] [V] [TRT] *************** Autotuning format combination: Float(16,1:4,16,16) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:29:36] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_184 (Shuffle)
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.43541
[06/10/2022-19:29:36] [V] [TRT] Tactic: 0x0000000000000001 Time: 7.00226
[06/10/2022-19:29:36] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 7.00226
[06/10/2022-19:29:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:29:36] [V] [TRT] *************** Autotuning format combination: Float(2,1:32,1,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:29:36] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_184 (Shuffle)
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 63.6897
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 8.77085
[06/10/2022-19:29:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 8.77085
[06/10/2022-19:29:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:29:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1), Float(4194304,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: Add_186 (ElementWise)
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.409746
[06/10/2022-19:29:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.409746
[06/10/2022-19:29:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: Add_186 (ElementWise)
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.409746
[06/10/2022-19:29:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.409746
[06/10/2022-19:29:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1), Float(4194304:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: Add_186 (ElementWise)
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 3.23847
[06/10/2022-19:29:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 3.23847
[06/10/2022-19:29:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(65536,1,1) ***************
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: ReduceMean_187 (Reduce)
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.19781
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.238299
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.187685
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.188123
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.202898
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.203045
[06/10/2022-19:29:37] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 0.187685
[06/10/2022-19:29:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000003
[06/10/2022-19:29:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1), Float(65536,1,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: Sub_188 (ElementWise)
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.274871
[06/10/2022-19:29:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.274871
[06/10/2022-19:29:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: Sub_188 (ElementWise)
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.270482
[06/10/2022-19:29:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.270482
[06/10/2022-19:29:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1), Float(65536:32,1,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: Sub_188 (ElementWise)
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.12348
[06/10/2022-19:29:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.12348
[06/10/2022-19:29:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 64 (# 0 (SHAPE input))) ***************
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: PWN(557 + (Unnamed Layer* 279) [Shuffle], Pow_190) (PointWiseV2)
[06/10/2022-19:29:37] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: PWN(557 + (Unnamed Layer* 279) [Shuffle], Pow_190) (PointWise)
[06/10/2022-19:29:37] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:29:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(65536,1,1) ***************
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: ReduceMean_191 (Reduce)
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.31148
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.24459
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.187977
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.18827
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.202898
[06/10/2022-19:29:37] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.202898
[06/10/2022-19:29:37] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 0.187977
[06/10/2022-19:29:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000003
[06/10/2022-19:29:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(65536,1,1), Float(4194304,64,1), Float(64,64,1), Float(64,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,64,1), Float(1,64,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 64 (# 0 (SHAPE input))) ***************
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193), Sqrt_194), Div_195), Mul_196), Add_197) (PointWiseV2)
[06/10/2022-19:29:37] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193), Sqrt_194), Div_195), Mul_196), Add_197) (PointWise)
[06/10/2022-19:29:37] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,64,1), Float(1:4,64,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(65536:32,1,1), Float(4194304:32,64,1), Float(64:32,64,1), Float(64:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:29:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 64 E0),E0) -> Float(1048576,1:4,4096,16) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:29:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304,65536,256,1) -> Float(65536,1024,32,1) ***************
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,16384,64) -> Float(65536,1,2048,64) ***************
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,4096,16) -> Float(16384,1:4,512,16) ***************
[06/10/2022-19:29:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:37] [V] [TRT] *************** Autotuning format combination: Float(65536,1024,32,1), Float(4194304,64,1), Float(4194304,64,1), Int32() -> Float(4194304,64,1), Float(16777216,65536,256,1) ***************
[06/10/2022-19:29:37] [V] [TRT] --------------- Timing Runner: {ForeignNode[636...Transpose_292 + Reshape_298]} (Myelin)
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 19.0397
[06/10/2022-19:29:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 19.0397
[06/10/2022-19:29:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(16777216,65536,256,1) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(16777216,1,65536,256) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304,1:4,16384,64) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: Conv_299 (CaskConvolution)
[06/10/2022-19:29:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination:  -> Float(64,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination:  -> Float(64,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(16777216,65536,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(16777216,1,65536,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304,1:4,16384,64) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(524288,65536:32,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(16777216,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 256 (# 0 (SHAPE input))) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310), Erf_311), PWN(694 + (Unnamed Layer* 450) [Shuffle], Add_313)), Mul_314), PWN(697 + (Unnamed Layer* 454) [Shuffle], Mul_316)) (PointWiseV2)
[06/10/2022-19:29:53] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310), Erf_311), PWN(694 + (Unnamed Layer* 450) [Shuffle], Add_313)), Mul_314), PWN(697 + (Unnamed Layer* 454) [Shuffle], Mul_316)) (PointWise)
[06/10/2022-19:29:53] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 256 E0) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(16777216:32,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(16777216,256,1) -> Float(256,1,1,1) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 256 E0),E0) -> Float(64,1:4,64,64) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(16777216:32,256,1) -> Float(8,1:32,1,1) ***************
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(256,1,1,1) -> Float(64,1,1,1) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(256,1,256,256) -> Float(64,1,64,64) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(64,1:4,64,64) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(64,1,1,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(64,1,64,64) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(16,1:4,16,16) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(2,1:32,1,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1), Float(4194304,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: Add_319 (ElementWise)
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.411639
[06/10/2022-19:29:53] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.411639
[06/10/2022-19:29:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: Add_319 (ElementWise)
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.411355
[06/10/2022-19:29:53] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.411355
[06/10/2022-19:29:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1), Float(4194304:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: Add_319 (ElementWise)
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 3.2373
[06/10/2022-19:29:53] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 3.2373
[06/10/2022-19:29:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(65536,1,1) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: ReduceMean_320 (Reduce)
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.09629
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.235959
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.187831
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.18827
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.203191
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.203483
[06/10/2022-19:29:53] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 0.187831
[06/10/2022-19:29:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000003
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1), Float(65536,1,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: Sub_321 (ElementWise)
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.276041
[06/10/2022-19:29:53] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.276041
[06/10/2022-19:29:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: Sub_321 (ElementWise)
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.269751
[06/10/2022-19:29:53] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.269751
[06/10/2022-19:29:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1), Float(65536:32,1,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: Sub_321 (ElementWise)
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.12977
[06/10/2022-19:29:53] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.12977
[06/10/2022-19:29:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 64 (# 0 (SHAPE input))) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: PWN(705 + (Unnamed Layer* 466) [Shuffle], Pow_323) (PointWiseV2)
[06/10/2022-19:29:53] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: PWN(705 + (Unnamed Layer* 466) [Shuffle], Pow_323) (PointWise)
[06/10/2022-19:29:53] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(65536,1,1) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: ReduceMean_324 (Reduce)
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.26906
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.242542
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.187831
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.187685
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.203045
[06/10/2022-19:29:53] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.203045
[06/10/2022-19:29:53] [V] [TRT] Fastest Tactic: 0x0000000000000004 Time: 0.187685
[06/10/2022-19:29:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000004
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(65536,1,1), Float(4194304,64,1), Float(64,64,1), Float(64,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,64,1), Float(1,64,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 64 (# 0 (SHAPE input))) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326), Sqrt_327), Div_328), Mul_329), Add_330) (PointWiseV2)
[06/10/2022-19:29:53] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326), Sqrt_327), Div_328), Mul_329), Add_330) (PointWise)
[06/10/2022-19:29:53] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,64,1), Float(1:4,64,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(65536:32,1,1), Float(4194304:32,64,1), Float(64:32,64,1), Float(64:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 64 E0),E0) -> Float(1048576,1:4,4096,16) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304,65536,256,1) -> Float(65536,1024,32,1) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,16384,64) -> Float(65536,1,2048,64) ***************
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,4096,16) -> Float(16384,1:4,512,16) ***************
[06/10/2022-19:29:53] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:29:53] [V] [TRT] *************** Autotuning format combination: Float(65536,1024,32,1), Float(4194304,64,1), Float(4194304,64,1), Int32() -> Float(4194304,64,1), Float(16777216,65536,256,1) ***************
[06/10/2022-19:29:53] [V] [TRT] --------------- Timing Runner: {ForeignNode[784...Transpose_425 + Reshape_431]} (Myelin)
[06/10/2022-19:30:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 19.0695
[06/10/2022-19:30:09] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 19.0695
[06/10/2022-19:30:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:30:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(16777216,65536,256,1) -> Float(16777216,65536,256,1) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(16777216,1,65536,256) -> Float(16777216,1,65536,256) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(4194304,1:4,16384,64) -> Float(4194304,1:4,16384,64) ***************
[06/10/2022-19:30:09] [V] [TRT] --------------- Timing Runner: Conv_432 (CaskConvolution)
[06/10/2022-19:30:09] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:30:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination:  -> Float(64,64,1) ***************
[06/10/2022-19:30:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination:  -> Float(64,64,1) ***************
[06/10/2022-19:30:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(16777216,65536,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(16777216,1,65536,256) -> Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(4194304,1:4,16384,64) -> Float(1:4,(* 256 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(524288,65536:32,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:30:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(16777216,256,1) -> Float(16777216,256,1) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 256 (# 0 (SHAPE input))) ***************
[06/10/2022-19:30:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443), Erf_444), PWN(842 + (Unnamed Layer* 637) [Shuffle], Add_446)), Mul_447), PWN(845 + (Unnamed Layer* 641) [Shuffle], Mul_449)) (PointWiseV2)
[06/10/2022-19:30:09] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:30:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443), Erf_444), PWN(842 + (Unnamed Layer* 637) [Shuffle], Add_446)), Mul_447), PWN(845 + (Unnamed Layer* 641) [Shuffle], Mul_449)) (PointWise)
[06/10/2022-19:30:09] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 256 E0) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(16777216:32,256,1) -> Float(16777216:32,256,1) ***************
[06/10/2022-19:30:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(16777216,256,1) -> Float(256,1,1,1) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(1,(* 256 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(256,1,256,256) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 256 E0),E0) -> Float(64,1:4,64,64) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(16777216:32,256,1) -> Float(8,1:32,1,1) ***************
[06/10/2022-19:30:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(256,1,1,1) -> Float(64,1,1,1) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(256,1,256,256) -> Float(64,1,64,64) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(64,1:4,64,64) -> Float(16,1:4,16,16) ***************
[06/10/2022-19:30:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(64,1,1,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(64,1,64,64) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(16,1:4,16,16) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(2,1:32,1,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:30:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1), Float(4194304,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:30:09] [V] [TRT] --------------- Timing Runner: Add_452 (ElementWise)
[06/10/2022-19:30:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.411502
[06/10/2022-19:30:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.411502
[06/10/2022-19:30:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:30:09] [V] [TRT] --------------- Timing Runner: Add_452 (ElementWise)
[06/10/2022-19:30:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.409307
[06/10/2022-19:30:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.409307
[06/10/2022-19:30:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1), Float(4194304:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:30:09] [V] [TRT] --------------- Timing Runner: Add_452 (ElementWise)
[06/10/2022-19:30:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 3.24257
[06/10/2022-19:30:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 3.24257
[06/10/2022-19:30:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:09] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(65536,1,1) ***************
[06/10/2022-19:30:09] [V] [TRT] --------------- Timing Runner: ReduceMean_453 (Reduce)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.10302
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.23669
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.187685
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.188123
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.203223
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.202752
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 0.187685
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000003
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1), Float(65536,1,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Sub_454 (ElementWise)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.275145
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.275145
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Sub_454 (ElementWise)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.269751
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.269751
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1), Float(65536:32,1,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Sub_454 (ElementWise)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.12933
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.12933
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 64 (# 0 (SHAPE input))) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: PWN(853 + (Unnamed Layer* 653) [Shuffle], Pow_456) (PointWiseV2)
[06/10/2022-19:30:10] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: PWN(853 + (Unnamed Layer* 653) [Shuffle], Pow_456) (PointWise)
[06/10/2022-19:30:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(65536,1,1) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: ReduceMean_457 (Reduce)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.2123
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.240494
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.188416
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.18827
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.203045
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.202917
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000004 Time: 0.18827
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000004
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(65536,1,1), Float(4194304,64,1), Float(64,64,1), Float(64,64,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,64,1), Float(1,64,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 64 (# 0 (SHAPE input))) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459), Sqrt_460), Div_461), Mul_462), Add_463) (PointWiseV2)
[06/10/2022-19:30:10] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459), Sqrt_460), Div_461), Mul_462), Add_463) (PointWise)
[06/10/2022-19:30:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,64,1), Float(1:4,64,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 64 E0) ***************
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(65536:32,1,1), Float(4194304:32,64,1), Float(64:32,64,1), Float(64:32,64,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(4194304,65536,256,1) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Reshape_468 + Transpose_469 (Shuffle)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.39644
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.55925
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.55925
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(4194304,1,16384,64) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Reshape_468 + Transpose_469 (Shuffle)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.23933
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.90142
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.23933
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 64 E0),E0) -> Float(1048576,1:4,4096,16) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Reshape_468 + Transpose_469 (Shuffle)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.41605
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.37786
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.41605
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1) -> Float(131072,65536:32,256,1) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Reshape_468 + Transpose_469 (Shuffle)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.96553
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.0303
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.0303
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(4194304,65536,256,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Conv_470 (CudaDepthwiseConvolution)
[06/10/2022-19:30:10] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Conv_470 (FusedConvActConvolution)
[06/10/2022-19:30:10] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Conv_470 (CudnnConvolution)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.04594
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.772535
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 1.44369
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000005 Time: 8.65703
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000038 Time: 1.24694
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.805888
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x000000000000003a Time: 1.59305
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x000000000000003d Time: 8.72696
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000070 Time: 1.23538
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000071 Time: 1.12552
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000072 Time: 1.57506
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000075 Time: 8.75461
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.772535
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Conv_470 (CaskConvolution)
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x01cf8ce2da913006 Time: 0.939739
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x12dbf7d94ee3696d Time: 1.05531
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 0.840997
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x4727434768e46395 Time: 0.931109
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x4efce38acc876f5c Time: 0.87947
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 0.777801
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 0x5403ad713f811a18
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x5403ad713f811a18 Time: 0.825783
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x5aa723e0481da855 Time: 0.834706
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x5deb29b7a8e275f7 Time: 0.76917
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xa31d27de74b895ff Time: 0.903314
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 0.917943
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xbb8c3889c7eacd30 Time: 0.88576
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 1.26917
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 0.757029
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 0.805888
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0xf067e6205da31c2e Time: 0.757029
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xf067e6205da31c2e
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,16384,64) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Conv_470 (CaskConvolution)
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 0.850066
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x1da91d865428f237 Time: 0.738597
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.795063
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 0.871863
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 0.858697
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x3f0c846d6379bc98 Time: 1.70598
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 0.81525
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 0.946469
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x62835fce994f06dd Time: 0.764928
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0x634e99502974e4da
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x634e99502974e4da Time: 0.907703
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.419401
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 0.923941
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x8014228ec08b4d49 Time: 0.874789
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x94a7db94ba744c45 Time: 0.837193
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x999e005e3b016ea6 Time: 0.409893
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xb443c221fcb1565b Time: 0.416329
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xbdfdef6b84f7ccc9 Time: 0.819785
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: 0xca7eeb8d9143d738
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xca7eeb8d9143d738 Time: 0.974555
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xd15dd11d64344e83 Time: 0.722944
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 0.967241
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xf48db81f02eca9ee Time: 0.75659
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 0.925111
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x999e005e3b016ea6 Time: 0.409893
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x999e005e3b016ea6
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,4096,16) -> Float(524288,1:4,4096,32) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Conv_470 (CaskConvolution)
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.425106
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x999e005e3b016ea6 Time: 0.416622
[06/10/2022-19:30:10] [V] [TRT] Conv_470 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0xb443c221fcb1565b Time: 0.422473
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x999e005e3b016ea6 Time: 0.416622
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x999e005e3b016ea6
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Reshape_484 + Transpose_485 (Shuffle)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.197486
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.286866
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.197486
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Reshape_484 + Transpose_485 (Shuffle)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.32184
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.464311
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.464311
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Reshape_484 + Transpose_485 (Shuffle)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.31657
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.465189
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.465189
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(65536,16384:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: Reshape_484 + Transpose_485 (Shuffle)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.1145
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.10021
[06/10/2022-19:30:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.10021
[06/10/2022-19:30:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:30:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:10] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:30:10] [V] [TRT] --------------- Timing Runner: ReduceMean_486 (Reduce)
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.0771
[06/10/2022-19:30:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.06656
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.104594
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.104741
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.111762
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.111689
[06/10/2022-19:30:11] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.06656
[06/10/2022-19:30:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:30:11] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:11] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1), Float(16384,1,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: Sub_487 (ElementWise)
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.134875
[06/10/2022-19:30:11] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.134875
[06/10/2022-19:30:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:11] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: Sub_487 (ElementWise)
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.138167
[06/10/2022-19:30:11] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.138167
[06/10/2022-19:30:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:11] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1), Float(16384:32,1,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: Sub_487 (ElementWise)
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.07271
[06/10/2022-19:30:11] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.07271
[06/10/2022-19:30:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:11] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:11] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(888 + (Unnamed Layer* 690) [Shuffle], Pow_489) (PointWiseV2)
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.138898
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.144091
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.139849
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.146432
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.141897
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.140581
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.151406
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.145554
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.144677
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.14197
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000001c Time: 0.138752
[06/10/2022-19:30:11] [V] [TRT] Fastest Tactic: 0x000000000000001c Time: 0.138752
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(888 + (Unnamed Layer* 690) [Shuffle], Pow_489) (PointWise)
[06/10/2022-19:30:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001c
[06/10/2022-19:30:11] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(888 + (Unnamed Layer* 690) [Shuffle], Pow_489) (PointWiseV2)
[06/10/2022-19:30:11] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(888 + (Unnamed Layer* 690) [Shuffle], Pow_489) (PointWise)
[06/10/2022-19:30:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:11] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(888 + (Unnamed Layer* 690) [Shuffle], Pow_489) (PointWiseV2)
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.691488
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.805157
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.780009
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000003 Time: 1.12772
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000004 Time: 1.13518
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.851529
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000006 Time: 1.79653
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000007 Time: 1.52459
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000008 Time: 1.32052
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000009 Time: 1.3233
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000a Time: 0.708169
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000b Time: 0.822551
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000c Time: 0.77707
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000d Time: 1.0458
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000e Time: 1.05209
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000f Time: 0.811625
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000010 Time: 1.54141
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000011 Time: 1.41502
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000012 Time: 1.18374
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000013 Time: 0.974702
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000014 Time: 0.663721
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000015 Time: 0.855625
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000016 Time: 1.09539
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000017 Time: 1.59861
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000001c Time: 0.140361
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000001d Time: 0.139557
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000001e Time: 0.134071
[06/10/2022-19:30:11] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 0.134071
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(888 + (Unnamed Layer* 690) [Shuffle], Pow_489) (PointWise)
[06/10/2022-19:30:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[06/10/2022-19:30:11] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(888 + (Unnamed Layer* 690) [Shuffle], Pow_489) (PointWiseV2)
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000018 Time: 1.1008
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000019 Time: 1.12494
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000001a Time: 1.12684
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000001b Time: 1.12991
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000001f Time: 1.10214
[06/10/2022-19:30:11] [V] [TRT] Fastest Tactic: 0x0000000000000018 Time: 1.1008
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(888 + (Unnamed Layer* 690) [Shuffle], Pow_489) (PointWise)
[06/10/2022-19:30:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000018
[06/10/2022-19:30:11] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:11] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: ReduceMean_490 (Reduce)
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.03336
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0662629
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.103351
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.103424
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.110885
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.111031
[06/10/2022-19:30:11] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0662629
[06/10/2022-19:30:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:30:11] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:11] [V] [TRT] *************** Autotuning format combination: Float(16384,1,1), Float(2097152,128,1), Float(128,128,1), Float(128,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495), Add_496) (PointWiseV2)
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.143067
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.140361
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.141093
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.146725
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.142921
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.142617
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.146432
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.14336
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.142263
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.141749
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000001c Time: 0.142336
[06/10/2022-19:30:11] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.140361
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495), Add_496) (PointWise)
[06/10/2022-19:30:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000001
[06/10/2022-19:30:11] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,128,1), Float(1,128,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495), Add_496) (PointWiseV2)
[06/10/2022-19:30:11] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495), Add_496) (PointWise)
[06/10/2022-19:30:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:11] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,128,1), Float(1:4,128,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:30:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495), Add_496) (PointWiseV2)
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.76349
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.28031
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000002 Time: 5.58577
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000003 Time: 4.59323
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000004 Time: 4.11458
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000005 Time: 4.21391
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000006 Time: 6.45413
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000007 Time: 4.63389
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000008 Time: 5.51731
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000009 Time: 6.66358
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000a Time: 1.8609
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000b Time: 2.26743
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000c Time: 2.42264
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000d Time: 2.8062
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000e Time: 3.07376
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x000000000000000f Time: 2.03001
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000010 Time: 3.81294
[06/10/2022-19:30:11] [V] [TRT] Tactic: 0x0000000000000011 Time: 3.69825
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000012 Time: 2.98598
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000013 Time: 2.91343
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000014 Time: 1.28219
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000015 Time: 1.60841
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000016 Time: 1.88738
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000017 Time: 2.48437
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000001c Time: 0.141166
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000001d Time: 0.136265
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000001e Time: 0.163547
[06/10/2022-19:30:12] [V] [TRT] Fastest Tactic: 0x000000000000001d Time: 0.136265
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495), Add_496) (PointWise)
[06/10/2022-19:30:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001d
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(16384:32,1,1), Float(2097152:32,128,1), Float(128:32,128,1), Float(128:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495), Add_496) (PointWiseV2)
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000018 Time: 1.07754
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000019 Time: 1.11733
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000001a Time: 1.13254
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000001b Time: 1.13927
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000001f Time: 1.12903
[06/10/2022-19:30:12] [V] [TRT] Fastest Tactic: 0x0000000000000018 Time: 1.07754
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495), Add_496) (PointWise)
[06/10/2022-19:30:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000018
[06/10/2022-19:30:12] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: ReduceMean_497 (Reduce)
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.21637
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.067779
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.106496
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.105691
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.112421
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.112347
[06/10/2022-19:30:12] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.067779
[06/10/2022-19:30:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:30:12] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1), Float(16384,1,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: Sub_498 (ElementWise)
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.134802
[06/10/2022-19:30:12] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.134802
[06/10/2022-19:30:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: Sub_498 (ElementWise)
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.13933
[06/10/2022-19:30:12] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.13933
[06/10/2022-19:30:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1), Float(16384:32,1,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: Sub_498 (ElementWise)
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.08427
[06/10/2022-19:30:12] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.08427
[06/10/2022-19:30:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:30:12] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(899 + (Unnamed Layer* 707) [Shuffle], Pow_500) (PointWiseV2)
[06/10/2022-19:30:12] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(899 + (Unnamed Layer* 707) [Shuffle], Pow_500) (PointWise)
[06/10/2022-19:30:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:30:12] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: ReduceMean_501 (Reduce)
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.14015
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.066755
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.105472
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.105472
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.112567
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.112274
[06/10/2022-19:30:12] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.066755
[06/10/2022-19:30:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:30:12] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(16384,1,1), Float(2097152,128,1), Float(128,128,1), Float(128,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506), Add_507) (PointWiseV2)
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.147895
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.141678
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.141312
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.146578
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.143506
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.142711
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.146158
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.143653
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.142117
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.141458
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000001c Time: 0.144114
[06/10/2022-19:30:12] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.141312
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506), Add_507) (PointWise)
[06/10/2022-19:30:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000002
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,128,1), Float(1,128,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506), Add_507) (PointWiseV2)
[06/10/2022-19:30:12] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506), Add_507) (PointWise)
[06/10/2022-19:30:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,128,1), Float(1:4,128,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506), Add_507) (PointWiseV2)
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.78295
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.2802
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000002 Time: 5.59453
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000003 Time: 4.60932
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000004 Time: 4.15159
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000005 Time: 4.14266
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000006 Time: 6.35816
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000007 Time: 4.70484
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000008 Time: 5.70046
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000009 Time: 6.68263
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000000a Time: 1.84817
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000000b Time: 2.3198
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000000c Time: 2.45745
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000000d Time: 2.83458
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000000e Time: 3.09687
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000000f Time: 2.03878
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000010 Time: 3.8362
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000011 Time: 3.69796
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000012 Time: 3.00851
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000013 Time: 2.85755
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000014 Time: 1.26947
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000015 Time: 1.60022
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000016 Time: 1.90391
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000017 Time: 2.50778
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000001c Time: 0.140873
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000001d Time: 0.136265
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000001e Time: 0.163547
[06/10/2022-19:30:12] [V] [TRT] Fastest Tactic: 0x000000000000001d Time: 0.136265
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506), Add_507) (PointWise)
[06/10/2022-19:30:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001d
[06/10/2022-19:30:12] [V] [TRT] *************** Autotuning format combination: Float(16384:32,1,1), Float(2097152:32,128,1), Float(128:32,128,1), Float(128:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:30:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506), Add_507) (PointWiseV2)
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000018 Time: 1.07213
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x0000000000000019 Time: 1.11367
[06/10/2022-19:30:12] [V] [TRT] Tactic: 0x000000000000001a Time: 1.13123
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x000000000000001b Time: 1.14
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x000000000000001f Time: 1.13357
[06/10/2022-19:30:13] [V] [TRT] Fastest Tactic: 0x0000000000000018 Time: 1.07213
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506), Add_507) (PointWise)
[06/10/2022-19:30:13] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000018
[06/10/2022-19:30:13] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:13] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: Transpose_529 + Reshape_535 (Shuffle)
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.209627
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.286281
[06/10/2022-19:30:13] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.209627
[06/10/2022-19:30:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:30:13] [V] [TRT] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: Transpose_529 + Reshape_535 (Shuffle)
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.694583
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.18082
[06/10/2022-19:30:13] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.694583
[06/10/2022-19:30:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:30:13] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 128 E0),E0) -> Float(524288,1:4,4096,32) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: Transpose_529 + Reshape_535 (Shuffle)
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.685934
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.22997
[06/10/2022-19:30:13] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.685934
[06/10/2022-19:30:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:30:13] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: Transpose_529 + Reshape_535 (Shuffle)
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.7525
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.22368
[06/10/2022-19:30:13] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.22368
[06/10/2022-19:30:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:30:13] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:13] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: Conv_536 (CudaDepthwiseConvolution)
[06/10/2022-19:30:13] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: Conv_536 (FusedConvActConvolution)
[06/10/2022-19:30:13] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: Conv_536 (CudnnConvolution)
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.424375
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.268727
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.424082
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000038 Time: 0.40053
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.26229
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x000000000000003a Time: 0.416037
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000070 Time: 0.398336
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000071 Time: 0.264631
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x0000000000000072 Time: 0.412526
[06/10/2022-19:30:13] [V] [TRT] Fastest Tactic: 0x0000000000000039 Time: 0.26229
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: Conv_536 (CaskConvolution)
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x12dbf7d94ee3696d Time: 0.184759
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 0.236082
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 0.274107
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 0x5403ad713f811a18
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x5403ad713f811a18 Time: 0.276626
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x5aa723e0481da855 Time: 0.164864
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x5deb29b7a8e275f7 Time: 0.24459
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x9808072e706def96 Time: 0.365861
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xa31d27de74b895ff Time: 0.181541
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 0.360741
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 0.263168
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xbb8c3889c7eacd30 Time: 0.537454
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 0.218245
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 0.290523
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 0.26741
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 0.243419
[06/10/2022-19:30:13] [V] [TRT] Fastest Tactic: 0x5aa723e0481da855 Time: 0.164864
[06/10/2022-19:30:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x5aa723e0481da855
[06/10/2022-19:30:13] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(131072,1,4096,128) ***************
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: Conv_536 (CaskConvolution)
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 0.383813
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 0.298862
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x1da91d865428f237 Time: 0.300325
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.165449
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 0.172178
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 0.17013
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 0.165449
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 0.373029
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x62835fce994f06dd Time: 0.281307
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0x634e99502974e4da
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x634e99502974e4da Time: 0.421595
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.157696
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 0.420571
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x8014228ec08b4d49 Time: 0.316709
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 0.166181
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xb443c221fcb1565b Time: 0.158405
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xbdfdef6b84f7ccc9 Time: 0.171305
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 0.174226
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: 0xca7eeb8d9143d738
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xca7eeb8d9143d738 Time: 0.386487
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 0.375515
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 0.427904
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 0.428032
[06/10/2022-19:30:13] [V] [TRT] Fastest Tactic: 0x65e41d81f093b482 Time: 0.157696
[06/10/2022-19:30:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x65e41d81f093b482
[06/10/2022-19:30:13] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(32768,1:4,1024,32) ***************
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: Conv_536 (CaskConvolution)
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.157989
[06/10/2022-19:30:13] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:30:13] [V] [TRT] Tactic: 0xb443c221fcb1565b Time: 0.158574
[06/10/2022-19:30:13] [V] [TRT] Fastest Tactic: 0x65e41d81f093b482 Time: 0.157989
[06/10/2022-19:30:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x65e41d81f093b482
[06/10/2022-19:30:13] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:13] [V] [TRT] *************** Autotuning format combination: Float(131072,1024,32,1), Float(2097152,128,1), Float(2097152,128,1), Int32() -> Float(2097152,128,1), Float(8388608,16384,128,1) ***************
[06/10/2022-19:30:13] [V] [TRT] --------------- Timing Runner: {ForeignNode[978...Transpose_602 + Reshape_608]} (Myelin)
[06/10/2022-19:30:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.09003
[06/10/2022-19:30:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 7.09003
[06/10/2022-19:30:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:30:25] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:25] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:30:25] [V] [TRT] --------------- Timing Runner: Conv_609 (CudaDepthwiseConvolution)
[06/10/2022-19:30:25] [V] [TRT] Tactic: 0xffffffffffffffff Time: 0.623762
[06/10/2022-19:30:25] [V] [TRT] Fastest Tactic: 0xffffffffffffffff Time: 0.623762
[06/10/2022-19:30:25] [V] [TRT] --------------- Timing Runner: Conv_609 (CudnnConvolution)
[06/10/2022-19:30:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.15171
[06/10/2022-19:30:25] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.14907
[06/10/2022-19:30:25] [V] [TRT] Tactic: 0x0000000000000002 Time: 1.34846
[06/10/2022-19:30:26] [V] [TRT] Tactic: 0x0000000000000004 Time: 92.2472
[06/10/2022-19:30:27] [V] [TRT] Tactic: 0x0000000000000005 Time: 135.338
[06/10/2022-19:30:27] [V] [TRT] Tactic: 0x0000000000000006 Time: 53.1219
[06/10/2022-19:30:27] [V] [TRT] Tactic: 0x0000000000000038 Time: 1.14776
[06/10/2022-19:30:27] [V] [TRT] Tactic: 0x0000000000000039 Time: 1.14717
[06/10/2022-19:30:27] [V] [TRT] Tactic: 0x000000000000003a Time: 1.33559
[06/10/2022-19:30:28] [V] [TRT] Tactic: 0x000000000000003c Time: 92.3859
[06/10/2022-19:30:29] [V] [TRT] Tactic: 0x000000000000003d Time: 135.275
[06/10/2022-19:30:30] [V] [TRT] Tactic: 0x000000000000003e Time: 53.1591
[06/10/2022-19:30:30] [V] [TRT] Tactic: 0x0000000000000070 Time: 1.14688
[06/10/2022-19:30:30] [V] [TRT] Tactic: 0x0000000000000071 Time: 1.14632
[06/10/2022-19:30:30] [V] [TRT] Tactic: 0x0000000000000072 Time: 1.33764
[06/10/2022-19:30:30] [V] [TRT] Tactic: 0x0000000000000074 Time: 92.8032
[06/10/2022-19:30:31] [V] [TRT] Tactic: 0x0000000000000075 Time: 135.194
[06/10/2022-19:30:32] [V] [TRT] Tactic: 0x0000000000000076 Time: 53.1399
[06/10/2022-19:30:32] [V] [TRT] Fastest Tactic: 0x0000000000000071 Time: 1.14632
[06/10/2022-19:30:32] [V] [TRT] --------------- Timing Runner: Conv_609 (CaskConvolution)
[06/10/2022-19:30:32] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006
[06/10/2022-19:30:32] [V] [TRT] Tactic: 0x01cf8ce2da913006 Time: 36.8258
[06/10/2022-19:30:32] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d
[06/10/2022-19:30:32] [V] [TRT] Tactic: 0x12dbf7d94ee3696d Time: 21.5714
[06/10/2022-19:30:32] [V] [TRT] Conv_609 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:30:32] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 13.7057
[06/10/2022-19:30:32] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395
[06/10/2022-19:30:33] [V] [TRT] Tactic: 0x4727434768e46395 Time: 20.4913
[06/10/2022-19:30:33] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c
[06/10/2022-19:30:33] [V] [TRT] Tactic: 0x4efce38acc876f5c Time: 35.71
[06/10/2022-19:30:33] [V] [TRT] Conv_609 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:30:33] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 26.2004
[06/10/2022-19:30:33] [V] [TRT] Conv_609 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 0x5403ad713f811a18
[06/10/2022-19:30:33] [V] [TRT] Tactic: 0x5403ad713f811a18 Time: 33.8123
[06/10/2022-19:30:33] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:30:34] [V] [TRT] Tactic: 0x5aa723e0481da855 Time: 37.8071
[06/10/2022-19:30:34] [V] [TRT] Conv_609 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7
[06/10/2022-19:30:34] [V] [TRT] Tactic: 0x5deb29b7a8e275f7 Time: 15.036
[06/10/2022-19:30:34] [V] [TRT] Conv_609 Set Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a
[06/10/2022-19:30:34] [V] [TRT] Tactic: 0x94119b4c514b211a Time: 18.7617
[06/10/2022-19:30:34] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff
[06/10/2022-19:30:34] [V] [TRT] Tactic: 0xa31d27de74b895ff Time: 21.0771
[06/10/2022-19:30:34] [V] [TRT] Conv_609 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:30:34] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 7.17546
[06/10/2022-19:30:34] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30
[06/10/2022-19:30:35] [V] [TRT] Tactic: 0xbb8c3889c7eacd30 Time: 37.1329
[06/10/2022-19:30:35] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:30:35] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 22.8472
[06/10/2022-19:30:35] [V] [TRT] Conv_609 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:30:35] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 26.2868
[06/10/2022-19:30:35] [V] [TRT] Conv_609 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:30:35] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 13.9194
[06/10/2022-19:30:35] [V] [TRT] Fastest Tactic: 0xa8609adc4e0ceb90 Time: 7.17546
[06/10/2022-19:30:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: 0xffffffffffffffff
[06/10/2022-19:30:35] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:30:35] [V] [TRT] --------------- Timing Runner: Conv_609 (CaskConvolution)
[06/10/2022-19:30:35] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:30:36] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 43.9109
[06/10/2022-19:30:36] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237
[06/10/2022-19:30:36] [V] [TRT] Tactic: 0x1da91d865428f237 Time: 44.8534
[06/10/2022-19:30:36] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98
[06/10/2022-19:30:38] [V] [TRT] Tactic: 0x3f0c846d6379bc98 Time: 288.68
[06/10/2022-19:30:38] [V] [TRT] Conv_609 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf2
[06/10/2022-19:30:39] [V] [TRT] Tactic: 0x5030121339a48bf2 Time: 53.1305
[06/10/2022-19:30:39] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd
[06/10/2022-19:30:39] [V] [TRT] Tactic: 0x62835fce994f06dd Time: 42.1781
[06/10/2022-19:30:39] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49
[06/10/2022-19:30:39] [V] [TRT] Tactic: 0x8014228ec08b4d49 Time: 46.2504
[06/10/2022-19:30:39] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45
[06/10/2022-19:30:40] [V] [TRT] Tactic: 0x94a7db94ba744c45 Time: 41.607
[06/10/2022-19:30:40] [V] [TRT] Conv_609 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: 0xca7eeb8d9143d739
[06/10/2022-19:30:40] [V] [TRT] Tactic: 0xca7eeb8d9143d739 Time: 53.1495
[06/10/2022-19:30:40] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83
[06/10/2022-19:30:41] [V] [TRT] Tactic: 0xd15dd11d64344e83 Time: 66.7408
[06/10/2022-19:30:41] [V] [TRT] Conv_609 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf50
[06/10/2022-19:30:41] [V] [TRT] Tactic: 0xd9031472c05adf50 Time: 52.1574
[06/10/2022-19:30:41] [V] [TRT] Conv_609 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0xf48db81f02eca9ee Time: 44.2263
[06/10/2022-19:30:42] [V] [TRT] Fastest Tactic: 0x94a7db94ba744c45 Time: 41.607
[06/10/2022-19:30:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x94a7db94ba744c45
[06/10/2022-19:30:42] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:30:42] [V] [TRT] --------------- Timing Runner: Conv_609 (CaskConvolution)
[06/10/2022-19:30:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:30:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:42] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:30:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:42] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:30:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:42] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:30:42] [V] [TRT] --------------- Timing Runner: Reshape_617 + Transpose_618 (Shuffle)
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.72587
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.11455
[06/10/2022-19:30:42] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.72587
[06/10/2022-19:30:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:30:42] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:30:42] [V] [TRT] --------------- Timing Runner: Reshape_617 + Transpose_618 (Shuffle)
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.93979
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.09145
[06/10/2022-19:30:42] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.09145
[06/10/2022-19:30:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:30:42] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:30:42] [V] [TRT] --------------- Timing Runner: Reshape_617 + Transpose_618 (Shuffle)
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.94418
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.09379
[06/10/2022-19:30:42] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.09379
[06/10/2022-19:30:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:30:42] [V] [TRT] *************** Autotuning format combination: Float(262144,16384:32,128,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:30:42] [V] [TRT] --------------- Timing Runner: Reshape_617 + Transpose_618 (Shuffle)
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 43.8532
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.88565
[06/10/2022-19:30:42] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 4.88565
[06/10/2022-19:30:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:30:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:42] [V] [TRT] *************** Autotuning format combination: Float(8388608,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:30:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624), PWN(1039 + (Unnamed Layer* 884) [Shuffle], Mul_626)) (PointWiseV2)
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.549742
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.549138
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.54667
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.569051
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.55296
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.551936
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.591287
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.566126
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.565102
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.5632
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x000000000000001c Time: 0.53365
[06/10/2022-19:30:42] [V] [TRT] Fastest Tactic: 0x000000000000001c Time: 0.53365
[06/10/2022-19:30:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624), PWN(1039 + (Unnamed Layer* 884) [Shuffle], Mul_626)) (PointWise)
[06/10/2022-19:30:42] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001c
[06/10/2022-19:30:42] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************
[06/10/2022-19:30:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624), PWN(1039 + (Unnamed Layer* 884) [Shuffle], Mul_626)) (PointWiseV2)
[06/10/2022-19:30:42] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:30:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624), PWN(1039 + (Unnamed Layer* 884) [Shuffle], Mul_626)) (PointWise)
[06/10/2022-19:30:42] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:42] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 512 E0) ***************
[06/10/2022-19:30:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624), PWN(1039 + (Unnamed Layer* 884) [Shuffle], Mul_626)) (PointWiseV2)
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 10.5273
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 11.1758
[06/10/2022-19:30:42] [V] [TRT] Tactic: 0x0000000000000002 Time: 10.9738
[06/10/2022-19:30:43] [V] [TRT] Tactic: 0x0000000000000003 Time: 12.3297
[06/10/2022-19:30:43] [V] [TRT] Tactic: 0x0000000000000004 Time: 12.4217
[06/10/2022-19:30:43] [V] [TRT] Tactic: 0x0000000000000005 Time: 11.6373
[06/10/2022-19:30:43] [V] [TRT] Tactic: 0x0000000000000006 Time: 14.0642
[06/10/2022-19:30:43] [V] [TRT] Tactic: 0x0000000000000007 Time: 14.1034
[06/10/2022-19:30:43] [V] [TRT] Tactic: 0x0000000000000008 Time: 13.7071
[06/10/2022-19:30:43] [V] [TRT] Tactic: 0x0000000000000009 Time: 13.8187
[06/10/2022-19:30:43] [V] [TRT] Tactic: 0x000000000000000a Time: 6.45968
[06/10/2022-19:30:43] [V] [TRT] Tactic: 0x000000000000000b Time: 7.49919
[06/10/2022-19:30:43] [V] [TRT] Tactic: 0x000000000000000c Time: 7.01338
[06/10/2022-19:30:43] [V] [TRT] Tactic: 0x000000000000000d Time: 8.34399
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x000000000000000e Time: 8.45868
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x000000000000000f Time: 7.40337
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000010 Time: 9.79251
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000011 Time: 9.9546
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000012 Time: 9.21688
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000013 Time: 8.14855
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000014 Time: 4.0862
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000015 Time: 4.67471
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000016 Time: 5.53531
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000017 Time: 7.09382
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x000000000000001c Time: 0.551351
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x000000000000001d Time: 0.547109
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x000000000000001e Time: 0.559543
[06/10/2022-19:30:44] [V] [TRT] Fastest Tactic: 0x000000000000001d Time: 0.547109
[06/10/2022-19:30:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624), PWN(1039 + (Unnamed Layer* 884) [Shuffle], Mul_626)) (PointWise)
[06/10/2022-19:30:44] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001d
[06/10/2022-19:30:44] [V] [TRT] *************** Autotuning format combination: Float(8388608:32,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:30:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624), PWN(1039 + (Unnamed Layer* 884) [Shuffle], Mul_626)) (PointWiseV2)
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000018 Time: 4.37072
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000019 Time: 4.46669
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x000000000000001a Time: 4.49463
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x000000000000001b Time: 4.5075
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x000000000000001f Time: 4.36999
[06/10/2022-19:30:44] [V] [TRT] Fastest Tactic: 0x000000000000001f Time: 4.36999
[06/10/2022-19:30:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624), PWN(1039 + (Unnamed Layer* 884) [Shuffle], Mul_626)) (PointWise)
[06/10/2022-19:30:44] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:30:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001f
[06/10/2022-19:30:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:44] [V] [TRT] *************** Autotuning format combination: Float(8388608,512,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:30:44] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_627 (Shuffle)
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.551205
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.10182
[06/10/2022-19:30:44] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.551205
[06/10/2022-19:30:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:30:44] [V] [TRT] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************
[06/10/2022-19:30:44] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_627 (Shuffle)
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.29346
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.20235
[06/10/2022-19:30:44] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.29346
[06/10/2022-19:30:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:30:44] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 512 E0),E0) -> Float(128,1:4,128,128) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:30:44] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_627 (Shuffle)
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.29492
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.90452
[06/10/2022-19:30:44] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.29492
[06/10/2022-19:30:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:30:44] [V] [TRT] *************** Autotuning format combination: Float(8388608:32,512,1) -> Float(16,1:32,1,1) ***************
[06/10/2022-19:30:44] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_627 (Shuffle)
[06/10/2022-19:30:44] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.94868
[06/10/2022-19:30:45] [V] [TRT] Tactic: 0x0000000000000001 Time: 18.3673
[06/10/2022-19:30:45] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 2.94868
[06/10/2022-19:30:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:30:45] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:30:45] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(128,1,1,1) ***************
[06/10/2022-19:30:45] [V] [TRT] --------------- Timing Runner: MatMul_627 (CudaDepthwiseConvolution)
[06/10/2022-19:30:45] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:30:45] [V] [TRT] --------------- Timing Runner: MatMul_627 (FusedConvActConvolution)
[06/10/2022-19:30:45] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:31:21] [V] [TRT] --------------- Timing Runner: MatMul_627 (CudnnConvolution)
[06/10/2022-19:31:24] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.06715
[06/10/2022-19:31:43] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.90348
[06/10/2022-19:31:46] [V] [TRT] Tactic: 0x0000000000000002 Time: 5.22167
[06/10/2022-19:31:49] [V] [TRT] Tactic: 0x0000000000000038 Time: 1.06745
[06/10/2022-19:32:08] [V] [TRT] Tactic: 0x0000000000000039 Time: 2.9045
[06/10/2022-19:32:11] [V] [TRT] Tactic: 0x000000000000003a Time: 5.21128
[06/10/2022-19:32:13] [V] [TRT] Tactic: 0x0000000000000070 Time: 1.06672
[06/10/2022-19:32:29] [V] [TRT] Tactic: 0x0000000000000071 Time: 2.00368
[06/10/2022-19:32:31] [V] [TRT] Tactic: 0x0000000000000072 Time: 5.2243
[06/10/2022-19:32:31] [V] [TRT] Fastest Tactic: 0x0000000000000070 Time: 1.06672
[06/10/2022-19:32:31] [V] [TRT] --------------- Timing Runner: MatMul_627 (CublasConvolution)
[06/10/2022-19:32:31] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.677449
[06/10/2022-19:32:31] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.660334
[06/10/2022-19:32:31] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.529993
[06/10/2022-19:32:31] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.543013
[06/10/2022-19:32:31] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.529993
[06/10/2022-19:32:31] [V] [TRT] --------------- Timing Runner: MatMul_627 (CaskConvolution)
[06/10/2022-19:32:31] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a
[06/10/2022-19:32:31] [V] [TRT] Tactic: 0x1fc87d7eb370bb7a Time: 1.35812
[06/10/2022-19:32:31] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675
[06/10/2022-19:32:31] [V] [TRT] Tactic: 0x2ee10e11d6651675 Time: 1.66839
[06/10/2022-19:32:31] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:32:31] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 1.38021
[06/10/2022-19:32:31] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:32:31] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 1.2329
[06/10/2022-19:32:31] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338
[06/10/2022-19:32:31] [V] [TRT] Tactic: 0x7f0145cb49517338 Time: 0.918967
[06/10/2022-19:32:31] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd
[06/10/2022-19:32:31] [V] [TRT] Tactic: 0x865894c4635db7fd Time: 1.42
[06/10/2022-19:32:31] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x8e3884f0eaec3ecd Time: 1.38167
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x9808072e706def96 Time: 2.103
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x9cd5cdc35441c505 Time: 1.14293
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x9de226a0c44627c4 Time: 1.82228
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xa419b3b68f2da07b Time: 0.893947
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 2.08413
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 1.23626
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xc0b05b61d128e46e Time: 1.11835
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 1.39381
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xe5603263b7f00303 Time: 1.36938
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 1.28629
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 1.45832
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xfff46c7893896eb1 Time: 1.21593
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0xa419b3b68f2da07b Time: 0.893947
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000002
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512) -> Float(128,1,128,128) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: MatMul_627 (CublasConvolution)
[06/10/2022-19:32:32] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: MatMul_627 (CaskConvolution)
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 0.55808
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.399799
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 0.675401
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.659602
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 0.545353
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 0.709486
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 0.754103
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 0.721335
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 0.725285
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 0.726162
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 0.698807
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 0.727479
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.407991
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 0.675694
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 0.695589
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 0.628151
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 0.786432
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 0.616448
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 0.763465
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 0.728503
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 0.733477
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 0.399799
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: MatMul_627 (CublasConvolution)
[06/10/2022-19:32:32] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: MatMul_627 (CaskConvolution)
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.413842
[06/10/2022-19:32:32] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.410917
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x9dece0dc37e90462 Time: 0.410917
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9dece0dc37e90462
[06/10/2022-19:32:32] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_627 (Shuffle)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.141751
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.07186
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.141751
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_627 (Shuffle)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.3094
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 3.61106
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.3094
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_627 (Shuffle)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.30984
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 3.53397
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.30984
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_627 (Shuffle)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.0159
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.21449
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 4.21449
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:32:32] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1), Float(2097152,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: Add_629 (ElementWise)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.206272
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.206272
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: Add_629 (ElementWise)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.206555
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.206555
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1), Float(2097152:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: Add_629 (ElementWise)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.62948
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.62948
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:32] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: ReduceMean_630 (Reduce)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.1403
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0668114
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.105253
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.105179
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.111824
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.11125
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0668114
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:32:32] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1), Float(16384,1,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: Sub_631 (ElementWise)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.136997
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.136997
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: Sub_631 (ElementWise)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.137362
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.137362
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1), Float(16384:32,1,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: Sub_631 (ElementWise)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.06993
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.06993
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:32] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: PWN(1047 + (Unnamed Layer* 896) [Shuffle], Pow_633) (PointWiseV2)
[06/10/2022-19:32:32] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: PWN(1047 + (Unnamed Layer* 896) [Shuffle], Pow_633) (PointWise)
[06/10/2022-19:32:32] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: ReduceMean_634 (Reduce)
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.08339
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0664137
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.104448
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.103863
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.11147
[06/10/2022-19:32:32] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.111543
[06/10/2022-19:32:32] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0664137
[06/10/2022-19:32:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:32:32] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(16384,1,1), Float(2097152,128,1), Float(128,128,1), Float(128,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,128,1), Float(1,128,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636), Sqrt_637), Div_638), Mul_639), Add_640) (PointWiseV2)
[06/10/2022-19:32:32] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636), Sqrt_637), Div_638), Mul_639), Add_640) (PointWise)
[06/10/2022-19:32:32] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,128,1), Float(1:4,128,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(16384:32,1,1), Float(2097152:32,128,1), Float(128:32,128,1), Float(128:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 128 E0),E0) -> Float(524288,1:4,4096,32) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(131072,1,4096,128) ***************
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(32768,1:4,1024,32) ***************
[06/10/2022-19:32:32] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:32] [V] [TRT] *************** Autotuning format combination: Float(131072,1024,32,1), Float(2097152,128,1), Float(2097152,128,1), Int32() -> Float(2097152,128,1), Float(8388608,16384,128,1) ***************
[06/10/2022-19:32:32] [V] [TRT] --------------- Timing Runner: {ForeignNode[1126...Transpose_735 + Reshape_741]} (Myelin)
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.09749
[06/10/2022-19:32:44] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 7.09749
[06/10/2022-19:32:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: Conv_742 (CaskConvolution)
[06/10/2022-19:32:44] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(262144,16384:32,128,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(8388608,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753), Erf_754), PWN(1184 + (Unnamed Layer* 1069) [Shuffle], Add_756)), Mul_757), PWN(1187 + (Unnamed Layer* 1073) [Shuffle], Mul_759)) (PointWiseV2)
[06/10/2022-19:32:44] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753), Erf_754), PWN(1184 + (Unnamed Layer* 1069) [Shuffle], Add_756)), Mul_757), PWN(1187 + (Unnamed Layer* 1073) [Shuffle], Mul_759)) (PointWise)
[06/10/2022-19:32:44] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 512 E0) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(8388608:32,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(8388608,512,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 512 E0),E0) -> Float(128,1:4,128,128) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(8388608:32,512,1) -> Float(16,1:32,1,1) ***************
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(128,1,1,1) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512) -> Float(128,1,128,128) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1), Float(2097152,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: Add_762 (ElementWise)
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.207442
[06/10/2022-19:32:44] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.207442
[06/10/2022-19:32:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: Add_762 (ElementWise)
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.206117
[06/10/2022-19:32:44] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.206117
[06/10/2022-19:32:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1), Float(2097152:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: Add_762 (ElementWise)
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.62377
[06/10/2022-19:32:44] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.62377
[06/10/2022-19:32:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: ReduceMean_763 (Reduce)
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.05882
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0663162
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.10357
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.103205
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.111323
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.11147
[06/10/2022-19:32:44] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0663162
[06/10/2022-19:32:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1), Float(16384,1,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: Sub_764 (ElementWise)
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.137728
[06/10/2022-19:32:44] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.137728
[06/10/2022-19:32:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: Sub_764 (ElementWise)
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.13707
[06/10/2022-19:32:44] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.13707
[06/10/2022-19:32:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1), Float(16384:32,1,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: Sub_764 (ElementWise)
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.06379
[06/10/2022-19:32:44] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.06379
[06/10/2022-19:32:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: PWN(1195 + (Unnamed Layer* 1085) [Shuffle], Pow_766) (PointWiseV2)
[06/10/2022-19:32:44] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: PWN(1195 + (Unnamed Layer* 1085) [Shuffle], Pow_766) (PointWise)
[06/10/2022-19:32:44] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: ReduceMean_767 (Reduce)
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.02546
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0663162
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.103566
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.10379
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.111031
[06/10/2022-19:32:44] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.111397
[06/10/2022-19:32:44] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0663162
[06/10/2022-19:32:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(16384,1,1), Float(2097152,128,1), Float(128,128,1), Float(128,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,128,1), Float(1,128,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769), Sqrt_770), Div_771), Mul_772), Add_773) (PointWiseV2)
[06/10/2022-19:32:44] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769), Sqrt_770), Div_771), Mul_772), Add_773) (PointWise)
[06/10/2022-19:32:44] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,128,1), Float(1:4,128,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(16384:32,1,1), Float(2097152:32,128,1), Float(128:32,128,1), Float(128:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 128 E0),E0) -> Float(524288,1:4,4096,32) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(131072,1,4096,128) ***************
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(32768,1:4,1024,32) ***************
[06/10/2022-19:32:44] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:44] [V] [TRT] *************** Autotuning format combination: Float(131072,1024,32,1), Float(2097152,128,1), Float(2097152,128,1), Int32() -> Float(2097152,128,1), Float(8388608,16384,128,1) ***************
[06/10/2022-19:32:44] [V] [TRT] --------------- Timing Runner: {ForeignNode[1274...Transpose_868 + Reshape_874]} (Myelin)
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.095
[06/10/2022-19:32:56] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 7.095
[06/10/2022-19:32:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: Conv_875 (CaskConvolution)
[06/10/2022-19:32:56] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(262144,16384:32,128,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(8388608,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886), Erf_887), PWN(1332 + (Unnamed Layer* 1258) [Shuffle], Add_889)), Mul_890), PWN(1335 + (Unnamed Layer* 1262) [Shuffle], Mul_892)) (PointWiseV2)
[06/10/2022-19:32:56] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886), Erf_887), PWN(1332 + (Unnamed Layer* 1258) [Shuffle], Add_889)), Mul_890), PWN(1335 + (Unnamed Layer* 1262) [Shuffle], Mul_892)) (PointWise)
[06/10/2022-19:32:56] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 512 E0) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(8388608:32,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(8388608,512,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 512 E0),E0) -> Float(128,1:4,128,128) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(8388608:32,512,1) -> Float(16,1:32,1,1) ***************
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(128,1,1,1) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512) -> Float(128,1,128,128) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1), Float(2097152,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: Add_895 (ElementWise)
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.205531
[06/10/2022-19:32:56] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.205531
[06/10/2022-19:32:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: Add_895 (ElementWise)
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.205824
[06/10/2022-19:32:56] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.205824
[06/10/2022-19:32:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1), Float(2097152:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: Add_895 (ElementWise)
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.62245
[06/10/2022-19:32:56] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.62245
[06/10/2022-19:32:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: ReduceMean_896 (Reduce)
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.07535
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0664137
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.103643
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.103351
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.111177
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.111323
[06/10/2022-19:32:56] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0664137
[06/10/2022-19:32:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1), Float(16384,1,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: Sub_897 (ElementWise)
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.136935
[06/10/2022-19:32:56] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.136935
[06/10/2022-19:32:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: Sub_897 (ElementWise)
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.13685
[06/10/2022-19:32:56] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.13685
[06/10/2022-19:32:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1), Float(16384:32,1,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: Sub_897 (ElementWise)
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.06642
[06/10/2022-19:32:56] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.06642
[06/10/2022-19:32:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: PWN(1343 + (Unnamed Layer* 1274) [Shuffle], Pow_899) (PointWiseV2)
[06/10/2022-19:32:56] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: PWN(1343 + (Unnamed Layer* 1274) [Shuffle], Pow_899) (PointWise)
[06/10/2022-19:32:56] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: ReduceMean_900 (Reduce)
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.0575
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0663162
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.103205
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.103863
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.111177
[06/10/2022-19:32:56] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.11189
[06/10/2022-19:32:56] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0663162
[06/10/2022-19:32:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(16384,1,1), Float(2097152,128,1), Float(128,128,1), Float(128,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,128,1), Float(1,128,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902), Sqrt_903), Div_904), Mul_905), Add_906) (PointWiseV2)
[06/10/2022-19:32:56] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902), Sqrt_903), Div_904), Mul_905), Add_906) (PointWise)
[06/10/2022-19:32:56] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,128,1), Float(1:4,128,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(16384:32,1,1), Float(2097152:32,128,1), Float(128:32,128,1), Float(128:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 128 E0),E0) -> Float(524288,1:4,4096,32) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(131072,1024,32,1) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(131072,1,4096,128) ***************
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(32768,1:4,1024,32) ***************
[06/10/2022-19:32:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:32:56] [V] [TRT] *************** Autotuning format combination: Float(131072,1024,32,1), Float(2097152,128,1), Float(2097152,128,1), Int32() -> Float(2097152,128,1), Float(8388608,16384,128,1) ***************
[06/10/2022-19:32:56] [V] [TRT] --------------- Timing Runner: {ForeignNode[1422...Transpose_1001 + Reshape_1007]} (Myelin)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.09164
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 7.09164
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(8388608,1,65536,512) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(2097152,1:4,16384,128) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Conv_1008 (CaskConvolution)
[06/10/2022-19:33:09] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination:  -> Float(128,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(262144,16384:32,128,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(8388608,512,1) -> Float(8388608,512,1) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019), Erf_1020), PWN(1480 + (Unnamed Layer* 1447) [Shuffle], Add_1022)), Mul_1023), PWN(1483 + (Unnamed Layer* 1451) [Shuffle], Mul_1025)) (PointWiseV2)
[06/10/2022-19:33:09] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019), Erf_1020), PWN(1480 + (Unnamed Layer* 1447) [Shuffle], Add_1022)), Mul_1023), PWN(1483 + (Unnamed Layer* 1451) [Shuffle], Mul_1025)) (PointWise)
[06/10/2022-19:33:09] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 512 E0) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(8388608:32,512,1) -> Float(8388608:32,512,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(8388608,512,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 512 E0),E0) -> Float(128,1:4,128,128) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(8388608:32,512,1) -> Float(16,1:32,1,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(128,1,1,1) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512) -> Float(128,1,128,128) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128) -> Float(32,1:4,32,32) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(4,1:32,1,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1), Float(2097152,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Add_1028 (ElementWise)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.205678
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.205678
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Add_1028 (ElementWise)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.20597
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.20597
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1), Float(2097152:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Add_1028 (ElementWise)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.62465
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.62465
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: ReduceMean_1029 (Reduce)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.04141
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0661821
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.103058
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.103278
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.111189
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.111104
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0661821
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1), Float(16384,1,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Sub_1030 (ElementWise)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.137435
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.137435
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Sub_1030 (ElementWise)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.136464
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.136464
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1), Float(16384:32,1,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Sub_1030 (ElementWise)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.06364
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.06364
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: PWN(1491 + (Unnamed Layer* 1463) [Shuffle], Pow_1032) (PointWiseV2)
[06/10/2022-19:33:09] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: PWN(1491 + (Unnamed Layer* 1463) [Shuffle], Pow_1032) (PointWise)
[06/10/2022-19:33:09] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(16384,1,1) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: ReduceMean_1033 (Reduce)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.0386
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0664625
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.104229
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.10416
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.111835
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.112066
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0664625
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(16384,1,1), Float(2097152,128,1), Float(128,128,1), Float(128,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,128,1), Float(1,128,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 128 (# 0 (SHAPE input))) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035), Sqrt_1036), Div_1037), Mul_1038), Add_1039) (PointWiseV2)
[06/10/2022-19:33:09] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035), Sqrt_1036), Div_1037), Mul_1038), Add_1039) (PointWise)
[06/10/2022-19:33:09] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,128,1), Float(1:4,128,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 128 E0) ***************
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(16384:32,1,1), Float(2097152:32,128,1), Float(128:32,128,1), Float(128:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(2097152,16384,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Reshape_1044 + Transpose_1045 (Shuffle)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.204361
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.284818
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.204361
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2097152,1,16384,128) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Reshape_1044 + Transpose_1045 (Shuffle)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.608987
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.971337
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.608987
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 128 E0),E0) -> Float(524288,1:4,4096,32) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Reshape_1044 + Transpose_1045 (Shuffle)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.600795
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.10446
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.600795
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(65536,16384:32,128,1) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Reshape_1044 + Transpose_1045 (Shuffle)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.75192
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.10241
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.10241
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Conv_1046 (CudaDepthwiseConvolution)
[06/10/2022-19:33:09] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Conv_1046 (FusedConvActConvolution)
[06/10/2022-19:33:09] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Conv_1046 (CudnnConvolution)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.25776
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.585289
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000002 Time: 1.40888
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000005 Time: 11.8338
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000038 Time: 1.78132
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.724699
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x000000000000003a Time: 1.75909
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x000000000000003d Time: 11.7946
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000070 Time: 1.78147
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000071 Time: 1.39483
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000072 Time: 1.7032
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000075 Time: 11.902
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.585289
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Conv_1046 (CaskConvolution)
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x01cf8ce2da913006 Time: 1.58384
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x12dbf7d94ee3696d Time: 1.35153
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 1.02649
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x4727434768e46395 Time: 1.12333
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x4efce38acc876f5c Time: 1.17643
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 1.10446
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 0x5403ad713f811a18
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x5403ad713f811a18 Time: 1.13883
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x5aa723e0481da855 Time: 1.20847
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x5deb29b7a8e275f7 Time: 0.883127
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xa31d27de74b895ff Time: 1.04638
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 1.04682
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xbb8c3889c7eacd30 Time: 1.13591
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 1.51362
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 1.10928
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 0.952613
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x5deb29b7a8e275f7 Time: 0.883127
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0x0000000000000001
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Conv_1046 (CaskConvolution)
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 1.00118
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x1da91d865428f237 Time: 0.748398
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.921893
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 1.01873
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 1.00776
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x3f0c846d6379bc98 Time: 1.49972
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 0.953637
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 1.12361
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x62835fce994f06dd Time: 0.903314
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0x634e99502974e4da
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x634e99502974e4da Time: 1.1147
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.464018
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 1.13093
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x8014228ec08b4d49 Time: 1.0379
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x94a7db94ba744c45 Time: 1.0063
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x999e005e3b016ea6 Time: 0.422619
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xb443c221fcb1565b Time: 0.43008
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xbdfdef6b84f7ccc9 Time: 0.952027
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: 0xca7eeb8d9143d738
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xca7eeb8d9143d738 Time: 1.14644
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xd15dd11d64344e83 Time: 0.930523
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 1.13006
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xf48db81f02eca9ee Time: 0.777362
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 1.08061
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x999e005e3b016ea6 Time: 0.422619
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x999e005e3b016ea6
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(327680,1:4,5120,80) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Conv_1046 (CaskConvolution)
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.463579
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x999e005e3b016ea6 Time: 0.427301
[06/10/2022-19:33:09] [V] [TRT] Conv_1046 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0xb443c221fcb1565b Time: 0.44544
[06/10/2022-19:33:09] [V] [TRT] Fastest Tactic: 0x999e005e3b016ea6 Time: 0.427301
[06/10/2022-19:33:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x999e005e3b016ea6
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:33:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:09] [V] [TRT] *************** Autotuning format combination: Float(1310720,4096,64,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:33:09] [V] [TRT] --------------- Timing Runner: Reshape_1060 + Transpose_1061 (Shuffle)
[06/10/2022-19:33:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.126098
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.183296
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.126098
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720,1,20480,320) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: Reshape_1060 + Transpose_1061 (Shuffle)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.372882
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.238299
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.238299
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(327680,1:4,5120,80) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: Reshape_1060 + Transpose_1061 (Shuffle)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.354011
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.239616
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.239616
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(40960,4096:32,64,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: Reshape_1060 + Transpose_1061 (Shuffle)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.92999
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.693394
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.693394
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:33:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: ReduceMean_1062 (Reduce)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.275163
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0454217
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0748983
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0751909
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0861623
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0860891
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0454217
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:33:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(4096,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: Sub_1063 (ElementWise)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0871863
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0871863
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: Sub_1063 (ElementWise)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0889417
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0889417
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(4096:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: Sub_1063 (ElementWise)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.677888
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.677888
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(1526 + (Unnamed Layer* 1500) [Shuffle], Pow_1065) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0874789
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0912823
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0887954
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0925989
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0896571
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.0888686
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.096256
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0918674
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.091648
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.0897463
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001c Time: 0.0872594
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x000000000000001c Time: 0.0872594
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(1526 + (Unnamed Layer* 1500) [Shuffle], Pow_1065) (PointWise)
[06/10/2022-19:33:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001c
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(1526 + (Unnamed Layer* 1500) [Shuffle], Pow_1065) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(1526 + (Unnamed Layer* 1500) [Shuffle], Pow_1065) (PointWise)
[06/10/2022-19:33:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(1526 + (Unnamed Layer* 1500) [Shuffle], Pow_1065) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.440338
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.509074
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.492837
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.666025
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.676133
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.509659
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000006 Time: 1.05911
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.929207
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.814519
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.821687
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000a Time: 0.441637
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000b Time: 0.515657
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000c Time: 0.486839
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000d Time: 0.643803
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000e Time: 0.652142
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000f Time: 0.498674
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000010 Time: 0.935497
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000011 Time: 0.85899
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000012 Time: 0.718848
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000013 Time: 0.598601
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000014 Time: 0.407991
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000015 Time: 0.525605
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000016 Time: 0.672183
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000017 Time: 0.985381
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001c Time: 0.088576
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001d Time: 0.089088
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001e Time: 0.0850651
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 0.0850651
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(1526 + (Unnamed Layer* 1500) [Shuffle], Pow_1065) (PointWise)
[06/10/2022-19:33:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(1526 + (Unnamed Layer* 1500) [Shuffle], Pow_1065) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000018 Time: 0.687982
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000019 Time: 0.70656
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001a Time: 0.706853
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001b Time: 0.707909
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001f Time: 0.688421
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000018 Time: 0.687982
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(1526 + (Unnamed Layer* 1500) [Shuffle], Pow_1065) (PointWise)
[06/10/2022-19:33:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000018
[06/10/2022-19:33:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: ReduceMean_1066 (Reduce)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.268288
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.045312
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0746057
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0745326
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0858697
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.086016
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.045312
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:33:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(4096,1,1), Float(1310720,320,1), Float(320,320,1), Float(320,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071), Add_1072) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0933303
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0901851
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.089536
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0944274
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0921486
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.0915749
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.0993211
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0941486
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0934766
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.0928183
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001c Time: 0.0917051
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.089536
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071), Add_1072) (PointWise)
[06/10/2022-19:33:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000002
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,320,1), Float(1,320,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071), Add_1072) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071), Add_1072) (PointWise)
[06/10/2022-19:33:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,320,1), Float(1:4,320,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071), Add_1072) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.2803
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.65126
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 3.4872
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 2.88768
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000004 Time: 2.45921
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000005 Time: 2.46228
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000006 Time: 4.15043
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000007 Time: 2.91591
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 3.49711
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000009 Time: 4.37643
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000a Time: 1.20086
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000b Time: 1.45423
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000c Time: 1.46988
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000d Time: 1.71593
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000e Time: 1.88533
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000000f Time: 1.23804
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000010 Time: 2.38753
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000011 Time: 2.32053
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000012 Time: 1.88284
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000013 Time: 1.78629
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000014 Time: 0.794624
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000015 Time: 1.00162
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000016 Time: 1.1795
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000017 Time: 1.53863
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001c Time: 0.0892297
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001d Time: 0.0863223
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001e Time: 0.103424
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x000000000000001d Time: 0.0863223
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071), Add_1072) (PointWise)
[06/10/2022-19:33:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001d
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(4096:32,1,1), Float(1310720:32,320,1), Float(320:32,320,1), Float(320:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071), Add_1072) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000018 Time: 0.677595
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000019 Time: 0.697929
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001a Time: 0.708462
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001b Time: 0.714167
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001f Time: 0.693394
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000018 Time: 0.677595
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071), Add_1072) (PointWise)
[06/10/2022-19:33:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000018
[06/10/2022-19:33:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: ReduceMean_1073 (Reduce)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.299447
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0456777
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0765074
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0760686
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.08704
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0876251
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0456777
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:33:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(4096,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: Sub_1074 (ElementWise)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0877714
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0877714
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: Sub_1074 (ElementWise)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0900389
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0900389
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(4096:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: Sub_1074 (ElementWise)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.685957
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.685957
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:33:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(1537 + (Unnamed Layer* 1517) [Shuffle], Pow_1076) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(1537 + (Unnamed Layer* 1517) [Shuffle], Pow_1076) (PointWise)
[06/10/2022-19:33:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: ReduceMean_1077 (Reduce)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.296521
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0456046
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0758491
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0762743
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.087552
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.087552
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0456046
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:33:10] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(4096,1,1), Float(1310720,320,1), Float(320,320,1), Float(320,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082), Add_1083) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0979383
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0912823
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0892343
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0953189
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0923794
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.0920137
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.101083
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0941349
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0936229
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.0935497
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x000000000000001c Time: 0.0941349
[06/10/2022-19:33:10] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0892343
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082), Add_1083) (PointWise)
[06/10/2022-19:33:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000002
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,320,1), Float(1,320,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082), Add_1083) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082), Add_1083) (PointWise)
[06/10/2022-19:33:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:10] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,320,1), Float(1:4,320,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:33:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082), Add_1083) (PointWiseV2)
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.41752
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.67659
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000002 Time: 3.51188
[06/10/2022-19:33:10] [V] [TRT] Tactic: 0x0000000000000003 Time: 2.91196
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000004 Time: 2.49534
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000005 Time: 2.51553
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000006 Time: 4.27037
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000007 Time: 2.95336
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000008 Time: 3.39544
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000009 Time: 4.34044
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000000a Time: 1.22427
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000000b Time: 1.44048
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000000c Time: 1.46447
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000000d Time: 1.70452
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000000e Time: 1.92219
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000000f Time: 1.25513
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000010 Time: 2.26202
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000011 Time: 2.29274
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000012 Time: 1.88153
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000013 Time: 1.78629
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000014 Time: 0.794624
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000015 Time: 1.00162
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000016 Time: 1.17979
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000017 Time: 1.53863
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000001c Time: 0.0893074
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000001d Time: 0.0863086
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000001e Time: 0.103424
[06/10/2022-19:33:11] [V] [TRT] Fastest Tactic: 0x000000000000001d Time: 0.0863086
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082), Add_1083) (PointWise)
[06/10/2022-19:33:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001d
[06/10/2022-19:33:11] [V] [TRT] *************** Autotuning format combination: Float(4096:32,1,1), Float(1310720:32,320,1), Float(320:32,320,1), Float(320:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082), Add_1083) (PointWiseV2)
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000018 Time: 0.676864
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000019 Time: 0.697637
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000001a Time: 0.708288
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000001b Time: 0.715045
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000001f Time: 0.685641
[06/10/2022-19:33:11] [V] [TRT] Fastest Tactic: 0x0000000000000018 Time: 0.676864
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082), Add_1083) (PointWise)
[06/10/2022-19:33:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000018
[06/10/2022-19:33:11] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:11] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: Transpose_1105 + Reshape_1111 (Shuffle)
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.140581
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.183589
[06/10/2022-19:33:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.140581
[06/10/2022-19:33:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:11] [V] [TRT] *************** Autotuning format combination: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: Transpose_1105 + Reshape_1111 (Shuffle)
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.306322
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.719579
[06/10/2022-19:33:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.306322
[06/10/2022-19:33:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:11] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 320 E0),E0) -> Float(327680,1:4,5120,80) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: Transpose_1105 + Reshape_1111 (Shuffle)
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.304274
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.757321
[06/10/2022-19:33:11] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.304274
[06/10/2022-19:33:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:11] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: Transpose_1105 + Reshape_1111 (Shuffle)
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.917797
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.762002
[06/10/2022-19:33:11] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.762002
[06/10/2022-19:33:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:33:11] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:11] [V] [TRT] *************** Autotuning format combination: Float(1310720,4096,64,1) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: Conv_1112 (CudaDepthwiseConvolution)
[06/10/2022-19:33:11] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: Conv_1112 (FusedConvActConvolution)
[06/10/2022-19:33:11] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: Conv_1112 (CudnnConvolution)
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.414281
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.263168
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.475721
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000005 Time: 11.7819
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000038 Time: 0.684617
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.376539
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000003a Time: 0.637513
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x000000000000003d Time: 10.8311
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000070 Time: 0.591726
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000071 Time: 0.455095
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000072 Time: 0.64
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x0000000000000075 Time: 10.4575
[06/10/2022-19:33:11] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.263168
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: Conv_1112 (CaskConvolution)
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x12dbf7d94ee3696d Time: 0.696174
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 0.511561
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 0.571538
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x5aa723e0481da855 Time: 0.538039
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x9808072e706def96 Time: 0.399067
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xa31d27de74b895ff Time: 0.361472
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 0.47221
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 0.440466
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xbb8c3889c7eacd30 Time: 0.421303
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 0.319488
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 0.479232
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 0.403602
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 0.371566
[06/10/2022-19:33:11] [V] [TRT] Fastest Tactic: 0xc3cf6e1d1c6aff27 Time: 0.319488
[06/10/2022-19:33:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0x0000000000000001
[06/10/2022-19:33:11] [V] [TRT] *************** Autotuning format combination: Float(1310720,1,20480,320) -> Float(327680,1,10240,320) ***************
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: Conv_1112 (CaskConvolution)
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 0.410185
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 0.291547
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x1da91d865428f237 Time: 0.264338
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.31861
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 0.308078
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 0.301495
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 0.312613
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 0.404919
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x62835fce994f06dd Time: 0.264485
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.148919
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 0.373029
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x8014228ec08b4d49 Time: 0.320951
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 0.277943
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xb443c221fcb1565b Time: 0.145847
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 0.29696
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 0.405504
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 0.375369
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 0.379173
[06/10/2022-19:33:11] [V] [TRT] Fastest Tactic: 0xb443c221fcb1565b Time: 0.145847
[06/10/2022-19:33:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xb443c221fcb1565b
[06/10/2022-19:33:11] [V] [TRT] *************** Autotuning format combination: Float(327680,1:4,5120,80) -> Float(81920,1:4,2560,80) ***************
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: Conv_1112 (CaskConvolution)
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.151429
[06/10/2022-19:33:11] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:33:11] [V] [TRT] Tactic: 0xb443c221fcb1565b Time: 0.146286
[06/10/2022-19:33:11] [V] [TRT] Fastest Tactic: 0xb443c221fcb1565b Time: 0.146286
[06/10/2022-19:33:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xb443c221fcb1565b
[06/10/2022-19:33:11] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:11] [V] [TRT] *************** Autotuning format combination: Float(327680,1024,32,1), Float(1310720,320,1), Float(1310720,320,1), Int32() -> Float(1310720,320,1), Float(5242880,4096,64,1) ***************
[06/10/2022-19:33:11] [V] [TRT] --------------- Timing Runner: {ForeignNode[1616...Transpose_1178 + Reshape_1184]} (Myelin)
[06/10/2022-19:33:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.73381
[06/10/2022-19:33:25] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 4.73381
[06/10/2022-19:33:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:33:25] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:25] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:33:25] [V] [TRT] --------------- Timing Runner: Conv_1185 (CudaDepthwiseConvolution)
[06/10/2022-19:33:25] [V] [TRT] Tactic: 0xffffffffffffffff Time: 0.373029
[06/10/2022-19:33:25] [V] [TRT] Fastest Tactic: 0xffffffffffffffff Time: 0.373029
[06/10/2022-19:33:25] [V] [TRT] --------------- Timing Runner: Conv_1185 (CudnnConvolution)
[06/10/2022-19:33:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.705979
[06/10/2022-19:33:25] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.704512
[06/10/2022-19:33:25] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.857088
[06/10/2022-19:33:25] [V] [TRT] Tactic: 0x0000000000000004 Time: 67.5514
[06/10/2022-19:33:26] [V] [TRT] Tactic: 0x0000000000000005 Time: 113.768
[06/10/2022-19:33:26] [V] [TRT] Tactic: 0x0000000000000006 Time: 27.15
[06/10/2022-19:33:26] [V] [TRT] Tactic: 0x0000000000000038 Time: 0.705682
[06/10/2022-19:33:26] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.706121
[06/10/2022-19:33:26] [V] [TRT] Tactic: 0x000000000000003a Time: 0.851237
[06/10/2022-19:33:27] [V] [TRT] Tactic: 0x000000000000003c Time: 67.3062
[06/10/2022-19:33:28] [V] [TRT] Tactic: 0x000000000000003d Time: 107.819
[06/10/2022-19:33:28] [V] [TRT] Tactic: 0x000000000000003e Time: 27.284
[06/10/2022-19:33:28] [V] [TRT] Tactic: 0x0000000000000070 Time: 0.70656
[06/10/2022-19:33:28] [V] [TRT] Tactic: 0x0000000000000071 Time: 0.704512
[06/10/2022-19:33:28] [V] [TRT] Tactic: 0x0000000000000072 Time: 0.857673
[06/10/2022-19:33:29] [V] [TRT] Tactic: 0x0000000000000074 Time: 67.1867
[06/10/2022-19:33:29] [V] [TRT] Tactic: 0x0000000000000075 Time: 107.691
[06/10/2022-19:33:30] [V] [TRT] Tactic: 0x0000000000000076 Time: 27.1307
[06/10/2022-19:33:30] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.704512
[06/10/2022-19:33:30] [V] [TRT] --------------- Timing Runner: Conv_1185 (CaskConvolution)
[06/10/2022-19:33:30] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006
[06/10/2022-19:33:30] [V] [TRT] Tactic: 0x01cf8ce2da913006 Time: 25.7015
[06/10/2022-19:33:30] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d
[06/10/2022-19:33:30] [V] [TRT] Tactic: 0x12dbf7d94ee3696d Time: 15.7593
[06/10/2022-19:33:30] [V] [TRT] Conv_1185 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:33:30] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 12.796
[06/10/2022-19:33:30] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395
[06/10/2022-19:33:30] [V] [TRT] Tactic: 0x4727434768e46395 Time: 14.9898
[06/10/2022-19:33:30] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c
[06/10/2022-19:33:31] [V] [TRT] Tactic: 0x4efce38acc876f5c Time: 24.1929
[06/10/2022-19:33:31] [V] [TRT] Conv_1185 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:33:31] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 18.1045
[06/10/2022-19:33:31] [V] [TRT] Conv_1185 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 0x5403ad713f811a18
[06/10/2022-19:33:31] [V] [TRT] Tactic: 0x5403ad713f811a18 Time: 23.2676
[06/10/2022-19:33:31] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:33:31] [V] [TRT] Tactic: 0x5aa723e0481da855 Time: 26.2495
[06/10/2022-19:33:31] [V] [TRT] Conv_1185 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7
[06/10/2022-19:33:31] [V] [TRT] Tactic: 0x5deb29b7a8e275f7 Time: 12.8748
[06/10/2022-19:33:32] [V] [TRT] Conv_1185 Set Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a
[06/10/2022-19:33:32] [V] [TRT] Tactic: 0x94119b4c514b211a Time: 13.783
[06/10/2022-19:33:32] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff
[06/10/2022-19:33:32] [V] [TRT] Tactic: 0xa31d27de74b895ff Time: 15.4074
[06/10/2022-19:33:32] [V] [TRT] Conv_1185 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:33:32] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 10.7772
[06/10/2022-19:33:32] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30
[06/10/2022-19:33:32] [V] [TRT] Tactic: 0xbb8c3889c7eacd30 Time: 25.5634
[06/10/2022-19:33:32] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:33:32] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 17.402
[06/10/2022-19:33:32] [V] [TRT] Conv_1185 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:33:33] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 18.3167
[06/10/2022-19:33:33] [V] [TRT] Conv_1185 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:33:33] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 13.0008
[06/10/2022-19:33:33] [V] [TRT] Fastest Tactic: 0xa8609adc4e0ceb90 Time: 10.7772
[06/10/2022-19:33:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: 0xffffffffffffffff
[06/10/2022-19:33:33] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:33:33] [V] [TRT] --------------- Timing Runner: Conv_1185 (CaskConvolution)
[06/10/2022-19:33:33] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:33:33] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 29.9631
[06/10/2022-19:33:33] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237
[06/10/2022-19:33:33] [V] [TRT] Tactic: 0x1da91d865428f237 Time: 25.6664
[06/10/2022-19:33:33] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98
[06/10/2022-19:33:35] [V] [TRT] Tactic: 0x3f0c846d6379bc98 Time: 199.245
[06/10/2022-19:33:35] [V] [TRT] Conv_1185 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf2
[06/10/2022-19:33:35] [V] [TRT] Tactic: 0x5030121339a48bf2 Time: 32.474
[06/10/2022-19:33:35] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd
[06/10/2022-19:33:35] [V] [TRT] Tactic: 0x62835fce994f06dd Time: 27.8974
[06/10/2022-19:33:35] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49
[06/10/2022-19:33:36] [V] [TRT] Tactic: 0x8014228ec08b4d49 Time: 30.3401
[06/10/2022-19:33:36] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45
[06/10/2022-19:33:36] [V] [TRT] Tactic: 0x94a7db94ba744c45 Time: 27.8603
[06/10/2022-19:33:36] [V] [TRT] Conv_1185 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: 0xca7eeb8d9143d739
[06/10/2022-19:33:36] [V] [TRT] Tactic: 0xca7eeb8d9143d739 Time: 33.0348
[06/10/2022-19:33:36] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0xd15dd11d64344e83 Time: 45.2759
[06/10/2022-19:33:37] [V] [TRT] Conv_1185 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf50
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0xd9031472c05adf50 Time: 32.7234
[06/10/2022-19:33:37] [V] [TRT] Conv_1185 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0xf48db81f02eca9ee Time: 24.8478
[06/10/2022-19:33:37] [V] [TRT] Fastest Tactic: 0xf48db81f02eca9ee Time: 24.8478
[06/10/2022-19:33:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xf48db81f02eca9ee
[06/10/2022-19:33:37] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:33:37] [V] [TRT] --------------- Timing Runner: Conv_1185 (CaskConvolution)
[06/10/2022-19:33:37] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:33:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:37] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:33:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:37] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:33:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:37] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:33:37] [V] [TRT] --------------- Timing Runner: Reshape_1193 + Transpose_1194 (Shuffle)
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.467968
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.698075
[06/10/2022-19:33:37] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.467968
[06/10/2022-19:33:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:37] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:33:37] [V] [TRT] --------------- Timing Runner: Reshape_1193 + Transpose_1194 (Shuffle)
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.38811
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.905947
[06/10/2022-19:33:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.905947
[06/10/2022-19:33:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:33:37] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:33:37] [V] [TRT] --------------- Timing Runner: Reshape_1193 + Transpose_1194 (Shuffle)
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.4039
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.906825
[06/10/2022-19:33:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.906825
[06/10/2022-19:33:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:33:37] [V] [TRT] *************** Autotuning format combination: Float(163840,4096:32,64,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:33:37] [V] [TRT] --------------- Timing Runner: Reshape_1193 + Transpose_1194 (Shuffle)
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 26.8259
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.7066
[06/10/2022-19:33:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.7066
[06/10/2022-19:33:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:33:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:37] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:33:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200), PWN(1677 + (Unnamed Layer* 1694) [Shuffle], Mul_1202)) (PointWiseV2)
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.336603
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.351525
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.343771
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.357815
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.347721
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.347282
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.372297
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.356352
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.356352
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.352695
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x000000000000001c Time: 0.333093
[06/10/2022-19:33:37] [V] [TRT] Fastest Tactic: 0x000000000000001c Time: 0.333093
[06/10/2022-19:33:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200), PWN(1677 + (Unnamed Layer* 1694) [Shuffle], Mul_1202)) (PointWise)
[06/10/2022-19:33:37] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001c
[06/10/2022-19:33:37] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 1280 (# 0 (SHAPE input))) ***************
[06/10/2022-19:33:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200), PWN(1677 + (Unnamed Layer* 1694) [Shuffle], Mul_1202)) (PointWiseV2)
[06/10/2022-19:33:37] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:33:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200), PWN(1677 + (Unnamed Layer* 1694) [Shuffle], Mul_1202)) (PointWise)
[06/10/2022-19:33:37] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:37] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 1280 E0) ***************
[06/10/2022-19:33:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200), PWN(1677 + (Unnamed Layer* 1694) [Shuffle], Mul_1202)) (PointWiseV2)
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.61372
[06/10/2022-19:33:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 7.01762
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000002 Time: 6.84924
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000003 Time: 7.57746
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000004 Time: 7.71204
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000005 Time: 7.30185
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000006 Time: 8.85994
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000007 Time: 8.89607
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000008 Time: 8.72463
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000009 Time: 8.62618
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x000000000000000a Time: 3.94913
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x000000000000000b Time: 4.70075
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x000000000000000c Time: 4.41593
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x000000000000000d Time: 5.20398
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x000000000000000e Time: 5.29584
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x000000000000000f Time: 4.61458
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000010 Time: 6.14181
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000011 Time: 6.22885
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000012 Time: 5.821
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000013 Time: 5.15335
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000014 Time: 2.54392
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000015 Time: 2.83019
[06/10/2022-19:33:38] [V] [TRT] Tactic: 0x0000000000000016 Time: 3.37042
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x0000000000000017 Time: 4.28354
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x000000000000001c Time: 0.346258
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x000000000000001d Time: 0.342309
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x000000000000001e Time: 0.348891
[06/10/2022-19:33:39] [V] [TRT] Fastest Tactic: 0x000000000000001d Time: 0.342309
[06/10/2022-19:33:39] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200), PWN(1677 + (Unnamed Layer* 1694) [Shuffle], Mul_1202)) (PointWise)
[06/10/2022-19:33:39] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001d
[06/10/2022-19:33:39] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:33:39] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200), PWN(1677 + (Unnamed Layer* 1694) [Shuffle], Mul_1202)) (PointWiseV2)
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x0000000000000018 Time: 2.73876
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x0000000000000019 Time: 2.80737
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x000000000000001a Time: 2.81249
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x000000000000001b Time: 2.82346
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x000000000000001f Time: 2.73437
[06/10/2022-19:33:39] [V] [TRT] Fastest Tactic: 0x000000000000001f Time: 2.73437
[06/10/2022-19:33:39] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200), PWN(1677 + (Unnamed Layer* 1694) [Shuffle], Mul_1202)) (PointWise)
[06/10/2022-19:33:39] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:33:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001f
[06/10/2022-19:33:39] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:39] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:33:39] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_1203 (Shuffle)
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.345966
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.691346
[06/10/2022-19:33:39] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.345966
[06/10/2022-19:33:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:39] [V] [TRT] *************** Autotuning format combination: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:33:39] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_1203 (Shuffle)
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.804425
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.61281
[06/10/2022-19:33:39] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.804425
[06/10/2022-19:33:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:39] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 1280 E0),E0) -> Float(320,1:4,320,320) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:33:39] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_1203 (Shuffle)
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.804722
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x0000000000000001 Time: 3.0325
[06/10/2022-19:33:39] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.804722
[06/10/2022-19:33:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:39] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(40,1:32,1,1) ***************
[06/10/2022-19:33:39] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_1203 (Shuffle)
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.84656
[06/10/2022-19:33:39] [V] [TRT] Tactic: 0x0000000000000001 Time: 11.8253
[06/10/2022-19:33:39] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.84656
[06/10/2022-19:33:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:33:39] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:33:39] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:33:39] [V] [TRT] --------------- Timing Runner: MatMul_1203 (CudaDepthwiseConvolution)
[06/10/2022-19:33:39] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:33:39] [V] [TRT] --------------- Timing Runner: MatMul_1203 (FusedConvActConvolution)
[06/10/2022-19:33:39] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:33:46] [V] [TRT] --------------- Timing Runner: MatMul_1203 (CudnnConvolution)
[06/10/2022-19:33:46] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.47766
[06/10/2022-19:33:50] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.44297
[06/10/2022-19:33:51] [V] [TRT] Tactic: 0x0000000000000002 Time: 3.03994
[06/10/2022-19:33:52] [V] [TRT] Tactic: 0x0000000000000005 Time: 68.4899
[06/10/2022-19:33:52] [V] [TRT] Tactic: 0x0000000000000038 Time: 4.47254
[06/10/2022-19:33:56] [V] [TRT] Tactic: 0x0000000000000039 Time: 2.44122
[06/10/2022-19:33:57] [V] [TRT] Tactic: 0x000000000000003a Time: 3.04655
[06/10/2022-19:33:58] [V] [TRT] Tactic: 0x000000000000003d Time: 68.1753
[06/10/2022-19:33:58] [V] [TRT] Tactic: 0x0000000000000070 Time: 4.47912
[06/10/2022-19:33:59] [V] [TRT] Tactic: 0x0000000000000071 Time: 4.47547
[06/10/2022-19:34:00] [V] [TRT] Tactic: 0x0000000000000072 Time: 3.03952
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x0000000000000075 Time: 68.0464
[06/10/2022-19:34:01] [V] [TRT] Fastest Tactic: 0x0000000000000039 Time: 2.44122
[06/10/2022-19:34:01] [V] [TRT] --------------- Timing Runner: MatMul_1203 (CublasConvolution)
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.24431
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.1991
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.559835
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.557934
[06/10/2022-19:34:01] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 0.557934
[06/10/2022-19:34:01] [V] [TRT] --------------- Timing Runner: MatMul_1203 (CaskConvolution)
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x1fc87d7eb370bb7a Time: 2.21096
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x2ee10e11d6651675 Time: 2.20877
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 2.74505
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 2.19677
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x7f0145cb49517338 Time: 1.29375
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x865894c4635db7fd Time: 1.93448
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x8e3884f0eaec3ecd Time: 1.89162
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x9808072e706def96 Time: 3.14865
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x9cd5cdc35441c505 Time: 1.6346
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x9de226a0c44627c4 Time: 2.0951
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xa419b3b68f2da07b Time: 1.28951
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 3.12715
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 2.15245
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xc0b05b61d128e46e Time: 1.61602
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 2.89865
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xe5603263b7f00303 Time: 2.01128
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 2.32082
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 2.76919
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xfff46c7893896eb1 Time: 1.78015
[06/10/2022-19:34:01] [V] [TRT] Fastest Tactic: 0xa419b3b68f2da07b Time: 1.28951
[06/10/2022-19:34:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000003
[06/10/2022-19:34:01] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1280,1280) -> Float(320,1,320,320) ***************
[06/10/2022-19:34:01] [V] [TRT] --------------- Timing Runner: MatMul_1203 (CublasConvolution)
[06/10/2022-19:34:01] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:34:01] [V] [TRT] --------------- Timing Runner: MatMul_1203 (CaskConvolution)
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 0.900827
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.39307
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 1.15024
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.996937
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 0.785701
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 1.2781
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 1.292
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 1.11528
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 1.37157
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 1.10826
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 1.26976
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 1.10548
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.457143
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 0.982162
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 1.17921
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 1.0496
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 1.23451
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 0.852846
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 1.34173
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 1.25016
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 1.25747
[06/10/2022-19:34:01] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 0.39307
[06/10/2022-19:34:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:34:01] [V] [TRT] *************** Autotuning format combination: Float(320,1:4,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:34:01] [V] [TRT] --------------- Timing Runner: MatMul_1203 (CublasConvolution)
[06/10/2022-19:34:01] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:34:01] [V] [TRT] --------------- Timing Runner: MatMul_1203 (CaskConvolution)
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.448219
[06/10/2022-19:34:01] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.44661
[06/10/2022-19:34:01] [V] [TRT] Fastest Tactic: 0x9dece0dc37e90462 Time: 0.44661
[06/10/2022-19:34:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9dece0dc37e90462
[06/10/2022-19:34:01] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:01] [V] [TRT] *************** Autotuning format combination: Float(320,1,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:01] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_1203 (Shuffle)
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0895269
[06/10/2022-19:34:01] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.184905
[06/10/2022-19:34:01] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0895269
[06/10/2022-19:34:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:34:01] [V] [TRT] *************** Autotuning format combination: Float(320,1,320,320) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:34:01] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_1203 (Shuffle)
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.366299
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.183296
[06/10/2022-19:34:02] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.183296
[06/10/2022-19:34:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(80,1:4,80,80) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_1203 (Shuffle)
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.366007
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.54084
[06/10/2022-19:34:02] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.366007
[06/10/2022-19:34:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(10,1:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_1203 (Shuffle)
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.8883
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.64002
[06/10/2022-19:34:02] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.64002
[06/10/2022-19:34:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:34:02] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: Add_1205 (ElementWise)
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.13064
[06/10/2022-19:34:02] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.13064
[06/10/2022-19:34:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: Add_1205 (ElementWise)
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.131161
[06/10/2022-19:34:02] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.131161
[06/10/2022-19:34:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: Add_1205 (ElementWise)
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.01976
[06/10/2022-19:34:02] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.01976
[06/10/2022-19:34:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:02] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: ReduceMean_1206 (Reduce)
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.286135
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0454583
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.075264
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0756297
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0864549
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0862354
[06/10/2022-19:34:02] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0454583
[06/10/2022-19:34:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:34:02] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(4096,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: Sub_1207 (ElementWise)
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0873326
[06/10/2022-19:34:02] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0873326
[06/10/2022-19:34:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: Sub_1207 (ElementWise)
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0891611
[06/10/2022-19:34:02] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0891611
[06/10/2022-19:34:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(4096:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: Sub_1207 (ElementWise)
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.680082
[06/10/2022-19:34:02] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.680082
[06/10/2022-19:34:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:02] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: PWN(1685 + (Unnamed Layer* 1706) [Shuffle], Pow_1209) (PointWiseV2)
[06/10/2022-19:34:02] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: PWN(1685 + (Unnamed Layer* 1706) [Shuffle], Pow_1209) (PointWise)
[06/10/2022-19:34:02] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:02] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: ReduceMean_1210 (Reduce)
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.281746
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0453486
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0754834
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0752709
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0863817
[06/10/2022-19:34:02] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.086304
[06/10/2022-19:34:02] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0453486
[06/10/2022-19:34:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:34:02] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(4096,1,1), Float(1310720,320,1), Float(320,320,1), Float(320,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,320,1), Float(1,320,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212), Sqrt_1213), Div_1214), Mul_1215), Add_1216) (PointWiseV2)
[06/10/2022-19:34:02] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212), Sqrt_1213), Div_1214), Mul_1215), Add_1216) (PointWise)
[06/10/2022-19:34:02] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,320,1), Float(1:4,320,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(4096:32,1,1), Float(1310720:32,320,1), Float(320:32,320,1), Float(320:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:02] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 320 E0),E0) -> Float(327680,1:4,5120,80) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:34:02] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720,4096,64,1) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(1310720,1,20480,320) -> Float(327680,1,10240,320) ***************
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(327680,1:4,5120,80) -> Float(81920,1:4,2560,80) ***************
[06/10/2022-19:34:02] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:02] [V] [TRT] *************** Autotuning format combination: Float(327680,1024,32,1), Float(1310720,320,1), Float(1310720,320,1), Int32() -> Float(1310720,320,1), Float(5242880,4096,64,1) ***************
[06/10/2022-19:34:02] [V] [TRT] --------------- Timing Runner: {ForeignNode[1764...Transpose_1311 + Reshape_1317]} (Myelin)
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.70104
[06/10/2022-19:34:15] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 4.70104
[06/10/2022-19:34:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: Conv_1318 (CaskConvolution)
[06/10/2022-19:34:15] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(163840,4096:32,64,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 1280 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329), Erf_1330), PWN(1822 + (Unnamed Layer* 1879) [Shuffle], Add_1332)), Mul_1333), PWN(1825 + (Unnamed Layer* 1883) [Shuffle], Mul_1335)) (PointWiseV2)
[06/10/2022-19:34:15] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329), Erf_1330), PWN(1822 + (Unnamed Layer* 1879) [Shuffle], Add_1332)), Mul_1333), PWN(1825 + (Unnamed Layer* 1883) [Shuffle], Mul_1335)) (PointWise)
[06/10/2022-19:34:15] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 1280 E0) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 1280 E0),E0) -> Float(320,1:4,320,320) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(40,1:32,1,1) ***************
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1280,1280) -> Float(320,1,320,320) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(320,1:4,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(320,1,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(320,1,320,320) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(80,1:4,80,80) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(10,1:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: Add_1338 (ElementWise)
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.131298
[06/10/2022-19:34:15] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.131298
[06/10/2022-19:34:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: Add_1338 (ElementWise)
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.131877
[06/10/2022-19:34:15] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.131877
[06/10/2022-19:34:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: Add_1338 (ElementWise)
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.02034
[06/10/2022-19:34:15] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.02034
[06/10/2022-19:34:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: ReduceMean_1339 (Reduce)
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.272384
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0452754
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0746789
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0748251
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0859977
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0860937
[06/10/2022-19:34:15] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0452754
[06/10/2022-19:34:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(4096,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: Sub_1340 (ElementWise)
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.08704
[06/10/2022-19:34:15] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.08704
[06/10/2022-19:34:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: Sub_1340 (ElementWise)
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.088576
[06/10/2022-19:34:15] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.088576
[06/10/2022-19:34:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(4096:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: Sub_1340 (ElementWise)
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.674816
[06/10/2022-19:34:15] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.674816
[06/10/2022-19:34:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: PWN(1833 + (Unnamed Layer* 1895) [Shuffle], Pow_1342) (PointWiseV2)
[06/10/2022-19:34:15] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: PWN(1833 + (Unnamed Layer* 1895) [Shuffle], Pow_1342) (PointWise)
[06/10/2022-19:34:15] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: ReduceMean_1343 (Reduce)
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.266094
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0452023
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.074752
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0743863
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0858697
[06/10/2022-19:34:15] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0855771
[06/10/2022-19:34:15] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0452023
[06/10/2022-19:34:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(4096,1,1), Float(1310720,320,1), Float(320,320,1), Float(320,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,320,1), Float(1,320,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345), Sqrt_1346), Div_1347), Mul_1348), Add_1349) (PointWiseV2)
[06/10/2022-19:34:15] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345), Sqrt_1346), Div_1347), Mul_1348), Add_1349) (PointWise)
[06/10/2022-19:34:15] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,320,1), Float(1:4,320,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(4096:32,1,1), Float(1310720:32,320,1), Float(320:32,320,1), Float(320:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 320 E0),E0) -> Float(327680,1:4,5120,80) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720,4096,64,1) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(1310720,1,20480,320) -> Float(327680,1,10240,320) ***************
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(327680,1:4,5120,80) -> Float(81920,1:4,2560,80) ***************
[06/10/2022-19:34:15] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:15] [V] [TRT] *************** Autotuning format combination: Float(327680,1024,32,1), Float(1310720,320,1), Float(1310720,320,1), Int32() -> Float(1310720,320,1), Float(5242880,4096,64,1) ***************
[06/10/2022-19:34:15] [V] [TRT] --------------- Timing Runner: {ForeignNode[1912...Transpose_1444 + Reshape_1450]} (Myelin)
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.72327
[06/10/2022-19:34:28] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 4.72327
[06/10/2022-19:34:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: Conv_1451 (CaskConvolution)
[06/10/2022-19:34:28] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(163840,4096:32,64,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 1280 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462), Erf_1463), PWN(1970 + (Unnamed Layer* 2068) [Shuffle], Add_1465)), Mul_1466), PWN(1973 + (Unnamed Layer* 2072) [Shuffle], Mul_1468)) (PointWiseV2)
[06/10/2022-19:34:28] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462), Erf_1463), PWN(1970 + (Unnamed Layer* 2068) [Shuffle], Add_1465)), Mul_1466), PWN(1973 + (Unnamed Layer* 2072) [Shuffle], Mul_1468)) (PointWise)
[06/10/2022-19:34:28] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 1280 E0) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 1280 E0),E0) -> Float(320,1:4,320,320) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(40,1:32,1,1) ***************
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1280,1280) -> Float(320,1,320,320) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(320,1:4,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(320,1,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(320,1,320,320) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(80,1:4,80,80) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(10,1:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: Add_1471 (ElementWise)
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.130633
[06/10/2022-19:34:28] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.130633
[06/10/2022-19:34:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: Add_1471 (ElementWise)
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.131291
[06/10/2022-19:34:28] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.131291
[06/10/2022-19:34:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: Add_1471 (ElementWise)
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.01508
[06/10/2022-19:34:28] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.01508
[06/10/2022-19:34:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: ReduceMean_1472 (Reduce)
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.274578
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0452754
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0746789
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0743131
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0857966
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0858697
[06/10/2022-19:34:28] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0452754
[06/10/2022-19:34:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(4096,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: Sub_1473 (ElementWise)
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0869669
[06/10/2022-19:34:28] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0869669
[06/10/2022-19:34:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: Sub_1473 (ElementWise)
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0885029
[06/10/2022-19:34:28] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0885029
[06/10/2022-19:34:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(4096:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: Sub_1473 (ElementWise)
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.675109
[06/10/2022-19:34:28] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.675109
[06/10/2022-19:34:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: PWN(1981 + (Unnamed Layer* 2084) [Shuffle], Pow_1475) (PointWiseV2)
[06/10/2022-19:34:28] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: PWN(1981 + (Unnamed Layer* 2084) [Shuffle], Pow_1475) (PointWise)
[06/10/2022-19:34:28] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: ReduceMean_1476 (Reduce)
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.266117
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.045312
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0748914
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0750446
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0861623
[06/10/2022-19:34:28] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0861623
[06/10/2022-19:34:28] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.045312
[06/10/2022-19:34:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(4096,1,1), Float(1310720,320,1), Float(320,320,1), Float(320,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,320,1), Float(1,320,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478), Sqrt_1479), Div_1480), Mul_1481), Add_1482) (PointWiseV2)
[06/10/2022-19:34:28] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478), Sqrt_1479), Div_1480), Mul_1481), Add_1482) (PointWise)
[06/10/2022-19:34:28] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,320,1), Float(1:4,320,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(4096:32,1,1), Float(1310720:32,320,1), Float(320:32,320,1), Float(320:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 320 E0),E0) -> Float(327680,1:4,5120,80) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720,4096,64,1) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(1310720,1,20480,320) -> Float(327680,1,10240,320) ***************
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(327680,1:4,5120,80) -> Float(81920,1:4,2560,80) ***************
[06/10/2022-19:34:28] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:28] [V] [TRT] *************** Autotuning format combination: Float(327680,1024,32,1), Float(1310720,320,1), Float(1310720,320,1), Int32() -> Float(1310720,320,1), Float(5242880,4096,64,1) ***************
[06/10/2022-19:34:28] [V] [TRT] --------------- Timing Runner: {ForeignNode[2060...Transpose_1577 + Reshape_1583]} (Myelin)
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.71713
[06/10/2022-19:34:42] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 4.71713
[06/10/2022-19:34:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: Conv_1584 (CaskConvolution)
[06/10/2022-19:34:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(163840,4096:32,64,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 1280 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595), Erf_1596), PWN(2118 + (Unnamed Layer* 2257) [Shuffle], Add_1598)), Mul_1599), PWN(2121 + (Unnamed Layer* 2261) [Shuffle], Mul_1601)) (PointWiseV2)
[06/10/2022-19:34:42] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595), Erf_1596), PWN(2118 + (Unnamed Layer* 2257) [Shuffle], Add_1598)), Mul_1599), PWN(2121 + (Unnamed Layer* 2261) [Shuffle], Mul_1601)) (PointWise)
[06/10/2022-19:34:42] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 1280 E0) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 1280 E0),E0) -> Float(320,1:4,320,320) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(40,1:32,1,1) ***************
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1280,1280) -> Float(320,1,320,320) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(320,1:4,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(320,1,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(320,1,320,320) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(80,1:4,80,80) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(10,1:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: Add_1604 (ElementWise)
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.131365
[06/10/2022-19:34:42] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.131365
[06/10/2022-19:34:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: Add_1604 (ElementWise)
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.131145
[06/10/2022-19:34:42] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.131145
[06/10/2022-19:34:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: Add_1604 (ElementWise)
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.01552
[06/10/2022-19:34:42] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.01552
[06/10/2022-19:34:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: ReduceMean_1605 (Reduce)
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.276919
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0453851
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0748251
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0749714
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0859429
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0860891
[06/10/2022-19:34:42] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0453851
[06/10/2022-19:34:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(4096,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: Sub_1606 (ElementWise)
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0872594
[06/10/2022-19:34:42] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0872594
[06/10/2022-19:34:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: Sub_1606 (ElementWise)
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.089008
[06/10/2022-19:34:42] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.089008
[06/10/2022-19:34:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(4096:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: Sub_1606 (ElementWise)
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.676718
[06/10/2022-19:34:42] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.676718
[06/10/2022-19:34:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: PWN(2129 + (Unnamed Layer* 2273) [Shuffle], Pow_1608) (PointWiseV2)
[06/10/2022-19:34:42] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: PWN(2129 + (Unnamed Layer* 2273) [Shuffle], Pow_1608) (PointWise)
[06/10/2022-19:34:42] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: ReduceMean_1609 (Reduce)
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.27019
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0451657
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0751908
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0744594
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0857166
[06/10/2022-19:34:42] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0856503
[06/10/2022-19:34:42] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0451657
[06/10/2022-19:34:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(4096,1,1), Float(1310720,320,1), Float(320,320,1), Float(320,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,320,1), Float(1,320,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611), Sqrt_1612), Div_1613), Mul_1614), Add_1615) (PointWiseV2)
[06/10/2022-19:34:42] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611), Sqrt_1612), Div_1613), Mul_1614), Add_1615) (PointWise)
[06/10/2022-19:34:42] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,320,1), Float(1:4,320,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(4096:32,1,1), Float(1310720:32,320,1), Float(320:32,320,1), Float(320:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 320 E0),E0) -> Float(327680,1:4,5120,80) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720,4096,64,1) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(1310720,1,20480,320) -> Float(327680,1,10240,320) ***************
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(327680,1:4,5120,80) -> Float(81920,1:4,2560,80) ***************
[06/10/2022-19:34:42] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:42] [V] [TRT] *************** Autotuning format combination: Float(327680,1024,32,1), Float(1310720,320,1), Float(1310720,320,1), Int32() -> Float(1310720,320,1), Float(5242880,4096,64,1) ***************
[06/10/2022-19:34:42] [V] [TRT] --------------- Timing Runner: {ForeignNode[2208...Transpose_1710 + Reshape_1716]} (Myelin)
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.71786
[06/10/2022-19:34:55] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 4.71786
[06/10/2022-19:34:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: Conv_1717 (CaskConvolution)
[06/10/2022-19:34:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(163840,4096:32,64,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 1280 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728), Erf_1729), PWN(2266 + (Unnamed Layer* 2446) [Shuffle], Add_1731)), Mul_1732), PWN(2269 + (Unnamed Layer* 2450) [Shuffle], Mul_1734)) (PointWiseV2)
[06/10/2022-19:34:55] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728), Erf_1729), PWN(2266 + (Unnamed Layer* 2446) [Shuffle], Add_1731)), Mul_1732), PWN(2269 + (Unnamed Layer* 2450) [Shuffle], Mul_1734)) (PointWise)
[06/10/2022-19:34:55] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 1280 E0) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 1280 E0),E0) -> Float(320,1:4,320,320) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(40,1:32,1,1) ***************
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1280,1280) -> Float(320,1,320,320) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(320,1:4,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(320,1,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(320,1,320,320) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(80,1:4,80,80) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(10,1:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: Add_1737 (ElementWise)
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.131145
[06/10/2022-19:34:55] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.131145
[06/10/2022-19:34:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: Add_1737 (ElementWise)
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.131511
[06/10/2022-19:34:55] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.131511
[06/10/2022-19:34:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: Add_1737 (ElementWise)
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.01392
[06/10/2022-19:34:55] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.01392
[06/10/2022-19:34:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: ReduceMean_1738 (Reduce)
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.276919
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0453486
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0751177
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.075056
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0862354
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0863086
[06/10/2022-19:34:55] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0453486
[06/10/2022-19:34:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(4096,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: Sub_1739 (ElementWise)
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0871863
[06/10/2022-19:34:55] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0871863
[06/10/2022-19:34:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: Sub_1739 (ElementWise)
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0889417
[06/10/2022-19:34:55] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0889417
[06/10/2022-19:34:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(4096:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: Sub_1739 (ElementWise)
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.676571
[06/10/2022-19:34:55] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.676571
[06/10/2022-19:34:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: PWN(2277 + (Unnamed Layer* 2462) [Shuffle], Pow_1741) (PointWiseV2)
[06/10/2022-19:34:55] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: PWN(2277 + (Unnamed Layer* 2462) [Shuffle], Pow_1741) (PointWise)
[06/10/2022-19:34:55] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: ReduceMean_1742 (Reduce)
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.27019
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0452023
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0745326
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.074752
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0857234
[06/10/2022-19:34:55] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0859429
[06/10/2022-19:34:55] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0452023
[06/10/2022-19:34:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(4096,1,1), Float(1310720,320,1), Float(320,320,1), Float(320,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,320,1), Float(1,320,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744), Sqrt_1745), Div_1746), Mul_1747), Add_1748) (PointWiseV2)
[06/10/2022-19:34:55] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744), Sqrt_1745), Div_1746), Mul_1747), Add_1748) (PointWise)
[06/10/2022-19:34:55] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,320,1), Float(1:4,320,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(4096:32,1,1), Float(1310720:32,320,1), Float(320:32,320,1), Float(320:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 320 E0),E0) -> Float(327680,1:4,5120,80) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720,4096,64,1) -> Float(327680,1024,32,1) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(1310720,1,20480,320) -> Float(327680,1,10240,320) ***************
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(327680,1:4,5120,80) -> Float(81920,1:4,2560,80) ***************
[06/10/2022-19:34:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:34:55] [V] [TRT] *************** Autotuning format combination: Float(327680,1024,32,1), Float(1310720,320,1), Float(1310720,320,1), Int32() -> Float(1310720,320,1), Float(5242880,4096,64,1) ***************
[06/10/2022-19:34:55] [V] [TRT] --------------- Timing Runner: {ForeignNode[2356...Transpose_1843 + Reshape_1849]} (Myelin)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.71859
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 4.71859
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,4096,64,1) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(5242880,1,81920,1280) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1310720,1:4,20480,320) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Conv_1850 (CaskConvolution)
[06/10/2022-19:35:08] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination:  -> Float(320,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(5242880,4096,64,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(5242880,1,81920,1280) -> Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720,1:4,20480,320) -> Float(1:4,(* 1280 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(163840,4096:32,64,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(5242880,1280,1) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 1280 (# 0 (SHAPE input))) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861), Erf_1862), PWN(2414 + (Unnamed Layer* 2635) [Shuffle], Add_1864)), Mul_1865), PWN(2417 + (Unnamed Layer* 2639) [Shuffle], Mul_1867)) (PointWiseV2)
[06/10/2022-19:35:08] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861), Erf_1862), PWN(2414 + (Unnamed Layer* 2635) [Shuffle], Add_1864)), Mul_1865), PWN(2417 + (Unnamed Layer* 2639) [Shuffle], Mul_1867)) (PointWise)
[06/10/2022-19:35:08] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 1280 E0) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(5242880:32,1280,1) ***************
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(5242880,1280,1) -> Float(1280,1,1,1) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1,(* 1280 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1280,1,1280,1280) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 1280 E0),E0) -> Float(320,1:4,320,320) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(5242880:32,1280,1) -> Float(40,1:32,1,1) ***************
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1280,1,1280,1280) -> Float(320,1,320,320) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(320,1:4,320,320) -> Float(80,1:4,80,80) ***************
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(320,1,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(320,1,320,320) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(80,1:4,80,80) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(10,1:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Add_1870 (ElementWise)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.130926
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.130926
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Add_1870 (ElementWise)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.130706
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.130706
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Add_1870 (ElementWise)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.01449
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.01449
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: ReduceMean_1871 (Reduce)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.27253
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0452023
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.074528
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0749714
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0856457
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0855771
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0452023
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1), Float(4096,1,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Sub_1872 (ElementWise)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0870171
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0870171
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Sub_1872 (ElementWise)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0886491
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0886491
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1), Float(4096:32,1,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Sub_1872 (ElementWise)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.675547
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.675547
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: PWN(2425 + (Unnamed Layer* 2651) [Shuffle], Pow_1874) (PointWiseV2)
[06/10/2022-19:35:08] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: PWN(2425 + (Unnamed Layer* 2651) [Shuffle], Pow_1874) (PointWise)
[06/10/2022-19:35:08] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(4096,1,1) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: ReduceMean_1875 (Reduce)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.268142
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0452023
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0745326
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0745326
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0866011
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0860891
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0452023
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(4096,1,1), Float(1310720,320,1), Float(320,320,1), Float(320,320,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,320,1), Float(1,320,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 320 (# 0 (SHAPE input))) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877), Sqrt_1878), Div_1879), Mul_1880), Add_1881) (PointWiseV2)
[06/10/2022-19:35:08] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877), Sqrt_1878), Div_1879), Mul_1880), Add_1881) (PointWise)
[06/10/2022-19:35:08] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,320,1), Float(1:4,320,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 320 E0) ***************
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(4096:32,1,1), Float(1310720:32,320,1), Float(320:32,320,1), Float(320:32,320,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(1310720,4096,64,1) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Reshape_1886 + Transpose_1887 (Shuffle)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.138459
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.182126
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.138459
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(1310720,1,20480,320) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Reshape_1886 + Transpose_1887 (Shuffle)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.282478
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.620398
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.282478
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 320 E0),E0) -> Float(327680,1:4,5120,80) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Reshape_1886 + Transpose_1887 (Shuffle)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.280722
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.722944
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.280722
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(40960,4096:32,64,1) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Reshape_1886 + Transpose_1887 (Shuffle)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.919698
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.697783
[06/10/2022-19:35:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.697783
[06/10/2022-19:35:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:35:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:08] [V] [TRT] *************** Autotuning format combination: Float(1310720,4096,64,1) -> Float(524288,1024,32,1) ***************
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Conv_1888 (CudaDepthwiseConvolution)
[06/10/2022-19:35:08] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Conv_1888 (FusedConvActConvolution)
[06/10/2022-19:35:08] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:35:08] [V] [TRT] --------------- Timing Runner: Conv_1888 (CudnnConvolution)
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.35373
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.441929
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000002 Time: 1.21125
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000005 Time: 17.8679
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000038 Time: 1.87611
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.582802
[06/10/2022-19:35:08] [V] [TRT] Tactic: 0x000000000000003a Time: 1.4513
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x000000000000003d Time: 17.7032
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x0000000000000070 Time: 1.87538
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x0000000000000071 Time: 1.54814
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x0000000000000072 Time: 1.42907
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x0000000000000075 Time: 17.6062
[06/10/2022-19:35:09] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.441929
[06/10/2022-19:35:09] [V] [TRT] --------------- Timing Runner: Conv_1888 (CaskConvolution)
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x01cf8ce2da913006 Time: 1.3527
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x12dbf7d94ee3696d Time: 1.28366
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 1.18786
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x4727434768e46395 Time: 1.18111
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x4efce38acc876f5c Time: 0.936082
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 0.912823
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 0x5403ad713f811a18
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x5403ad713f811a18 Time: 0.904777
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x5aa723e0481da855 Time: 0.931109
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x5deb29b7a8e275f7 Time: 1.00498
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xa31d27de74b895ff Time: 1.08385
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 1.18857
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xbb8c3889c7eacd30 Time: 0.876398
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 1.55151
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 0.841143
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 1.01829
[06/10/2022-19:35:09] [V] [TRT] Fastest Tactic: 0xf067e6205da31c2e Time: 0.841143
[06/10/2022-19:35:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0x0000000000000001
[06/10/2022-19:35:09] [V] [TRT] *************** Autotuning format combination: Float(1310720,1,20480,320) -> Float(524288,1,16384,512) ***************
[06/10/2022-19:35:09] [V] [TRT] --------------- Timing Runner: Conv_1888 (CaskConvolution)
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 1.0379
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x1da91d865428f237 Time: 0.804133
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.9728
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 1.13708
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 1.15361
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x3f0c846d6379bc98 Time: 0.91019
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 1.03219
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 0.994304
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x62835fce994f06dd Time: 1.0003
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0x634e99502974e4da
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x634e99502974e4da Time: 0.939593
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.36747
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 0.950272
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x8014228ec08b4d49 Time: 0.795794
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x94a7db94ba744c45 Time: 1.06262
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x999e005e3b016ea6 Time: 0.327241
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xb443c221fcb1565b Time: 0.339968
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xbdfdef6b84f7ccc9 Time: 1.01947
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: 0xca7eeb8d9143d738
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xca7eeb8d9143d738 Time: 0.991086
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xd15dd11d64344e83 Time: 0.825344
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 0.956709
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xf48db81f02eca9ee Time: 0.834121
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 0.900827
[06/10/2022-19:35:09] [V] [TRT] Fastest Tactic: 0x999e005e3b016ea6 Time: 0.327241
[06/10/2022-19:35:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x999e005e3b016ea6
[06/10/2022-19:35:09] [V] [TRT] *************** Autotuning format combination: Float(327680,1:4,5120,80) -> Float(131072,1:4,4096,128) ***************
[06/10/2022-19:35:09] [V] [TRT] --------------- Timing Runner: Conv_1888 (CaskConvolution)
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x65e41d81f093b482 Time: 0.349477
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0x999e005e3b016ea6 Time: 0.320219
[06/10/2022-19:35:09] [V] [TRT] Conv_1888 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:35:09] [V] [TRT] Tactic: 0xb443c221fcb1565b Time: 0.335872
[06/10/2022-19:35:09] [V] [TRT] Fastest Tactic: 0x999e005e3b016ea6 Time: 0.320219
[06/10/2022-19:35:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x999e005e3b016ea6
[06/10/2022-19:35:09] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:09] [V] [TRT] *************** Autotuning format combination: Float(524288,1024,32,1), Int32() -> Float(524288,512,1), Float(2097152,1024,32,1) ***************
[06/10/2022-19:35:09] [V] [TRT] --------------- Timing Runner: {ForeignNode[2524...Transpose_1996 + Reshape_2002]} (Myelin)
[06/10/2022-19:35:22] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.21681
[06/10/2022-19:35:22] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 2.21681
[06/10/2022-19:35:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:35:22] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:22] [V] [TRT] *************** Autotuning format combination: Float(2097152,1024,32,1) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:35:22] [V] [TRT] --------------- Timing Runner: Conv_2003 (CudaDepthwiseConvolution)
[06/10/2022-19:35:22] [V] [TRT] Tactic: 0xffffffffffffffff Time: 0.143214
[06/10/2022-19:35:22] [V] [TRT] Fastest Tactic: 0xffffffffffffffff Time: 0.143214
[06/10/2022-19:35:22] [V] [TRT] --------------- Timing Runner: Conv_2003 (CudnnConvolution)
[06/10/2022-19:35:22] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.2816
[06/10/2022-19:35:22] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.281893
[06/10/2022-19:35:22] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.350354
[06/10/2022-19:35:23] [V] [TRT] Tactic: 0x0000000000000004 Time: 50.5028
[06/10/2022-19:35:23] [V] [TRT] Tactic: 0x0000000000000005 Time: 92.6503
[06/10/2022-19:35:24] [V] [TRT] Tactic: 0x0000000000000006 Time: 18.1917
[06/10/2022-19:35:24] [V] [TRT] Tactic: 0x0000000000000038 Time: 0.281307
[06/10/2022-19:35:24] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.281321
[06/10/2022-19:35:24] [V] [TRT] Tactic: 0x000000000000003a Time: 0.347575
[06/10/2022-19:35:24] [V] [TRT] Tactic: 0x000000000000003c Time: 50.6407
[06/10/2022-19:35:25] [V] [TRT] Tactic: 0x000000000000003d Time: 92.154
[06/10/2022-19:35:25] [V] [TRT] Tactic: 0x000000000000003e Time: 18.2035
[06/10/2022-19:35:25] [V] [TRT] Tactic: 0x0000000000000070 Time: 0.281015
[06/10/2022-19:35:25] [V] [TRT] Tactic: 0x0000000000000071 Time: 0.281454
[06/10/2022-19:35:25] [V] [TRT] Tactic: 0x0000000000000072 Time: 0.34816
[06/10/2022-19:35:25] [V] [TRT] Tactic: 0x0000000000000074 Time: 50.3921
[06/10/2022-19:35:26] [V] [TRT] Tactic: 0x0000000000000075 Time: 92.4997
[06/10/2022-19:35:26] [V] [TRT] Tactic: 0x0000000000000076 Time: 18.5057
[06/10/2022-19:35:26] [V] [TRT] Fastest Tactic: 0x0000000000000070 Time: 0.281015
[06/10/2022-19:35:26] [V] [TRT] --------------- Timing Runner: Conv_2003 (CaskConvolution)
[06/10/2022-19:35:26] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006
[06/10/2022-19:35:26] [V] [TRT] Tactic: 0x01cf8ce2da913006 Time: 18.5438
[06/10/2022-19:35:27] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d
[06/10/2022-19:35:27] [V] [TRT] Tactic: 0x12dbf7d94ee3696d Time: 19.8766
[06/10/2022-19:35:27] [V] [TRT] Conv_2003 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:35:27] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 17.4785
[06/10/2022-19:35:27] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395
[06/10/2022-19:35:27] [V] [TRT] Tactic: 0x4727434768e46395 Time: 11.3526
[06/10/2022-19:35:27] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c
[06/10/2022-19:35:27] [V] [TRT] Tactic: 0x4efce38acc876f5c Time: 38.1343
[06/10/2022-19:35:27] [V] [TRT] Conv_2003 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:35:28] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 20.1235
[06/10/2022-19:35:28] [V] [TRT] Conv_2003 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 0x5403ad713f811a18
[06/10/2022-19:35:28] [V] [TRT] Tactic: 0x5403ad713f811a18 Time: 20.4603
[06/10/2022-19:35:28] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:35:28] [V] [TRT] Tactic: 0x5aa723e0481da855 Time: 19.3261
[06/10/2022-19:35:28] [V] [TRT] Conv_2003 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7
[06/10/2022-19:35:28] [V] [TRT] Tactic: 0x5deb29b7a8e275f7 Time: 17.8079
[06/10/2022-19:35:28] [V] [TRT] Conv_2003 Set Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a
[06/10/2022-19:35:28] [V] [TRT] Tactic: 0x94119b4c514b211a Time: 13.9399
[06/10/2022-19:35:29] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff
[06/10/2022-19:35:29] [V] [TRT] Tactic: 0xa31d27de74b895ff Time: 11.7207
[06/10/2022-19:35:29] [V] [TRT] Conv_2003 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:35:29] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 16.2857
[06/10/2022-19:35:29] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30
[06/10/2022-19:35:29] [V] [TRT] Tactic: 0xbb8c3889c7eacd30 Time: 40.6837
[06/10/2022-19:35:29] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:35:29] [V] [TRT] Tactic: 0xd828f024626fa982 Time: 12.8897
[06/10/2022-19:35:29] [V] [TRT] Conv_2003 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:35:30] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 20.3391
[06/10/2022-19:35:30] [V] [TRT] Conv_2003 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:35:30] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 17.95
[06/10/2022-19:35:30] [V] [TRT] Fastest Tactic: 0x4727434768e46395 Time: 11.3526
[06/10/2022-19:35:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: 0xffffffffffffffff
[06/10/2022-19:35:30] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,65536,2048) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:35:30] [V] [TRT] --------------- Timing Runner: Conv_2003 (CaskConvolution)
[06/10/2022-19:35:30] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0
[06/10/2022-19:35:30] [V] [TRT] Tactic: 0x19b688348f983aa0 Time: 16.9769
[06/10/2022-19:35:30] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237
[06/10/2022-19:35:30] [V] [TRT] Tactic: 0x1da91d865428f237 Time: 24.6635
[06/10/2022-19:35:30] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98
[06/10/2022-19:35:31] [V] [TRT] Tactic: 0x3f0c846d6379bc98 Time: 82.5129
[06/10/2022-19:35:31] [V] [TRT] Conv_2003 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf2
[06/10/2022-19:35:31] [V] [TRT] Tactic: 0x5030121339a48bf2 Time: 12.7092
[06/10/2022-19:35:31] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd
[06/10/2022-19:35:31] [V] [TRT] Tactic: 0x62835fce994f06dd Time: 17.0319
[06/10/2022-19:35:31] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49
[06/10/2022-19:35:32] [V] [TRT] Tactic: 0x8014228ec08b4d49 Time: 46.4679
[06/10/2022-19:35:32] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45
[06/10/2022-19:35:32] [V] [TRT] Tactic: 0x94a7db94ba744c45 Time: 17.0427
[06/10/2022-19:35:32] [V] [TRT] Conv_2003 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: 0xca7eeb8d9143d739
[06/10/2022-19:35:32] [V] [TRT] Tactic: 0xca7eeb8d9143d739 Time: 12.7587
[06/10/2022-19:35:32] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83
[06/10/2022-19:35:32] [V] [TRT] Tactic: 0xd15dd11d64344e83 Time: 23.7711
[06/10/2022-19:35:32] [V] [TRT] Conv_2003 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf50
[06/10/2022-19:35:32] [V] [TRT] Tactic: 0xd9031472c05adf50 Time: 12.5102
[06/10/2022-19:35:32] [V] [TRT] Conv_2003 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee
[06/10/2022-19:35:33] [V] [TRT] Tactic: 0xf48db81f02eca9ee Time: 24.307
[06/10/2022-19:35:33] [V] [TRT] Fastest Tactic: 0xd9031472c05adf50 Time: 12.5102
[06/10/2022-19:35:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xd9031472c05adf50
[06/10/2022-19:35:33] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,16384,512) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:35:33] [V] [TRT] --------------- Timing Runner: Conv_2003 (CaskConvolution)
[06/10/2022-19:35:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:35:33] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:33] [V] [TRT] *************** Autotuning format combination: Float(2097152,1024,32,1), Float(524288,512,1), Int32() -> Float(524288,512,1), Float(2097152,1024,32,1) ***************
[06/10/2022-19:35:33] [V] [TRT] --------------- Timing Runner: {ForeignNode[2646...Transpose_2105 + Reshape_2111]} (Myelin)
[06/10/2022-19:35:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.63739
[06/10/2022-19:35:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 2.63739
[06/10/2022-19:35:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:35:49] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:49] [V] [TRT] *************** Autotuning format combination: Float(2097152,1024,32,1) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:35:49] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,65536,2048) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:35:49] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,16384,512) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:35:49] [V] [TRT] --------------- Timing Runner: Conv_2112 (CaskConvolution)
[06/10/2022-19:35:49] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:35:49] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:35:49] [V] [TRT] *************** Autotuning format combination: Float(2097152,1024,32,1), Float(524288,512,1), Int32() -> Float(524288,512,1), Float(2097152,1024,32,1) ***************
[06/10/2022-19:35:49] [V] [TRT] --------------- Timing Runner: {ForeignNode[2768...Transpose_2214 + Reshape_2220]} (Myelin)
[06/10/2022-19:36:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.61983
[06/10/2022-19:36:05] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 2.61983
[06/10/2022-19:36:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Myelin Tactic: 0x0000000000000000
[06/10/2022-19:36:05] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:36:05] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(2097152,128,1) ***************
[06/10/2022-19:36:05] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:36:05] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(1:4,(* 128 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:36:05] [V] [TRT] *************** Autotuning format combination: Float(65536,16384:32,128,1) -> Float(2097152:32,128,1) ***************
[06/10/2022-19:36:05] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:36:05] [V] [TRT] *************** Autotuning format combination: Float(2097152,128,1) -> Float(128,1,1,1) ***************
[06/10/2022-19:36:05] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2335 (Shuffle)
[06/10/2022-19:36:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.140873
[06/10/2022-19:36:05] [V] [TRT] Tactic: 0x0000000000000001 Time: 3.42382
[06/10/2022-19:36:05] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.140873
[06/10/2022-19:36:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:36:05] [V] [TRT] *************** Autotuning format combination: Float(1,(* 128 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(128,1,128,128) ***************
[06/10/2022-19:36:05] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2335 (Shuffle)
[06/10/2022-19:36:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.320951
[06/10/2022-19:36:05] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.02488
[06/10/2022-19:36:05] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.320951
[06/10/2022-19:36:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:36:05] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 128 E0),E0) -> Float(32,1:4,32,32) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:36:05] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2335 (Shuffle)
[06/10/2022-19:36:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.32139
[06/10/2022-19:36:05] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.1915
[06/10/2022-19:36:05] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.32139
[06/10/2022-19:36:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:36:05] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,128,1) -> Float(4,1:32,1,1) ***************
[06/10/2022-19:36:05] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2335 (Shuffle)
[06/10/2022-19:36:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.741669
[06/10/2022-19:36:05] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.73044
[06/10/2022-19:36:05] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.741669
[06/10/2022-19:36:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:36:05] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:36:05] [V] [TRT] *************** Autotuning format combination: Float(128,1,1,1) -> Float(768,1,1,1) ***************
[06/10/2022-19:36:05] [V] [TRT] --------------- Timing Runner: MatMul_2335 (CudaDepthwiseConvolution)
[06/10/2022-19:36:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:36:05] [V] [TRT] --------------- Timing Runner: MatMul_2335 (FusedConvActConvolution)
[06/10/2022-19:36:05] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:36:22] [V] [TRT] --------------- Timing Runner: MatMul_2335 (CudnnConvolution)
[06/10/2022-19:36:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.85009
[06/10/2022-19:36:32] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.16005
[06/10/2022-19:36:35] [V] [TRT] Tactic: 0x0000000000000002 Time: 2.37963
[06/10/2022-19:36:37] [V] [TRT] Tactic: 0x0000000000000038 Time: 3.78675
[06/10/2022-19:36:44] [V] [TRT] Tactic: 0x0000000000000039 Time: 2.16005
[06/10/2022-19:36:47] [V] [TRT] Tactic: 0x000000000000003a Time: 2.38928
[06/10/2022-19:36:49] [V] [TRT] Tactic: 0x0000000000000070 Time: 3.77212
[06/10/2022-19:36:52] [V] [TRT] Tactic: 0x0000000000000071 Time: 3.81659
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x0000000000000072 Time: 2.40903
[06/10/2022-19:36:55] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.16005
[06/10/2022-19:36:55] [V] [TRT] --------------- Timing Runner: MatMul_2335 (CublasConvolution)
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.6422
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.66034
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x0000000000000002 Time: 1.46315
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x0000000000000003 Time: 1.39249
[06/10/2022-19:36:55] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 1.39249
[06/10/2022-19:36:55] [V] [TRT] --------------- Timing Runner: MatMul_2335 (CaskConvolution)
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x1fc87d7eb370bb7a Time: 3.25954
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x2ee10e11d6651675 Time: 3.21097
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 3.35331
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 4.02812
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x7f0145cb49517338 Time: 3.28543
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x865894c4635db7fd Time: 3.35506
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x8e3884f0eaec3ecd Time: 3.32946
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x9808072e706def96 Time: 4.29875
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x9cd5cdc35441c505 Time: 3.17147
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x9de226a0c44627c4 Time: 3.27475
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xa419b3b68f2da07b Time: 3.15816
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 4.25633
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 3.97019
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xc0b05b61d128e46e Time: 3.17586
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 3.3596
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xe5603263b7f00303 Time: 3.70498
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 4.12804
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 3.40714
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xfff46c7893896eb1 Time: 3.62116
[06/10/2022-19:36:55] [V] [TRT] Fastest Tactic: 0xa419b3b68f2da07b Time: 3.15816
[06/10/2022-19:36:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000003
[06/10/2022-19:36:55] [V] [TRT] *************** Autotuning format combination: Float(128,1,128,128) -> Float(768,1,768,768) ***************
[06/10/2022-19:36:55] [V] [TRT] --------------- Timing Runner: MatMul_2335 (CublasConvolution)
[06/10/2022-19:36:55] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:36:55] [V] [TRT] --------------- Timing Runner: MatMul_2335 (CaskConvolution)
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 1.15054
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.601673
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 1.08193
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 1.08707
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 1.15141
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 1.40405
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 1.43682
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 1.18038
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 1.17087
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 1.17511
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 1.16663
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 1.20627
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.647607
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 1.12772
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 1.3192
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 1.24665
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 1.4554
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 1.21314
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 1.18345
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 1.19325
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 1.22251
[06/10/2022-19:36:55] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 0.601673
[06/10/2022-19:36:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:36:55] [V] [TRT] *************** Autotuning format combination: Float(32,1:4,32,32) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:36:55] [V] [TRT] --------------- Timing Runner: MatMul_2335 (CublasConvolution)
[06/10/2022-19:36:55] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:36:55] [V] [TRT] --------------- Timing Runner: MatMul_2335 (CaskConvolution)
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:36:55] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.679936
[06/10/2022-19:36:55] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:36:56] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.686665
[06/10/2022-19:36:56] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 0.679936
[06/10/2022-19:36:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:36:56] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:36:56] [V] [TRT] *************** Autotuning format combination: Float(768,1,1,1) -> Float(12582912,768,1) ***************
[06/10/2022-19:36:56] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2335 (Shuffle)
[06/10/2022-19:36:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.822286
[06/10/2022-19:36:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.64337
[06/10/2022-19:36:56] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.822286
[06/10/2022-19:36:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:36:56] [V] [TRT] *************** Autotuning format combination: Float(768,1,768,768) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:36:56] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2335 (Shuffle)
[06/10/2022-19:36:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.8728
[06/10/2022-19:36:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.65654
[06/10/2022-19:36:56] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.65654
[06/10/2022-19:36:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:36:56] [V] [TRT] *************** Autotuning format combination: Float(192,1:4,192,192) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:36:56] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2335 (Shuffle)
[06/10/2022-19:36:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.8749
[06/10/2022-19:36:56] [V] [TRT] Tactic: 0x0000000000000001 Time: 22.1089
[06/10/2022-19:36:56] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 11.8749
[06/10/2022-19:36:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:36:56] [V] [TRT] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(12582912:32,768,1) ***************
[06/10/2022-19:36:56] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2335 (Shuffle)
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 102.416
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000001 Time: 27.8714
[06/10/2022-19:36:57] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 27.8714
[06/10/2022-19:36:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:36:57] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(12582912,768,1) -> Float(12582912,16384,128,1) ***************
[06/10/2022-19:36:57] [V] [TRT] --------------- Timing Runner: Transpose_2337 + Reshape_2348 (Shuffle)
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.61134
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.67336
[06/10/2022-19:36:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.61134
[06/10/2022-19:36:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(12582912,1,98304,768) ***************
[06/10/2022-19:36:57] [V] [TRT] --------------- Timing Runner: Transpose_2337 + Reshape_2348 (Shuffle)
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.2015
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000001 Time: 6.71627
[06/10/2022-19:36:57] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 6.71627
[06/10/2022-19:36:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 768 E0),E0) -> Float(3145728,1:4,24576,192) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:36:57] [V] [TRT] --------------- Timing Runner: Transpose_2337 + Reshape_2348 (Shuffle)
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 7.76455
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000001 Time: 7.09588
[06/10/2022-19:36:57] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 7.09588
[06/10/2022-19:36:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(12582912:32,768,1) -> Float(393216,16384:32,128,1) ***************
[06/10/2022-19:36:57] [V] [TRT] --------------- Timing Runner: Transpose_2337 + Reshape_2348 (Shuffle)
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 16.14
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000001 Time: 7.16039
[06/10/2022-19:36:57] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 7.16039
[06/10/2022-19:36:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:36:57] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(12582912,16384,128,1) -> Float(50331648,65536,256,1) ***************
[06/10/2022-19:36:57] [V] [TRT] --------------- Timing Runner: Resize_2357 (Resize)
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.7471
[06/10/2022-19:36:57] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.7471
[06/10/2022-19:36:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0x0000000000000001
[06/10/2022-19:36:57] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(1310720,4096,64,1) -> Float(1310720,320,1) ***************
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(1310720,1,20480,320) -> Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(327680,1:4,5120,80) -> Float(1:4,(* 320 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(40960,4096:32,64,1) -> Float(1310720:32,320,1) ***************
[06/10/2022-19:36:57] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(1310720,320,1) -> Float(320,1,1,1) ***************
[06/10/2022-19:36:57] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2303 (Shuffle)
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0895269
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.189147
[06/10/2022-19:36:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0895269
[06/10/2022-19:36:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(1,(* 320 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(320,1,320,320) ***************
[06/10/2022-19:36:57] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2303 (Shuffle)
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.202898
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.772681
[06/10/2022-19:36:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.202898
[06/10/2022-19:36:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 320 E0),E0) -> Float(80,1:4,80,80) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:36:57] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2303 (Shuffle)
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.203337
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.845385
[06/10/2022-19:36:57] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.203337
[06/10/2022-19:36:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:36:57] [V] [TRT] *************** Autotuning format combination: Float(1310720:32,320,1) -> Float(10,1:32,1,1) ***************
[06/10/2022-19:36:57] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2303 (Shuffle)
[06/10/2022-19:36:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.465042
[06/10/2022-19:36:58] [V] [TRT] Tactic: 0x0000000000000001 Time: 3.12671
[06/10/2022-19:36:58] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.465042
[06/10/2022-19:36:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:36:58] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:36:58] [V] [TRT] *************** Autotuning format combination: Float(320,1,1,1) -> Float(768,1,1,1) ***************
[06/10/2022-19:36:58] [V] [TRT] --------------- Timing Runner: MatMul_2303 (CudaDepthwiseConvolution)
[06/10/2022-19:36:58] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:36:58] [V] [TRT] --------------- Timing Runner: MatMul_2303 (FusedConvActConvolution)
[06/10/2022-19:36:58] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:04] [V] [TRT] --------------- Timing Runner: MatMul_2303 (CudnnConvolution)
[06/10/2022-19:37:04] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.10343
[06/10/2022-19:37:07] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.942519
[06/10/2022-19:37:08] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.990793
[06/10/2022-19:37:09] [V] [TRT] Tactic: 0x0000000000000005 Time: 41.7129
[06/10/2022-19:37:09] [V] [TRT] Tactic: 0x0000000000000038 Time: 1.10446
[06/10/2022-19:37:12] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.942226
[06/10/2022-19:37:13] [V] [TRT] Tactic: 0x000000000000003a Time: 0.994304
[06/10/2022-19:37:14] [V] [TRT] Tactic: 0x000000000000003d Time: 42.2919
[06/10/2022-19:37:14] [V] [TRT] Tactic: 0x0000000000000070 Time: 1.10431
[06/10/2022-19:37:15] [V] [TRT] Tactic: 0x0000000000000071 Time: 1.10358
[06/10/2022-19:37:16] [V] [TRT] Tactic: 0x0000000000000072 Time: 0.99211
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000075 Time: 42.02
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000039 Time: 0.942226
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: MatMul_2303 (CublasConvolution)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.892197
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.877861
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.536869
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.525458
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 0.525458
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: MatMul_2303 (CaskConvolution)
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x1fc87d7eb370bb7a Time: 1.61851
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x2ee10e11d6651675 Time: 1.19764
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 1.81979
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 1.47602
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x7f0145cb49517338 Time: 1.09685
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x865894c4635db7fd Time: 1.48699
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x8e3884f0eaec3ecd Time: 1.46768
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x9808072e706def96 Time: 2.19941
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x9cd5cdc35441c505 Time: 1.21593
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x9de226a0c44627c4 Time: 1.22353
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xa419b3b68f2da07b Time: 1.09158
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 2.20657
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 1.45642
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xc0b05b61d128e46e Time: 1.23758
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 1.82023
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xe5603263b7f00303 Time: 1.47544
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 1.48641
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 1.86968
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xfff46c7893896eb1 Time: 1.40639
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0xa419b3b68f2da07b Time: 1.09158
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000003
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(320,1,320,320) -> Float(768,1,768,768) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: MatMul_2303 (CublasConvolution)
[06/10/2022-19:37:17] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: MatMul_2303 (CaskConvolution)
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 0.508343
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.300617
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 0.594359
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.605184
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 0.498834
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 0.72075
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 0.756736
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 0.672622
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 0.647899
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 0.649664
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 0.621568
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 0.661211
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.320073
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 0.613815
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 0.673792
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 0.57973
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 0.817591
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 0.569198
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 0.674231
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 0.634002
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 0.632978
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 0.300617
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(80,1:4,80,80) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: MatMul_2303 (CublasConvolution)
[06/10/2022-19:37:17] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: MatMul_2303 (CaskConvolution)
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.323877
[06/10/2022-19:37:17] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.323278
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x9dece0dc37e90462 Time: 0.323278
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9dece0dc37e90462
[06/10/2022-19:37:17] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(768,1,1,1) -> Float(3145728,768,1) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2303 (Shuffle)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.209335
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.420133
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.209335
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(768,1,768,768) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2303 (Shuffle)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.834121
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.420571
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.420571
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(192,1:4,192,192) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2303 (Shuffle)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.829147
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 5.73381
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.829147
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(3145728:32,768,1) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2303 (Shuffle)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 19.3502
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 6.58856
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 6.58856
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:17] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(3145728,768,1) -> Float(3145728,4096,64,1) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: Transpose_2305 + Reshape_2316 (Shuffle)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.31861
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.424375
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.31861
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(3145728,1,49152,768) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: Transpose_2305 + Reshape_2316 (Shuffle)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.06657
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.68976
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.06657
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 768 E0),E0) -> Float(786432,1:4,12288,192) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: Transpose_2305 + Reshape_2316 (Shuffle)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.03453
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.76538
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.03453
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(3145728:32,768,1) -> Float(98304,4096:32,64,1) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: Transpose_2305 + Reshape_2316 (Shuffle)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.21185
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.67773
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.67773
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:17] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(3145728,4096,64,1) -> Float(50331648,65536,256,1) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: Resize_2325 (Resize)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.27255
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.27255
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0x0000000000000001
[06/10/2022-19:37:17] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(2097152,1024,32,1) -> Float(2097152,1024,32,1) ***************
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,65536,2048) -> Float(2097152,1,65536,2048) ***************
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,16384,512) -> Float(524288,1:4,16384,512) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: Conv_2221 (CaskConvolution)
[06/10/2022-19:37:17] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:17] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination:  -> Float(512,512,1) ***************
[06/10/2022-19:37:17] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination:  -> Float(512,512,1) ***************
[06/10/2022-19:37:17] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(2097152,1024,32,1) -> Float(2097152,2048,1) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: Reshape_2229 + Transpose_2230 (Shuffle)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.196169
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.285989
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.196169
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,65536,2048) -> Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: Reshape_2229 + Transpose_2230 (Shuffle)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.497518
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.336018
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.336018
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,16384,512) -> Float(1:4,(* 2048 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: Reshape_2229 + Transpose_2230 (Shuffle)
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.497518
[06/10/2022-19:37:17] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.336018
[06/10/2022-19:37:17] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.336018
[06/10/2022-19:37:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:17] [V] [TRT] *************** Autotuning format combination: Float(65536,1024:32,32,1) -> Float(2097152:32,2048,1) ***************
[06/10/2022-19:37:17] [V] [TRT] --------------- Timing Runner: Reshape_2229 + Transpose_2230 (Shuffle)
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.7191
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.03307
[06/10/2022-19:37:18] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.03307
[06/10/2022-19:37:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:18] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:18] [V] [TRT] *************** Autotuning format combination: Float(2097152,2048,1) -> Float(2097152,2048,1) ***************
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236), PWN(2829 + (Unnamed Layer* 3167) [Shuffle], Mul_2238)) (PointWiseV2)
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.133669
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.143653
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.139557
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.146139
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.141824
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.141166
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.151845
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.146578
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.145554
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.142555
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000001c Time: 0.134144
[06/10/2022-19:37:18] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.133669
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236), PWN(2829 + (Unnamed Layer* 3167) [Shuffle], Mul_2238)) (PointWise)
[06/10/2022-19:37:18] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000000
[06/10/2022-19:37:18] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 2048 (# 0 (SHAPE input))) ***************
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236), PWN(2829 + (Unnamed Layer* 3167) [Shuffle], Mul_2238)) (PointWiseV2)
[06/10/2022-19:37:18] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236), PWN(2829 + (Unnamed Layer* 3167) [Shuffle], Mul_2238)) (PointWise)
[06/10/2022-19:37:18] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:18] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 2048 E0) ***************
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236), PWN(2829 + (Unnamed Layer* 3167) [Shuffle], Mul_2238)) (PointWiseV2)
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.49417
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.75471
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000002 Time: 2.68873
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000003 Time: 2.99578
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000004 Time: 3.01787
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000005 Time: 2.86822
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000006 Time: 3.49023
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000007 Time: 3.42089
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000008 Time: 3.37584
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000009 Time: 3.48616
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000000a Time: 1.56248
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000000b Time: 1.70555
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000000c Time: 1.64791
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000000d Time: 1.98949
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000000e Time: 2.04712
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000000f Time: 1.79273
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000010 Time: 2.38914
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000011 Time: 2.47691
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000012 Time: 2.33062
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000013 Time: 2.08121
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000014 Time: 1.03
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000015 Time: 1.14556
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000016 Time: 1.32257
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000017 Time: 1.68945
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000001c Time: 0.141093
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000001d Time: 0.13941
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000001e Time: 0.141605
[06/10/2022-19:37:18] [V] [TRT] Fastest Tactic: 0x000000000000001d Time: 0.13941
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236), PWN(2829 + (Unnamed Layer* 3167) [Shuffle], Mul_2238)) (PointWise)
[06/10/2022-19:37:18] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001d
[06/10/2022-19:37:18] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,2048,1) -> Float(2097152:32,2048,1) ***************
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236), PWN(2829 + (Unnamed Layer* 3167) [Shuffle], Mul_2238)) (PointWiseV2)
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000018 Time: 1.09831
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000019 Time: 1.12246
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000001a Time: 1.12918
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000001b Time: 1.13503
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x000000000000001f Time: 1.09904
[06/10/2022-19:37:18] [V] [TRT] Fastest Tactic: 0x0000000000000018 Time: 1.09831
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236), PWN(2829 + (Unnamed Layer* 3167) [Shuffle], Mul_2238)) (PointWise)
[06/10/2022-19:37:18] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000018
[06/10/2022-19:37:18] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:18] [V] [TRT] *************** Autotuning format combination: Float(2097152,2048,1) -> Float(2048,1,1,1) ***************
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2239 (Shuffle)
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.141239
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.282478
[06/10/2022-19:37:18] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.141239
[06/10/2022-19:37:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:18] [V] [TRT] *************** Autotuning format combination: Float(1,(* 2048 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(2048,1,2048,2048) ***************
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2239 (Shuffle)
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.321243
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.03336
[06/10/2022-19:37:18] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.321243
[06/10/2022-19:37:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:18] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 2048 E0),E0) -> Float(512,1:4,512,512) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2239 (Shuffle)
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.321097
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.16546
[06/10/2022-19:37:18] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.321097
[06/10/2022-19:37:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:18] [V] [TRT] *************** Autotuning format combination: Float(2097152:32,2048,1) -> Float(64,1:32,1,1) ***************
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2239 (Shuffle)
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.74123
[06/10/2022-19:37:18] [V] [TRT] Tactic: 0x0000000000000001 Time: 4.56441
[06/10/2022-19:37:18] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.74123
[06/10/2022-19:37:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:18] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:18] [V] [TRT] *************** Autotuning format combination: Float(2048,1,1,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: MatMul_2239 (CudaDepthwiseConvolution)
[06/10/2022-19:37:18] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:18] [V] [TRT] --------------- Timing Runner: MatMul_2239 (FusedConvActConvolution)
[06/10/2022-19:37:18] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:20] [V] [TRT] --------------- Timing Runner: MatMul_2239 (CudnnConvolution)
[06/10/2022-19:37:20] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.20336
[06/10/2022-19:37:22] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.969728
[06/10/2022-19:37:22] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.961243
[06/10/2022-19:37:22] [V] [TRT] Tactic: 0x0000000000000005 Time: 41.723
[06/10/2022-19:37:22] [V] [TRT] Tactic: 0x0000000000000038 Time: 2.19765
[06/10/2022-19:37:24] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.970167
[06/10/2022-19:37:24] [V] [TRT] Tactic: 0x000000000000003a Time: 0.956855
[06/10/2022-19:37:24] [V] [TRT] Tactic: 0x000000000000003d Time: 41.1731
[06/10/2022-19:37:24] [V] [TRT] Tactic: 0x0000000000000070 Time: 2.19429
[06/10/2022-19:37:25] [V] [TRT] Tactic: 0x0000000000000071 Time: 1.13737
[06/10/2022-19:37:25] [V] [TRT] Tactic: 0x0000000000000072 Time: 0.956709
[06/10/2022-19:37:25] [V] [TRT] Tactic: 0x0000000000000075 Time: 41.2792
[06/10/2022-19:37:25] [V] [TRT] Fastest Tactic: 0x0000000000000072 Time: 0.956709
[06/10/2022-19:37:25] [V] [TRT] --------------- Timing Runner: MatMul_2239 (CublasConvolution)
[06/10/2022-19:37:25] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.807205
[06/10/2022-19:37:25] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.657847
[06/10/2022-19:37:25] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.292864
[06/10/2022-19:37:25] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.255415
[06/10/2022-19:37:25] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 0.255415
[06/10/2022-19:37:25] [V] [TRT] --------------- Timing Runner: MatMul_2239 (CaskConvolution)
[06/10/2022-19:37:25] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a
[06/10/2022-19:37:25] [V] [TRT] Tactic: 0x1fc87d7eb370bb7a Time: 1.4099
[06/10/2022-19:37:25] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x2ee10e11d6651675 Time: 0.763611
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 1.2424
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 0.886053
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x7f0145cb49517338 Time: 0.537161
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x865894c4635db7fd Time: 1.22222
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x8e3884f0eaec3ecd Time: 1.13986
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x9808072e706def96 Time: 2.06073
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x9cd5cdc35441c505 Time: 0.870839
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x9de226a0c44627c4 Time: 0.784823
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xa419b3b68f2da07b Time: 0.54784
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 1.93638
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 0.905362
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xc0b05b61d128e46e Time: 0.852846
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 1.21417
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xe5603263b7f00303 Time: 1.12786
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 0.897495
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 1.21856
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xfff46c7893896eb1 Time: 0.814519
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x7f0145cb49517338 Time: 0.537161
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000003
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(2048,1,2048,2048) -> Float(512,1,512,512) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: MatMul_2239 (CublasConvolution)
[06/10/2022-19:37:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: MatMul_2239 (CaskConvolution)
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 0.531602
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.196901
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 0.583534
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.622299
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 0.545792
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 0.712265
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 0.706999
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 0.697198
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 0.671013
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 0.72704
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 0.636782
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 0.752786
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.230546
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 0.64512
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 0.579145
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 0.599918
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 0.758053
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 0.594066
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 0.685495
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 0.637211
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 0.641902
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 0.196901
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(512,1:4,512,512) -> Float(128,1:4,128,128) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: MatMul_2239 (CublasConvolution)
[06/10/2022-19:37:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: MatMul_2239 (CaskConvolution)
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.228498
[06/10/2022-19:37:26] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.228206
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x9dece0dc37e90462 Time: 0.228206
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9dece0dc37e90462
[06/10/2022-19:37:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(524288,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2239 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0389486
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0776046
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0389486
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2239 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.128439
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0766537
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0766537
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2239 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.128293
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.991232
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.128293
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(16,1:32,1,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2239 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.69491
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.14966
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.14966
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288,512,1), Float(524288,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Add_2241 (ElementWise)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0554834
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0554834
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 512 E0) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Add_2241 (ElementWise)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0557349
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0557349
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288:32,512,1), Float(524288:32,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Add_2241 (ElementWise)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.40843
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.40843
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288,512,1) -> Float(1024,1,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: ReduceMean_2242 (Reduce)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0743131
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0204957
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0388754
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0389063
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0625539
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0626103
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0204957
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:37:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288,512,1), Float(1024,1,1) -> Float(524288,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Sub_2243 (ElementWise)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0373394
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0373394
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0), Float(1:4,E0,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 512 E0) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Sub_2243 (ElementWise)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0383269
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0383269
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288:32,512,1), Float(1024:32,1,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Sub_2243 (ElementWise)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.275602
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.275602
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(2837 + (Unnamed Layer* 3179) [Shuffle], Pow_2245) (PointWiseV2)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0374491
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0393154
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0381074
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0404069
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0386194
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.0373394
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.0419474
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0400457
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0389851
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.0380709
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001c Time: 0.0372686
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x000000000000001c Time: 0.0372686
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(2837 + (Unnamed Layer* 3179) [Shuffle], Pow_2245) (PointWise)
[06/10/2022-19:37:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001c
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1,E0,(# 0 (SHAPE input))) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(2837 + (Unnamed Layer* 3179) [Shuffle], Pow_2245) (PointWiseV2)
[06/10/2022-19:37:26] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(2837 + (Unnamed Layer* 3179) [Shuffle], Pow_2245) (PointWise)
[06/10/2022-19:37:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1:4,E1,E0) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 512 E0) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(2837 + (Unnamed Layer* 3179) [Shuffle], Pow_2245) (PointWiseV2)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.171154
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.203922
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.197458
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.265947
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.263461
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.195438
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.400677
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.342747
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.299442
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.303835
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000a Time: 0.16384
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000b Time: 0.190318
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000c Time: 0.180224
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000d Time: 0.238299
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000e Time: 0.243858
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000f Time: 0.187685
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000010 Time: 0.348453
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000011 Time: 0.320219
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000012 Time: 0.268288
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000013 Time: 0.224841
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000014 Time: 0.154331
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000015 Time: 0.204507
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000016 Time: 0.260535
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000017 Time: 0.379026
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001c Time: 0.03712
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001d Time: 0.0382537
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001e Time: 0.0357669
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 0.0357669
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(2837 + (Unnamed Layer* 3179) [Shuffle], Pow_2245) (PointWise)
[06/10/2022-19:37:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288:32,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(2837 + (Unnamed Layer* 3179) [Shuffle], Pow_2245) (PointWiseV2)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000018 Time: 0.277211
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000019 Time: 0.283941
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001a Time: 0.285403
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001b Time: 0.28555
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001f Time: 0.277504
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000018 Time: 0.277211
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(2837 + (Unnamed Layer* 3179) [Shuffle], Pow_2245) (PointWise)
[06/10/2022-19:37:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000018
[06/10/2022-19:37:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288,512,1) -> Float(1024,1,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: ReduceMean_2246 (Reduce)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.071808
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0203154
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0375863
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0378149
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0609036
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0610011
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0203154
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[06/10/2022-19:37:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1024,1,1), Float(524288,512,1), Float(512,512,1), Float(512,512,1) -> Float(524288,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251), Add_2252) (PointWiseV2)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.03968
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0389794
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0377051
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0408137
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0390583
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.0382606
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000006 Time: 0.0434103
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0405634
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0398949
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000009 Time: 0.0395063
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001c Time: 0.0392869
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0377051
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251), Add_2252) (PointWise)
[06/10/2022-19:37:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000002
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1,(# 0 (SHAPE input)),(# 0 (SHAPE input))), Float(1,E0,(# 0 (SHAPE input))), Float(1,512,1), Float(1,512,1) -> Float(1,E0,(# 0 (SHAPE input))) where E0=(* 512 (# 0 (SHAPE input))) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251), Add_2252) (PointWiseV2)
[06/10/2022-19:37:26] [V] [TRT] PointWiseV2 has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251), Add_2252) (PointWise)
[06/10/2022-19:37:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1:4,E0,E0), Float(1:4,E1,E0), Float(1:4,512,1), Float(1:4,512,1) -> Float(1:4,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 512 E0) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251), Add_2252) (PointWiseV2)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.895269
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.00586
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000002 Time: 1.35227
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000003 Time: 1.13445
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.957733
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.846994
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000006 Time: 1.52942
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000007 Time: 1.17336
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000008 Time: 1.30033
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000009 Time: 1.73319
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000a Time: 0.51712
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000b Time: 0.625957
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000c Time: 0.612937
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000d Time: 0.690907
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000e Time: 0.75659
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000000f Time: 0.496933
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000010 Time: 0.883419
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000011 Time: 0.876983
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000012 Time: 0.731282
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000013 Time: 0.696174
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000014 Time: 0.311003
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000015 Time: 0.391429
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000016 Time: 0.460361
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000017 Time: 0.599771
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001c Time: 0.0375589
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001d Time: 0.0367886
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001e Time: 0.042752
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x000000000000001d Time: 0.0367886
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251), Add_2252) (PointWise)
[06/10/2022-19:37:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001d
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1024:32,1,1), Float(524288:32,512,1), Float(512:32,512,1), Float(512:32,512,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251), Add_2252) (PointWiseV2)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000018 Time: 0.275895
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000019 Time: 0.283209
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001a Time: 0.287744
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001b Time: 0.293157
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x000000000000001f Time: 0.275749
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x000000000000001f Time: 0.275749
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251), Add_2252) (PointWise)
[06/10/2022-19:37:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001f
[06/10/2022-19:37:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288,512,1) -> Float(524288,1024,32,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Reshape_2257 + Transpose_2258 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0456411
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0753211
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0456411
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(524288,1,16384,512) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Reshape_2257 + Transpose_2258 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.123831
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.248832
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.123831
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 512 E0),E0) -> Float(131072,1:4,4096,128) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Reshape_2257 + Transpose_2258 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.123687
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.282917
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.123687
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288:32,512,1) -> Float(16384,1024:32,32,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Reshape_2257 + Transpose_2258 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.319488
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.271799
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.271799
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288,1024,32,1) -> Float(524288,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Reshape_2269 + Transpose_2270 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.047104
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0751177
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.047104
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288,1,16384,512) -> Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Reshape_2269 + Transpose_2270 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.112055
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0855131
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0855131
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(131072,1:4,4096,128) -> Float(1:4,(* 512 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Reshape_2269 + Transpose_2270 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.111762
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0857966
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.0857966
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(16384,1024:32,32,1) -> Float(524288:32,512,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: Reshape_2269 + Transpose_2270 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.57989
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.292571
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.292571
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288,512,1) -> Float(512,1,1,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2271 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0386103
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0769463
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0386103
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1,(* 512 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(512,1,512,512) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2271 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0833097
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.252197
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0833097
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 512 E0),E0) -> Float(128,1:4,128,128) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2271 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0833943
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.282331
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0833943
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(524288:32,512,1) -> Float(16,1:32,1,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2271 (Shuffle)
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.187538
[06/10/2022-19:37:26] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.09158
[06/10/2022-19:37:26] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.187538
[06/10/2022-19:37:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:26] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:26] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(768,1,1,1) ***************
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: MatMul_2271 (CudaDepthwiseConvolution)
[06/10/2022-19:37:26] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:26] [V] [TRT] --------------- Timing Runner: MatMul_2271 (FusedConvActConvolution)
[06/10/2022-19:37:26] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:28] [V] [TRT] --------------- Timing Runner: MatMul_2271 (CudnnConvolution)
[06/10/2022-19:37:28] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.763758
[06/10/2022-19:37:29] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.346697
[06/10/2022-19:37:30] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.412818
[06/10/2022-19:37:31] [V] [TRT] Tactic: 0x0000000000000004 Time: 145.101
[06/10/2022-19:37:31] [V] [TRT] Tactic: 0x0000000000000005 Time: 15.1621
[06/10/2022-19:37:31] [V] [TRT] Tactic: 0x0000000000000038 Time: 0.768439
[06/10/2022-19:37:32] [V] [TRT] Tactic: 0x0000000000000039 Time: 0.346697
[06/10/2022-19:37:33] [V] [TRT] Tactic: 0x000000000000003a Time: 0.412818
[06/10/2022-19:37:34] [V] [TRT] Tactic: 0x000000000000003c Time: 145.129
[06/10/2022-19:37:34] [V] [TRT] Tactic: 0x000000000000003d Time: 15.5022
[06/10/2022-19:37:34] [V] [TRT] Tactic: 0x0000000000000070 Time: 0.769769
[06/10/2022-19:37:35] [V] [TRT] Tactic: 0x0000000000000071 Time: 0.765367
[06/10/2022-19:37:35] [V] [TRT] Tactic: 0x0000000000000072 Time: 0.412965
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x0000000000000074 Time: 145.404
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x0000000000000075 Time: 15.1647
[06/10/2022-19:37:36] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.346697
[06/10/2022-19:37:36] [V] [TRT] --------------- Timing Runner: MatMul_2271 (CublasConvolution)
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.356059
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.341285
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.204946
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.204215
[06/10/2022-19:37:36] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 0.204215
[06/10/2022-19:37:36] [V] [TRT] --------------- Timing Runner: MatMul_2271 (CaskConvolution)
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x1fc87d7eb370bb7a Time: 0.672183
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x2ee10e11d6651675 Time: 0.446171
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 0.59509
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 0.544914
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x7f0145cb49517338 Time: 0.357815
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x865894c4635db7fd Time: 0.531456
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x8e3884f0eaec3ecd Time: 0.552082
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x9808072e706def96 Time: 0.821248
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x9cd5cdc35441c505 Time: 0.427415
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x9de226a0c44627c4 Time: 0.484059
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xa419b3b68f2da07b Time: 0.326473
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 0.796818
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 0.503077
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xc0b05b61d128e46e Time: 0.41589
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 0.526043
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xe5603263b7f00303 Time: 0.515803
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 0.516827
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 0.544183
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xfff46c7893896eb1 Time: 0.556032
[06/10/2022-19:37:36] [V] [TRT] Fastest Tactic: 0xa419b3b68f2da07b Time: 0.326473
[06/10/2022-19:37:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000003
[06/10/2022-19:37:36] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512) -> Float(768,1,768,768) ***************
[06/10/2022-19:37:36] [V] [TRT] --------------- Timing Runner: MatMul_2271 (CublasConvolution)
[06/10/2022-19:37:36] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:36] [V] [TRT] --------------- Timing Runner: MatMul_2271 (CaskConvolution)
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 0.204946
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.095232
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 0.228206
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 0.245467
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 0.201582
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 0.250149
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 0.245614
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 0.24576
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 0.232887
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 0.237422
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 0.22443
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 0.23669
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.0979954
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 0.225719
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 0.277797
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 0.208457
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 0.251611
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 0.217088
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 0.251319
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 0.235227
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 0.236837
[06/10/2022-19:37:36] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 0.095232
[06/10/2022-19:37:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:37:36] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:37:36] [V] [TRT] --------------- Timing Runner: MatMul_2271 (CublasConvolution)
[06/10/2022-19:37:36] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:36] [V] [TRT] --------------- Timing Runner: MatMul_2271 (CaskConvolution)
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x130df49cb195156b Time: 0.102619
[06/10/2022-19:37:36] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 0.102034
[06/10/2022-19:37:36] [V] [TRT] Fastest Tactic: 0x9dece0dc37e90462 Time: 0.102034
[06/10/2022-19:37:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9dece0dc37e90462
[06/10/2022-19:37:36] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:36] [V] [TRT] *************** Autotuning format combination: Float(768,1,1,1) -> Float(786432,768,1) ***************
[06/10/2022-19:37:36] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2271 (Shuffle)
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0564099
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.111689
[06/10/2022-19:37:36] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0564099
[06/10/2022-19:37:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:36] [V] [TRT] *************** Autotuning format combination: Float(768,1,768,768) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:37:36] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2271 (Shuffle)
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.187685
[06/10/2022-19:37:36] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.111762
[06/10/2022-19:37:36] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.111762
[06/10/2022-19:37:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:36] [V] [TRT] *************** Autotuning format combination: Float(192,1:4,192,192) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:36] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2271 (Shuffle)
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.187685
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.43579
[06/10/2022-19:37:37] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.187685
[06/10/2022-19:37:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(786432:32,768,1) ***************
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2271 (Shuffle)
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.15262
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.54331
[06/10/2022-19:37:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.54331
[06/10/2022-19:37:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(786432,768,1) -> Float(786432,1024,32,1) ***************
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: Transpose_2273 + Reshape_2284 (Shuffle)
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0689981
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.112713
[06/10/2022-19:37:37] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0689981
[06/10/2022-19:37:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(786432,1,24576,768) ***************
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: Transpose_2273 + Reshape_2284 (Shuffle)
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.176421
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.384146
[06/10/2022-19:37:37] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.176421
[06/10/2022-19:37:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 768 E0),E0) -> Float(196608,1:4,6144,192) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: Transpose_2273 + Reshape_2284 (Shuffle)
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.184905
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.420133
[06/10/2022-19:37:37] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.184905
[06/10/2022-19:37:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(786432:32,768,1) -> Float(24576,1024:32,32,1) ***************
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: Transpose_2273 + Reshape_2284 (Shuffle)
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.703781
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.42101
[06/10/2022-19:37:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.42101
[06/10/2022-19:37:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:37:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(786432,1024,32,1) -> Float(50331648,65536,256,1) ***************
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: Resize_2293 (Resize)
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.31965
[06/10/2022-19:37:37] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.31965
[06/10/2022-19:37:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0x0000000000000001
[06/10/2022-19:37:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(4194304,65536,256,1) -> Float(4194304,64,1) ***************
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,16384,64) -> Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,4096,16) -> Float(1:4,(* 64 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(131072,65536:32,256,1) -> Float(4194304:32,64,1) ***************
[06/10/2022-19:37:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(4194304,64,1) -> Float(64,1,1,1) ***************
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2367 (Shuffle)
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.277504
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 7.69273
[06/10/2022-19:37:37] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.277504
[06/10/2022-19:37:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(1,(* 64 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(64,1,64,64) ***************
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2367 (Shuffle)
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.640146
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.02854
[06/10/2022-19:37:37] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.640146
[06/10/2022-19:37:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 64 E0),E0) -> Float(16,1:4,16,16) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2367 (Shuffle)
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.643657
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.30034
[06/10/2022-19:37:37] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.643657
[06/10/2022-19:37:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(4194304:32,64,1) -> Float(2,1:32,1,1) ***************
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: reshape_before_MatMul_2367 (Shuffle)
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.47822
[06/10/2022-19:37:37] [V] [TRT] Tactic: 0x0000000000000001 Time: 9.16977
[06/10/2022-19:37:37] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.47822
[06/10/2022-19:37:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:37:37] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:37:37] [V] [TRT] *************** Autotuning format combination: Float(64,1,1,1) -> Float(768,1,1,1) ***************
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: MatMul_2367 (CudaDepthwiseConvolution)
[06/10/2022-19:37:37] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:37:37] [V] [TRT] --------------- Timing Runner: MatMul_2367 (FusedConvActConvolution)
[06/10/2022-19:37:37] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:38:39] [V] [TRT] --------------- Timing Runner: MatMul_2367 (CudnnConvolution)
[06/10/2022-19:38:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 10.2666
[06/10/2022-19:39:16] [V] [TRT] Tactic: 0x0000000000000001 Time: 6.65556
[06/10/2022-19:39:27] [V] [TRT] Tactic: 0x0000000000000002 Time: 8.07921
[06/10/2022-19:39:36] [V] [TRT] Tactic: 0x0000000000000038 Time: 10.4059
[06/10/2022-19:40:03] [V] [TRT] Tactic: 0x0000000000000039 Time: 6.66726
[06/10/2022-19:40:14] [V] [TRT] Tactic: 0x000000000000003a Time: 8.07058
[06/10/2022-19:40:23] [V] [TRT] Tactic: 0x0000000000000070 Time: 10.3544
[06/10/2022-19:40:33] [V] [TRT] Tactic: 0x0000000000000071 Time: 10.3329
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x0000000000000072 Time: 8.07146
[06/10/2022-19:40:45] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 6.65556
[06/10/2022-19:40:45] [V] [TRT] --------------- Timing Runner: MatMul_2367 (CublasConvolution)
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.59938
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x0000000000000001 Time: 5.69461
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x0000000000000002 Time: 5.16345
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x0000000000000003 Time: 5.15233
[06/10/2022-19:40:45] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 5.15233
[06/10/2022-19:40:45] [V] [TRT] --------------- Timing Runner: MatMul_2367 (CaskConvolution)
[06/10/2022-19:40:45] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x1fc87d7eb370bb7a Time: 10.1985
[06/10/2022-19:40:45] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x2ee10e11d6651675 Time: 10.556
[06/10/2022-19:40:45] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 10.9771
[06/10/2022-19:40:45] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 13.696
[06/10/2022-19:40:45] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x7f0145cb49517338 Time: 11.0099
[06/10/2022-19:40:45] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x865894c4635db7fd Time: 10.4882
[06/10/2022-19:40:45] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x8e3884f0eaec3ecd Time: 11.2311
[06/10/2022-19:40:45] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:40:45] [V] [TRT] Tactic: 0x9808072e706def96 Time: 12.9925
[06/10/2022-19:40:45] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505
[06/10/2022-19:40:46] [V] [TRT] Tactic: 0x9cd5cdc35441c505 Time: 10.3607
[06/10/2022-19:40:46] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4
[06/10/2022-19:40:46] [V] [TRT] Tactic: 0x9de226a0c44627c4 Time: 10.9893
[06/10/2022-19:40:46] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b
[06/10/2022-19:40:46] [V] [TRT] Tactic: 0xa419b3b68f2da07b Time: 10.8364
[06/10/2022-19:40:46] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:40:46] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 12.6849
[06/10/2022-19:40:46] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:40:46] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 13.6985
[06/10/2022-19:40:46] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e
[06/10/2022-19:40:46] [V] [TRT] Tactic: 0xc0b05b61d128e46e Time: 10.1494
[06/10/2022-19:40:46] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:40:46] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 11.0996
[06/10/2022-19:40:46] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303
[06/10/2022-19:40:46] [V] [TRT] Tactic: 0xe5603263b7f00303 Time: 10.6887
[06/10/2022-19:40:46] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:40:46] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 14.0199
[06/10/2022-19:40:46] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:40:46] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 11.6742
[06/10/2022-19:40:46] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0xfff46c7893896eb1 Time: 11.7105
[06/10/2022-19:40:47] [V] [TRT] Fastest Tactic: 0xc0b05b61d128e46e Time: 10.1494
[06/10/2022-19:40:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000003
[06/10/2022-19:40:47] [V] [TRT] *************** Autotuning format combination: Float(64,1,64,64) -> Float(768,1,768,768) ***************
[06/10/2022-19:40:47] [V] [TRT] --------------- Timing Runner: MatMul_2367 (CublasConvolution)
[06/10/2022-19:40:47] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:40:47] [V] [TRT] --------------- Timing Runner: MatMul_2367 (CaskConvolution)
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 3.20746
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x130df49cb195156b Time: 1.83735
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 2.36763
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 2.76816
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 3.31835
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 4.03705
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 3.92294
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 2.78221
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 2.62217
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 2.8122
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 2.60784
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 3.14309
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 1.90274
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 3.33488
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 3.41519
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 3.18069
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 3.72063
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 3.22604
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 2.49388
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 2.37758
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 2.45233
[06/10/2022-19:40:47] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 1.83735
[06/10/2022-19:40:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:40:47] [V] [TRT] *************** Autotuning format combination: Float(16,1:4,16,16) -> Float(192,1:4,192,192) ***************
[06/10/2022-19:40:47] [V] [TRT] --------------- Timing Runner: MatMul_2367 (CublasConvolution)
[06/10/2022-19:40:47] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:40:47] [V] [TRT] --------------- Timing Runner: MatMul_2367 (CaskConvolution)
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x130df49cb195156b Time: 1.82901
[06/10/2022-19:40:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 1.83954
[06/10/2022-19:40:47] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 1.82901
[06/10/2022-19:40:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:40:47] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:40:47] [V] [TRT] *************** Autotuning format combination: Float(768,1,1,1) -> Float(50331648,768,1) ***************
[06/10/2022-19:40:47] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2367 (Shuffle)
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.27592
[06/10/2022-19:40:47] [V] [TRT] Tactic: 0x0000000000000001 Time: 6.55228
[06/10/2022-19:40:47] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.27592
[06/10/2022-19:40:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:40:47] [V] [TRT] *************** Autotuning format combination: Float(768,1,768,768) -> Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) ***************
[06/10/2022-19:40:47] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2367 (Shuffle)
[06/10/2022-19:40:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 111.988
[06/10/2022-19:40:48] [V] [TRT] Tactic: 0x0000000000000001 Time: 6.57086
[06/10/2022-19:40:48] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 6.57086
[06/10/2022-19:40:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:40:48] [V] [TRT] *************** Autotuning format combination: Float(192,1:4,192,192) -> Float(1:4,(* 768 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:40:48] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2367 (Shuffle)
[06/10/2022-19:40:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 112.017
[06/10/2022-19:40:50] [V] [TRT] Tactic: 0x0000000000000001 Time: 87.2422
[06/10/2022-19:40:50] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 87.2422
[06/10/2022-19:40:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:40:50] [V] [TRT] *************** Autotuning format combination: Float(24,1:32,1,1) -> Float(50331648:32,768,1) ***************
[06/10/2022-19:40:50] [V] [TRT] --------------- Timing Runner: reshape_after_MatMul_2367 (Shuffle)
[06/10/2022-19:41:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 1868.03
[06/10/2022-19:41:06] [V] [TRT] Tactic: 0x0000000000000001 Time: 109.911
[06/10/2022-19:41:06] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 109.911
[06/10/2022-19:41:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:41:06] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:41:06] [V] [TRT] *************** Autotuning format combination: Float(50331648,768,1) -> Float(201326592,65536,256,1) ***************
[06/10/2022-19:41:06] [V] [TRT] --------------- Timing Runner: Transpose_2369 + Reshape_2380 (Shuffle)
[06/10/2022-19:41:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 25.7094
[06/10/2022-19:41:06] [V] [TRT] Tactic: 0x0000000000000001 Time: 6.66229
[06/10/2022-19:41:06] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 6.66229
[06/10/2022-19:41:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:41:06] [V] [TRT] *************** Autotuning format combination: Float(1,(* 768 (# 0 (SHAPE input))),(# 0 (SHAPE input))) -> Float(201326592,1,786432,3072) ***************
[06/10/2022-19:41:06] [V] [TRT] --------------- Timing Runner: Transpose_2369 + Reshape_2380 (Shuffle)
[06/10/2022-19:41:06] [V] [TRT] Tactic: 0x0000000000000000 Time: 39.3219
[06/10/2022-19:41:07] [V] [TRT] Tactic: 0x0000000000000001 Time: 29.9732
[06/10/2022-19:41:07] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 29.9732
[06/10/2022-19:41:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:41:07] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 768 E0),E0) -> Float(50331648,1:4,196608,768) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:41:07] [V] [TRT] --------------- Timing Runner: Transpose_2369 + Reshape_2380 (Shuffle)
[06/10/2022-19:41:07] [V] [TRT] Tactic: 0x0000000000000000 Time: 39.4794
[06/10/2022-19:41:07] [V] [TRT] Tactic: 0x0000000000000001 Time: 31.5917
[06/10/2022-19:41:07] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 31.5917
[06/10/2022-19:41:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:41:07] [V] [TRT] *************** Autotuning format combination: Float(50331648:32,768,1) -> Float(6291456,65536:32,256,1) ***************
[06/10/2022-19:41:07] [V] [TRT] --------------- Timing Runner: Transpose_2369 + Reshape_2380 (Shuffle)
[06/10/2022-19:41:08] [V] [TRT] Tactic: 0x0000000000000000 Time: 90.1594
[06/10/2022-19:41:08] [V] [TRT] Tactic: 0x0000000000000001 Time: 30.6885
[06/10/2022-19:41:08] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 30.6885
[06/10/2022-19:41:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[06/10/2022-19:41:08] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:41:08] [V] [TRT] *************** Autotuning format combination: Float(201326592,65536,256,1) -> Float(50331648,65536,256,1) ***************
[06/10/2022-19:41:08] [V] [TRT] --------------- Timing Runner: Conv_2382 + Relu_2383 (CudaDepthwiseConvolution)
[06/10/2022-19:41:08] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:41:08] [V] [TRT] --------------- Timing Runner: Conv_2382 + Relu_2383 (FusedConvActConvolution)
[06/10/2022-19:41:08] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:41:08] [V] [TRT] --------------- Timing Runner: Conv_2382 + Relu_2383 (CudnnConvolution)
[06/10/2022-19:41:09] [V] [TRT] Tactic: 0x0000000000000000 Time: 132.693
[06/10/2022-19:41:10] [V] [TRT] Tactic: 0x0000000000000001 Time: 49.3041
[06/10/2022-19:41:11] [V] [TRT] Tactic: 0x0000000000000002 Time: 135.731
[06/10/2022-19:41:12] [V] [TRT] Tactic: 0x0000000000000005 Time: 181.756
[06/10/2022-19:41:13] [V] [TRT] Tactic: 0x0000000000000038 Time: 131.743
[06/10/2022-19:41:14] [V] [TRT] Tactic: 0x0000000000000039 Time: 49.4428
[06/10/2022-19:41:15] [V] [TRT] Tactic: 0x000000000000003a Time: 136.082
[06/10/2022-19:41:16] [V] [TRT] Tactic: 0x000000000000003d Time: 181.388
[06/10/2022-19:41:17] [V] [TRT] Tactic: 0x0000000000000070 Time: 132.303
[06/10/2022-19:41:18] [V] [TRT] Tactic: 0x0000000000000071 Time: 121.685
[06/10/2022-19:41:20] [V] [TRT] Tactic: 0x0000000000000072 Time: 136.021
[06/10/2022-19:41:21] [V] [TRT] Tactic: 0x0000000000000075 Time: 182.773
[06/10/2022-19:41:21] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 49.3041
[06/10/2022-19:41:21] [V] [TRT] --------------- Timing Runner: Conv_2382 + Relu_2383 (CublasConvolution)
[06/10/2022-19:41:21] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:41:21] [V] [TRT] --------------- Timing Runner: Conv_2382 + Relu_2383 (CaskConvolution)
[06/10/2022-19:41:21] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a
[06/10/2022-19:41:22] [V] [TRT] Tactic: 0x1fc87d7eb370bb7a Time: 119.845
[06/10/2022-19:41:22] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675
[06/10/2022-19:41:23] [V] [TRT] Tactic: 0x2ee10e11d6651675 Time: 95.6583
[06/10/2022-19:41:23] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:41:24] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 101.122
[06/10/2022-19:41:24] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:41:24] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 90.1815
[06/10/2022-19:41:24] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338
[06/10/2022-19:41:25] [V] [TRT] Tactic: 0x7f0145cb49517338 Time: 40.6821
[06/10/2022-19:41:25] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd
[06/10/2022-19:41:26] [V] [TRT] Tactic: 0x865894c4635db7fd Time: 118.435
[06/10/2022-19:41:26] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd
[06/10/2022-19:41:27] [V] [TRT] Tactic: 0x8e3884f0eaec3ecd Time: 105.378
[06/10/2022-19:41:27] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:41:27] [V] [TRT] Tactic: 0x9808072e706def96 Time: 104.211
[06/10/2022-19:41:27] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505
[06/10/2022-19:41:28] [V] [TRT] Tactic: 0x9cd5cdc35441c505 Time: 100.563
[06/10/2022-19:41:28] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4
[06/10/2022-19:41:29] [V] [TRT] Tactic: 0x9de226a0c44627c4 Time: 101.152
[06/10/2022-19:41:29] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b
[06/10/2022-19:41:29] [V] [TRT] Tactic: 0xa419b3b68f2da07b Time: 41.6442
[06/10/2022-19:41:29] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:41:30] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 113.312
[06/10/2022-19:41:30] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:41:31] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 89.4012
[06/10/2022-19:41:31] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e
[06/10/2022-19:41:32] [V] [TRT] Tactic: 0xc0b05b61d128e46e Time: 99.4652
[06/10/2022-19:41:32] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:41:33] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 95.1824
[06/10/2022-19:41:33] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303
[06/10/2022-19:41:33] [V] [TRT] Tactic: 0xe5603263b7f00303 Time: 104.991
[06/10/2022-19:41:33] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:41:34] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 91.404
[06/10/2022-19:41:34] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:41:35] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 103.434
[06/10/2022-19:41:35] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1
[06/10/2022-19:41:36] [V] [TRT] Tactic: 0xfff46c7893896eb1 Time: 87.7499
[06/10/2022-19:41:36] [V] [TRT] Fastest Tactic: 0x7f0145cb49517338 Time: 40.6821
[06/10/2022-19:41:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x7f0145cb49517338
[06/10/2022-19:41:36] [V] [TRT] *************** Autotuning format combination: Float(201326592,1,786432,3072) -> Float(50331648,1,196608,768) ***************
[06/10/2022-19:41:36] [V] [TRT] --------------- Timing Runner: Conv_2382 + Relu_2383 (CublasConvolution)
[06/10/2022-19:41:36] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:41:36] [V] [TRT] --------------- Timing Runner: Conv_2382 + Relu_2383 (CaskConvolution)
[06/10/2022-19:41:36] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[06/10/2022-19:41:37] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 90.3373
[06/10/2022-19:41:37] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:41:37] [V] [TRT] Tactic: 0x130df49cb195156b Time: 32.1431
[06/10/2022-19:41:37] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484
[06/10/2022-19:41:38] [V] [TRT] Tactic: 0x17173deba0b64484 Time: 95.2221
[06/10/2022-19:41:38] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x27b316f52c109002
[06/10/2022-19:41:38] [V] [TRT] Tactic: 0x27b316f52c109002 Time: 99.5565
[06/10/2022-19:41:38] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[06/10/2022-19:41:39] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 92.2052
[06/10/2022-19:41:39] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x3e191488237fab8f
[06/10/2022-19:41:40] [V] [TRT] Tactic: 0x3e191488237fab8f Time: 114.186
[06/10/2022-19:41:40] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d
[06/10/2022-19:41:41] [V] [TRT] Tactic: 0x3e2b881168d9689d Time: 112.31
[06/10/2022-19:41:41] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x412c44dfeaf9161d
[06/10/2022-19:41:42] [V] [TRT] Tactic: 0x412c44dfeaf9161d Time: 99.6623
[06/10/2022-19:41:42] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x5030121339a48bf3
[06/10/2022-19:41:43] [V] [TRT] Tactic: 0x5030121339a48bf3 Time: 96.5891
[06/10/2022-19:41:43] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[06/10/2022-19:41:44] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 116.206
[06/10/2022-19:41:44] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48
[06/10/2022-19:41:44] [V] [TRT] Tactic: 0x7bc32c782b800c48 Time: 90.9909
[06/10/2022-19:41:44] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[06/10/2022-19:41:45] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 115.12
[06/10/2022-19:41:45] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:41:45] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 33.1017
[06/10/2022-19:41:45] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3
[06/10/2022-19:41:46] [V] [TRT] Tactic: 0xae0c89d047932ba3 Time: 93.0301
[06/10/2022-19:41:46] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[06/10/2022-19:41:47] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 88.271
[06/10/2022-19:41:47] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[06/10/2022-19:41:48] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 90.3098
[06/10/2022-19:41:48] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7
[06/10/2022-19:41:49] [V] [TRT] Tactic: 0xc7feb33970feefa7 Time: 111.343
[06/10/2022-19:41:49] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[06/10/2022-19:41:49] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 90.5933
[06/10/2022-19:41:49] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0xd9031472c05adf51
[06/10/2022-19:41:50] [V] [TRT] Tactic: 0xd9031472c05adf51 Time: 97.3392
[06/10/2022-19:41:50] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4
[06/10/2022-19:41:51] [V] [TRT] Tactic: 0xe47307053a42b3e4 Time: 91.0836
[06/10/2022-19:41:51] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811
[06/10/2022-19:41:52] [V] [TRT] Tactic: 0xf90060ce8193b811 Time: 91.7731
[06/10/2022-19:41:52] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 32.1431
[06/10/2022-19:41:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:41:52] [V] [TRT] *************** Autotuning format combination: Float(50331648,1:4,196608,768) -> Float(12582912,1:4,49152,192) ***************
[06/10/2022-19:41:52] [V] [TRT] --------------- Timing Runner: Conv_2382 + Relu_2383 (CublasConvolution)
[06/10/2022-19:41:52] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:41:52] [V] [TRT] --------------- Timing Runner: Conv_2382 + Relu_2383 (CaskConvolution)
[06/10/2022-19:41:52] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:41:52] [V] [TRT] Tactic: 0x130df49cb195156b Time: 32.7282
[06/10/2022-19:41:52] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:41:52] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 32.925
[06/10/2022-19:41:52] [V] [TRT] Fastest Tactic: 0x130df49cb195156b Time: 32.7282
[06/10/2022-19:41:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x130df49cb195156b
[06/10/2022-19:41:52] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:41:52] [V] [TRT] *************** Autotuning format combination: Float(50331648,65536,256,1) -> Float(1245184,65536,256,1) ***************
[06/10/2022-19:41:52] [V] [TRT] --------------- Timing Runner: Conv_2384 (CudaDepthwiseConvolution)
[06/10/2022-19:41:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[06/10/2022-19:41:52] [V] [TRT] --------------- Timing Runner: Conv_2384 (FusedConvActConvolution)
[06/10/2022-19:41:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[06/10/2022-19:41:52] [V] [TRT] --------------- Timing Runner: Conv_2384 (CudnnConvolution)
[06/10/2022-19:41:52] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.90903
[06/10/2022-19:41:52] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.7566
[06/10/2022-19:41:52] [V] [TRT] Tactic: 0x0000000000000002 Time: 7.60057
[06/10/2022-19:41:53] [V] [TRT] Tactic: 0x0000000000000004 Time: 66.7312
[06/10/2022-19:41:53] [V] [TRT] Tactic: 0x0000000000000005 Time: 5.93101
[06/10/2022-19:41:53] [V] [TRT] Tactic: 0x0000000000000038 Time: 1.83618
[06/10/2022-19:41:53] [V] [TRT] Tactic: 0x0000000000000039 Time: 1.73729
[06/10/2022-19:41:53] [V] [TRT] Tactic: 0x000000000000003a Time: 7.47622
[06/10/2022-19:41:54] [V] [TRT] Tactic: 0x000000000000003c Time: 66.8573
[06/10/2022-19:41:54] [V] [TRT] Tactic: 0x000000000000003d Time: 5.95076
[06/10/2022-19:41:54] [V] [TRT] Tactic: 0x0000000000000070 Time: 1.82857
[06/10/2022-19:41:54] [V] [TRT] Tactic: 0x0000000000000071 Time: 1.7348
[06/10/2022-19:41:54] [V] [TRT] Tactic: 0x0000000000000072 Time: 7.45341
[06/10/2022-19:41:54] [V] [TRT] Tactic: 0x0000000000000074 Time: 66.7458
[06/10/2022-19:41:54] [V] [TRT] Tactic: 0x0000000000000075 Time: 5.9746
[06/10/2022-19:41:54] [V] [TRT] Fastest Tactic: 0x0000000000000071 Time: 1.7348
[06/10/2022-19:41:54] [V] [TRT] --------------- Timing Runner: Conv_2384 (CublasConvolution)
[06/10/2022-19:41:54] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:41:54] [V] [TRT] --------------- Timing Runner: Conv_2384 (CaskConvolution)
[06/10/2022-19:41:54] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a
[06/10/2022-19:41:54] [V] [TRT] Tactic: 0x1fc87d7eb370bb7a Time: 2.15011
[06/10/2022-19:41:54] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675
[06/10/2022-19:41:54] [V] [TRT] Tactic: 0x2ee10e11d6651675 Time: 7.78152
[06/10/2022-19:41:54] [V] [TRT] Conv_2384 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb
[06/10/2022-19:41:54] [V] [TRT] Tactic: 0x3f243c490d502deb Time: 1.9949
[06/10/2022-19:41:54] [V] [TRT] Conv_2384 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff
[06/10/2022-19:41:54] [V] [TRT] Tactic: 0x503619c69ae500ff Time: 3.65451
[06/10/2022-19:41:54] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x7f0145cb49517338 Time: 1.97954
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x865894c4635db7fd Time: 2.20511
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x8e3884f0eaec3ecd Time: 2.34013
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x9808072e706def96 Time: 1.67029
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x9cd5cdc35441c505 Time: 4.0489
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x9de226a0c44627c4 Time: 8.05508
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xa419b3b68f2da07b Time: 1.79566
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xa8609adc4e0ceb90 Time: 1.64703
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xa8ef60e712f8ad24 Time: 3.25793
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xc0b05b61d128e46e Time: 4.10258
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xc3cf6e1d1c6aff27 Time: 1.8767
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xe5603263b7f00303 Time: 2.54537
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xf067e6205da31c2e Time: 3.83064
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xf64396b97c889179 Time: 2.10754
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xfff46c7893896eb1 Time: 4.00267
[06/10/2022-19:41:55] [V] [TRT] Fastest Tactic: 0xa8609adc4e0ceb90 Time: 1.64703
[06/10/2022-19:41:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xa8609adc4e0ceb90
[06/10/2022-19:41:55] [V] [TRT] *************** Autotuning format combination: Float(50331648,1,196608,768) -> Float(1245184,1,4864,19) ***************
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: Conv_2384 (CublasConvolution)
[06/10/2022-19:41:55] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: Conv_2384 (CaskConvolution)
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x1022069e6f8d9aeb Time: 3.16562
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x35f26f9c09557d86 Time: 1.91781
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x55d80c17b1cd982d Time: 2.2664
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x90898977fc8ce537 Time: 2.32828
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xbc0bba0ff1a92939 Time: 2.59087
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xc7b3afceb5fb03c0 Time: 3.39734
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0xd55ee6fd0b56f808 Time: 1.96549
[06/10/2022-19:41:55] [V] [TRT] Fastest Tactic: 0x35f26f9c09557d86 Time: 1.91781
[06/10/2022-19:41:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x35f26f9c09557d86
[06/10/2022-19:41:55] [V] [TRT] *************** Autotuning format combination: Float(12582912,1:4,49152,192) -> Float(327680,1:4,1280,5) ***************
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: Conv_2384 (CublasConvolution)
[06/10/2022-19:41:55] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: Conv_2384 (CaskConvolution)
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x130df49cb195156b Time: 1.85008
[06/10/2022-19:41:55] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x9dece0dc37e90462 Time: 1.8296
[06/10/2022-19:41:55] [V] [TRT] Fastest Tactic: 0x9dece0dc37e90462 Time: 1.8296
[06/10/2022-19:41:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9dece0dc37e90462
[06/10/2022-19:41:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:41:55] [V] [TRT] *************** Autotuning format combination: Float(1245184,65536,256,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: Resize_2393 (Resize)
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.01873
[06/10/2022-19:41:55] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.01873
[06/10/2022-19:41:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0x0000000000000001
[06/10/2022-19:41:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:41:55] [V] [TRT] *************** Autotuning format combination:  -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:41:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:41:55] [V] [TRT] *************** Autotuning format combination:  -> Float(1,1,1,1) ***************
[06/10/2022-19:41:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:41:55] [V] [TRT] *************** Autotuning format combination: Float(1,1,1,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: ConstantOfShape_13 (Slice)
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.644974
[06/10/2022-19:41:55] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.644974
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: ConstantOfShape_13 (Padding)
[06/10/2022-19:41:55] [V] [TRT] Padding has no valid tactics for this config, skipping
[06/10/2022-19:41:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Slice Tactic: 0x0000000000000000
[06/10/2022-19:41:55] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:41:55] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:55] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.2939
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.29858
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.29565
[06/10/2022-19:41:55] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.2939
[06/10/2022-19:41:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[06/10/2022-19:41:55] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:55] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.35856
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.14133
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.3688
[06/10/2022-19:41:55] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.35856
[06/10/2022-19:41:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[06/10/2022-19:41:55] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:55] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.44048
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.28089
[06/10/2022-19:41:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.44019
[06/10/2022-19:41:55] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.28089
[06/10/2022-19:41:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:55] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:55] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:55] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 30.5364
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.93448
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 30.5807
[06/10/2022-19:41:56] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.93448
[06/10/2022-19:41:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:56] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:41:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:56] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.30092
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.30311
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.31745
[06/10/2022-19:41:56] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.30092
[06/10/2022-19:41:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[06/10/2022-19:41:56] [V] [TRT] *************** Autotuning format combination: Float(19922944,1,19456,19) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:41:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:56] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 6.34821
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.95774
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.3469
[06/10/2022-19:41:56] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.95774
[06/10/2022-19:41:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:56] [V] [TRT] *************** Autotuning format combination: Float(19922944,1,19456,19) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:41:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:56] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.26566
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.29975
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.25718
[06/10/2022-19:41:56] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.25718
[06/10/2022-19:41:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[06/10/2022-19:41:56] [V] [TRT] *************** Autotuning format combination: Float(19922944,1,19456,19) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:41:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:56] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.48774
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.20746
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.50061
[06/10/2022-19:41:56] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.20746
[06/10/2022-19:41:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:56] [V] [TRT] *************** Autotuning format combination: Float(19922944,1,19456,19) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:41:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:56] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:56] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 32.7288
[06/10/2022-19:41:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.92995
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 32.742
[06/10/2022-19:41:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.92995
[06/10/2022-19:41:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:57] [V] [TRT] *************** Autotuning format combination: Float(19922944,1,19456,19) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:41:57] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:57] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:57] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 10.8622
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.14061
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 10.8617
[06/10/2022-19:41:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.14061
[06/10/2022-19:41:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:57] [V] [TRT] *************** Autotuning format combination: Float(5242880,1:4,5120,5) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:41:57] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:57] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:57] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 6.40073
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 1.93697
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.39737
[06/10/2022-19:41:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 1.93697
[06/10/2022-19:41:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:57] [V] [TRT] *************** Autotuning format combination: Float(5242880,1:4,5120,5) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:41:57] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:57] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:57] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.28161
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.24563
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.29507
[06/10/2022-19:41:57] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.28161
[06/10/2022-19:41:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[06/10/2022-19:41:57] [V] [TRT] *************** Autotuning format combination: Float(5242880,1:4,5120,5) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:41:57] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:57] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:57] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.51889
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.43493
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.52006
[06/10/2022-19:41:57] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.43493
[06/10/2022-19:41:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:57] [V] [TRT] *************** Autotuning format combination: Float(5242880,1:4,5120,5) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:41:57] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:57] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:57] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 32.6336
[06/10/2022-19:41:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.04595
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 32.6488
[06/10/2022-19:41:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.04595
[06/10/2022-19:41:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:58] [V] [TRT] *************** Autotuning format combination: Float(5242880,1:4,5120,5) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:41:58] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:58] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:58] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 10.8859
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.30138
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 10.888
[06/10/2022-19:41:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.30138
[06/10/2022-19:41:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:58] [V] [TRT] *************** Autotuning format combination: Float(1048576,1048576:32,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:41:58] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:58] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:58] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 6.98514
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.05634
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 6.98105
[06/10/2022-19:41:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.05634
[06/10/2022-19:41:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:58] [V] [TRT] *************** Autotuning format combination: Float(1048576,1048576:32,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:41:58] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:58] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:58] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.48524
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.29873
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.42087
[06/10/2022-19:41:58] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.42087
[06/10/2022-19:41:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[06/10/2022-19:41:58] [V] [TRT] *************** Autotuning format combination: Float(1048576,1048576:32,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:41:58] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:58] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:58] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 2.70716
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.4794
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.69605
[06/10/2022-19:41:58] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.4794
[06/10/2022-19:41:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:58] [V] [TRT] *************** Autotuning format combination: Float(1048576,1048576:32,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:41:58] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:58] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:58] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x00000000000003e8 Time: 32.8518
[06/10/2022-19:41:58] [V] [TRT] Tactic: 0x00000000000003ea Time: 2.03864
[06/10/2022-19:41:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 32.8555
[06/10/2022-19:41:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 2.03864
[06/10/2022-19:41:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:59] [V] [TRT] *************** Autotuning format combination: Float(1048576,1048576:32,1024,1) -> Float(1:4,(* 1048576 E0),(* 1024 E0),E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:41:59] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:59] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:59] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 11.4849
[06/10/2022-19:41:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 3.51656
[06/10/2022-19:41:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 11.4869
[06/10/2022-19:41:59] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 3.51656
[06/10/2022-19:41:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[06/10/2022-19:41:59] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) -> Float(19922944,1048576,1024,1) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:41:59] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:59] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:59] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.09877
[06/10/2022-19:41:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 10.8389
[06/10/2022-19:41:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.09363
[06/10/2022-19:41:59] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 3.09363
[06/10/2022-19:41:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[06/10/2022-19:41:59] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) -> Float(19922944,1,19456,19) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:41:59] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:59] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:59] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 3.25032
[06/10/2022-19:41:59] [V] [TRT] Tactic: 0x00000000000003ea Time: 34.0027
[06/10/2022-19:41:59] [V] [TRT] Tactic: 0x0000000000000000 Time: 3.25091
[06/10/2022-19:41:59] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 3.25032
[06/10/2022-19:41:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[06/10/2022-19:41:59] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) -> Float(5242880,1:4,5120,5) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:41:59] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:41:59] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:41:59] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:41:59] [V] [TRT] Tactic: 0x00000000000003e8 Time: 4.40319
[06/10/2022-19:42:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 33.8245
[06/10/2022-19:42:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.40598
[06/10/2022-19:42:00] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 4.40319
[06/10/2022-19:42:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[06/10/2022-19:42:00] [V] [TRT] *************** Autotuning format combination: Float(1:4,(* 1048576 E0),(* 1024 E0),E0) -> Float(1048576,1048576:32,1024,1) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) ***************
[06/10/2022-19:42:00] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:42:00] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:42:00] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:42:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 31.3511
[06/10/2022-19:42:00] [V] [TRT] Tactic: 0x00000000000003ea Time: 34.3059
[06/10/2022-19:42:00] [V] [TRT] Tactic: 0x0000000000000000 Time: 31.3325
[06/10/2022-19:42:00] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 31.3325
[06/10/2022-19:42:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[06/10/2022-19:42:00] [V] [TRT] *************** Autotuning format combination: Float(1:4,E2,E1,E0) -> Float(1:4,E2,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 1024 E0) E2=(* 1048576 E0) ***************
[06/10/2022-19:42:00] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Cast)
[06/10/2022-19:42:00] [V] [TRT] Cast has no valid tactics for this config, skipping
[06/10/2022-19:42:00] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3327) [Identity] (Reformat)
[06/10/2022-19:42:00] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.24606
[06/10/2022-19:42:01] [V] [TRT] Tactic: 0x00000000000003ea Time: 10.9716
[06/10/2022-19:42:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.32432
[06/10/2022-19:42:01] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 1.24606
[06/10/2022-19:42:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[06/10/2022-19:42:01] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:42:01] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1), Float(19922944,1048576,1024,1), Float(1048576,1048576,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:42:01] [V] [TRT] --------------- Timing Runner: PWN(Add_2409, Div_2411) (PointWiseV2)
[06/10/2022-19:42:01] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.5363
[06/10/2022-19:42:01] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.63782
[06/10/2022-19:42:01] [V] [TRT] Tactic: 0x0000000000000002 Time: 2.63256
[06/10/2022-19:42:01] [V] [TRT] Tactic: 0x0000000000000003 Time: 2.63665
[06/10/2022-19:42:02] [V] [TRT] Tactic: 0x0000000000000004 Time: 2.53689
[06/10/2022-19:42:02] [V] [TRT] Tactic: 0x0000000000000005 Time: 2.56395
[06/10/2022-19:42:02] [V] [TRT] Tactic: 0x0000000000000006 Time: 2.76056
[06/10/2022-19:42:02] [V] [TRT] Tactic: 0x0000000000000007 Time: 2.60228
[06/10/2022-19:42:02] [V] [TRT] Tactic: 0x0000000000000008 Time: 2.61135
[06/10/2022-19:42:03] [V] [TRT] Tactic: 0x0000000000000009 Time: 2.60901
[06/10/2022-19:42:03] [V] [TRT] Tactic: 0x000000000000001c Time: 2.53572
[06/10/2022-19:42:03] [V] [TRT] Fastest Tactic: 0x000000000000001c Time: 2.53572
[06/10/2022-19:42:03] [V] [TRT] --------------- Timing Runner: PWN(Add_2409, Div_2411) (PointWise)
[06/10/2022-19:42:03] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:42:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001c
[06/10/2022-19:42:03] [V] [TRT] *************** Autotuning format combination: Float(19922944,1,19456,19), Float(19922944,1,19456,19), Float(1048576,1,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:42:03] [V] [TRT] --------------- Timing Runner: PWN(Add_2409, Div_2411) (PointWiseV2)
[06/10/2022-19:42:03] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.08077
[06/10/2022-19:42:03] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.38533
[06/10/2022-19:42:03] [V] [TRT] Tactic: 0x0000000000000002 Time: 2.1896
[06/10/2022-19:42:04] [V] [TRT] Tactic: 0x0000000000000003 Time: 2.80487
[06/10/2022-19:42:04] [V] [TRT] Tactic: 0x0000000000000004 Time: 2.95146
[06/10/2022-19:42:04] [V] [TRT] Tactic: 0x0000000000000005 Time: 2.52533
[06/10/2022-19:42:04] [V] [TRT] Tactic: 0x0000000000000006 Time: 3.49213
[06/10/2022-19:42:04] [V] [TRT] Tactic: 0x0000000000000007 Time: 3.72765
[06/10/2022-19:42:05] [V] [TRT] Tactic: 0x0000000000000008 Time: 3.82011
[06/10/2022-19:42:05] [V] [TRT] Tactic: 0x0000000000000009 Time: 3.87657
[06/10/2022-19:42:05] [V] [TRT] Tactic: 0x000000000000001c Time: 1.95262
[06/10/2022-19:42:05] [V] [TRT] Fastest Tactic: 0x000000000000001c Time: 1.95262
[06/10/2022-19:42:05] [V] [TRT] --------------- Timing Runner: PWN(Add_2409, Div_2411) (PointWise)
[06/10/2022-19:42:05] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:42:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001c
[06/10/2022-19:42:05] [V] [TRT] *************** Autotuning format combination: Float(5242880,1:4,5120,5), Float(5242880,1:4,5120,5), Float(1048576,1:4,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:42:05] [V] [TRT] --------------- Timing Runner: PWN(Add_2409, Div_2411) (PointWiseV2)
[06/10/2022-19:42:05] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.87264
[06/10/2022-19:42:05] [V] [TRT] Tactic: 0x0000000000000001 Time: 6.63099
[06/10/2022-19:42:06] [V] [TRT] Tactic: 0x0000000000000002 Time: 8.1781
[06/10/2022-19:42:06] [V] [TRT] Tactic: 0x0000000000000003 Time: 7.43146
[06/10/2022-19:42:06] [V] [TRT] Tactic: 0x0000000000000004 Time: 10.6508
[06/10/2022-19:42:07] [V] [TRT] Tactic: 0x0000000000000005 Time: 6.02244
[06/10/2022-19:42:07] [V] [TRT] Tactic: 0x0000000000000006 Time: 9.11682
[06/10/2022-19:42:07] [V] [TRT] Tactic: 0x0000000000000007 Time: 12.4845
[06/10/2022-19:42:07] [V] [TRT] Tactic: 0x0000000000000008 Time: 8.8696
[06/10/2022-19:42:08] [V] [TRT] Tactic: 0x0000000000000009 Time: 9.27115
[06/10/2022-19:42:08] [V] [TRT] Tactic: 0x000000000000000a Time: 3.11194
[06/10/2022-19:42:08] [V] [TRT] Tactic: 0x000000000000000b Time: 3.84892
[06/10/2022-19:42:08] [V] [TRT] Tactic: 0x000000000000000c Time: 3.65071
[06/10/2022-19:42:09] [V] [TRT] Tactic: 0x000000000000000d Time: 4.36034
[06/10/2022-19:42:09] [V] [TRT] Tactic: 0x000000000000000e Time: 5.31178
[06/10/2022-19:42:09] [V] [TRT] Tactic: 0x000000000000000f Time: 4.67237
[06/10/2022-19:42:09] [V] [TRT] Tactic: 0x0000000000000010 Time: 5.41286
[06/10/2022-19:42:10] [V] [TRT] Tactic: 0x0000000000000011 Time: 6.51995
[06/10/2022-19:42:10] [V] [TRT] Tactic: 0x0000000000000012 Time: 7.2192
[06/10/2022-19:42:10] [V] [TRT] Tactic: 0x0000000000000013 Time: 4.37526
[06/10/2022-19:42:10] [V] [TRT] Tactic: 0x0000000000000014 Time: 2.33765
[06/10/2022-19:42:11] [V] [TRT] Tactic: 0x0000000000000015 Time: 2.70424
[06/10/2022-19:42:11] [V] [TRT] Tactic: 0x0000000000000016 Time: 3.18844
[06/10/2022-19:42:11] [V] [TRT] Tactic: 0x0000000000000017 Time: 4.45484
[06/10/2022-19:42:11] [V] [TRT] Tactic: 0x000000000000001c Time: 2.18697
[06/10/2022-19:42:11] [V] [TRT] Tactic: 0x000000000000001d Time: 2.17278
[06/10/2022-19:42:12] [V] [TRT] Tactic: 0x000000000000001e Time: 2.16635
[06/10/2022-19:42:12] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 2.16635
[06/10/2022-19:42:12] [V] [TRT] --------------- Timing Runner: PWN(Add_2409, Div_2411) (PointWise)
[06/10/2022-19:42:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:42:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[06/10/2022-19:42:12] [V] [TRT] *************** Autotuning format combination: Float(1048576,1048576:32,1024,1), Float(1048576,1048576:32,1024,1), Float(1048576,1048576:32,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:42:12] [V] [TRT] --------------- Timing Runner: PWN(Add_2409, Div_2411) (PointWiseV2)
[06/10/2022-19:42:12] [V] [TRT] Tactic: 0x0000000000000018 Time: 3.61238
[06/10/2022-19:42:12] [V] [TRT] Tactic: 0x0000000000000019 Time: 3.69328
[06/10/2022-19:42:12] [V] [TRT] Tactic: 0x000000000000001a Time: 3.71434
[06/10/2022-19:42:13] [V] [TRT] Tactic: 0x000000000000001b Time: 3.73087
[06/10/2022-19:42:13] [V] [TRT] Tactic: 0x000000000000001f Time: 3.61677
[06/10/2022-19:42:13] [V] [TRT] Fastest Tactic: 0x0000000000000018 Time: 3.61238
[06/10/2022-19:42:13] [V] [TRT] --------------- Timing Runner: PWN(Add_2409, Div_2411) (PointWise)
[06/10/2022-19:42:13] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:42:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000018
[06/10/2022-19:42:13] [V] [TRT] *************** Autotuning format combination: Float(1:4,E2,E1,E0), Float(1:4,E2,E1,E0), Float(1:4,1048576,1024,1) -> Float(1:4,E2,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 1024 E0) E2=(* 1048576 E0) ***************
[06/10/2022-19:42:13] [V] [TRT] --------------- Timing Runner: PWN(Add_2409, Div_2411) (PointWiseV2)
[06/10/2022-19:42:13] [V] [TRT] Tactic: 0x0000000000000000 Time: 30.258
[06/10/2022-19:42:13] [V] [TRT] Tactic: 0x0000000000000001 Time: 33.0395
[06/10/2022-19:42:14] [V] [TRT] Tactic: 0x0000000000000002 Time: 39.6728
[06/10/2022-19:42:14] [V] [TRT] Tactic: 0x0000000000000003 Time: 37.322
[06/10/2022-19:42:14] [V] [TRT] Tactic: 0x0000000000000004 Time: 49.4038
[06/10/2022-19:42:15] [V] [TRT] Tactic: 0x0000000000000005 Time: 33.0446
[06/10/2022-19:42:15] [V] [TRT] Tactic: 0x0000000000000006 Time: 44.2318
[06/10/2022-19:42:15] [V] [TRT] Tactic: 0x0000000000000007 Time: 57.3455
[06/10/2022-19:42:16] [V] [TRT] Tactic: 0x0000000000000008 Time: 44.1928
[06/10/2022-19:42:16] [V] [TRT] Tactic: 0x0000000000000009 Time: 44.4878
[06/10/2022-19:42:16] [V] [TRT] Tactic: 0x000000000000000a Time: 17.6874
[06/10/2022-19:42:16] [V] [TRT] Tactic: 0x000000000000000b Time: 20.622
[06/10/2022-19:42:17] [V] [TRT] Tactic: 0x000000000000000c Time: 20.2916
[06/10/2022-19:42:17] [V] [TRT] Tactic: 0x000000000000000d Time: 23.881
[06/10/2022-19:42:17] [V] [TRT] Tactic: 0x000000000000000e Time: 28.1145
[06/10/2022-19:42:17] [V] [TRT] Tactic: 0x000000000000000f Time: 24.8968
[06/10/2022-19:42:17] [V] [TRT] Tactic: 0x0000000000000010 Time: 28.2666
[06/10/2022-19:42:18] [V] [TRT] Tactic: 0x0000000000000011 Time: 33.7041
[06/10/2022-19:42:18] [V] [TRT] Tactic: 0x0000000000000012 Time: 36.0193
[06/10/2022-19:42:18] [V] [TRT] Tactic: 0x0000000000000013 Time: 23.6677
[06/10/2022-19:42:18] [V] [TRT] Tactic: 0x0000000000000014 Time: 12.6992
[06/10/2022-19:42:18] [V] [TRT] Tactic: 0x0000000000000015 Time: 15.4789
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x0000000000000016 Time: 18.6712
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x0000000000000017 Time: 24.6876
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x000000000000001c Time: 2.53572
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x000000000000001d Time: 2.51655
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x000000000000001e Time: 2.53513
[06/10/2022-19:42:19] [V] [TRT] Fastest Tactic: 0x000000000000001d Time: 2.51655
[06/10/2022-19:42:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001d
[06/10/2022-19:42:19] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:42:19] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:42:19] [V] [TRT] --------------- Timing Runner: Resize_2420 (Resize)
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.29814
[06/10/2022-19:42:19] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.29814
[06/10/2022-19:42:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0x0000000000000001
[06/10/2022-19:42:19] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:42:19] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:42:19] [V] [TRT] --------------- Timing Runner: ReduceMax_2421 (Reduce)
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.665897
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.74869
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.744448
[06/10/2022-19:42:19] [V] [TRT] Fastest Tactic: 0x0000000000000005 Time: 0.665897
[06/10/2022-19:42:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000005
[06/10/2022-19:42:19] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:42:19] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1), Float(1048576,1048576,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:42:19] [V] [TRT] --------------- Timing Runner: PWN(Sub_2422, Exp_2423) (PointWiseV2)
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.92176
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.00909
[06/10/2022-19:42:19] [V] [TRT] Tactic: 0x0000000000000002 Time: 1.9494
[06/10/2022-19:42:20] [V] [TRT] Tactic: 0x0000000000000003 Time: 2.02079
[06/10/2022-19:42:20] [V] [TRT] Tactic: 0x0000000000000004 Time: 1.95511
[06/10/2022-19:42:20] [V] [TRT] Tactic: 0x0000000000000005 Time: 1.97734
[06/10/2022-19:42:20] [V] [TRT] Tactic: 0x0000000000000006 Time: 2.09072
[06/10/2022-19:42:20] [V] [TRT] Tactic: 0x0000000000000007 Time: 2.00119
[06/10/2022-19:42:21] [V] [TRT] Tactic: 0x0000000000000008 Time: 2.02854
[06/10/2022-19:42:21] [V] [TRT] Tactic: 0x0000000000000009 Time: 2.02547
[06/10/2022-19:42:21] [V] [TRT] Tactic: 0x000000000000001c Time: 1.9219
[06/10/2022-19:42:21] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 1.92176
[06/10/2022-19:42:21] [V] [TRT] --------------- Timing Runner: PWN(Sub_2422, Exp_2423) (PointWise)
[06/10/2022-19:42:21] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:42:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x0000000000000000
[06/10/2022-19:42:21] [V] [TRT] *************** Autotuning format combination: Float(19922944,1,19456,19), Float(1048576,1,1024,1) -> Float(19922944,1,19456,19) ***************
[06/10/2022-19:42:21] [V] [TRT] --------------- Timing Runner: PWN(Sub_2422, Exp_2423) (PointWiseV2)
[06/10/2022-19:42:21] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.40917
[06/10/2022-19:42:21] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.55619
[06/10/2022-19:42:21] [V] [TRT] Tactic: 0x0000000000000002 Time: 1.46651
[06/10/2022-19:42:22] [V] [TRT] Tactic: 0x0000000000000003 Time: 1.83706
[06/10/2022-19:42:22] [V] [TRT] Tactic: 0x0000000000000004 Time: 1.93141
[06/10/2022-19:42:22] [V] [TRT] Tactic: 0x0000000000000005 Time: 1.65113
[06/10/2022-19:42:22] [V] [TRT] Tactic: 0x0000000000000006 Time: 2.47545
[06/10/2022-19:42:22] [V] [TRT] Tactic: 0x0000000000000007 Time: 2.43229
[06/10/2022-19:42:23] [V] [TRT] Tactic: 0x0000000000000008 Time: 2.39075
[06/10/2022-19:42:23] [V] [TRT] Tactic: 0x0000000000000009 Time: 2.71857
[06/10/2022-19:42:23] [V] [TRT] Tactic: 0x000000000000001c Time: 1.32067
[06/10/2022-19:42:23] [V] [TRT] Fastest Tactic: 0x000000000000001c Time: 1.32067
[06/10/2022-19:42:23] [V] [TRT] --------------- Timing Runner: PWN(Sub_2422, Exp_2423) (PointWise)
[06/10/2022-19:42:23] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:42:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001c
[06/10/2022-19:42:23] [V] [TRT] *************** Autotuning format combination: Float(5242880,1:4,5120,5), Float(1048576,1:4,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:42:23] [V] [TRT] --------------- Timing Runner: PWN(Sub_2422, Exp_2423) (PointWiseV2)
[06/10/2022-19:42:23] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.36515
[06/10/2022-19:42:23] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.7392
[06/10/2022-19:42:24] [V] [TRT] Tactic: 0x0000000000000002 Time: 4.02461
[06/10/2022-19:42:24] [V] [TRT] Tactic: 0x0000000000000003 Time: 3.34512
[06/10/2022-19:42:24] [V] [TRT] Tactic: 0x0000000000000004 Time: 5.47109
[06/10/2022-19:42:24] [V] [TRT] Tactic: 0x0000000000000005 Time: 3.24842
[06/10/2022-19:42:24] [V] [TRT] Tactic: 0x0000000000000006 Time: 4.51511
[06/10/2022-19:42:25] [V] [TRT] Tactic: 0x0000000000000007 Time: 6.73339
[06/10/2022-19:42:25] [V] [TRT] Tactic: 0x0000000000000008 Time: 4.6485
[06/10/2022-19:42:25] [V] [TRT] Tactic: 0x0000000000000009 Time: 4.06674
[06/10/2022-19:42:25] [V] [TRT] Tactic: 0x000000000000000a Time: 1.72866
[06/10/2022-19:42:26] [V] [TRT] Tactic: 0x000000000000000b Time: 2.08794
[06/10/2022-19:42:26] [V] [TRT] Tactic: 0x000000000000000c Time: 2.05634
[06/10/2022-19:42:26] [V] [TRT] Tactic: 0x000000000000000d Time: 2.55239
[06/10/2022-19:42:26] [V] [TRT] Tactic: 0x000000000000000e Time: 2.94619
[06/10/2022-19:42:26] [V] [TRT] Tactic: 0x000000000000000f Time: 2.61413
[06/10/2022-19:42:27] [V] [TRT] Tactic: 0x0000000000000010 Time: 3.58678
[06/10/2022-19:42:27] [V] [TRT] Tactic: 0x0000000000000011 Time: 3.77505
[06/10/2022-19:42:27] [V] [TRT] Tactic: 0x0000000000000012 Time: 4.05299
[06/10/2022-19:42:27] [V] [TRT] Tactic: 0x0000000000000013 Time: 4.81514
[06/10/2022-19:42:27] [V] [TRT] Tactic: 0x0000000000000014 Time: 1.57418
[06/10/2022-19:42:28] [V] [TRT] Tactic: 0x0000000000000015 Time: 1.79771
[06/10/2022-19:42:28] [V] [TRT] Tactic: 0x0000000000000016 Time: 2.29157
[06/10/2022-19:42:28] [V] [TRT] Tactic: 0x0000000000000017 Time: 3.34117
[06/10/2022-19:42:28] [V] [TRT] Tactic: 0x000000000000001c Time: 1.51596
[06/10/2022-19:42:28] [V] [TRT] Tactic: 0x000000000000001d Time: 1.50733
[06/10/2022-19:42:29] [V] [TRT] Tactic: 0x000000000000001e Time: 1.4946
[06/10/2022-19:42:29] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 1.4946
[06/10/2022-19:42:29] [V] [TRT] --------------- Timing Runner: PWN(Sub_2422, Exp_2423) (PointWise)
[06/10/2022-19:42:29] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:42:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[06/10/2022-19:42:29] [V] [TRT] *************** Autotuning format combination: Float(1048576,1048576:32,1024,1), Float(1048576,1048576:32,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:42:29] [V] [TRT] --------------- Timing Runner: PWN(Sub_2422, Exp_2423) (PointWiseV2)
[06/10/2022-19:42:29] [V] [TRT] Tactic: 0x0000000000000018 Time: 2.54347
[06/10/2022-19:42:29] [V] [TRT] Tactic: 0x0000000000000019 Time: 2.64909
[06/10/2022-19:42:29] [V] [TRT] Tactic: 0x000000000000001a Time: 2.6327
[06/10/2022-19:42:29] [V] [TRT] Tactic: 0x000000000000001b Time: 2.64119
[06/10/2022-19:42:30] [V] [TRT] Tactic: 0x000000000000001f Time: 2.54332
[06/10/2022-19:42:30] [V] [TRT] Fastest Tactic: 0x000000000000001f Time: 2.54332
[06/10/2022-19:42:30] [V] [TRT] --------------- Timing Runner: PWN(Sub_2422, Exp_2423) (PointWise)
[06/10/2022-19:42:30] [V] [TRT] PointWise has no valid tactics for this config, skipping
[06/10/2022-19:42:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001f
[06/10/2022-19:42:30] [V] [TRT] *************** Autotuning format combination: Float(1:4,E2,E1,E0), Float(1:4,E2,E1,E0) -> Float(1:4,E2,E1,E0) where E0=(CEIL_DIV (# 0 (SHAPE input)) 4) E1=(* 1024 E0) E2=(* 1048576 E0) ***************
[06/10/2022-19:42:30] [V] [TRT] --------------- Timing Runner: PWN(Sub_2422, Exp_2423) (PointWiseV2)
[06/10/2022-19:42:30] [V] [TRT] Tactic: 0x0000000000000000 Time: 14.3544
[06/10/2022-19:42:30] [V] [TRT] Tactic: 0x0000000000000001 Time: 16.4299
[06/10/2022-19:42:31] [V] [TRT] Tactic: 0x0000000000000002 Time: 22.8244
[06/10/2022-19:42:31] [V] [TRT] Tactic: 0x0000000000000003 Time: 19.3871
[06/10/2022-19:42:31] [V] [TRT] Tactic: 0x0000000000000004 Time: 29.3752
[06/10/2022-19:42:32] [V] [TRT] Tactic: 0x0000000000000005 Time: 16.1981
[06/10/2022-19:42:32] [V] [TRT] Tactic: 0x0000000000000006 Time: 25.1366
[06/10/2022-19:42:33] [V] [TRT] Tactic: 0x0000000000000007 Time: 35.475
[06/10/2022-19:42:33] [V] [TRT] Tactic: 0x0000000000000008 Time: 25.9676
[06/10/2022-19:42:33] [V] [TRT] Tactic: 0x0000000000000009 Time: 22.4078
[06/10/2022-19:42:34] [V] [TRT] Tactic: 0x000000000000000a Time: 10.0552
[06/10/2022-19:42:34] [V] [TRT] Tactic: 0x000000000000000b Time: 12.8578
[06/10/2022-19:42:34] [V] [TRT] Tactic: 0x000000000000000c Time: 12.4735
[06/10/2022-19:42:34] [V] [TRT] Tactic: 0x000000000000000d Time: 15.6189
[06/10/2022-19:42:35] [V] [TRT] Tactic: 0x000000000000000e Time: 18.139
[06/10/2022-19:42:35] [V] [TRT] Tactic: 0x000000000000000f Time: 15.8095
[06/10/2022-19:42:35] [V] [TRT] Tactic: 0x0000000000000010 Time: 21.1715
[06/10/2022-19:42:36] [V] [TRT] Tactic: 0x0000000000000011 Time: 22.0704
[06/10/2022-19:42:36] [V] [TRT] Tactic: 0x0000000000000012 Time: 23.6581
[06/10/2022-19:42:37] [V] [TRT] Tactic: 0x0000000000000013 Time: 25.6059
[06/10/2022-19:42:37] [V] [TRT] Tactic: 0x0000000000000014 Time: 8.17664
[06/10/2022-19:42:37] [V] [TRT] Tactic: 0x0000000000000015 Time: 10.925
[06/10/2022-19:42:37] [V] [TRT] Tactic: 0x0000000000000016 Time: 13.6793
[06/10/2022-19:42:38] [V] [TRT] Tactic: 0x0000000000000017 Time: 19.2236
[06/10/2022-19:42:38] [V] [TRT] Tactic: 0x000000000000001c Time: 1.94604
[06/10/2022-19:42:38] [V] [TRT] Tactic: 0x000000000000001d Time: 1.93112
[06/10/2022-19:42:38] [V] [TRT] Tactic: 0x000000000000001e Time: 1.92205
[06/10/2022-19:42:38] [V] [TRT] Fastest Tactic: 0x000000000000001e Time: 1.92205
[06/10/2022-19:42:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001e
[06/10/2022-19:42:38] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:42:38] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1) -> Float(1048576,1048576,1024,1) ***************
[06/10/2022-19:42:38] [V] [TRT] --------------- Timing Runner: ReduceSum_2424 (Reduce)
[06/10/2022-19:42:38] [V] [TRT] Tactic: 0x0000000000000005 Time: 0.660773
[06/10/2022-19:42:38] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.729819
[06/10/2022-19:42:38] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.729979
[06/10/2022-19:42:38] [V] [TRT] Fastest Tactic: 0x0000000000000005 Time: 0.660773
[06/10/2022-19:42:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000005
[06/10/2022-19:42:38] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:42:38] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1), Float(1048576,1048576,1024,1) -> Float(19922944,1048576,1024,1) ***************
[06/10/2022-19:42:38] [V] [TRT] --------------- Timing Runner: Div_2425 (ElementWise)
[06/10/2022-19:42:38] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.91971
[06/10/2022-19:42:38] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.91971
[06/10/2022-19:42:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:42:38] [V] [TRT] *************** Autotuning format combination: Float(5242880,1:4,5120,5), Float(1048576,1:4,1024,1) -> Float(5242880,1:4,5120,5) ***************
[06/10/2022-19:42:38] [V] [TRT] --------------- Timing Runner: Div_2425 (ElementWise)
[06/10/2022-19:42:38] [V] [TRT] Tactic: 0x0000000000000001 Time: 1.47427
[06/10/2022-19:42:38] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 1.47427
[06/10/2022-19:42:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:42:38] [V] [TRT] *************** Autotuning format combination: Float(1048576,1048576:32,1024,1), Float(1048576,1048576:32,1024,1) -> Float(1048576,1048576:32,1024,1) ***************
[06/10/2022-19:42:38] [V] [TRT] --------------- Timing Runner: Div_2425 (ElementWise)
[06/10/2022-19:42:38] [V] [TRT] Tactic: 0x0000000000000001 Time: 2.41737
[06/10/2022-19:42:38] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 2.41737
[06/10/2022-19:42:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 0x0000000000000001
[06/10/2022-19:42:38] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:42:38] [V] [TRT] *************** Autotuning format combination: Float(19922944,1048576,1024,1) -> Float(1048576,1048576,1024,1), Int32(1048576,1048576,1024,1) ***************
[06/10/2022-19:42:38] [V] [TRT] --------------- Timing Runner: ArgMax_2426 (TopK)
[06/10/2022-19:42:39] [V] [TRT] Tactic: 0x0000000000000000 Time: 25.0821
[06/10/2022-19:42:40] [V] [TRT] Tactic: 0x0000000000000001 Time: 122.289
[06/10/2022-19:42:40] [V] [TRT] Tactic: 0x0000000000000003 Time: 1.95218
[06/10/2022-19:42:47] [V] [TRT] Tactic: 0x0000000000000002 Time: 891.758
[06/10/2022-19:42:47] [V] [TRT] Fastest Tactic: 0x0000000000000003 Time: 1.95218
[06/10/2022-19:42:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: TopK Tactic: 0x0000000000000003
[06/10/2022-19:42:47] [V] [TRT] =============== Computing costs for 
[06/10/2022-19:42:47] [V] [TRT] *************** Autotuning format combination: Int32(1048576,1048576,1024,1) -> Int32((* 1048576 (# 0 (SHAPE input))),1048576,1024,1) ***************
[06/10/2022-19:42:47] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 3345) [Shuffle] + Unsqueeze_2427 (Shuffle)
[06/10/2022-19:42:47] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.073728
[06/10/2022-19:42:47] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.145847
[06/10/2022-19:42:47] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.073728
[06/10/2022-19:42:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_184 (reshape_before_MatMul_184_out_tensor) from Float(256,1,1,1) to Float(256,1,256,256)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_184 (MatMul_184_out_tensor) from Float(64,1,64,64) to Float(64,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_317 (reshape_before_MatMul_317_out_tensor) from Float(256,1,1,1) to Float(256,1,256,256)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_317 (MatMul_317_out_tensor) from Float(64,1,64,64) to Float(64,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_450 (reshape_before_MatMul_450_out_tensor) from Float(256,1,1,1) to Float(256,1,256,256)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_450 (MatMul_450_out_tensor) from Float(64,1,64,64) to Float(64,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_627 (reshape_before_MatMul_627_out_tensor) from Float(512,1,1,1) to Float(512,1,512,512)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_627 (MatMul_627_out_tensor) from Float(128,1,128,128) to Float(128,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_760 (reshape_before_MatMul_760_out_tensor) from Float(512,1,1,1) to Float(512,1,512,512)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_760 (MatMul_760_out_tensor) from Float(128,1,128,128) to Float(128,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_893 (reshape_before_MatMul_893_out_tensor) from Float(512,1,1,1) to Float(512,1,512,512)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_893 (MatMul_893_out_tensor) from Float(128,1,128,128) to Float(128,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_1026 (reshape_before_MatMul_1026_out_tensor) from Float(512,1,1,1) to Float(512,1,512,512)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_1026 (MatMul_1026_out_tensor) from Float(128,1,128,128) to Float(128,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_1112 (1576) from Float(1310720,4096,64,1) to Float(1310720,1,20480,320)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to {ForeignNode[1616...Transpose_1178 + Reshape_1184]} (1577) from Float(327680,1,10240,320) to Float(327680,1024,32,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_1203 (reshape_before_MatMul_1203_out_tensor) from Float(1280,1,1,1) to Float(1280,1,1280,1280)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_1203 (MatMul_1203_out_tensor) from Float(320,1,320,320) to Float(320,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_1245 (1724) from Float(1310720,4096,64,1) to Float(1310720,1,20480,320)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to {ForeignNode[1764...Transpose_1311 + Reshape_1317]} (1725) from Float(327680,1,10240,320) to Float(327680,1024,32,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_1336 (reshape_before_MatMul_1336_out_tensor) from Float(1280,1,1,1) to Float(1280,1,1280,1280)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_1336 (MatMul_1336_out_tensor) from Float(320,1,320,320) to Float(320,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_1378 (1872) from Float(1310720,4096,64,1) to Float(1310720,1,20480,320)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to {ForeignNode[1912...Transpose_1444 + Reshape_1450]} (1873) from Float(327680,1,10240,320) to Float(327680,1024,32,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_1469 (reshape_before_MatMul_1469_out_tensor) from Float(1280,1,1,1) to Float(1280,1,1280,1280)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_1469 (MatMul_1469_out_tensor) from Float(320,1,320,320) to Float(320,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_1511 (2020) from Float(1310720,4096,64,1) to Float(1310720,1,20480,320)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to {ForeignNode[2060...Transpose_1577 + Reshape_1583]} (2021) from Float(327680,1,10240,320) to Float(327680,1024,32,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_1602 (reshape_before_MatMul_1602_out_tensor) from Float(1280,1,1,1) to Float(1280,1,1280,1280)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_1602 (MatMul_1602_out_tensor) from Float(320,1,320,320) to Float(320,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_1644 (2168) from Float(1310720,4096,64,1) to Float(1310720,1,20480,320)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to {ForeignNode[2208...Transpose_1710 + Reshape_1716]} (2169) from Float(327680,1,10240,320) to Float(327680,1024,32,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_1735 (reshape_before_MatMul_1735_out_tensor) from Float(1280,1,1,1) to Float(1280,1,1280,1280)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_1735 (MatMul_1735_out_tensor) from Float(320,1,320,320) to Float(320,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_1777 (2316) from Float(1310720,4096,64,1) to Float(1310720,1,20480,320)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to {ForeignNode[2356...Transpose_1843 + Reshape_1849]} (2317) from Float(327680,1,10240,320) to Float(327680,1024,32,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_1868 (reshape_before_MatMul_1868_out_tensor) from Float(1280,1,1,1) to Float(1280,1,1280,1280)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_1868 (MatMul_1868_out_tensor) from Float(320,1,320,320) to Float(320,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_2335 (reshape_before_MatMul_2335_out_tensor) from Float(128,1,1,1) to Float(128,1,128,128)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_2335 (MatMul_2335_out_tensor) from Float(768,1,768,768) to Float(768,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_2303 (reshape_before_MatMul_2303_out_tensor) from Float(320,1,1,1) to Float(320,1,320,320)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_2303 (MatMul_2303_out_tensor) from Float(768,1,768,768) to Float(768,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_2239 (reshape_before_MatMul_2239_out_tensor) from Float(2048,1,1,1) to Float(2048,1,2048,2048)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_2239 (MatMul_2239_out_tensor) from Float(512,1,512,512) to Float(512,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_2271 (reshape_before_MatMul_2271_out_tensor) from Float(512,1,1,1) to Float(512,1,512,512)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_2271 (MatMul_2271_out_tensor) from Float(768,1,768,768) to Float(768,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to MatMul_2367 (reshape_before_MatMul_2367_out_tensor) from Float(64,1,1,1) to Float(16,1:4,16,16)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to reshape_after_MatMul_2367 (MatMul_2367_out_tensor) from Float(192,1:4,192,192) to Float(768,1,1,1)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Transpose_2369 + Reshape_2380 (2993) from Float(201326592,65536,256,1) to Float(201326592,1,786432,3072)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_2384 (2997) from Float(50331648,1,196608,768) to Float(12582912,1:4,49152,192)
[06/10/2022-19:42:47] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Resize_2393 (2998) from Float(327680,1:4,1280,5) to Float(1245184,65536,256,1)
[06/10/2022-19:42:47] [V] [TRT] Formats and tactics selection completed in 1269.47 seconds.
[06/10/2022-19:42:47] [V] [TRT] After reformat layers: 386 layers
[06/10/2022-19:42:47] [V] [TRT] Pre-optimized block assignment.
[06/10/2022-19:42:47] [V] [TRT] Block size 637534208
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 536870912
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 2097152
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 4194304
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 4194304
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 4194304
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 4194304
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 268435456
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 524288
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 167772160
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 131072
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 16777216
[06/10/2022-19:42:47] [V] [TRT] Block size 16777216
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 16777216
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 16777216
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 16777216
[06/10/2022-19:42:47] [V] [TRT] Block size 32768
[06/10/2022-19:42:47] [V] [TRT] Block size 16777216
[06/10/2022-19:42:47] [V] [TRT] Block size 16777216
[06/10/2022-19:42:47] [V] [TRT] Block size 32768
[06/10/2022-19:42:47] [V] [TRT] Block size 16777216
[06/10/2022-19:42:47] [V] [TRT] Block size 16777216
[06/10/2022-19:42:47] [V] [TRT] Block size 16777216
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 25165824
[06/10/2022-19:42:47] [V] [TRT] Block size 1610612736
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 100663296
[06/10/2022-19:42:47] [V] [TRT] Block size 1610612736
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 402653184
[06/10/2022-19:42:47] [V] [TRT] Block size 1610612736
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 6442450944
[06/10/2022-19:42:47] [V] [TRT] Block size 1610612736
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 637534208
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 637534208
[06/10/2022-19:42:47] [V] [TRT] Block size 637534208
[06/10/2022-19:42:47] [V] [TRT] Block size 33554432
[06/10/2022-19:42:47] [V] [TRT] Block size 637534208
[06/10/2022-19:42:47] [V] [TRT] Block size 33554432
[06/10/2022-19:42:47] [V] [TRT] Block size 637534208
[06/10/2022-19:42:47] [V] [TRT] Block size 33554432
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 134217728
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 67108864
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 402653184
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 100663296
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 16777216
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 25165824
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 1610612736
[06/10/2022-19:42:47] [V] [TRT] Block size 512
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 41943040
[06/10/2022-19:42:47] [V] [TRT] Block size 10485760
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 1610612736
[06/10/2022-19:42:47] [V] [TRT] Block size 4
[06/10/2022-19:42:47] [V] [TRT] Block size 39845888
[06/10/2022-19:42:47] [V] [TRT] Block size 24117248000
[06/10/2022-19:42:47] [V] [TRT] Total Activation Memory: 70095274796
[06/10/2022-19:42:47] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[06/10/2022-19:42:47] [V] [TRT] Conv_27 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179
[06/10/2022-19:42:47] [V] [TRT] Conv_93 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:42:47] [V] [TRT] MatMul_184 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_226 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:42:47] [V] [TRT] MatMul_317 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_359 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982
[06/10/2022-19:42:47] [V] [TRT] MatMul_450 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_470 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e
[06/10/2022-19:42:47] [V] [TRT] Conv_536 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:42:47] [V] [TRT] MatMul_627 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_669 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:42:47] [V] [TRT] MatMul_760 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_802 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:42:47] [V] [TRT] MatMul_893 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_935 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855
[06/10/2022-19:42:47] [V] [TRT] MatMul_1026 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_1112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:42:47] [V] [TRT] MatMul_1203 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_1245 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:42:47] [V] [TRT] MatMul_1336 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_1378 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:42:47] [V] [TRT] MatMul_1469 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_1511 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:42:47] [V] [TRT] MatMul_1602 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_1644 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:42:47] [V] [TRT] MatMul_1735 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_1777 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b
[06/10/2022-19:42:47] [V] [TRT] MatMul_1868 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] MatMul_2335 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] MatMul_2303 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] MatMul_2239 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] MatMul_2271 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] MatMul_2367 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_2382 + Relu_2383 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b
[06/10/2022-19:42:47] [V] [TRT] Conv_2384 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462
[06/10/2022-19:42:48] [V] [TRT] Layer: [HostToDeviceCopy] Host Persistent: 4 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_27 Host Persistent: 2176 Device Persistent: 393728 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block1.0.norm1.bias + (Unnamed Layer* 104) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block1.0.norm1.weight + (Unnamed Layer* 101) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.patch_embed1.norm.bias + (Unnamed Layer* 87) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.patch_embed1.norm.weight + (Unnamed Layer* 84) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_41 + Transpose_42 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_43 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_44 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(398 + (Unnamed Layer* 75) [Shuffle], Pow_46) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_47 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52), Add_53) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_54 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_55 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(409 + (Unnamed Layer* 92) [Shuffle], Pow_57) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_58 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63), Add_64) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_86 + Reshape_92 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 134217728
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_93 Host Persistent: 1952 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[488...Transpose_159 + Reshape_165]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 4706009088
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_166 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block1.1.norm1.bias + (Unnamed Layer* 291) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block1.1.norm1.weight + (Unnamed Layer* 288) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_174 + Transpose_175 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 536870912
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181), PWN(549 + (Unnamed Layer* 267) [Shuffle], Mul_183)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_184 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_184 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_184 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_184 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_184 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_186 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_187 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_188 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(557 + (Unnamed Layer* 279) [Shuffle], Pow_190) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_191 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193), Sqrt_194), Div_195), Mul_196), Add_197) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_219 + Reshape_225 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 134217728
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_226 Host Persistent: 1952 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[636...Transpose_292 + Reshape_298]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 4706009088
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_299 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block1.2.norm1.bias + (Unnamed Layer* 478) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block1.2.norm1.weight + (Unnamed Layer* 475) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_307 + Transpose_308 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 536870912
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310), Erf_311), PWN(694 + (Unnamed Layer* 450) [Shuffle], Add_313)), Mul_314), PWN(697 + (Unnamed Layer* 454) [Shuffle], Mul_316)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_317 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_317 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_317 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_317 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_317 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_319 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_320 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_321 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(705 + (Unnamed Layer* 466) [Shuffle], Pow_323) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_324 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326), Sqrt_327), Div_328), Mul_329), Add_330) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_352 + Reshape_358 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 134217728
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_359 Host Persistent: 1952 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[784...Transpose_425 + Reshape_431]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 4706009088
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_432 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.norm1.bias + (Unnamed Layer* 665) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.norm1.weight + (Unnamed Layer* 662) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_440 + Transpose_441 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 536870912
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443), Erf_444), PWN(842 + (Unnamed Layer* 637) [Shuffle], Add_446)), Mul_447), PWN(845 + (Unnamed Layer* 641) [Shuffle], Mul_449)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_450 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_450 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_450 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_450 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_450 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_452 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_453 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_454 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(853 + (Unnamed Layer* 653) [Shuffle], Pow_456) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_457 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459), Sqrt_460), Div_461), Mul_462), Add_463) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_468 + Transpose_469 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 134217728
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_470 Host Persistent: 2176 Device Persistent: 98816 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block2.0.norm1.bias + (Unnamed Layer* 719) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block2.0.norm1.weight + (Unnamed Layer* 716) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.patch_embed2.norm.bias + (Unnamed Layer* 702) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.patch_embed2.norm.weight + (Unnamed Layer* 699) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_484 + Transpose_485 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_486 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_487 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(888 + (Unnamed Layer* 690) [Shuffle], Pow_489) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_490 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495), Add_496) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_497 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_498 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(899 + (Unnamed Layer* 707) [Shuffle], Pow_500) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_501 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506), Add_507) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_529 + Reshape_535 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_536 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[978...Transpose_602 + Reshape_608]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 2432696320
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_609 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block2.1.norm1.bias + (Unnamed Layer* 908) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block2.1.norm1.weight + (Unnamed Layer* 905) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_617 + Transpose_618 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624), PWN(1039 + (Unnamed Layer* 884) [Shuffle], Mul_626)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_627 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_627 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_627 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_627 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_627 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_629 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_630 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_631 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(1047 + (Unnamed Layer* 896) [Shuffle], Pow_633) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_634 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636), Sqrt_637), Div_638), Mul_639), Add_640) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_662 + Reshape_668 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_669 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[1126...Transpose_735 + Reshape_741]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 2432696320
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_742 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block2.2.norm1.bias + (Unnamed Layer* 1097) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block2.2.norm1.weight + (Unnamed Layer* 1094) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_750 + Transpose_751 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753), Erf_754), PWN(1184 + (Unnamed Layer* 1069) [Shuffle], Add_756)), Mul_757), PWN(1187 + (Unnamed Layer* 1073) [Shuffle], Mul_759)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_760 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_760 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_760 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_760 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_760 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_762 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_763 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_764 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(1195 + (Unnamed Layer* 1085) [Shuffle], Pow_766) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_767 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769), Sqrt_770), Div_771), Mul_772), Add_773) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_795 + Reshape_801 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_802 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[1274...Transpose_868 + Reshape_874]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 2432696320
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_875 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block2.3.norm1.bias + (Unnamed Layer* 1286) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block2.3.norm1.weight + (Unnamed Layer* 1283) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_883 + Transpose_884 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886), Erf_887), PWN(1332 + (Unnamed Layer* 1258) [Shuffle], Add_889)), Mul_890), PWN(1335 + (Unnamed Layer* 1262) [Shuffle], Mul_892)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_893 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_893 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_893 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_893 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_893 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_895 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_896 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_897 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(1343 + (Unnamed Layer* 1274) [Shuffle], Pow_899) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_900 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902), Sqrt_903), Div_904), Mul_905), Add_906) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_928 + Reshape_934 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_935 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[1422...Transpose_1001 + Reshape_1007]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 2432696320
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1008 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.norm2.bias + (Unnamed Layer* 1475) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.norm2.weight + (Unnamed Layer* 1472) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_1016 + Transpose_1017 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019), Erf_1020), PWN(1480 + (Unnamed Layer* 1447) [Shuffle], Add_1022)), Mul_1023), PWN(1483 + (Unnamed Layer* 1451) [Shuffle], Mul_1025)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_1026 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_1026 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_1026 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1026 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_1026 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_1028 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1029 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_1030 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(1491 + (Unnamed Layer* 1463) [Shuffle], Pow_1032) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1033 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035), Sqrt_1036), Div_1037), Mul_1038), Add_1039) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_1044 + Transpose_1045 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1046 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 68583936
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.0.norm1.bias + (Unnamed Layer* 1529) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.0.norm1.weight + (Unnamed Layer* 1526) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.patch_embed3.norm.bias + (Unnamed Layer* 1512) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.patch_embed3.norm.weight + (Unnamed Layer* 1509) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_1060 + Transpose_1061 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1062 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_1063 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(1526 + (Unnamed Layer* 1500) [Shuffle], Pow_1065) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1066 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071), Add_1072) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1073 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_1074 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(1537 + (Unnamed Layer* 1517) [Shuffle], Pow_1076) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1077 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082), Add_1083) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_1105 + Reshape_1111 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_1112 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1112 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to {ForeignNode[1616...Transpose_1178 + Reshape_1184]} Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[1616...Transpose_1178 + Reshape_1184]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 1551892480
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1185 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.1.norm1.bias + (Unnamed Layer* 1718) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.1.norm1.weight + (Unnamed Layer* 1715) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_1193 + Transpose_1194 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200), PWN(1677 + (Unnamed Layer* 1694) [Shuffle], Mul_1202)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_1203 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_1203 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_1203 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1203 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_1203 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_1205 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1206 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_1207 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(1685 + (Unnamed Layer* 1706) [Shuffle], Pow_1209) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1210 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212), Sqrt_1213), Div_1214), Mul_1215), Add_1216) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_1238 + Reshape_1244 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_1245 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1245 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to {ForeignNode[1764...Transpose_1311 + Reshape_1317]} Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[1764...Transpose_1311 + Reshape_1317]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 1551892480
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1318 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.2.norm1.bias + (Unnamed Layer* 1907) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.2.norm1.weight + (Unnamed Layer* 1904) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_1326 + Transpose_1327 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329), Erf_1330), PWN(1822 + (Unnamed Layer* 1879) [Shuffle], Add_1332)), Mul_1333), PWN(1825 + (Unnamed Layer* 1883) [Shuffle], Mul_1335)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_1336 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_1336 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_1336 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1336 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_1336 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_1338 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1339 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_1340 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(1833 + (Unnamed Layer* 1895) [Shuffle], Pow_1342) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1343 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345), Sqrt_1346), Div_1347), Mul_1348), Add_1349) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_1371 + Reshape_1377 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_1378 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1378 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to {ForeignNode[1912...Transpose_1444 + Reshape_1450]} Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[1912...Transpose_1444 + Reshape_1450]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 1551892480
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1451 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.3.norm1.bias + (Unnamed Layer* 2096) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.3.norm1.weight + (Unnamed Layer* 2093) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_1459 + Transpose_1460 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462), Erf_1463), PWN(1970 + (Unnamed Layer* 2068) [Shuffle], Add_1465)), Mul_1466), PWN(1973 + (Unnamed Layer* 2072) [Shuffle], Mul_1468)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_1469 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_1469 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_1469 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1469 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_1469 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_1471 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1472 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_1473 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(1981 + (Unnamed Layer* 2084) [Shuffle], Pow_1475) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1476 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478), Sqrt_1479), Div_1480), Mul_1481), Add_1482) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_1504 + Reshape_1510 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_1511 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1511 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to {ForeignNode[2060...Transpose_1577 + Reshape_1583]} Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[2060...Transpose_1577 + Reshape_1583]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 1551892480
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1584 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.4.norm1.bias + (Unnamed Layer* 2285) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.4.norm1.weight + (Unnamed Layer* 2282) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_1592 + Transpose_1593 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595), Erf_1596), PWN(2118 + (Unnamed Layer* 2257) [Shuffle], Add_1598)), Mul_1599), PWN(2121 + (Unnamed Layer* 2261) [Shuffle], Mul_1601)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_1602 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_1602 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_1602 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1602 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_1602 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_1604 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1605 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_1606 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(2129 + (Unnamed Layer* 2273) [Shuffle], Pow_1608) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1609 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611), Sqrt_1612), Div_1613), Mul_1614), Add_1615) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_1637 + Reshape_1643 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_1644 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1644 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to {ForeignNode[2208...Transpose_1710 + Reshape_1716]} Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[2208...Transpose_1710 + Reshape_1716]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 1551892480
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1717 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.5.norm1.bias + (Unnamed Layer* 2474) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.block3.5.norm1.weight + (Unnamed Layer* 2471) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_1725 + Transpose_1726 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728), Erf_1729), PWN(2266 + (Unnamed Layer* 2446) [Shuffle], Add_1731)), Mul_1732), PWN(2269 + (Unnamed Layer* 2450) [Shuffle], Mul_1734)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_1735 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_1735 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_1735 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1735 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_1735 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_1737 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1738 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_1739 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(2277 + (Unnamed Layer* 2462) [Shuffle], Pow_1741) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1742 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744), Sqrt_1745), Div_1746), Mul_1747), Add_1748) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_1770 + Reshape_1776 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_1777 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1777 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to {ForeignNode[2356...Transpose_1843 + Reshape_1849]} Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[2356...Transpose_1843 + Reshape_1849]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 1551892480
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1850 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.norm3.bias + (Unnamed Layer* 2663) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.norm3.weight + (Unnamed Layer* 2660) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_1858 + Transpose_1859 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861), Erf_1862), PWN(2414 + (Unnamed Layer* 2635) [Shuffle], Add_1864)), Mul_1865), PWN(2417 + (Unnamed Layer* 2639) [Shuffle], Mul_1867)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_1868 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_1868 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_1868 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1868 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_1868 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_1870 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1871 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_1872 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(2425 + (Unnamed Layer* 2651) [Shuffle], Pow_1874) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_1875 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877), Sqrt_1878), Div_1879), Mul_1880), Add_1881) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_1886 + Transpose_1887 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_1888 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 47841792
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[2524...Transpose_1996 + Reshape_2002]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 654344192
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_2003 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[2646...Transpose_2105 + Reshape_2111]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 687865856
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_2112 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: {ForeignNode[2768...Transpose_2214 + Reshape_2220]} Host Persistent: 120 Device Persistent: 0 Scratch Memory: 687865856
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_2333 + Transpose_2334 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_2335 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_2335 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_2335 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_2335 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_2335 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_2337 + Reshape_2348 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Resize_2357 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_2301 + Transpose_2302 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_2303 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_2303 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_2303 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_2303 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_2303 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_2305 + Reshape_2316 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Resize_2325 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_2221 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.norm4.bias + (Unnamed Layer* 3191) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: backbone.norm4.weight + (Unnamed Layer* 3188) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_2229 + Transpose_2230 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236), PWN(2829 + (Unnamed Layer* 3167) [Shuffle], Mul_2238)) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_2239 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_2239 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_2239 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_2239 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_2239 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Add_2241 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_2242 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Sub_2243 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(2837 + (Unnamed Layer* 3179) [Shuffle], Pow_2245) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMean_2246 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251), Add_2252) Host Persistent: 580 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_2257 + Transpose_2258 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_2269 + Transpose_2270 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_2271 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_2271 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_2271 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_2271 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_2271 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_2273 + Reshape_2284 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Resize_2293 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reshape_2365 + Transpose_2366 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_before_MatMul_2367 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to MatMul_2367 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: MatMul_2367 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_2367 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: reshape_after_MatMul_2367 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Transpose_2369 + Reshape_2380 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 1610612736
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Transpose_2369 + Reshape_2380 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: 2893 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: 2930 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: 2967 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_2382 + Relu_2383 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_2384 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Conv_2384 Host Persistent: 2784 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Resize_2393 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Resize_2393 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: 3035 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: (Unnamed Layer* 8) [Constant] + (Unnamed Layer* 9) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ConstantOfShape_13 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: (Unnamed Layer* 3327) [Identity] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(Add_2409, Div_2411) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Resize_2420 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceMax_2421 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: PWN(Sub_2422, Exp_2423) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ReduceSum_2424 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: Div_2425 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [V] [TRT] Layer: ArgMax_2426 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 268435456
[06/10/2022-19:42:48] [V] [TRT] Layer: (Unnamed Layer* 3345) [Shuffle] + Unsqueeze_2427 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[06/10/2022-19:42:48] [I] [TRT] Total Host Persistent Memory: 117264
[06/10/2022-19:42:48] [I] [TRT] Total Device Persistent Memory: 492544
[06/10/2022-19:42:48] [I] [TRT] Total Scratch Memory: 4706009088
[06/10/2022-19:42:48] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 26 MiB, GPU 13868 MiB
[06/10/2022-19:42:48] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 198.752ms to assign 10 blocks to 384 nodes requiring 14571012608 bytes.
[06/10/2022-19:42:48] [V] [TRT] Optimized block assignment.
[06/10/2022-19:42:48] [V] [TRT] Block size 6442450944
[06/10/2022-19:42:48] [V] [TRT] Block size 1610612736
[06/10/2022-19:42:48] [V] [TRT] Block size 1610612736
[06/10/2022-19:42:48] [V] [TRT] Block size 1610612736
[06/10/2022-19:42:48] [V] [TRT] Block size 1610612736
[06/10/2022-19:42:48] [V] [TRT] Block size 1610612736
[06/10/2022-19:42:48] [V] [TRT] Block size 41943040
[06/10/2022-19:42:48] [V] [TRT] Block size 16777216
[06/10/2022-19:42:48] [V] [TRT] Block size 16777216
[06/10/2022-19:42:48] [V] [TRT] Block size 512
[06/10/2022-19:42:48] [I] [TRT] Total Activation Memory: 14571012608
[06/10/2022-19:42:48] [V] [TRT] Disabling unused tactic source: CUBLAS, CUBLAS_LT
[06/10/2022-19:42:48] [V] [TRT] Using cuDNN as a tactic source
[06/10/2022-19:42:48] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 3216, GPU 1769 (MiB)
[06/10/2022-19:42:48] [V] [TRT] Engine generation completed in 1272.27 seconds.
[06/10/2022-19:42:48] [V] [TRT] Deleting timing cache: 974 entries, served 4088 hits since creation.
[06/10/2022-19:42:48] [V] [TRT] Engine Layer Information:
Layer(ShapeHostToDevice): [HostToDeviceCopy], Tactic: 0x0000000000000000,  -> 449[implicit padding 0][Int32()]
Layer(CaskConvolution): Conv_27, Tactic: 0xf64396b97c889179, input[Float(-12,3,1024,1024)] -> 380[Float(-12,64,256,256)]
Layer(Constant): backbone.block1.0.norm1.bias + (Unnamed Layer* 104) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 104) [Shuffle]_output[Float(1,1,64)]
Layer(Constant): backbone.block1.0.norm1.weight + (Unnamed Layer* 101) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 101) [Shuffle]_output[Float(1,1,64)]
Layer(Constant): backbone.patch_embed1.norm.bias + (Unnamed Layer* 87) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 87) [Shuffle]_output[Float(1,1,64)]
Layer(Constant): backbone.patch_embed1.norm.weight + (Unnamed Layer* 84) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 84) [Shuffle]_output[Float(1,1,64)]
Layer(Shuffle): Reshape_41 + Transpose_42, Tactic: 0x0000000000000000, 380[Float(-12,64,256,256)] -> 395[Float(-12,65536,64)]
Layer(Reduce): ReduceMean_43, Tactic: 0x0000000000000004, 395[Float(-12,65536,64)] -> 396[Float(-12,65536,1)]
Layer(ElementWise): Sub_44, Tactic: 0x0000000000000001, 395[Float(-12,65536,64)], 396[Float(-12,65536,1)] -> 397[Float(-12,65536,64)]
Layer(PointWiseV2): PWN(398 + (Unnamed Layer* 75) [Shuffle], Pow_46), Tactic: 0x0000000000000000, 397[Float(-12,65536,64)] -> 399[Float(-12,65536,64)]
Layer(Reduce): ReduceMean_47, Tactic: 0x0000000000000003, 399[Float(-12,65536,64)] -> 400[Float(-12,65536,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(401 + (Unnamed Layer* 79) [Shuffle], Add_49), Sqrt_50), Div_51), Mul_52), Add_53), Tactic: 0x0000000000000009, 400[Float(-12,65536,1)], 397[Float(-12,65536,64)], (Unnamed Layer* 84) [Shuffle]_output[Float(1,1,64)], (Unnamed Layer* 87) [Shuffle]_output[Float(1,1,64)] -> 406[Float(-12,65536,64)]
Layer(Reduce): ReduceMean_54, Tactic: 0x0000000000000004, 406[Float(-12,65536,64)] -> 407[Float(-12,65536,1)]
Layer(ElementWise): Sub_55, Tactic: 0x0000000000000001, 406[Float(-12,65536,64)], 407[Float(-12,65536,1)] -> 408[Float(-12,65536,64)]
Layer(PointWiseV2): PWN(409 + (Unnamed Layer* 92) [Shuffle], Pow_57), Tactic: 0x0000000000000000, 408[Float(-12,65536,64)] -> 410[Float(-12,65536,64)]
Layer(Reduce): ReduceMean_58, Tactic: 0x0000000000000003, 410[Float(-12,65536,64)] -> 411[Float(-12,65536,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(412 + (Unnamed Layer* 96) [Shuffle], Add_60), Sqrt_61), Div_62), Mul_63), Add_64), Tactic: 0x0000000000000009, 411[Float(-12,65536,1)], 408[Float(-12,65536,64)], (Unnamed Layer* 101) [Shuffle]_output[Float(1,1,64)], (Unnamed Layer* 104) [Shuffle]_output[Float(1,1,64)] -> 417[Float(-12,65536,64)]
Layer(Shuffle): Transpose_86 + Reshape_92, Tactic: 0x0000000000000001, 417[Float(-12,65536,64)] -> 448[Float(-12,64,256,256)]
Layer(CaskConvolution): Conv_93, Tactic: 0xd828f024626fa982, 448[Float(-12,64,256,256)] -> 449[Float(-12,64,32,32)]
Layer(Myelin): {ForeignNode[488...Transpose_159 + Reshape_165]}, Tactic: 0x0000000000000000, 449[Float(-12,64,32,32)], 417[Float(-12,65536,64)], 406[Float(-12,65536,64)], 449[implicit padding 0][Int32()] -> 505[Float(-12,65536,64)], 532[Float(-12,256,256,256)]
Layer(CudaDepthwiseConvolution): Conv_166, Tactic: 0xffffffffffffffff, 532[Float(-12,256,256,256)] -> 533[Float(-12,256,256,256)]
Layer(Constant): backbone.block1.1.norm1.bias + (Unnamed Layer* 291) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 291) [Shuffle]_output[Float(1,1,64)]
Layer(Constant): backbone.block1.1.norm1.weight + (Unnamed Layer* 288) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 288) [Shuffle]_output[Float(1,1,64)]
Layer(Shuffle): Reshape_174 + Transpose_175, Tactic: 0x0000000000000001, 533[Float(-12,256,256,256)] -> 542[Float(-12,65536,256)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(543 + (Unnamed Layer* 259) [Shuffle], Div_177), Erf_178), PWN(546 + (Unnamed Layer* 263) [Shuffle], Add_180)), Mul_181), PWN(549 + (Unnamed Layer* 267) [Shuffle], Mul_183)), Tactic: 0x0000000000000000, 542[Float(-12,65536,256)] -> 550[Float(-12,65536,256)]
Layer(NoOp): reshape_before_MatMul_184, Tactic: 0x0000000000000000, 550[Float(-12,65536,256)] -> reshape_before_MatMul_184_out_region[Float(-23,256,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_184, Tactic: 0x0000000000000000, reshape_before_MatMul_184_out_region[Float(-23,256,1,1)] -> Reformatted Input Tensor 0 to MatMul_184[Float(-23,256,1,1)]
Layer(CaskConvolution): MatMul_184, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_184[Float(-23,256,1,1)] -> MatMul_184_out_region[Float(-23,64,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_184, Tactic: 0x0000000000000000, MatMul_184_out_region[Float(-23,64,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_184[Float(-23,64,1,1)]
Layer(NoOp): reshape_after_MatMul_184, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_184[Float(-23,64,1,1)] -> 553[Float(-12,65536,64)]
Layer(ElementWise): Add_186, Tactic: 0x0000000000000001, 505[Float(-12,65536,64)], 553[Float(-12,65536,64)] -> 554[Float(-12,65536,64)]
Layer(Reduce): ReduceMean_187, Tactic: 0x0000000000000003, 554[Float(-12,65536,64)] -> 555[Float(-12,65536,1)]
Layer(ElementWise): Sub_188, Tactic: 0x0000000000000001, 554[Float(-12,65536,64)], 555[Float(-12,65536,1)] -> 556[Float(-12,65536,64)]
Layer(PointWiseV2): PWN(557 + (Unnamed Layer* 279) [Shuffle], Pow_190), Tactic: 0x0000000000000000, 556[Float(-12,65536,64)] -> 558[Float(-12,65536,64)]
Layer(Reduce): ReduceMean_191, Tactic: 0x0000000000000003, 558[Float(-12,65536,64)] -> 559[Float(-12,65536,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(560 + (Unnamed Layer* 283) [Shuffle], Add_193), Sqrt_194), Div_195), Mul_196), Add_197), Tactic: 0x0000000000000009, 559[Float(-12,65536,1)], 556[Float(-12,65536,64)], (Unnamed Layer* 288) [Shuffle]_output[Float(1,1,64)], (Unnamed Layer* 291) [Shuffle]_output[Float(1,1,64)] -> 565[Float(-12,65536,64)]
Layer(Shuffle): Transpose_219 + Reshape_225, Tactic: 0x0000000000000001, 565[Float(-12,65536,64)] -> 596[Float(-12,64,256,256)]
Layer(CaskConvolution): Conv_226, Tactic: 0xd828f024626fa982, 596[Float(-12,64,256,256)] -> 597[Float(-12,64,32,32)]
Layer(Myelin): {ForeignNode[636...Transpose_292 + Reshape_298]}, Tactic: 0x0000000000000000, 597[Float(-12,64,32,32)], 565[Float(-12,65536,64)], 554[Float(-12,65536,64)], 449[implicit padding 0][Int32()] -> 653[Float(-12,65536,64)], 680[Float(-12,256,256,256)]
Layer(CudaDepthwiseConvolution): Conv_299, Tactic: 0xffffffffffffffff, 680[Float(-12,256,256,256)] -> 681[Float(-12,256,256,256)]
Layer(Constant): backbone.block1.2.norm1.bias + (Unnamed Layer* 478) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 478) [Shuffle]_output[Float(1,1,64)]
Layer(Constant): backbone.block1.2.norm1.weight + (Unnamed Layer* 475) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 475) [Shuffle]_output[Float(1,1,64)]
Layer(Shuffle): Reshape_307 + Transpose_308, Tactic: 0x0000000000000001, 681[Float(-12,256,256,256)] -> 690[Float(-12,65536,256)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(691 + (Unnamed Layer* 446) [Shuffle], Div_310), Erf_311), PWN(694 + (Unnamed Layer* 450) [Shuffle], Add_313)), Mul_314), PWN(697 + (Unnamed Layer* 454) [Shuffle], Mul_316)), Tactic: 0x0000000000000000, 690[Float(-12,65536,256)] -> 698[Float(-12,65536,256)]
Layer(NoOp): reshape_before_MatMul_317, Tactic: 0x0000000000000000, 698[Float(-12,65536,256)] -> reshape_before_MatMul_317_out_region[Float(-23,256,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_317, Tactic: 0x0000000000000000, reshape_before_MatMul_317_out_region[Float(-23,256,1,1)] -> Reformatted Input Tensor 0 to MatMul_317[Float(-23,256,1,1)]
Layer(CaskConvolution): MatMul_317, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_317[Float(-23,256,1,1)] -> MatMul_317_out_region[Float(-23,64,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_317, Tactic: 0x0000000000000000, MatMul_317_out_region[Float(-23,64,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_317[Float(-23,64,1,1)]
Layer(NoOp): reshape_after_MatMul_317, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_317[Float(-23,64,1,1)] -> 701[Float(-12,65536,64)]
Layer(ElementWise): Add_319, Tactic: 0x0000000000000001, 653[Float(-12,65536,64)], 701[Float(-12,65536,64)] -> 702[Float(-12,65536,64)]
Layer(Reduce): ReduceMean_320, Tactic: 0x0000000000000003, 702[Float(-12,65536,64)] -> 703[Float(-12,65536,1)]
Layer(ElementWise): Sub_321, Tactic: 0x0000000000000001, 702[Float(-12,65536,64)], 703[Float(-12,65536,1)] -> 704[Float(-12,65536,64)]
Layer(PointWiseV2): PWN(705 + (Unnamed Layer* 466) [Shuffle], Pow_323), Tactic: 0x0000000000000000, 704[Float(-12,65536,64)] -> 706[Float(-12,65536,64)]
Layer(Reduce): ReduceMean_324, Tactic: 0x0000000000000004, 706[Float(-12,65536,64)] -> 707[Float(-12,65536,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(708 + (Unnamed Layer* 470) [Shuffle], Add_326), Sqrt_327), Div_328), Mul_329), Add_330), Tactic: 0x0000000000000009, 707[Float(-12,65536,1)], 704[Float(-12,65536,64)], (Unnamed Layer* 475) [Shuffle]_output[Float(1,1,64)], (Unnamed Layer* 478) [Shuffle]_output[Float(1,1,64)] -> 713[Float(-12,65536,64)]
Layer(Shuffle): Transpose_352 + Reshape_358, Tactic: 0x0000000000000001, 713[Float(-12,65536,64)] -> 744[Float(-12,64,256,256)]
Layer(CaskConvolution): Conv_359, Tactic: 0xd828f024626fa982, 744[Float(-12,64,256,256)] -> 745[Float(-12,64,32,32)]
Layer(Myelin): {ForeignNode[784...Transpose_425 + Reshape_431]}, Tactic: 0x0000000000000000, 745[Float(-12,64,32,32)], 713[Float(-12,65536,64)], 702[Float(-12,65536,64)], 449[implicit padding 0][Int32()] -> 801[Float(-12,65536,64)], 828[Float(-12,256,256,256)]
Layer(CudaDepthwiseConvolution): Conv_432, Tactic: 0xffffffffffffffff, 828[Float(-12,256,256,256)] -> 829[Float(-12,256,256,256)]
Layer(Constant): backbone.norm1.bias + (Unnamed Layer* 665) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 665) [Shuffle]_output[Float(1,1,64)]
Layer(Constant): backbone.norm1.weight + (Unnamed Layer* 662) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 662) [Shuffle]_output[Float(1,1,64)]
Layer(Shuffle): Reshape_440 + Transpose_441, Tactic: 0x0000000000000001, 829[Float(-12,256,256,256)] -> 838[Float(-12,65536,256)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(839 + (Unnamed Layer* 633) [Shuffle], Div_443), Erf_444), PWN(842 + (Unnamed Layer* 637) [Shuffle], Add_446)), Mul_447), PWN(845 + (Unnamed Layer* 641) [Shuffle], Mul_449)), Tactic: 0x0000000000000000, 838[Float(-12,65536,256)] -> 846[Float(-12,65536,256)]
Layer(NoOp): reshape_before_MatMul_450, Tactic: 0x0000000000000000, 846[Float(-12,65536,256)] -> reshape_before_MatMul_450_out_region[Float(-23,256,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_450, Tactic: 0x0000000000000000, reshape_before_MatMul_450_out_region[Float(-23,256,1,1)] -> Reformatted Input Tensor 0 to MatMul_450[Float(-23,256,1,1)]
Layer(CaskConvolution): MatMul_450, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_450[Float(-23,256,1,1)] -> MatMul_450_out_region[Float(-23,64,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_450, Tactic: 0x0000000000000000, MatMul_450_out_region[Float(-23,64,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_450[Float(-23,64,1,1)]
Layer(NoOp): reshape_after_MatMul_450, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_450[Float(-23,64,1,1)] -> 849[Float(-12,65536,64)]
Layer(ElementWise): Add_452, Tactic: 0x0000000000000001, 801[Float(-12,65536,64)], 849[Float(-12,65536,64)] -> 850[Float(-12,65536,64)]
Layer(Reduce): ReduceMean_453, Tactic: 0x0000000000000003, 850[Float(-12,65536,64)] -> 851[Float(-12,65536,1)]
Layer(ElementWise): Sub_454, Tactic: 0x0000000000000001, 850[Float(-12,65536,64)], 851[Float(-12,65536,1)] -> 852[Float(-12,65536,64)]
Layer(PointWiseV2): PWN(853 + (Unnamed Layer* 653) [Shuffle], Pow_456), Tactic: 0x0000000000000000, 852[Float(-12,65536,64)] -> 854[Float(-12,65536,64)]
Layer(Reduce): ReduceMean_457, Tactic: 0x0000000000000004, 854[Float(-12,65536,64)] -> 855[Float(-12,65536,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(856 + (Unnamed Layer* 657) [Shuffle], Add_459), Sqrt_460), Div_461), Mul_462), Add_463), Tactic: 0x0000000000000009, 855[Float(-12,65536,1)], 852[Float(-12,65536,64)], (Unnamed Layer* 662) [Shuffle]_output[Float(1,1,64)], (Unnamed Layer* 665) [Shuffle]_output[Float(1,1,64)] -> 861[Float(-12,65536,64)]
Layer(Shuffle): Reshape_468 + Transpose_469, Tactic: 0x0000000000000001, 861[Float(-12,65536,64)] -> 869[Float(-12,64,256,256)]
Layer(CaskConvolution): Conv_470, Tactic: 0xf067e6205da31c2e, 869[Float(-12,64,256,256)] -> 870[Float(-12,128,128,128)]
Layer(Constant): backbone.block2.0.norm1.bias + (Unnamed Layer* 719) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 719) [Shuffle]_output[Float(1,1,128)]
Layer(Constant): backbone.block2.0.norm1.weight + (Unnamed Layer* 716) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 716) [Shuffle]_output[Float(1,1,128)]
Layer(Constant): backbone.patch_embed2.norm.bias + (Unnamed Layer* 702) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 702) [Shuffle]_output[Float(1,1,128)]
Layer(Constant): backbone.patch_embed2.norm.weight + (Unnamed Layer* 699) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 699) [Shuffle]_output[Float(1,1,128)]
Layer(Shuffle): Reshape_484 + Transpose_485, Tactic: 0x0000000000000000, 870[Float(-12,128,128,128)] -> 885[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_486, Tactic: 0x0000000000000002, 885[Float(-12,16384,128)] -> 886[Float(-12,16384,1)]
Layer(ElementWise): Sub_487, Tactic: 0x0000000000000001, 885[Float(-12,16384,128)], 886[Float(-12,16384,1)] -> 887[Float(-12,16384,128)]
Layer(PointWiseV2): PWN(888 + (Unnamed Layer* 690) [Shuffle], Pow_489), Tactic: 0x000000000000001c, 887[Float(-12,16384,128)] -> 889[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_490, Tactic: 0x0000000000000002, 889[Float(-12,16384,128)] -> 890[Float(-12,16384,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(891 + (Unnamed Layer* 694) [Shuffle], Add_492), Sqrt_493), Div_494), Mul_495), Add_496), Tactic: 0x0000000000000001, 890[Float(-12,16384,1)], 887[Float(-12,16384,128)], (Unnamed Layer* 699) [Shuffle]_output[Float(1,1,128)], (Unnamed Layer* 702) [Shuffle]_output[Float(1,1,128)] -> 896[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_497, Tactic: 0x0000000000000002, 896[Float(-12,16384,128)] -> 897[Float(-12,16384,1)]
Layer(ElementWise): Sub_498, Tactic: 0x0000000000000001, 896[Float(-12,16384,128)], 897[Float(-12,16384,1)] -> 898[Float(-12,16384,128)]
Layer(PointWiseV2): PWN(899 + (Unnamed Layer* 707) [Shuffle], Pow_500), Tactic: 0x000000000000001c, 898[Float(-12,16384,128)] -> 900[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_501, Tactic: 0x0000000000000002, 900[Float(-12,16384,128)] -> 901[Float(-12,16384,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(902 + (Unnamed Layer* 711) [Shuffle], Add_503), Sqrt_504), Div_505), Mul_506), Add_507), Tactic: 0x0000000000000002, 901[Float(-12,16384,1)], 898[Float(-12,16384,128)], (Unnamed Layer* 716) [Shuffle]_output[Float(1,1,128)], (Unnamed Layer* 719) [Shuffle]_output[Float(1,1,128)] -> 907[Float(-12,16384,128)]
Layer(Shuffle): Transpose_529 + Reshape_535, Tactic: 0x0000000000000000, 907[Float(-12,16384,128)] -> 938[Float(-12,128,128,128)]
Layer(CaskConvolution): Conv_536, Tactic: 0x5aa723e0481da855, 938[Float(-12,128,128,128)] -> 939[Float(-12,128,32,32)]
Layer(Myelin): {ForeignNode[978...Transpose_602 + Reshape_608]}, Tactic: 0x0000000000000000, 939[Float(-12,128,32,32)], 907[Float(-12,16384,128)], 896[Float(-12,16384,128)], 449[implicit padding 0][Int32()] -> 995[Float(-12,16384,128)], 1022[Float(-12,512,128,128)]
Layer(CudaDepthwiseConvolution): Conv_609, Tactic: 0xffffffffffffffff, 1022[Float(-12,512,128,128)] -> 1023[Float(-12,512,128,128)]
Layer(Constant): backbone.block2.1.norm1.bias + (Unnamed Layer* 908) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 908) [Shuffle]_output[Float(1,1,128)]
Layer(Constant): backbone.block2.1.norm1.weight + (Unnamed Layer* 905) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 905) [Shuffle]_output[Float(1,1,128)]
Layer(Shuffle): Reshape_617 + Transpose_618, Tactic: 0x0000000000000000, 1023[Float(-12,512,128,128)] -> 1032[Float(-12,16384,512)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1033 + (Unnamed Layer* 876) [Shuffle], Div_620), Erf_621), PWN(1036 + (Unnamed Layer* 880) [Shuffle], Add_623)), Mul_624), PWN(1039 + (Unnamed Layer* 884) [Shuffle], Mul_626)), Tactic: 0x000000000000001c, 1032[Float(-12,16384,512)] -> 1040[Float(-12,16384,512)]
Layer(NoOp): reshape_before_MatMul_627, Tactic: 0x0000000000000000, 1040[Float(-12,16384,512)] -> reshape_before_MatMul_627_out_region[Float(-22,512,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_627, Tactic: 0x0000000000000000, reshape_before_MatMul_627_out_region[Float(-22,512,1,1)] -> Reformatted Input Tensor 0 to MatMul_627[Float(-22,512,1,1)]
Layer(CaskConvolution): MatMul_627, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_627[Float(-22,512,1,1)] -> MatMul_627_out_region[Float(-22,128,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_627, Tactic: 0x0000000000000000, MatMul_627_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_627[Float(-22,128,1,1)]
Layer(NoOp): reshape_after_MatMul_627, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_627[Float(-22,128,1,1)] -> 1043[Float(-12,16384,128)]
Layer(ElementWise): Add_629, Tactic: 0x0000000000000001, 995[Float(-12,16384,128)], 1043[Float(-12,16384,128)] -> 1044[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_630, Tactic: 0x0000000000000002, 1044[Float(-12,16384,128)] -> 1045[Float(-12,16384,1)]
Layer(ElementWise): Sub_631, Tactic: 0x0000000000000001, 1044[Float(-12,16384,128)], 1045[Float(-12,16384,1)] -> 1046[Float(-12,16384,128)]
Layer(PointWiseV2): PWN(1047 + (Unnamed Layer* 896) [Shuffle], Pow_633), Tactic: 0x000000000000001c, 1046[Float(-12,16384,128)] -> 1048[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_634, Tactic: 0x0000000000000002, 1048[Float(-12,16384,128)] -> 1049[Float(-12,16384,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1050 + (Unnamed Layer* 900) [Shuffle], Add_636), Sqrt_637), Div_638), Mul_639), Add_640), Tactic: 0x0000000000000002, 1049[Float(-12,16384,1)], 1046[Float(-12,16384,128)], (Unnamed Layer* 905) [Shuffle]_output[Float(1,1,128)], (Unnamed Layer* 908) [Shuffle]_output[Float(1,1,128)] -> 1055[Float(-12,16384,128)]
Layer(Shuffle): Transpose_662 + Reshape_668, Tactic: 0x0000000000000000, 1055[Float(-12,16384,128)] -> 1086[Float(-12,128,128,128)]
Layer(CaskConvolution): Conv_669, Tactic: 0x5aa723e0481da855, 1086[Float(-12,128,128,128)] -> 1087[Float(-12,128,32,32)]
Layer(Myelin): {ForeignNode[1126...Transpose_735 + Reshape_741]}, Tactic: 0x0000000000000000, 1087[Float(-12,128,32,32)], 1055[Float(-12,16384,128)], 1044[Float(-12,16384,128)], 449[implicit padding 0][Int32()] -> 1143[Float(-12,16384,128)], 1170[Float(-12,512,128,128)]
Layer(CudaDepthwiseConvolution): Conv_742, Tactic: 0xffffffffffffffff, 1170[Float(-12,512,128,128)] -> 1171[Float(-12,512,128,128)]
Layer(Constant): backbone.block2.2.norm1.bias + (Unnamed Layer* 1097) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1097) [Shuffle]_output[Float(1,1,128)]
Layer(Constant): backbone.block2.2.norm1.weight + (Unnamed Layer* 1094) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1094) [Shuffle]_output[Float(1,1,128)]
Layer(Shuffle): Reshape_750 + Transpose_751, Tactic: 0x0000000000000000, 1171[Float(-12,512,128,128)] -> 1180[Float(-12,16384,512)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1181 + (Unnamed Layer* 1065) [Shuffle], Div_753), Erf_754), PWN(1184 + (Unnamed Layer* 1069) [Shuffle], Add_756)), Mul_757), PWN(1187 + (Unnamed Layer* 1073) [Shuffle], Mul_759)), Tactic: 0x000000000000001c, 1180[Float(-12,16384,512)] -> 1188[Float(-12,16384,512)]
Layer(NoOp): reshape_before_MatMul_760, Tactic: 0x0000000000000000, 1188[Float(-12,16384,512)] -> reshape_before_MatMul_760_out_region[Float(-22,512,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_760, Tactic: 0x0000000000000000, reshape_before_MatMul_760_out_region[Float(-22,512,1,1)] -> Reformatted Input Tensor 0 to MatMul_760[Float(-22,512,1,1)]
Layer(CaskConvolution): MatMul_760, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_760[Float(-22,512,1,1)] -> MatMul_760_out_region[Float(-22,128,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_760, Tactic: 0x0000000000000000, MatMul_760_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_760[Float(-22,128,1,1)]
Layer(NoOp): reshape_after_MatMul_760, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_760[Float(-22,128,1,1)] -> 1191[Float(-12,16384,128)]
Layer(ElementWise): Add_762, Tactic: 0x0000000000000001, 1143[Float(-12,16384,128)], 1191[Float(-12,16384,128)] -> 1192[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_763, Tactic: 0x0000000000000002, 1192[Float(-12,16384,128)] -> 1193[Float(-12,16384,1)]
Layer(ElementWise): Sub_764, Tactic: 0x0000000000000001, 1192[Float(-12,16384,128)], 1193[Float(-12,16384,1)] -> 1194[Float(-12,16384,128)]
Layer(PointWiseV2): PWN(1195 + (Unnamed Layer* 1085) [Shuffle], Pow_766), Tactic: 0x000000000000001c, 1194[Float(-12,16384,128)] -> 1196[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_767, Tactic: 0x0000000000000002, 1196[Float(-12,16384,128)] -> 1197[Float(-12,16384,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1198 + (Unnamed Layer* 1089) [Shuffle], Add_769), Sqrt_770), Div_771), Mul_772), Add_773), Tactic: 0x0000000000000002, 1197[Float(-12,16384,1)], 1194[Float(-12,16384,128)], (Unnamed Layer* 1094) [Shuffle]_output[Float(1,1,128)], (Unnamed Layer* 1097) [Shuffle]_output[Float(1,1,128)] -> 1203[Float(-12,16384,128)]
Layer(Shuffle): Transpose_795 + Reshape_801, Tactic: 0x0000000000000000, 1203[Float(-12,16384,128)] -> 1234[Float(-12,128,128,128)]
Layer(CaskConvolution): Conv_802, Tactic: 0x5aa723e0481da855, 1234[Float(-12,128,128,128)] -> 1235[Float(-12,128,32,32)]
Layer(Myelin): {ForeignNode[1274...Transpose_868 + Reshape_874]}, Tactic: 0x0000000000000000, 1235[Float(-12,128,32,32)], 1203[Float(-12,16384,128)], 1192[Float(-12,16384,128)], 449[implicit padding 0][Int32()] -> 1291[Float(-12,16384,128)], 1318[Float(-12,512,128,128)]
Layer(CudaDepthwiseConvolution): Conv_875, Tactic: 0xffffffffffffffff, 1318[Float(-12,512,128,128)] -> 1319[Float(-12,512,128,128)]
Layer(Constant): backbone.block2.3.norm1.bias + (Unnamed Layer* 1286) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1286) [Shuffle]_output[Float(1,1,128)]
Layer(Constant): backbone.block2.3.norm1.weight + (Unnamed Layer* 1283) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1283) [Shuffle]_output[Float(1,1,128)]
Layer(Shuffle): Reshape_883 + Transpose_884, Tactic: 0x0000000000000000, 1319[Float(-12,512,128,128)] -> 1328[Float(-12,16384,512)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1329 + (Unnamed Layer* 1254) [Shuffle], Div_886), Erf_887), PWN(1332 + (Unnamed Layer* 1258) [Shuffle], Add_889)), Mul_890), PWN(1335 + (Unnamed Layer* 1262) [Shuffle], Mul_892)), Tactic: 0x000000000000001c, 1328[Float(-12,16384,512)] -> 1336[Float(-12,16384,512)]
Layer(NoOp): reshape_before_MatMul_893, Tactic: 0x0000000000000000, 1336[Float(-12,16384,512)] -> reshape_before_MatMul_893_out_region[Float(-22,512,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_893, Tactic: 0x0000000000000000, reshape_before_MatMul_893_out_region[Float(-22,512,1,1)] -> Reformatted Input Tensor 0 to MatMul_893[Float(-22,512,1,1)]
Layer(CaskConvolution): MatMul_893, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_893[Float(-22,512,1,1)] -> MatMul_893_out_region[Float(-22,128,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_893, Tactic: 0x0000000000000000, MatMul_893_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_893[Float(-22,128,1,1)]
Layer(NoOp): reshape_after_MatMul_893, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_893[Float(-22,128,1,1)] -> 1339[Float(-12,16384,128)]
Layer(ElementWise): Add_895, Tactic: 0x0000000000000001, 1291[Float(-12,16384,128)], 1339[Float(-12,16384,128)] -> 1340[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_896, Tactic: 0x0000000000000002, 1340[Float(-12,16384,128)] -> 1341[Float(-12,16384,1)]
Layer(ElementWise): Sub_897, Tactic: 0x0000000000000001, 1340[Float(-12,16384,128)], 1341[Float(-12,16384,1)] -> 1342[Float(-12,16384,128)]
Layer(PointWiseV2): PWN(1343 + (Unnamed Layer* 1274) [Shuffle], Pow_899), Tactic: 0x000000000000001c, 1342[Float(-12,16384,128)] -> 1344[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_900, Tactic: 0x0000000000000002, 1344[Float(-12,16384,128)] -> 1345[Float(-12,16384,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1346 + (Unnamed Layer* 1278) [Shuffle], Add_902), Sqrt_903), Div_904), Mul_905), Add_906), Tactic: 0x0000000000000002, 1345[Float(-12,16384,1)], 1342[Float(-12,16384,128)], (Unnamed Layer* 1283) [Shuffle]_output[Float(1,1,128)], (Unnamed Layer* 1286) [Shuffle]_output[Float(1,1,128)] -> 1351[Float(-12,16384,128)]
Layer(Shuffle): Transpose_928 + Reshape_934, Tactic: 0x0000000000000000, 1351[Float(-12,16384,128)] -> 1382[Float(-12,128,128,128)]
Layer(CaskConvolution): Conv_935, Tactic: 0x5aa723e0481da855, 1382[Float(-12,128,128,128)] -> 1383[Float(-12,128,32,32)]
Layer(Myelin): {ForeignNode[1422...Transpose_1001 + Reshape_1007]}, Tactic: 0x0000000000000000, 1383[Float(-12,128,32,32)], 1351[Float(-12,16384,128)], 1340[Float(-12,16384,128)], 449[implicit padding 0][Int32()] -> 1439[Float(-12,16384,128)], 1466[Float(-12,512,128,128)]
Layer(CudaDepthwiseConvolution): Conv_1008, Tactic: 0xffffffffffffffff, 1466[Float(-12,512,128,128)] -> 1467[Float(-12,512,128,128)]
Layer(Constant): backbone.norm2.bias + (Unnamed Layer* 1475) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1475) [Shuffle]_output[Float(1,1,128)]
Layer(Constant): backbone.norm2.weight + (Unnamed Layer* 1472) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1472) [Shuffle]_output[Float(1,1,128)]
Layer(Shuffle): Reshape_1016 + Transpose_1017, Tactic: 0x0000000000000000, 1467[Float(-12,512,128,128)] -> 1476[Float(-12,16384,512)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1477 + (Unnamed Layer* 1443) [Shuffle], Div_1019), Erf_1020), PWN(1480 + (Unnamed Layer* 1447) [Shuffle], Add_1022)), Mul_1023), PWN(1483 + (Unnamed Layer* 1451) [Shuffle], Mul_1025)), Tactic: 0x000000000000001c, 1476[Float(-12,16384,512)] -> 1484[Float(-12,16384,512)]
Layer(NoOp): reshape_before_MatMul_1026, Tactic: 0x0000000000000000, 1484[Float(-12,16384,512)] -> reshape_before_MatMul_1026_out_region[Float(-22,512,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_1026, Tactic: 0x0000000000000000, reshape_before_MatMul_1026_out_region[Float(-22,512,1,1)] -> Reformatted Input Tensor 0 to MatMul_1026[Float(-22,512,1,1)]
Layer(CaskConvolution): MatMul_1026, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_1026[Float(-22,512,1,1)] -> MatMul_1026_out_region[Float(-22,128,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1026, Tactic: 0x0000000000000000, MatMul_1026_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_1026[Float(-22,128,1,1)]
Layer(NoOp): reshape_after_MatMul_1026, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_1026[Float(-22,128,1,1)] -> 1487[Float(-12,16384,128)]
Layer(ElementWise): Add_1028, Tactic: 0x0000000000000001, 1439[Float(-12,16384,128)], 1487[Float(-12,16384,128)] -> 1488[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_1029, Tactic: 0x0000000000000002, 1488[Float(-12,16384,128)] -> 1489[Float(-12,16384,1)]
Layer(ElementWise): Sub_1030, Tactic: 0x0000000000000001, 1488[Float(-12,16384,128)], 1489[Float(-12,16384,1)] -> 1490[Float(-12,16384,128)]
Layer(PointWiseV2): PWN(1491 + (Unnamed Layer* 1463) [Shuffle], Pow_1032), Tactic: 0x000000000000001c, 1490[Float(-12,16384,128)] -> 1492[Float(-12,16384,128)]
Layer(Reduce): ReduceMean_1033, Tactic: 0x0000000000000002, 1492[Float(-12,16384,128)] -> 1493[Float(-12,16384,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1494 + (Unnamed Layer* 1467) [Shuffle], Add_1035), Sqrt_1036), Div_1037), Mul_1038), Add_1039), Tactic: 0x0000000000000002, 1493[Float(-12,16384,1)], 1490[Float(-12,16384,128)], (Unnamed Layer* 1472) [Shuffle]_output[Float(1,1,128)], (Unnamed Layer* 1475) [Shuffle]_output[Float(1,1,128)] -> 1499[Float(-12,16384,128)]
Layer(Shuffle): Reshape_1044 + Transpose_1045, Tactic: 0x0000000000000000, 1499[Float(-12,16384,128)] -> 1507[Float(-12,128,128,128)]
Layer(CudnnConvolution): Conv_1046, Tactic: 0x0000000000000001, 1507[Float(-12,128,128,128)] -> 1508[Float(-12,320,64,64)]
Layer(Constant): backbone.block3.0.norm1.bias + (Unnamed Layer* 1529) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1529) [Shuffle]_output[Float(1,1,320)]
Layer(Constant): backbone.block3.0.norm1.weight + (Unnamed Layer* 1526) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1526) [Shuffle]_output[Float(1,1,320)]
Layer(Constant): backbone.patch_embed3.norm.bias + (Unnamed Layer* 1512) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1512) [Shuffle]_output[Float(1,1,320)]
Layer(Constant): backbone.patch_embed3.norm.weight + (Unnamed Layer* 1509) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1509) [Shuffle]_output[Float(1,1,320)]
Layer(Shuffle): Reshape_1060 + Transpose_1061, Tactic: 0x0000000000000000, 1508[Float(-12,320,64,64)] -> 1523[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1062, Tactic: 0x0000000000000002, 1523[Float(-12,4096,320)] -> 1524[Float(-12,4096,1)]
Layer(ElementWise): Sub_1063, Tactic: 0x0000000000000001, 1523[Float(-12,4096,320)], 1524[Float(-12,4096,1)] -> 1525[Float(-12,4096,320)]
Layer(PointWiseV2): PWN(1526 + (Unnamed Layer* 1500) [Shuffle], Pow_1065), Tactic: 0x000000000000001c, 1525[Float(-12,4096,320)] -> 1527[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1066, Tactic: 0x0000000000000002, 1527[Float(-12,4096,320)] -> 1528[Float(-12,4096,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1529 + (Unnamed Layer* 1504) [Shuffle], Add_1068), Sqrt_1069), Div_1070), Mul_1071), Add_1072), Tactic: 0x0000000000000002, 1528[Float(-12,4096,1)], 1525[Float(-12,4096,320)], (Unnamed Layer* 1509) [Shuffle]_output[Float(1,1,320)], (Unnamed Layer* 1512) [Shuffle]_output[Float(1,1,320)] -> 1534[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1073, Tactic: 0x0000000000000002, 1534[Float(-12,4096,320)] -> 1535[Float(-12,4096,1)]
Layer(ElementWise): Sub_1074, Tactic: 0x0000000000000001, 1534[Float(-12,4096,320)], 1535[Float(-12,4096,1)] -> 1536[Float(-12,4096,320)]
Layer(PointWiseV2): PWN(1537 + (Unnamed Layer* 1517) [Shuffle], Pow_1076), Tactic: 0x000000000000001c, 1536[Float(-12,4096,320)] -> 1538[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1077, Tactic: 0x0000000000000002, 1538[Float(-12,4096,320)] -> 1539[Float(-12,4096,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1540 + (Unnamed Layer* 1521) [Shuffle], Add_1079), Sqrt_1080), Div_1081), Mul_1082), Add_1083), Tactic: 0x0000000000000002, 1539[Float(-12,4096,1)], 1536[Float(-12,4096,320)], (Unnamed Layer* 1526) [Shuffle]_output[Float(1,1,320)], (Unnamed Layer* 1529) [Shuffle]_output[Float(1,1,320)] -> 1545[Float(-12,4096,320)]
Layer(Shuffle): Transpose_1105 + Reshape_1111, Tactic: 0x0000000000000000, 1545[Float(-12,4096,320)] -> 1576[Float(-12,320,64,64)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_1112, Tactic: 0x00000000000003ea, 1576[Float(-12,320,64,64)] -> Reformatted Input Tensor 0 to Conv_1112[Float(-12,320,64,64)]
Layer(CaskConvolution): Conv_1112, Tactic: 0xb443c221fcb1565b, Reformatted Input Tensor 0 to Conv_1112[Float(-12,320,64,64)] -> 1577[Float(-12,320,32,32)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to {ForeignNode[1616...Transpose_1178 + Reshape_1184]}, Tactic: 0x00000000000003ea, 1577[Float(-12,320,32,32)] -> Reformatted Input Tensor 0 to {ForeignNode[1616...Transpose_1178 + Reshape_1184]}[Float(-12,320,32,32)]
Layer(Myelin): {ForeignNode[1616...Transpose_1178 + Reshape_1184]}, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to {ForeignNode[1616...Transpose_1178 + Reshape_1184]}[Float(-12,320,32,32)], 1545[Float(-12,4096,320)], 1534[Float(-12,4096,320)], 449[implicit padding 0][Int32()] -> 1633[Float(-12,4096,320)], 1660[Float(-12,1280,64,64)]
Layer(CudaDepthwiseConvolution): Conv_1185, Tactic: 0xffffffffffffffff, 1660[Float(-12,1280,64,64)] -> 1661[Float(-12,1280,64,64)]
Layer(Constant): backbone.block3.1.norm1.bias + (Unnamed Layer* 1718) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1718) [Shuffle]_output[Float(1,1,320)]
Layer(Constant): backbone.block3.1.norm1.weight + (Unnamed Layer* 1715) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1715) [Shuffle]_output[Float(1,1,320)]
Layer(Shuffle): Reshape_1193 + Transpose_1194, Tactic: 0x0000000000000000, 1661[Float(-12,1280,64,64)] -> 1670[Float(-12,4096,1280)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1671 + (Unnamed Layer* 1686) [Shuffle], Div_1196), Erf_1197), PWN(1674 + (Unnamed Layer* 1690) [Shuffle], Add_1199)), Mul_1200), PWN(1677 + (Unnamed Layer* 1694) [Shuffle], Mul_1202)), Tactic: 0x000000000000001c, 1670[Float(-12,4096,1280)] -> 1678[Float(-12,4096,1280)]
Layer(NoOp): reshape_before_MatMul_1203, Tactic: 0x0000000000000000, 1678[Float(-12,4096,1280)] -> reshape_before_MatMul_1203_out_region[Float(-21,1280,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_1203, Tactic: 0x0000000000000000, reshape_before_MatMul_1203_out_region[Float(-21,1280,1,1)] -> Reformatted Input Tensor 0 to MatMul_1203[Float(-21,1280,1,1)]
Layer(CaskConvolution): MatMul_1203, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_1203[Float(-21,1280,1,1)] -> MatMul_1203_out_region[Float(-21,320,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1203, Tactic: 0x0000000000000000, MatMul_1203_out_region[Float(-21,320,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_1203[Float(-21,320,1,1)]
Layer(NoOp): reshape_after_MatMul_1203, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_1203[Float(-21,320,1,1)] -> 1681[Float(-12,4096,320)]
Layer(ElementWise): Add_1205, Tactic: 0x0000000000000001, 1633[Float(-12,4096,320)], 1681[Float(-12,4096,320)] -> 1682[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1206, Tactic: 0x0000000000000002, 1682[Float(-12,4096,320)] -> 1683[Float(-12,4096,1)]
Layer(ElementWise): Sub_1207, Tactic: 0x0000000000000001, 1682[Float(-12,4096,320)], 1683[Float(-12,4096,1)] -> 1684[Float(-12,4096,320)]
Layer(PointWiseV2): PWN(1685 + (Unnamed Layer* 1706) [Shuffle], Pow_1209), Tactic: 0x000000000000001c, 1684[Float(-12,4096,320)] -> 1686[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1210, Tactic: 0x0000000000000002, 1686[Float(-12,4096,320)] -> 1687[Float(-12,4096,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1688 + (Unnamed Layer* 1710) [Shuffle], Add_1212), Sqrt_1213), Div_1214), Mul_1215), Add_1216), Tactic: 0x0000000000000002, 1687[Float(-12,4096,1)], 1684[Float(-12,4096,320)], (Unnamed Layer* 1715) [Shuffle]_output[Float(1,1,320)], (Unnamed Layer* 1718) [Shuffle]_output[Float(1,1,320)] -> 1693[Float(-12,4096,320)]
Layer(Shuffle): Transpose_1238 + Reshape_1244, Tactic: 0x0000000000000000, 1693[Float(-12,4096,320)] -> 1724[Float(-12,320,64,64)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_1245, Tactic: 0x00000000000003ea, 1724[Float(-12,320,64,64)] -> Reformatted Input Tensor 0 to Conv_1245[Float(-12,320,64,64)]
Layer(CaskConvolution): Conv_1245, Tactic: 0xb443c221fcb1565b, Reformatted Input Tensor 0 to Conv_1245[Float(-12,320,64,64)] -> 1725[Float(-12,320,32,32)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to {ForeignNode[1764...Transpose_1311 + Reshape_1317]}, Tactic: 0x00000000000003ea, 1725[Float(-12,320,32,32)] -> Reformatted Input Tensor 0 to {ForeignNode[1764...Transpose_1311 + Reshape_1317]}[Float(-12,320,32,32)]
Layer(Myelin): {ForeignNode[1764...Transpose_1311 + Reshape_1317]}, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to {ForeignNode[1764...Transpose_1311 + Reshape_1317]}[Float(-12,320,32,32)], 1693[Float(-12,4096,320)], 1682[Float(-12,4096,320)], 449[implicit padding 0][Int32()] -> 1781[Float(-12,4096,320)], 1808[Float(-12,1280,64,64)]
Layer(CudaDepthwiseConvolution): Conv_1318, Tactic: 0xffffffffffffffff, 1808[Float(-12,1280,64,64)] -> 1809[Float(-12,1280,64,64)]
Layer(Constant): backbone.block3.2.norm1.bias + (Unnamed Layer* 1907) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1907) [Shuffle]_output[Float(1,1,320)]
Layer(Constant): backbone.block3.2.norm1.weight + (Unnamed Layer* 1904) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 1904) [Shuffle]_output[Float(1,1,320)]
Layer(Shuffle): Reshape_1326 + Transpose_1327, Tactic: 0x0000000000000000, 1809[Float(-12,1280,64,64)] -> 1818[Float(-12,4096,1280)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1819 + (Unnamed Layer* 1875) [Shuffle], Div_1329), Erf_1330), PWN(1822 + (Unnamed Layer* 1879) [Shuffle], Add_1332)), Mul_1333), PWN(1825 + (Unnamed Layer* 1883) [Shuffle], Mul_1335)), Tactic: 0x000000000000001c, 1818[Float(-12,4096,1280)] -> 1826[Float(-12,4096,1280)]
Layer(NoOp): reshape_before_MatMul_1336, Tactic: 0x0000000000000000, 1826[Float(-12,4096,1280)] -> reshape_before_MatMul_1336_out_region[Float(-21,1280,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_1336, Tactic: 0x0000000000000000, reshape_before_MatMul_1336_out_region[Float(-21,1280,1,1)] -> Reformatted Input Tensor 0 to MatMul_1336[Float(-21,1280,1,1)]
Layer(CaskConvolution): MatMul_1336, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_1336[Float(-21,1280,1,1)] -> MatMul_1336_out_region[Float(-21,320,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1336, Tactic: 0x0000000000000000, MatMul_1336_out_region[Float(-21,320,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_1336[Float(-21,320,1,1)]
Layer(NoOp): reshape_after_MatMul_1336, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_1336[Float(-21,320,1,1)] -> 1829[Float(-12,4096,320)]
Layer(ElementWise): Add_1338, Tactic: 0x0000000000000001, 1781[Float(-12,4096,320)], 1829[Float(-12,4096,320)] -> 1830[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1339, Tactic: 0x0000000000000002, 1830[Float(-12,4096,320)] -> 1831[Float(-12,4096,1)]
Layer(ElementWise): Sub_1340, Tactic: 0x0000000000000001, 1830[Float(-12,4096,320)], 1831[Float(-12,4096,1)] -> 1832[Float(-12,4096,320)]
Layer(PointWiseV2): PWN(1833 + (Unnamed Layer* 1895) [Shuffle], Pow_1342), Tactic: 0x000000000000001c, 1832[Float(-12,4096,320)] -> 1834[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1343, Tactic: 0x0000000000000002, 1834[Float(-12,4096,320)] -> 1835[Float(-12,4096,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1836 + (Unnamed Layer* 1899) [Shuffle], Add_1345), Sqrt_1346), Div_1347), Mul_1348), Add_1349), Tactic: 0x0000000000000002, 1835[Float(-12,4096,1)], 1832[Float(-12,4096,320)], (Unnamed Layer* 1904) [Shuffle]_output[Float(1,1,320)], (Unnamed Layer* 1907) [Shuffle]_output[Float(1,1,320)] -> 1841[Float(-12,4096,320)]
Layer(Shuffle): Transpose_1371 + Reshape_1377, Tactic: 0x0000000000000000, 1841[Float(-12,4096,320)] -> 1872[Float(-12,320,64,64)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_1378, Tactic: 0x00000000000003ea, 1872[Float(-12,320,64,64)] -> Reformatted Input Tensor 0 to Conv_1378[Float(-12,320,64,64)]
Layer(CaskConvolution): Conv_1378, Tactic: 0xb443c221fcb1565b, Reformatted Input Tensor 0 to Conv_1378[Float(-12,320,64,64)] -> 1873[Float(-12,320,32,32)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to {ForeignNode[1912...Transpose_1444 + Reshape_1450]}, Tactic: 0x00000000000003ea, 1873[Float(-12,320,32,32)] -> Reformatted Input Tensor 0 to {ForeignNode[1912...Transpose_1444 + Reshape_1450]}[Float(-12,320,32,32)]
Layer(Myelin): {ForeignNode[1912...Transpose_1444 + Reshape_1450]}, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to {ForeignNode[1912...Transpose_1444 + Reshape_1450]}[Float(-12,320,32,32)], 1841[Float(-12,4096,320)], 1830[Float(-12,4096,320)], 449[implicit padding 0][Int32()] -> 1929[Float(-12,4096,320)], 1956[Float(-12,1280,64,64)]
Layer(CudaDepthwiseConvolution): Conv_1451, Tactic: 0xffffffffffffffff, 1956[Float(-12,1280,64,64)] -> 1957[Float(-12,1280,64,64)]
Layer(Constant): backbone.block3.3.norm1.bias + (Unnamed Layer* 2096) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 2096) [Shuffle]_output[Float(1,1,320)]
Layer(Constant): backbone.block3.3.norm1.weight + (Unnamed Layer* 2093) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 2093) [Shuffle]_output[Float(1,1,320)]
Layer(Shuffle): Reshape_1459 + Transpose_1460, Tactic: 0x0000000000000000, 1957[Float(-12,1280,64,64)] -> 1966[Float(-12,4096,1280)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1967 + (Unnamed Layer* 2064) [Shuffle], Div_1462), Erf_1463), PWN(1970 + (Unnamed Layer* 2068) [Shuffle], Add_1465)), Mul_1466), PWN(1973 + (Unnamed Layer* 2072) [Shuffle], Mul_1468)), Tactic: 0x000000000000001c, 1966[Float(-12,4096,1280)] -> 1974[Float(-12,4096,1280)]
Layer(NoOp): reshape_before_MatMul_1469, Tactic: 0x0000000000000000, 1974[Float(-12,4096,1280)] -> reshape_before_MatMul_1469_out_region[Float(-21,1280,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_1469, Tactic: 0x0000000000000000, reshape_before_MatMul_1469_out_region[Float(-21,1280,1,1)] -> Reformatted Input Tensor 0 to MatMul_1469[Float(-21,1280,1,1)]
Layer(CaskConvolution): MatMul_1469, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_1469[Float(-21,1280,1,1)] -> MatMul_1469_out_region[Float(-21,320,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1469, Tactic: 0x0000000000000000, MatMul_1469_out_region[Float(-21,320,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_1469[Float(-21,320,1,1)]
Layer(NoOp): reshape_after_MatMul_1469, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_1469[Float(-21,320,1,1)] -> 1977[Float(-12,4096,320)]
Layer(ElementWise): Add_1471, Tactic: 0x0000000000000001, 1929[Float(-12,4096,320)], 1977[Float(-12,4096,320)] -> 1978[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1472, Tactic: 0x0000000000000002, 1978[Float(-12,4096,320)] -> 1979[Float(-12,4096,1)]
Layer(ElementWise): Sub_1473, Tactic: 0x0000000000000001, 1978[Float(-12,4096,320)], 1979[Float(-12,4096,1)] -> 1980[Float(-12,4096,320)]
Layer(PointWiseV2): PWN(1981 + (Unnamed Layer* 2084) [Shuffle], Pow_1475), Tactic: 0x000000000000001c, 1980[Float(-12,4096,320)] -> 1982[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1476, Tactic: 0x0000000000000002, 1982[Float(-12,4096,320)] -> 1983[Float(-12,4096,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(1984 + (Unnamed Layer* 2088) [Shuffle], Add_1478), Sqrt_1479), Div_1480), Mul_1481), Add_1482), Tactic: 0x0000000000000002, 1983[Float(-12,4096,1)], 1980[Float(-12,4096,320)], (Unnamed Layer* 2093) [Shuffle]_output[Float(1,1,320)], (Unnamed Layer* 2096) [Shuffle]_output[Float(1,1,320)] -> 1989[Float(-12,4096,320)]
Layer(Shuffle): Transpose_1504 + Reshape_1510, Tactic: 0x0000000000000000, 1989[Float(-12,4096,320)] -> 2020[Float(-12,320,64,64)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_1511, Tactic: 0x00000000000003ea, 2020[Float(-12,320,64,64)] -> Reformatted Input Tensor 0 to Conv_1511[Float(-12,320,64,64)]
Layer(CaskConvolution): Conv_1511, Tactic: 0xb443c221fcb1565b, Reformatted Input Tensor 0 to Conv_1511[Float(-12,320,64,64)] -> 2021[Float(-12,320,32,32)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to {ForeignNode[2060...Transpose_1577 + Reshape_1583]}, Tactic: 0x00000000000003ea, 2021[Float(-12,320,32,32)] -> Reformatted Input Tensor 0 to {ForeignNode[2060...Transpose_1577 + Reshape_1583]}[Float(-12,320,32,32)]
Layer(Myelin): {ForeignNode[2060...Transpose_1577 + Reshape_1583]}, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to {ForeignNode[2060...Transpose_1577 + Reshape_1583]}[Float(-12,320,32,32)], 1989[Float(-12,4096,320)], 1978[Float(-12,4096,320)], 449[implicit padding 0][Int32()] -> 2077[Float(-12,4096,320)], 2104[Float(-12,1280,64,64)]
Layer(CudaDepthwiseConvolution): Conv_1584, Tactic: 0xffffffffffffffff, 2104[Float(-12,1280,64,64)] -> 2105[Float(-12,1280,64,64)]
Layer(Constant): backbone.block3.4.norm1.bias + (Unnamed Layer* 2285) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 2285) [Shuffle]_output[Float(1,1,320)]
Layer(Constant): backbone.block3.4.norm1.weight + (Unnamed Layer* 2282) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 2282) [Shuffle]_output[Float(1,1,320)]
Layer(Shuffle): Reshape_1592 + Transpose_1593, Tactic: 0x0000000000000000, 2105[Float(-12,1280,64,64)] -> 2114[Float(-12,4096,1280)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(2115 + (Unnamed Layer* 2253) [Shuffle], Div_1595), Erf_1596), PWN(2118 + (Unnamed Layer* 2257) [Shuffle], Add_1598)), Mul_1599), PWN(2121 + (Unnamed Layer* 2261) [Shuffle], Mul_1601)), Tactic: 0x000000000000001c, 2114[Float(-12,4096,1280)] -> 2122[Float(-12,4096,1280)]
Layer(NoOp): reshape_before_MatMul_1602, Tactic: 0x0000000000000000, 2122[Float(-12,4096,1280)] -> reshape_before_MatMul_1602_out_region[Float(-21,1280,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_1602, Tactic: 0x0000000000000000, reshape_before_MatMul_1602_out_region[Float(-21,1280,1,1)] -> Reformatted Input Tensor 0 to MatMul_1602[Float(-21,1280,1,1)]
Layer(CaskConvolution): MatMul_1602, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_1602[Float(-21,1280,1,1)] -> MatMul_1602_out_region[Float(-21,320,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1602, Tactic: 0x0000000000000000, MatMul_1602_out_region[Float(-21,320,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_1602[Float(-21,320,1,1)]
Layer(NoOp): reshape_after_MatMul_1602, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_1602[Float(-21,320,1,1)] -> 2125[Float(-12,4096,320)]
Layer(ElementWise): Add_1604, Tactic: 0x0000000000000001, 2077[Float(-12,4096,320)], 2125[Float(-12,4096,320)] -> 2126[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1605, Tactic: 0x0000000000000002, 2126[Float(-12,4096,320)] -> 2127[Float(-12,4096,1)]
Layer(ElementWise): Sub_1606, Tactic: 0x0000000000000001, 2126[Float(-12,4096,320)], 2127[Float(-12,4096,1)] -> 2128[Float(-12,4096,320)]
Layer(PointWiseV2): PWN(2129 + (Unnamed Layer* 2273) [Shuffle], Pow_1608), Tactic: 0x000000000000001c, 2128[Float(-12,4096,320)] -> 2130[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1609, Tactic: 0x0000000000000002, 2130[Float(-12,4096,320)] -> 2131[Float(-12,4096,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(2132 + (Unnamed Layer* 2277) [Shuffle], Add_1611), Sqrt_1612), Div_1613), Mul_1614), Add_1615), Tactic: 0x0000000000000002, 2131[Float(-12,4096,1)], 2128[Float(-12,4096,320)], (Unnamed Layer* 2282) [Shuffle]_output[Float(1,1,320)], (Unnamed Layer* 2285) [Shuffle]_output[Float(1,1,320)] -> 2137[Float(-12,4096,320)]
Layer(Shuffle): Transpose_1637 + Reshape_1643, Tactic: 0x0000000000000000, 2137[Float(-12,4096,320)] -> 2168[Float(-12,320,64,64)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_1644, Tactic: 0x00000000000003ea, 2168[Float(-12,320,64,64)] -> Reformatted Input Tensor 0 to Conv_1644[Float(-12,320,64,64)]
Layer(CaskConvolution): Conv_1644, Tactic: 0xb443c221fcb1565b, Reformatted Input Tensor 0 to Conv_1644[Float(-12,320,64,64)] -> 2169[Float(-12,320,32,32)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to {ForeignNode[2208...Transpose_1710 + Reshape_1716]}, Tactic: 0x00000000000003ea, 2169[Float(-12,320,32,32)] -> Reformatted Input Tensor 0 to {ForeignNode[2208...Transpose_1710 + Reshape_1716]}[Float(-12,320,32,32)]
Layer(Myelin): {ForeignNode[2208...Transpose_1710 + Reshape_1716]}, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to {ForeignNode[2208...Transpose_1710 + Reshape_1716]}[Float(-12,320,32,32)], 2137[Float(-12,4096,320)], 2126[Float(-12,4096,320)], 449[implicit padding 0][Int32()] -> 2225[Float(-12,4096,320)], 2252[Float(-12,1280,64,64)]
Layer(CudaDepthwiseConvolution): Conv_1717, Tactic: 0xffffffffffffffff, 2252[Float(-12,1280,64,64)] -> 2253[Float(-12,1280,64,64)]
Layer(Constant): backbone.block3.5.norm1.bias + (Unnamed Layer* 2474) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 2474) [Shuffle]_output[Float(1,1,320)]
Layer(Constant): backbone.block3.5.norm1.weight + (Unnamed Layer* 2471) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 2471) [Shuffle]_output[Float(1,1,320)]
Layer(Shuffle): Reshape_1725 + Transpose_1726, Tactic: 0x0000000000000000, 2253[Float(-12,1280,64,64)] -> 2262[Float(-12,4096,1280)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(2263 + (Unnamed Layer* 2442) [Shuffle], Div_1728), Erf_1729), PWN(2266 + (Unnamed Layer* 2446) [Shuffle], Add_1731)), Mul_1732), PWN(2269 + (Unnamed Layer* 2450) [Shuffle], Mul_1734)), Tactic: 0x000000000000001c, 2262[Float(-12,4096,1280)] -> 2270[Float(-12,4096,1280)]
Layer(NoOp): reshape_before_MatMul_1735, Tactic: 0x0000000000000000, 2270[Float(-12,4096,1280)] -> reshape_before_MatMul_1735_out_region[Float(-21,1280,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_1735, Tactic: 0x0000000000000000, reshape_before_MatMul_1735_out_region[Float(-21,1280,1,1)] -> Reformatted Input Tensor 0 to MatMul_1735[Float(-21,1280,1,1)]
Layer(CaskConvolution): MatMul_1735, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_1735[Float(-21,1280,1,1)] -> MatMul_1735_out_region[Float(-21,320,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1735, Tactic: 0x0000000000000000, MatMul_1735_out_region[Float(-21,320,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_1735[Float(-21,320,1,1)]
Layer(NoOp): reshape_after_MatMul_1735, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_1735[Float(-21,320,1,1)] -> 2273[Float(-12,4096,320)]
Layer(ElementWise): Add_1737, Tactic: 0x0000000000000001, 2225[Float(-12,4096,320)], 2273[Float(-12,4096,320)] -> 2274[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1738, Tactic: 0x0000000000000002, 2274[Float(-12,4096,320)] -> 2275[Float(-12,4096,1)]
Layer(ElementWise): Sub_1739, Tactic: 0x0000000000000001, 2274[Float(-12,4096,320)], 2275[Float(-12,4096,1)] -> 2276[Float(-12,4096,320)]
Layer(PointWiseV2): PWN(2277 + (Unnamed Layer* 2462) [Shuffle], Pow_1741), Tactic: 0x000000000000001c, 2276[Float(-12,4096,320)] -> 2278[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1742, Tactic: 0x0000000000000002, 2278[Float(-12,4096,320)] -> 2279[Float(-12,4096,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(2280 + (Unnamed Layer* 2466) [Shuffle], Add_1744), Sqrt_1745), Div_1746), Mul_1747), Add_1748), Tactic: 0x0000000000000002, 2279[Float(-12,4096,1)], 2276[Float(-12,4096,320)], (Unnamed Layer* 2471) [Shuffle]_output[Float(1,1,320)], (Unnamed Layer* 2474) [Shuffle]_output[Float(1,1,320)] -> 2285[Float(-12,4096,320)]
Layer(Shuffle): Transpose_1770 + Reshape_1776, Tactic: 0x0000000000000000, 2285[Float(-12,4096,320)] -> 2316[Float(-12,320,64,64)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_1777, Tactic: 0x00000000000003ea, 2316[Float(-12,320,64,64)] -> Reformatted Input Tensor 0 to Conv_1777[Float(-12,320,64,64)]
Layer(CaskConvolution): Conv_1777, Tactic: 0xb443c221fcb1565b, Reformatted Input Tensor 0 to Conv_1777[Float(-12,320,64,64)] -> 2317[Float(-12,320,32,32)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to {ForeignNode[2356...Transpose_1843 + Reshape_1849]}, Tactic: 0x00000000000003ea, 2317[Float(-12,320,32,32)] -> Reformatted Input Tensor 0 to {ForeignNode[2356...Transpose_1843 + Reshape_1849]}[Float(-12,320,32,32)]
Layer(Myelin): {ForeignNode[2356...Transpose_1843 + Reshape_1849]}, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to {ForeignNode[2356...Transpose_1843 + Reshape_1849]}[Float(-12,320,32,32)], 2285[Float(-12,4096,320)], 2274[Float(-12,4096,320)], 449[implicit padding 0][Int32()] -> 2373[Float(-12,4096,320)], 2400[Float(-12,1280,64,64)]
Layer(CudaDepthwiseConvolution): Conv_1850, Tactic: 0xffffffffffffffff, 2400[Float(-12,1280,64,64)] -> 2401[Float(-12,1280,64,64)]
Layer(Constant): backbone.norm3.bias + (Unnamed Layer* 2663) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 2663) [Shuffle]_output[Float(1,1,320)]
Layer(Constant): backbone.norm3.weight + (Unnamed Layer* 2660) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 2660) [Shuffle]_output[Float(1,1,320)]
Layer(Shuffle): Reshape_1858 + Transpose_1859, Tactic: 0x0000000000000000, 2401[Float(-12,1280,64,64)] -> 2410[Float(-12,4096,1280)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(2411 + (Unnamed Layer* 2631) [Shuffle], Div_1861), Erf_1862), PWN(2414 + (Unnamed Layer* 2635) [Shuffle], Add_1864)), Mul_1865), PWN(2417 + (Unnamed Layer* 2639) [Shuffle], Mul_1867)), Tactic: 0x000000000000001c, 2410[Float(-12,4096,1280)] -> 2418[Float(-12,4096,1280)]
Layer(NoOp): reshape_before_MatMul_1868, Tactic: 0x0000000000000000, 2418[Float(-12,4096,1280)] -> reshape_before_MatMul_1868_out_region[Float(-21,1280,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_1868, Tactic: 0x0000000000000000, reshape_before_MatMul_1868_out_region[Float(-21,1280,1,1)] -> Reformatted Input Tensor 0 to MatMul_1868[Float(-21,1280,1,1)]
Layer(CaskConvolution): MatMul_1868, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_1868[Float(-21,1280,1,1)] -> MatMul_1868_out_region[Float(-21,320,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_1868, Tactic: 0x0000000000000000, MatMul_1868_out_region[Float(-21,320,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_1868[Float(-21,320,1,1)]
Layer(NoOp): reshape_after_MatMul_1868, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_1868[Float(-21,320,1,1)] -> 2421[Float(-12,4096,320)]
Layer(ElementWise): Add_1870, Tactic: 0x0000000000000001, 2373[Float(-12,4096,320)], 2421[Float(-12,4096,320)] -> 2422[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1871, Tactic: 0x0000000000000002, 2422[Float(-12,4096,320)] -> 2423[Float(-12,4096,1)]
Layer(ElementWise): Sub_1872, Tactic: 0x0000000000000001, 2422[Float(-12,4096,320)], 2423[Float(-12,4096,1)] -> 2424[Float(-12,4096,320)]
Layer(PointWiseV2): PWN(2425 + (Unnamed Layer* 2651) [Shuffle], Pow_1874), Tactic: 0x000000000000001c, 2424[Float(-12,4096,320)] -> 2426[Float(-12,4096,320)]
Layer(Reduce): ReduceMean_1875, Tactic: 0x0000000000000002, 2426[Float(-12,4096,320)] -> 2427[Float(-12,4096,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(2428 + (Unnamed Layer* 2655) [Shuffle], Add_1877), Sqrt_1878), Div_1879), Mul_1880), Add_1881), Tactic: 0x0000000000000002, 2427[Float(-12,4096,1)], 2424[Float(-12,4096,320)], (Unnamed Layer* 2660) [Shuffle]_output[Float(1,1,320)], (Unnamed Layer* 2663) [Shuffle]_output[Float(1,1,320)] -> 2433[Float(-12,4096,320)]
Layer(Shuffle): Reshape_1886 + Transpose_1887, Tactic: 0x0000000000000000, 2433[Float(-12,4096,320)] -> 2441[Float(-12,320,64,64)]
Layer(CudnnConvolution): Conv_1888, Tactic: 0x0000000000000001, 2441[Float(-12,320,64,64)] -> 2442[Float(-12,512,32,32)]
Layer(Myelin): {ForeignNode[2524...Transpose_1996 + Reshape_2002]}, Tactic: 0x0000000000000000, 2442[Float(-12,512,32,32)], 449[implicit padding 0][Int32()] -> 2541[Float(-12,1024,512)], 2568[Float(-12,2048,32,32)]
Layer(CudaDepthwiseConvolution): Conv_2003, Tactic: 0xffffffffffffffff, 2568[Float(-12,2048,32,32)] -> 2569[Float(-12,2048,32,32)]
Layer(Myelin): {ForeignNode[2646...Transpose_2105 + Reshape_2111]}, Tactic: 0x0000000000000000, 2569[Float(-12,2048,32,32)], 2541[Float(-12,1024,512)], 449[implicit padding 0][Int32()] -> 2663[Float(-12,1024,512)], 2690[Float(-12,2048,32,32)]
Layer(CudaDepthwiseConvolution): Conv_2112, Tactic: 0xffffffffffffffff, 2690[Float(-12,2048,32,32)] -> 2691[Float(-12,2048,32,32)]
Layer(Myelin): {ForeignNode[2768...Transpose_2214 + Reshape_2220]}, Tactic: 0x0000000000000000, 2691[Float(-12,2048,32,32)], 2663[Float(-12,1024,512)], 449[implicit padding 0][Int32()] -> 2785[Float(-12,1024,512)], 2812[Float(-12,2048,32,32)]
Layer(Shuffle): Reshape_2333 + Transpose_2334, Tactic: 0x0000000000000000, 1507[Float(-12,128,128,128)] -> 2939[Float(-12,16384,128)]
Layer(NoOp): reshape_before_MatMul_2335, Tactic: 0x0000000000000000, 2939[Float(-12,16384,128)] -> reshape_before_MatMul_2335_out_region[Float(-22,128,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_2335, Tactic: 0x0000000000000000, reshape_before_MatMul_2335_out_region[Float(-22,128,1,1)] -> Reformatted Input Tensor 0 to MatMul_2335[Float(-22,128,1,1)]
Layer(CaskConvolution): MatMul_2335, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_2335[Float(-22,128,1,1)] -> MatMul_2335_out_region[Float(-22,768,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_2335, Tactic: 0x0000000000000000, MatMul_2335_out_region[Float(-22,768,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_2335[Float(-22,768,1,1)]
Layer(NoOp): reshape_after_MatMul_2335, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_2335[Float(-22,768,1,1)] -> 2942[Float(-12,16384,768)]
Layer(Shuffle): Transpose_2337 + Reshape_2348, Tactic: 0x0000000000000000, 2942[Float(-12,16384,768)] -> 2956[Float(-12,768,128,128)]
Layer(Resize): Resize_2357, Tactic: 0x0000000000000001, 2956[Float(-12,768,128,128)] -> 2967[Float(-12,768,256,256)]
Layer(Shuffle): Reshape_2301 + Transpose_2302, Tactic: 0x0000000000000000, 2441[Float(-12,320,64,64)] -> 2902[Float(-12,4096,320)]
Layer(NoOp): reshape_before_MatMul_2303, Tactic: 0x0000000000000000, 2902[Float(-12,4096,320)] -> reshape_before_MatMul_2303_out_region[Float(-21,320,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_2303, Tactic: 0x0000000000000000, reshape_before_MatMul_2303_out_region[Float(-21,320,1,1)] -> Reformatted Input Tensor 0 to MatMul_2303[Float(-21,320,1,1)]
Layer(CaskConvolution): MatMul_2303, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_2303[Float(-21,320,1,1)] -> MatMul_2303_out_region[Float(-21,768,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_2303, Tactic: 0x0000000000000000, MatMul_2303_out_region[Float(-21,768,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_2303[Float(-21,768,1,1)]
Layer(NoOp): reshape_after_MatMul_2303, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_2303[Float(-21,768,1,1)] -> 2905[Float(-12,4096,768)]
Layer(Shuffle): Transpose_2305 + Reshape_2316, Tactic: 0x0000000000000000, 2905[Float(-12,4096,768)] -> 2919[Float(-12,768,64,64)]
Layer(Resize): Resize_2325, Tactic: 0x0000000000000001, 2919[Float(-12,768,64,64)] -> 2930[Float(-12,768,256,256)]
Layer(CudaDepthwiseConvolution): Conv_2221, Tactic: 0xffffffffffffffff, 2812[Float(-12,2048,32,32)] -> 2813[Float(-12,2048,32,32)]
Layer(Constant): backbone.norm4.bias + (Unnamed Layer* 3191) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 3191) [Shuffle]_output[Float(1,1,512)]
Layer(Constant): backbone.norm4.weight + (Unnamed Layer* 3188) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 3188) [Shuffle]_output[Float(1,1,512)]
Layer(Shuffle): Reshape_2229 + Transpose_2230, Tactic: 0x0000000000000000, 2813[Float(-12,2048,32,32)] -> 2822[Float(-12,1024,2048)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(2823 + (Unnamed Layer* 3159) [Shuffle], Div_2232), Erf_2233), PWN(2826 + (Unnamed Layer* 3163) [Shuffle], Add_2235)), Mul_2236), PWN(2829 + (Unnamed Layer* 3167) [Shuffle], Mul_2238)), Tactic: 0x0000000000000000, 2822[Float(-12,1024,2048)] -> 2830[Float(-12,1024,2048)]
Layer(NoOp): reshape_before_MatMul_2239, Tactic: 0x0000000000000000, 2830[Float(-12,1024,2048)] -> reshape_before_MatMul_2239_out_region[Float(-20,2048,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_2239, Tactic: 0x0000000000000000, reshape_before_MatMul_2239_out_region[Float(-20,2048,1,1)] -> Reformatted Input Tensor 0 to MatMul_2239[Float(-20,2048,1,1)]
Layer(CaskConvolution): MatMul_2239, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_2239[Float(-20,2048,1,1)] -> MatMul_2239_out_region[Float(-20,512,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_2239, Tactic: 0x0000000000000000, MatMul_2239_out_region[Float(-20,512,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_2239[Float(-20,512,1,1)]
Layer(NoOp): reshape_after_MatMul_2239, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_2239[Float(-20,512,1,1)] -> 2833[Float(-12,1024,512)]
Layer(ElementWise): Add_2241, Tactic: 0x0000000000000001, 2785[Float(-12,1024,512)], 2833[Float(-12,1024,512)] -> 2834[Float(-12,1024,512)]
Layer(Reduce): ReduceMean_2242, Tactic: 0x0000000000000002, 2834[Float(-12,1024,512)] -> 2835[Float(-12,1024,1)]
Layer(ElementWise): Sub_2243, Tactic: 0x0000000000000001, 2834[Float(-12,1024,512)], 2835[Float(-12,1024,1)] -> 2836[Float(-12,1024,512)]
Layer(PointWiseV2): PWN(2837 + (Unnamed Layer* 3179) [Shuffle], Pow_2245), Tactic: 0x000000000000001c, 2836[Float(-12,1024,512)] -> 2838[Float(-12,1024,512)]
Layer(Reduce): ReduceMean_2246, Tactic: 0x0000000000000002, 2838[Float(-12,1024,512)] -> 2839[Float(-12,1024,1)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(PWN(2840 + (Unnamed Layer* 3183) [Shuffle], Add_2248), Sqrt_2249), Div_2250), Mul_2251), Add_2252), Tactic: 0x0000000000000002, 2839[Float(-12,1024,1)], 2836[Float(-12,1024,512)], (Unnamed Layer* 3188) [Shuffle]_output[Float(1,1,512)], (Unnamed Layer* 3191) [Shuffle]_output[Float(1,1,512)] -> 2845[Float(-12,1024,512)]
Layer(Shuffle): Reshape_2257 + Transpose_2258, Tactic: 0x0000000000000000, 2845[Float(-12,1024,512)] -> 2853[Float(-12,512,32,32)]
Layer(Shuffle): Reshape_2269 + Transpose_2270, Tactic: 0x0000000000000000, 2853[Float(-12,512,32,32)] -> 2865[Float(-12,1024,512)]
Layer(NoOp): reshape_before_MatMul_2271, Tactic: 0x0000000000000000, 2865[Float(-12,1024,512)] -> reshape_before_MatMul_2271_out_region[Float(-20,512,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_2271, Tactic: 0x0000000000000000, reshape_before_MatMul_2271_out_region[Float(-20,512,1,1)] -> Reformatted Input Tensor 0 to MatMul_2271[Float(-20,512,1,1)]
Layer(CaskConvolution): MatMul_2271, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_2271[Float(-20,512,1,1)] -> MatMul_2271_out_region[Float(-20,768,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_2271, Tactic: 0x0000000000000000, MatMul_2271_out_region[Float(-20,768,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_2271[Float(-20,768,1,1)]
Layer(NoOp): reshape_after_MatMul_2271, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_2271[Float(-20,768,1,1)] -> 2868[Float(-12,1024,768)]
Layer(Shuffle): Transpose_2273 + Reshape_2284, Tactic: 0x0000000000000000, 2868[Float(-12,1024,768)] -> 2882[Float(-12,768,32,32)]
Layer(Resize): Resize_2293, Tactic: 0x0000000000000001, 2882[Float(-12,768,32,32)] -> 2893[Float(-12,768,256,256)]
Layer(Shuffle): Reshape_2365 + Transpose_2366, Tactic: 0x0000000000000000, 869[Float(-12,64,256,256)] -> 2976[Float(-12,65536,64)]
Layer(NoOp): reshape_before_MatMul_2367, Tactic: 0x0000000000000000, 2976[Float(-12,65536,64)] -> reshape_before_MatMul_2367_out_region[Float(-23,64,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to MatMul_2367, Tactic: 0x0000000000000000, reshape_before_MatMul_2367_out_region[Float(-23,64,1,1)] -> Reformatted Input Tensor 0 to MatMul_2367[Float(-23,64,1,1)]
Layer(CaskConvolution): MatMul_2367, Tactic: 0x130df49cb195156b, Reformatted Input Tensor 0 to MatMul_2367[Float(-23,64,1,1)] -> MatMul_2367_out_region[Float(-23,768,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to reshape_after_MatMul_2367, Tactic: 0x0000000000000000, MatMul_2367_out_region[Float(-23,768,1,1)] -> Reformatted Input Tensor 0 to reshape_after_MatMul_2367[Float(-23,768,1,1)]
Layer(NoOp): reshape_after_MatMul_2367, Tactic: 0x0000000000000000, Reformatted Input Tensor 0 to reshape_after_MatMul_2367[Float(-23,768,1,1)] -> 2979[Float(-12,65536,768)]
Layer(Shuffle): Transpose_2369 + Reshape_2380, Tactic: 0x0000000000000001, 2979[Float(-12,65536,768)] -> Reformatted Output Tensor 0 to Transpose_2369 + Reshape_2380[Float(-12,768,256,256)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Transpose_2369 + Reshape_2380, Tactic: 0x00000000000003ea, Reformatted Output Tensor 0 to Transpose_2369 + Reshape_2380[Float(-12,768,256,256)] -> 2994[Float(-12,768,256,256)]
Layer(Reformat): 2893 copy, Tactic: 0x00000000000003ea, 2893[Float(-12,768,256,256)] -> 2994[Float(-12,768,256,256)]
Layer(Reformat): 2930 copy, Tactic: 0x00000000000003ea, 2930[Float(-12,768,256,256)] -> 2994[Float(-12,768,256,256)]
Layer(Reformat): 2967 copy, Tactic: 0x00000000000003ea, 2967[Float(-12,768,256,256)] -> 2994[Float(-12,768,256,256)]
Layer(CaskConvolution): Conv_2382 + Relu_2383, Tactic: 0x130df49cb195156b, 2994[Float(-12,3072,256,256)] -> 2997[Float(-12,768,256,256)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to Conv_2384, Tactic: 0x0000000000000000, 2997[Float(-12,768,256,256)] -> Reformatted Input Tensor 0 to Conv_2384[Float(-12,768,256,256)]
Layer(CaskConvolution): Conv_2384, Tactic: 0x9dece0dc37e90462, Reformatted Input Tensor 0 to Conv_2384[Float(-12,768,256,256)] -> 2998[Float(-12,19,256,256)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Resize_2393, Tactic: 0x00000000000003ea, 2998[Float(-12,19,256,256)] -> Reformatted Input Tensor 0 to Resize_2393[Float(-12,19,256,256)]
Layer(Resize): Resize_2393, Tactic: 0x0000000000000001, Reformatted Input Tensor 0 to Resize_2393[Float(-12,19,256,256)] -> 3009[Float(-12,19,1024,1024)]
Layer(Constant): 3035, Tactic: 0x0000000000000000,  -> (Unnamed Layer* 3329) [Constant]_output[Float(1,1,1024,1024)]
Layer(Constant): (Unnamed Layer* 8) [Constant] + (Unnamed Layer* 9) [Shuffle], Tactic: 0x0000000000000000,  -> (Unnamed Layer* 9) [Shuffle]_output[Float(1,1,1,1)]
Layer(Slice): ConstantOfShape_13, Tactic: 0x0000000000000000, (Unnamed Layer* 9) [Shuffle]_output[Float(1,1,1,1)] -> 366[Float(-12,19,1024,1024)]
Layer(NoOp): (Unnamed Layer* 3327) [Identity], Tactic: 0x0000000000000000, 3009[Float(-12,19,1024,1024)] -> 3033[Float(-12,19,1024,1024)]
Layer(PointWiseV2): PWN(Add_2409, Div_2411), Tactic: 0x000000000000001c, 366[Float(-12,19,1024,1024)], 3033[Float(-12,19,1024,1024)], (Unnamed Layer* 3329) [Constant]_output[Float(1,1,1024,1024)] -> 3036[Float(-12,19,1024,1024)]
Layer(Resize): Resize_2420, Tactic: 0x0000000000000001, 3036[Float(-12,19,1024,1024)] -> 3047[Float(-12,19,1024,1024)]
Layer(Reduce): ReduceMax_2421, Tactic: 0x0000000000000005, 3047[Float(-12,19,1024,1024)] -> 3048[Float(-12,1,1024,1024)]
Layer(PointWiseV2): PWN(Sub_2422, Exp_2423), Tactic: 0x0000000000000000, 3047[Float(-12,19,1024,1024)], 3048[Float(-12,1,1024,1024)] -> 3050[Float(-12,19,1024,1024)]
Layer(Reduce): ReduceSum_2424, Tactic: 0x0000000000000005, 3050[Float(-12,19,1024,1024)] -> 3051[Float(-12,1,1024,1024)]
Layer(ElementWise): Div_2425, Tactic: 0x0000000000000001, 3050[Float(-12,19,1024,1024)], 3051[Float(-12,1,1024,1024)] -> 3052[Float(-12,19,1024,1024)]
Layer(TopK): ArgMax_2426, Tactic: 0x0000000000000003, 3052[Float(-12,19,1024,1024)] -> (Unnamed Layer* 3341) [TopK]_output_1[Float(-12,1,1024,1024)], (Unnamed Layer* 3341) [TopK]_output_2[Int32(-12,1,1024,1024)]
Layer(NoOp): (Unnamed Layer* 3345) [Shuffle] + Unsqueeze_2427, Tactic: 0x0000000000000000, (Unnamed Layer* 3341) [TopK]_output_2[Int32(-12,1,1024,1024)] -> output[Int32(1,-12,1024,1024)]
[06/10/2022-19:42:48] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +17, GPU +109, now: CPU 17, GPU 109 (MiB)
[06/10/2022-19:42:49] [I] Engine built in 1280.76 sec.
[06/10/2022-19:42:49] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2799, GPU 1537 (MiB)
[06/10/2022-19:42:49] [I] [TRT] Loaded engine size: 115 MiB
[06/10/2022-19:42:49] [V] [TRT] Using cuDNN as a tactic source
[06/10/2022-19:42:49] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2868, GPU 1657 (MiB)
[06/10/2022-19:42:49] [V] [TRT] Deserialization required 52494 microseconds.
[06/10/2022-19:42:49] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +108, now: CPU 0, GPU 108 (MiB)
[06/10/2022-19:42:49] [I] Engine deserialized in 0.0544849 sec.
[06/10/2022-19:42:49] [V] [TRT] Using cuDNN as a tactic source
[06/10/2022-19:42:49] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2868, GPU 1657 (MiB)
[06/10/2022-19:42:49] [V] [TRT] Total per-runner device persistent memory is 492544
[06/10/2022-19:42:49] [V] [TRT] Total per-runner host persistent memory is 117264
[06/10/2022-19:42:49] [V] [TRT] Allocated activation device memory of size 14571012608
[06/10/2022-19:42:50] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +13897, now: CPU 0, GPU 14005 (MiB)
[06/10/2022-19:42:50] [I] Using random values for input input
[06/10/2022-19:42:50] [I] Created input binding for input with dimensions 4x3x1024x1024
[06/10/2022-19:42:50] [I] Using random values for output output
[06/10/2022-19:42:50] [I] Created output binding for output with dimensions 1x4x1024x1024
[06/10/2022-19:42:50] [I] Starting inference
[06/10/2022-19:42:54] [I] Warmup completed 1 queries over 200 ms
[06/10/2022-19:42:54] [I] Timing trace has 13 queries over 3.97657 s
[06/10/2022-19:42:54] [I] 
[06/10/2022-19:42:54] [I] === Trace details ===
[06/10/2022-19:42:54] [I] Trace averages of 10 runs:
[06/10/2022-19:42:54] [I] Average on 10 runs - GPU latency: 284.529 ms - Host latency: 288.023 ms (enqueue 2.044 ms)
[06/10/2022-19:42:54] [I] 
[06/10/2022-19:42:54] [I] === Performance summary ===
[06/10/2022-19:42:54] [I] Throughput: 3.26915 qps
[06/10/2022-19:42:54] [I] Latency: min = 282.875 ms, max = 298.733 ms, mean = 288.091 ms, median = 287.384 ms, percentile(99%) = 298.733 ms
[06/10/2022-19:42:54] [I] Enqueue Time: min = 1.81543 ms, max = 3.3584 ms, mean = 1.99486 ms, median = 1.87061 ms, percentile(99%) = 3.3584 ms
[06/10/2022-19:42:54] [I] H2D Latency: min = 2.5631 ms, max = 2.73694 ms, mean = 2.68283 ms, median = 2.69482 ms, percentile(99%) = 2.73694 ms
[06/10/2022-19:42:54] [I] GPU Compute Time: min = 279.412 ms, max = 295.216 ms, mean = 284.605 ms, median = 284.029 ms, percentile(99%) = 295.216 ms
[06/10/2022-19:42:54] [I] D2H Latency: min = 0.688232 ms, max = 0.828979 ms, mean = 0.802993 ms, median = 0.812988 ms, percentile(99%) = 0.828979 ms
[06/10/2022-19:42:54] [I] Total Host Walltime: 3.97657 s
[06/10/2022-19:42:54] [I] Total GPU Compute Time: 3.69987 s
[06/10/2022-19:42:54] [I] Explanations of the performance metrics are printed in the verbose logs.
[06/10/2022-19:42:54] [V] 
[06/10/2022-19:42:54] [V] === Explanations of the performance metrics ===
[06/10/2022-19:42:54] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[06/10/2022-19:42:54] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[06/10/2022-19:42:54] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[06/10/2022-19:42:54] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[06/10/2022-19:42:54] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[06/10/2022-19:42:54] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[06/10/2022-19:42:54] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[06/10/2022-19:42:54] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[06/10/2022-19:42:54] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8401] # /usr/local/TensorRT-8.4.1.4/bin/trtexec --onnx=/root/onnx/segformer.b2.1024x1024.city.160k_v1.onnx --minShapes=input:1x3x1024x1024 --optShapes=input:4x3x1024x1024 --maxShapes=input:8x3x1024x1024 --workspace=23000 --saveEngine=segFormer.plan --verbose
